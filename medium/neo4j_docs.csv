url;text
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.base64UrlDecode;"apoc.text.base64UrlDecode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.base64UrlDecode(url String) - decodes the given Base64 encoded URL.
Signature
None
Copy to Clipboard
apoc.text.base64UrlDecode(url :: STRING?) :: (STRING?)
Input parameters
Name Type Default
url
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64UrlDecode(""aHR0cDovL25lbzRqLmNvbS8_dGVzdD10ZXN0"") AS output;
Table 1. Results
output
""http://neo4j.com/?test=test""
apoc.text.base64Encode
apoc.text.base64UrlEncode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.base64Encode;"apoc.text.base64Encode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.base64Encode(text String) - encodes the given string with Base64.
Signature
None
Copy to Clipboard
apoc.text.base64Encode(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Capitalise the first letter of the word with
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64Encode(""neo4j"") AS output;
Table 1. Results
output
""bmVvNGo=""
apoc.text.base64Decode
apoc.text.base64UrlDecode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.base64Decode;"apoc.text.base64Decode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.base64Decode(text String) - decodes the given Base64 encoded string.
Signature
None
Copy to Clipboard
apoc.text.base64Decode(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64Decode(""bmVvNGo="") AS output;
Table 1. Results
output
""neo4j""
apoc.text.phoneticDelta
apoc.text.base64Encode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.phoneticDelta;"apoc.text.phoneticDelta
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.text.phoneticDelta(text1 String, text2 String) - returns the US_ENGLISH soundex character difference between the two given strings.
Signature
None
Copy to Clipboard
apoc.text.phoneticDelta(text1 :: STRING?, text2 :: STRING?) :: (phonetic1 :: STRING?, phonetic2 :: STRING?, delta :: INTEGER?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Output parameters
Name Type
phonetic1
STRING?
phonetic2
STRING?
delta
INTEGER?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.text.phoneticDelta(""Neo4j"", ""Neo4j"");
Table 1. Results
phonetic1 phonetic2 delta
""N200""
""N200""
4
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.text.phoneticDelta(""Neo4j Graph Data Science Library"", ""Neo4j Graph Database"");
Table 2. Results
phonetic1 phonetic2 delta
""N261""
""N261""
4
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.text.phoneticDelta(""GRANDstack"", ""GraphQL"");
Table 3. Results
phonetic1 phonetic2 delta
""G653""
""G612""
2
apoc.text
apoc.text.base64Decode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text;"apoc.text
Qualified Name Type
apoc.text.phoneticDelta
apoc.text.phoneticDelta(text1 String, text2 String) - returns the US_ENGLISH soundex character difference between the two given strings.
Procedure
apoc.text.base64Decode
apoc.text.base64Decode(text String) - decodes the given Base64 encoded string.
Function
apoc.text.base64Encode
apoc.text.base64Encode(text String) - encodes the given string with Base64.
Function
apoc.text.base64UrlDecode
apoc.text.base64UrlDecode(url String) - decodes the given Base64 encoded URL.
Function
apoc.text.base64UrlEncode
apoc.text.base64UrlEncode(url String) - encodes the given URL with Base64.
Function
apoc.text.byteCount
apoc.text.byteCount(text String, charset String) - returns the size of the given string in bytes.
Function
apoc.text.bytes
apoc.text.bytes(text String, charset String) - returns the given string as bytes.
Function
apoc.text.camelCase
apoc.text.camelCase(text String) - converts the given string to camel case.
Function
apoc.text.capitalize
apoc.text.capitalize(text String) - capitalizes the first letter of the given string.
Function
apoc.text.capitalizeAll
apoc.text.capitalizeAll(text String) - capitalizes the first letter of every word in the given string.
Function
apoc.text.charAt
apoc.text.charAt(text String, index Integer) - returns the long value of the character at the given index.
Function
apoc.text.clean
apoc.text.clean(text String) - strips the given string of everything except alpha numeric characters and converts it to lower case.
Function
apoc.text.code
apoc.text.code(codepoint Long) - converts the long value into a string.
Function
apoc.text.compareCleaned
apoc.text.compareCleaned(text1 String, text2 String) - compares two given strings stripped of everything except alpha numeric characters converted to lower case.
Function
apoc.text.decapitalize
apoc.text.decapitalize(text String) - turns the first letter of the given string from upper case to lower case.
Function
apoc.text.decapitalizeAll
apoc.text.decapitalizeAll(text String) - turns the first letter of every word in the given string to lower case.
Function
apoc.text.distance
apoc.text.distance(text1 String, text2 String) - compares the two given strings using the Levenshtein distance algorithm.
Function
apoc.text.doubleMetaphone
apoc.text.doubleMetaphone(value String) - returns the double metaphone phonetic encoding of all words in the given string value.
Function
apoc.text.format
apoc.text.format(text String, params [Any], language String) - formats the given string with the given parameters.
Function
apoc.text.fuzzyMatch
apoc.text.fuzzyMatch(text1 String, text2 String) - performs a fuzzy match search of the two given strings.
Function
apoc.text.hammingDistance
apoc.text.hammingDistance(text1 String, text2 String) - compares the two given strings using the Hamming distance algorithm.
Function
apoc.text.hexCharAt
apoc.text.hexCharAt(text String, index Integer) - returns the hexadecimal value of the given string at the given index.
Function
apoc.text.hexValue
apoc.text.hexValue(value Integer) - returns the hexadecimal value of the given value.
Function
apoc.text.indexOf
apoc.text.indexOf(text String, lookup String, from Integer, to Integer) - returns the first occurrence of the lookup string in the given string, or -1 if not found.
Function
apoc.text.indexesOf
apoc.text.indexesOf(text String, lookup String, from Integer, to Integer) - returns all occurences of the lookup string in the given string, or an empty list if not found.
Function
apoc.text.jaroWinklerDistance
apoc.text.jaroWinklerDistance(text1 String, text2 String) - compares the two given strings using the Jaro-Winkler distance algorithm.
Function
apoc.text.join
apoc.text.join(texts [String], delimiter String) - joins the given strings using the given delimiter.
Function
apoc.text.levenshteinDistance
apoc.text.levenshteinDistance(text1 String, text2 String) - compares the given strings using the Levenshtein distance algorithm.
Function
apoc.text.levenshteinSimilarity
apoc.text.levenshteinSimilarity(text1 String, text2 String) - returns the similarity (a value within 0 and 1) between the two given strings based on the Levenshtein distance algorithm.
Function
apoc.text.lpad
apoc.text.lpad(text String, count Integer, delimiter String) - left pads the given string by the given width.
Function
apoc.text.phonetic
apoc.text.phonetic(text String) - returns the US_ENGLISH phonetic soundex encoding of all words of the string.
Function
apoc.text.random
apoc.text.random(length Integer, valid String) - generates a random string to the given length using a length parameter and an optional string of valid characters.
Function
apoc.text.regexGroups
apoc.text.regexGroups(text String, regex String) - returns all groups matching the given regular expression in the given text.
Function
apoc.text.regreplace
apoc.text.regreplace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Function
apoc.text.repeat
apoc.text.repeat(item String, count Integer) - returns the result of the given item multiplied by the given count.
Function
apoc.text.replace
apoc.text.replace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Function
apoc.text.rpad
apoc.text.rpad(text String, count Integer, delimiter String) - right pads the given string by the given width.
Function
apoc.text.slug
apoc.text.slug(text String, delimiter String) - replaces the whitespace in the given string with the given delimiter.
Function
apoc.text.snakeCase
apoc.text.snakeCase(text String) - converts the given string to snake case.
Function
apoc.text.sorensenDiceSimilarity
apoc.text.sorensenDiceSimilarityWithLanguage(text1 String, text2 String, languageTag String) - compares the two given strings using the Sørensen–Dice coefficient formula, with the provided IETF language tag.
Function
apoc.text.split
apoc.text.split(text String, regex String, limit Integer) - splits the given string using a given regular expression as a separator.
Function
apoc.text.swapCase
apoc.text.swapCase(text String) - swaps the cases in the given string.
Function
apoc.text.toCypher
apoc.text.toCypher(value Any, config Map<String, Any>) - converts the given value to a Cypher property string.
Function
apoc.text.toUpperCase
apoc.text.toUpperCase(text String) - converts the given string to upper case.
Function
apoc.text.upperCamelCase
apoc.text.upperCamelCase(text String) - converts the given string to upper camel case.
Function
apoc.text.urldecode
apoc.text.urldecode(text String) - decodes the given URL encoded string.
Function
apoc.text.urlencode
apoc.text.urlencode(text String) - encodes the given URL string.
Function
apoc.temporal.toZonedTemporal
apoc.text.phoneticDelta
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.decapitalize;"apoc.text.decapitalize
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.decapitalize(text String) - turns the first letter of the given string from upper case to lower case.
Signature
None
Copy to Clipboard
apoc.text.decapitalize(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Decapitalize the first letter of the string
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.decapitalize(""Graph Database"") AS output;
Table 1. Results
output
""graph Database""
apoc.text.compareCleaned
apoc.text.decapitalizeAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.decapitalizeAll;"apoc.text.decapitalizeAll
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.decapitalizeAll(text String) - turns the first letter of every word in the given string to lower case.
Signature
None
Copy to Clipboard
apoc.text.decapitalizeAll(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Decapitalize the first letter of all words
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.decapitalizeAll(""Graph Databases"")  AS output;
Table 1. Results
output
""graph databases""
apoc.text.decapitalize
apoc.text.distance
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.distance;"apoc.text.distance
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.distance(text1 String, text2 String) - compares the two given strings using the Levenshtein distance algorithm.
Signature
None
Copy to Clipboard
apoc.text.distance(text1 :: STRING?, text2 :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.distance(""Levenshtein"", ""Levenstein"") AS output;
Table 1. Results
output
1
apoc.text.decapitalizeAll
apoc.text.doubleMetaphone
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.doubleMetaphone;"apoc.text.doubleMetaphone
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.doubleMetaphone(value String) - returns the double metaphone phonetic encoding of all words in the given string value.
Signature
None
Copy to Clipboard
apoc.text.doubleMetaphone(value :: STRING?) :: (STRING?)
Input parameters
Name Type Default
value
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.doubleMetaphone(""Neo4j Aura"") AS output;
Table 1. Results
output
""NJAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.doubleMetaphone(""GRANDstack: Build Fullstack GraphQL Applications With Ease"") AS output;
Table 2. Results
output
""KRNTPLTFLSTKRFKAPLKA0AS""
apoc.text.distance
apoc.text.format
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.format;"apoc.text.format
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.format(text String, params [Any], language String) - formats the given string with the given parameters.
Signature
None
Copy to Clipboard
apoc.text.format(text :: STRING?, params :: LIST? OF ANY?, language = en :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
params
LIST? OF ANY?
null
language
STRING?
en
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.format(""Neo4j %s"", [""Bloom""]) AS output;
Table 1. Results
output
""Neo4j Bloom""
apoc.text.doubleMetaphone
apoc.text.fuzzyMatch
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.fuzzyMatch;"apoc.text.fuzzyMatch
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.fuzzyMatch(text1 String, text2 String) - performs a fuzzy match search of the two given strings.
Signature
None
Copy to Clipboard
apoc.text.fuzzyMatch(text1 :: STRING?, text2 :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.fuzzyMatch(""The"", ""the"") AS output;
Table 1. Results
output
TRUE
apoc.text.format
apoc.text.hammingDistance
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.hammingDistance;"apoc.text.hammingDistance
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.hammingDistance(text1 String, text2 String) - compares the two given strings using the Hamming distance algorithm.
Signature
None
Copy to Clipboard
apoc.text.hammingDistance(text1 :: STRING?, text2 :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.hammingDistance(""Neo4j"", ""Neo4j"") AS output;
Table 1. Results
output
0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.hammingDistance(""Neo4j"", ""Neoj4"") AS output;
Table 2. Results
output
2
The provided strings must be the same length, otherwise this procedure will throw an exception, as shown in the example below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.hammingDistance(""Neo4j Aura"", ""Neo4j Graph Database"") AS output;
Table 3. Results
Failed to invoke function apoc.text.hammingDistance: Caused by: java.lang.IllegalArgumentException: CharSequences must have the same length
apoc.text.fuzzyMatch
apoc.text.hexCharAt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.hexCharAt;"apoc.text.hexCharAt
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.hexCharAt(text String, index Integer) - returns the hexadecimal value of the given string at the given index.
Signature
None
Copy to Clipboard
apoc.text.hexCharAt(text :: STRING?, index :: INTEGER?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
index
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.hexCharAt(""Neo4j"", 4) AS output;
Table 1. Results
output
""006A""
apoc.text.hammingDistance
apoc.text.hexValue
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.hexValue;"apoc.text.hexValue
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.hexValue(value Integer) - returns the hexadecimal value of the given value.
Signature
None
Copy to Clipboard
apoc.text.hexValue(value :: INTEGER?) :: (STRING?)
Input parameters
Name Type Default
value
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.hexValue(10) AS output;
Table 1. Results
output
""000A""
apoc.text.hexCharAt
apoc.text.indexOf
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.indexOf;"apoc.text.indexOf
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.indexOf(text String, lookup String, from Integer, to Integer) - returns the first occurrence of the lookup string in the given string, or -1 if not found.
Signature
None
Copy to Clipboard
apoc.text.indexOf(text :: STRING?, lookup :: STRING?, from = 0 :: INTEGER?, to = -1 :: INTEGER?) :: (INTEGER?)
Input parameters
Name Type Default
text
STRING?
null
lookup
STRING?
null
from
INTEGER?
0
to
INTEGER?
-1
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexOf(""Hello World"", 'Hello') AS output;
Table 1. Results
output
0
Cypher
Starting from index 3, find the first occurrence of 'Hello',
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexOf(""Hello World, Hello"", 'Hello', 3) AS output;
Table 2. Results
output
13
apoc.text.hexValue
apoc.text.indexesOf
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.indexesOf;"apoc.text.indexesOf
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.indexesOf(text String, lookup String, from Integer, to Integer) - returns all occurences of the lookup string in the given string, or an empty list if not found.
Signature
None
Copy to Clipboard
apoc.text.indexesOf(text :: STRING?, lookup :: STRING?, from = 0 :: INTEGER?, to = -1 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
text
STRING?
null
lookup
STRING?
null
from
INTEGER?
0
to
INTEGER?
-1
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexesOf(""Hello World, Hello, Hello"", 'Hello') AS output;
Table 1. Results
output
[0, 13, 20]
Cypher
Starting from index 6, find the occurrences of 'Hello',
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexesOf(""Hello World, Hello, Hello"", 'Hello', 6) AS output;
Table 2. Results
output
[13, 20]
Cypher
Starting from index 6 up to index 20, find the occurrences of 'Hello',
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexesOf(""Hello World, Hello, Hello"", 'Hello', 6, 20) AS output;
Table 3. Results
output
[13]
apoc.text.indexOf
apoc.text.jaroWinklerDistance
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.jaroWinklerDistance;"apoc.text.jaroWinklerDistance
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.jaroWinklerDistance(text1 String, text2 String) - compares the two given strings using the Jaro-Winkler distance algorithm.
Signature
None
Copy to Clipboard
apoc.text.jaroWinklerDistance(text1 :: STRING?, text2 :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.jaroWinklerDistance(""Neo4j"", ""Neo4j"") AS output;
Table 1. Results
output
0.0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.jaroWinklerDistance(""Neo4j"", ""Neoj4"") AS output;
Table 2. Results
output
0.046666666666666745
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.jaroWinklerDistance(""Neo4j Aura"", ""Neo4j Graph Database"") AS output;
Table 3. Results
output
0.15999999999999992
apoc.text.indexesOf
apoc.text.join
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.join;"apoc.text.join
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.join(texts [String], delimiter String) - joins the given strings using the given delimiter.
Signature
None
Copy to Clipboard
apoc.text.join(texts :: LIST? OF STRING?, delimiter :: STRING?) :: (STRING?)
Input parameters
Name Type Default
texts
LIST? OF STRING?
null
delimiter
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.join(['Hello', 'World'], ' ') AS output;
Table 1. Results
output
""Hello World""
apoc.text.jaroWinklerDistance
apoc.text.levenshteinDistance
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.levenshteinDistance;"apoc.text.levenshteinDistance
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.levenshteinDistance(text1 String, text2 String) - compares the given strings using the Levenshtein distance algorithm.
Signature
None
Copy to Clipboard
apoc.text.levenshteinDistance(text1 :: STRING?, text2 :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinDistance(""Neo4j"", ""Neo4j"") AS output;
Table 1. Results
output
0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinDistance(""Neo4j"", ""Neoj4"") AS output;
Table 2. Results
output
2
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinDistance(""Neo4j Aura"", ""Neo4j Graph Database"") AS output;
Table 3. Results
output
13
apoc.text.join
apoc.text.levenshteinSimilarity
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.levenshteinSimilarity;"apoc.text.levenshteinSimilarity
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.levenshteinSimilarity(text1 String, text2 String) - returns the similarity (a value within 0 and 1) between the two given strings based on the Levenshtein distance algorithm.
Signature
None
Copy to Clipboard
apoc.text.levenshteinSimilarity(text1 :: STRING?, text2 :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinSimilarity(""Neo4j"", ""Neo4j"") AS output;
Table 1. Results
output
1.0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinSimilarity(""Neo4j"", ""Neoj4"") AS output;
Table 2. Results
output
0.6
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.levenshteinSimilarity(""Neo4j Aura"", ""Neo4j Graph Database"") AS output;
Table 3. Results
output
0.35
apoc.text.levenshteinDistance
apoc.text.lpad
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.lpad;"apoc.text.lpad
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.lpad(text String, count Integer, delimiter String) - left pads the given string by the given width.
Signature
None
Copy to Clipboard
apoc.text.lpad(text :: STRING?, count :: INTEGER?, delim =   :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
count
INTEGER?
null
delim
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.lpad(""Neo4j"", 8, ""-"") AS output;
Table 1. Results
output
""---Neo4j""
apoc.text.levenshteinSimilarity
apoc.text.phonetic
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.phonetic;"apoc.text.phonetic
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.phonetic(text String) - returns the US_ENGLISH phonetic soundex encoding of all words of the string.
Signature
None
Copy to Clipboard
apoc.text.phonetic(value :: STRING?) :: (STRING?)
Input parameters
Name Type Default
value
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.phonetic(""Neo4j"") AS output;
Table 1. Results
output
""N200""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.phonetic(""GRANDstack: Build Fullstack GraphQL Applications With Ease"") AS output;
Table 2. Results
output
""G653B430F423G612A142W300E200""
apoc.text.lpad
apoc.text.random
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.random;"apoc.text.random
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.random(length Integer, valid String) - generates a random string to the given length using a length parameter and an optional string of valid characters.
Signature
None
Copy to Clipboard
apoc.text.random(length :: INTEGER?, valid = A-Za-z0-9 :: STRING?) :: (STRING?)
Input parameters
Name Type Default
length
INTEGER?
null
valid
STRING?
A-Za-z0-9
Usage Examples
You can generate a random string to a specified length by calling apoc.text.random with a length parameter and optional string of valid characters.
The valid parameter will accept the following regex patterns, alternatively you can provide a string of letters and/or characters.
Pattern
Description
A-Z
A-Z in uppercase
a-z
A-Z in lowercase
0-9
Numbers 0-9 inclusive
The following call will return a random string including uppercase letters, numbers and . and $ characters.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.random(10, ""A-Z0-9.$"") AS output;
Table 1. Results
output
""V9Y7N54LO6""
apoc.text.phonetic
apoc.text.regexGroups
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.regexGroups;"apoc.text.regexGroups
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.regexGroups(text String, regex String) - returns all groups matching the given regular expression in the given text.
Signature
None
Copy to Clipboard
apoc.text.regexGroups(text :: STRING?, regex :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
text
STRING?
null
regex
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.regexGroups(
  'abc <link xxx1>yyy1</link> def <link xxx2>yyy2</link>',
  '<link (\\w+)>(\\w+)</link>'
) AS output;
Table 1. Results
output
[[""<link xxx1>yyy1</link>"", ""xxx1"", ""yyy1""], [""<link xxx2>yyy2</link>"", ""xxx2"", ""yyy2""]]
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.regexGroups(
  'Michael: 1234\nJennifer: 5678',
  '(\\w+): (\\d+)'
) AS output;
Table 2. Results
output
[[""Michael: 1234"", ""Michael"", ""1234""], [""Jennifer: 5678"", ""Jennifer"", ""5678""]]
apoc.text.random
apoc.text.regreplace
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.regreplace;"apoc.text.regreplace
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.regreplace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Signature
None
Copy to Clipboard
apoc.text.regreplace(text :: STRING?, regex :: STRING?, replacement :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
regex
STRING?
null
replacement
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.regreplace(""Neo4j GraphQL Neo4j GraphQL"", ""GraphQL"", ""GRANDstack"") AS output;
Table 1. Results
output
""Neo4j GRANDstack Neo4j GRANDstack""
apoc.text.regexGroups
apoc.text.repeat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.repeat;"apoc.text.repeat
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.repeat(item String, count Integer) - returns the result of the given item multiplied by the given count.
Signature
None
Copy to Clipboard
apoc.text.repeat(item :: STRING?, count :: INTEGER?) :: (STRING?)
Input parameters
Name Type Default
item
STRING?
null
count
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.repeat('item', 5) AS output;
Table 1. Results
output
""itemitemitemitemitem""
apoc.text.regreplace
apoc.text.replace
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.replace;"apoc.text.replace
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.replace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Signature
None
Copy to Clipboard
apoc.text.replace(text :: STRING?, regex :: STRING?, replacement :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
regex
STRING?
null
replacement
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.replace('Hello World!', '[^a-zA-Z]', '') AS output;
Table 1. Results
output
""HelloWorld""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.replace('GDS is a Neo4j Product', 'GDS', 'Bloom') AS output;
Table 2. Results
output
""Bloom is a Neo4j Product""
apoc.text.repeat
apoc.text.rpad
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.rpad;"apoc.text.rpad
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.rpad(text String, count Integer, delimiter String) - right pads the given string by the given width.
Signature
None
Copy to Clipboard
apoc.text.rpad(text :: STRING?, count :: INTEGER?, delim =   :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
count
INTEGER?
null
delim
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.rpad(""Neo4j"", 8, ""-"") AS output;
Table 1. Results
output
""Neo4j---""
apoc.text.replace
apoc.text.slug
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.slug;"apoc.text.slug
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.slug(text String, delimiter String) - replaces the whitespace in the given string with the given delimiter.
Signature
None
Copy to Clipboard
apoc.text.slug(text :: STRING?, delim = - :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
delim
STRING?
-
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.slug(""Neo4j Aura"") AS output;
Table 1. Results
output
""Neo4j-Aura""
The default delimiter is -. We can, however, pass in a custom delimiter as the second parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.slug(""Neo4j Aura"", ""."") AS output;
Table 2. Results
output
""Neo4j.Aura""
apoc.text.rpad
apoc.text.snakeCase
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.snakeCase;"apoc.text.snakeCase
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.snakeCase(text String) - converts the given string to snake case.
Signature
None
Copy to Clipboard
apoc.text.snakeCase(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""test Snake Case"") AS output;
Table 1. Results
output
""test-snake-case""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""FOO_BAR"") AS output;
Table 2. Results
output
""foo-bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""Foo bar"") AS output;
Table 3. Results
output
""foo-bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""fooBar"") AS output;
Table 4. Results
output
""foo-bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""foo-bar"") AS output;
Table 5. Results
output
""foo-bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""Foo bar"") AS output;
Table 6. Results
output
""foo-bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""Foo  bar"") AS output;
Table 7. Results
output
""foo-bar""
apoc.text.slug
apoc.text.sorensenDiceSimilarity
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.sorensenDiceSimilarity;"apoc.text.sorensenDiceSimilarity
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.sorensenDiceSimilarityWithLanguage(text1 String, text2 String, languageTag String) - compares the two given strings using the Sørensen–Dice coefficient formula, with the provided IETF language tag.
Signature
None
Copy to Clipboard
apoc.text.sorensenDiceSimilarity(text1 :: STRING?, text2 :: STRING?, languageTag = en :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
languageTag
STRING?
en
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.sorensenDiceSimilarity(""belly"", ""jolly"") AS output;
Table 1. Results
output
0.5
apoc.text.snakeCase
apoc.text.split
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.split;"apoc.text.split
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.split(text String, regex String, limit Integer) - splits the given string using a given regular expression as a separator.
Signature
None
Copy to Clipboard
apoc.text.split(text :: STRING?, regex :: STRING?, limit = 0 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
text
STRING?
null
regex
STRING?
null
limit
INTEGER?
0
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.split('Hello World', ' ') AS output;
Table 1. Results
output
[""Hello"", World""]
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.split('Hello  World', ' ') AS output;
Table 2. Results
output
[""Hello"", """", ""World""]
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.split('Hello   World', ' +') AS output;
Table 3. Results
output
[""Hello"", ""World""]
apoc.text.sorensenDiceSimilarity
apoc.text.swapCase
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.swapCase;"apoc.text.swapCase
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.swapCase(text String) - swaps the cases in the given string.
Signature
None
Copy to Clipboard
apoc.text.swapCase(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.swapCase(""Neo4j"")  AS output;
Table 1. Results
output
""nEO4J""
apoc.text.split
apoc.text.toCypher
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.toCypher;"apoc.text.toCypher
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.toCypher(value Any, config Map<String, Any>) - converts the given value to a Cypher property string.
Signature
None
Copy to Clipboard
apoc.text.toCypher(value :: ANY?, config = {} :: MAP?) :: (STRING?)
Input parameters
Name Type Default
value
ANY?
null
config
MAP?
{}
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toCypher(""Neo4j"") AS output;
Table 1. Results
output
""'Neo4j'""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toCypher({key: ""Value""}) AS output;
Table 2. Results
output
""{key:'Value'}""
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Person) RETURN apoc.text.toCypher(p) AS output;
Table 3. Results
output
""(:Person {})""
apoc.text.swapCase
apoc.text.toUpperCase
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.toUpperCase;"apoc.text.toUpperCase
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.toUpperCase(text String) - converts the given string to upper case.
Signature
None
Copy to Clipboard
apoc.text.toUpperCase(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""test upper case"") AS output;
Table 1. Results
output
""TEST_UPPER_CASE""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""FooBar"") AS output;
Table 2. Results
output
""FOO_BAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""fooBar"") AS output;
Table 3. Results
output
""FOO_BAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""foo-bar"") AS output;
Table 4. Results
output
""FOO_BAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""foo--bar"") AS output;
Table 5. Results
output
""FOO_BAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""foo$$bar"") AS output;
Table 6. Results
output
""FOO_BAR""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""foo 22 bar"") AS output;
Table 7. Results
output
""FOO_22_BAR""
apoc.text.toCypher
apoc.text.upperCamelCase
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.upperCamelCase;"apoc.text.upperCamelCase
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.upperCamelCase(text String) - converts the given string to upper camel case.
Signature
None
Copy to Clipboard
apoc.text.upperCamelCase(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""FOO_BAR"") AS output;
Table 1. Results
output
""FooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""Foo bar"") AS output;
Table 2. Results
output
""FooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""Foo22 bar"") AS output;
Table 3. Results
output
""Foo22Bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""foo-bar"") AS output;
Table 4. Results
output
""FooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""Foobar"") AS output;
Table 5. Results
output
""Foobar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""Foo$$Bar"") AS output;
Table 6. Results
output
""FooBar""
apoc.text.toUpperCase
apoc.text.urldecode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.urldecode;"apoc.text.urldecode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.urldecode(text String) - decodes the given URL encoded string.
Signature
None
Copy to Clipboard
apoc.text.urldecode(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.urldecode(""Neo4j+Aura"") AS output;
Table 1. Results
output
""Neo4j Aura""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.urldecode(""Neo4j%3C3GRANDstack"") AS output;
Table 2. Results
output
""Neo4j<3GRANDstack""
apoc.text.upperCamelCase
apoc.text.urlencode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.urlencode;"apoc.text.urlencode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.urlencode(text String) - encodes the given URL string.
Signature
None
Copy to Clipboard
apoc.text.urlencode(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.urlencode(""Neo4j Aura"") AS output;
Table 1. Results
output
""Neo4j+Aura""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.urlencode(""GRANDstack: Build Fullstack GraphQL Applications With Ease"") AS output;
Table 2. Results
output
""GRANDstack%3A+Build+Fullstack+GraphQL+Applications+With+Ease""
apoc.text.urldecode
apoc.trigger
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger;"apoc.trigger
Qualified Name Type
apoc.trigger.add
apoc.trigger.add(name String, statement String, selector Map<String, Any>, config Map<String, Any>) - adds a trigger to the given Cypher statement. The selector for this procedure is {phase:'before/after/rollback/afterAsync'}.
Procedure
apoc.trigger.list
apoc.trigger.list() - lists all installed triggers.
Procedure
apoc.trigger.pause
apoc.trigger.pause(name String) - pauses the given trigger.
Procedure
apoc.trigger.remove
apoc.trigger.remove(name String) - removes the given trigger.
Procedure
apoc.trigger.removeAll
apoc.trigger.removeAll() - removes all previously added triggers.
Procedure
apoc.trigger.resume
apoc.trigger.resume(name String) - resumes the given paused trigger.
Procedure
apoc.text.urlencode
apoc.trigger.add
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.resume;"apoc.trigger.resume
Contents
Signature
Input parameters
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.resume(name String) - resumes the given paused trigger.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.resume(name :: STRING?) :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
If we we have paused the trigger created by the example in apoc.trigger.add, we can resume it by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.resume(""count-removals"");
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
TRUE
FALSE
More documentation of apoc.trigger.resume
apoc.trigger.removeAll
apoc.util
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.removeAll;"apoc.trigger.removeAll
Contents
Signature
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.removeAll() - removes all previously added triggers.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.removeAll() :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
If we want to remove all triggers, including the one created by the example in apoc.trigger.add, we can run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.removeAll();
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
FALSE
FALSE
More documentation of apoc.trigger.removeAll
apoc.trigger.remove
apoc.trigger.resume
Was this page helpful?"
https://neo4j.com/docs/apoc/5/background-operations/triggers;"Triggers
Contents
Triggers Examples
In a trigger you register Cypher statements that are called when data in Neo4j is changed (created, updated, deleted). Triggers can be run before or after a commit.
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Qualified Name Type
apoc.trigger.add
add a trigger kernelTransaction under a name, in the kernelTransaction you can use {createdNodes}, {deletedNodes} etc., the selector is {phase:'before/after/rollback'} returns previous and new trigger information. Takes in an optional configuration.
Procedure
apoc.trigger.remove
remove previously added trigger, returns trigger information
Procedure
apoc.trigger.removeAll
removes all previously added trigger, returns trigger information
Procedure
apoc.trigger.list
list all installed triggers
Procedure
apoc.trigger.pause
CALL apoc.trigger.pause(name) | it pauses the trigger
Procedure
apoc.trigger.resume
CALL apoc.trigger.resume(name) | it resumes the paused trigger
Procedure
The transaction data from Neo4j is turned into appropriate data structures to be consumed as parameters to a statement, i.e. $createdNodes.
The parameters available are:
Statement Description
transactionId
returns the id of the transaction
commitTime
returns the date of the transaction in milliseconds
createdNodes
when a node is created our trigger fires (list of nodes)
createdRelationships
when a relationship is created our trigger fires (list of relationships)
deletedNodes
when a node is deleted our trigger fires (list of nodes)
deletedRelationships
when a relationship is deleted our trigger fires (list of relationships)
removedLabels
when a label is removed our trigger fires (map of label to list of nodes)
removedNodeProperties
when a properties of node is removed our trigger fires (map of key to list of map of key,old,node)
removedRelationshipProperties
when a properties of relationship is removed our trigger fires (map of key to list of map of key,old,relationship)
assignedLabels
when a labes is assigned our trigger fires (map of label to list of nodes)
assignedNodeProperties
when node property is assigned our trigger fires (map of key to list of map of key,old,new,node)
assignedRelationshipProperties
when relationship property is assigned our trigger fires (map of key to list of map of key,old,new,relationship)
metaData
a map containing the metadata of that transaction. Transaction meta data can be set on client side e.g. via https://neo4j.com/docs/api/java-driver/current/org/neo4j/driver/TransactionConfig.html#metadata--
The helper functions can be used to extract nodes or relationships by label/relationship-type or updated property key.
Table 2. Helper Functions
apoc.trigger.toNode(node, $removedLabels, $removedNodeProperties)
function to rebuild a node as a virtual, to be used in triggers with a not 'afterAsync' phase
apoc.trigger.toRelationship(rel, $removedRelationshipProperties)
function to rebuild a relationship as a virtual, to be used in triggers with a not 'afterAsync' phase
Unlike previous versions of Neo4j, it will not be possible using Neo4j 5 to modify an entity created in phase: “after”. For example, the following query will return an Exception with message can’t acquire ExclusiveLock…:
None
Copy to Clipboard
CALL apoc.trigger.add('name','UNWIND $createdNodes AS n SET n.txId = $transactionId',{phase:'after'});
CREATE (f:Baz);
It is instead necessary to use another phase or perform only reading operations.
Triggers Examples
Set properties connected to a node
It is possible to add a trigger which, when added to a specific property on a node, adds the same property to all nodes connected to this node.
Dataset
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (d:Person {name:'Daniel', surname: 'Craig'})
CREATE (l:Person {name:'Mary', age: 47})
CREATE (t:Person {name:'Tom'})
CREATE (j:Person {name:'John'})
CREATE (m:Person {name:'Michael'})
CREATE (a:Person {name:'Anne'})
CREATE (l)-[:DAUGHTER_OF]->(d)
CREATE (t)-[:SON_OF]->(d)
CREATE (t)-[:BROTHER]->(j)
CREATE (a)-[:WIFE_OF]->(d)
CREATE (d)-[:SON_OF]->(m)
CREATE (j)-[:SON_OF]->(d)
With the above dataset, if a trigger is added and the following query is executed: MATCH (n:Person) WHERE n.name IN ['Daniel', 'Mary'] SET n.age=55, n.surname='Quinn', the $assignedNodeProperties used in the trigger statement will be as follows (where NODE(1) is (:Person {name: 'Daniel'}), and NODE(2) is (:Person {name: 'Mary'})):
Json
Copy to Clipboard
{
   age: [{
         node : NODE(1),
         new: 55,
         old: null,
         key: ""age""
      },
      {
         node: NODE(2),
         new: 55,
         old: 47,
         key: ""age""
      }],

   surname: [{
         node: NODE(),
         new: ,
         old: ,
         key: 
      },
      {
         node: NODE(),
         new: ,
         old: ,
         key: 
      }]
}
View all (12 more lines)
The result is a map where the keys are the assigned properties, and the values are a list of entities involved. Every element of a list have the node itself, the new value of the changed properties, the old value (or null if the property didn’t exist) and the key with the property name.
The $removedNodeProperties parameter has the same structure and logic (in this case, new values will be always null).
The same is true for assignedRelationshipProperties and removedRelationshipProperties, with the only difference being that the node: NODE(n) key is replaced with the relationship: RELATIONSHIP(n) key.
As an example, the following statement creates a trigger which for every SET, updates the two properties time and lasts with the current date:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('setLastUpdate',
  ""UNWIND keys($assignedNodeProperties) AS k
  UNWIND $assignedNodeProperties[k] AS map
  WITH map.node AS node, collect(map.key) AS propList
  MATCH (n)
  WHERE id(n) = id(node) AND NOT 'lasts' in propList // to prevent loops
  SET n.time = date(),  n.lasts = propList"",
  {phase: 'afterAsync'});
In the example above, MATCH (n) WHERE id(n) = id(node) is used to demonstrate that the node is found by id first, before setting its parameters. However, it is more efficient to remove this command and instead change the penultimate row to: SET node.time = date(), node.lasts = propList. Note that the condition AND NOT 'lasts' IN propList must be added to prevent an infinite loop as the SET command will trigger this query again.
It is then possible to execute the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name: 'Daniel'}) set n.age = 123, n.country = 'Italy'
Executing
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name: 'Daniel'}) return n
It is possible to set the property time with today’s date, and lasts=['country','age'].
In cases where the surname property is added to a node, it’s added to all the nodes connected to it as well (in this case one level deep).
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (d:Person {name:'Daniel'})
SET d.surname = 'William'
Create relationship on a new node
To add a trigger that connects every new node with the label Actor and assign a specific value to the name property, run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('create-rel-new-node',""UNWIND $createdNodes AS n
MATCH (m:Movie {title:'Matrix'})
WHERE n:Actor AND n.name IN ['Keanu Reeves','Laurence Fishburne','Carrie-Anne Moss']
CREATE (n)-[:ACT_IN]->(m)"", {phase:'before'})
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (k:Actor {name:'Keanu Reeves'})
CREATE (l:Actor {name:'Laurence Fishburne'})
CREATE (c:Actor {name:'Carrie-Anne Moss'})
CREATE (a:Actor {name:'Tom Hanks'})
CREATE (m:Movie {title:'Matrix'})
Prevent transaction blocking
To prevent certain transaction locks, it is generally recommended to use the afterAsync phase. This will stop the query from pending indefinitely.
Pause trigger
To pause a trigger without removing it for future purposes, use the following procedure:
Resume paused trigger
To resume a paused trigger, use the following procedure:
Optional parameters
Add \{params: {parameterMaps}} to insert additional parameters.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('timeParams','UNWIND $createdNodes AS n SET n.time = $time', {}, {params: {time: timestamp()}});
Handle deleted entities
If a ‘before’ or ‘after’ trigger query has been created, with $deletedRelationships or $deletedNodes, and entities information such as labels and/or properties need to be retrieved, it is not possible to use the cypher functions labels() and properties(). However, it is possible to leverage virtual nodes and relationships via the functions apoc.trigger.toNode(node, $removedLabels, $removedNodeProperties) and apoc.trigger.toRelationship(rel, $removedRelationshipProperties). If so, it is possible to retrieve information about nodes and relationships using the apoc.any.properties and the apoc.node.labels functions.
For example, to create a new node with the same properties (plus the id) and with an additional label retrieved for each node, the following query can be executed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('myTrigger',
""UNWIND $deletedNodes as deletedNode
WITH apoc.trigger.toNode(deletedNode, $removedLabels, $removedNodeProperties) AS deletedNode
CREATE (r:Report {id: id(deletedNode)}) WITH r, deletedNode
CALL apoc.create.addLabels(r, apoc.node.labels(deletedNode)) yield node with node, deletedNode
set node+=apoc.any.properties(deletedNode)"" ,
{phase:'before'})
To create a node called Report with the same properties (plus the id and rel-type as additional properties) for each deleted relationship, the following query can be executed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('myTrigger',
""UNWIND $deletedRelationships as deletedRel
WITH apoc.trigger.toRelationship(deletedRel, $removedRelationshipProperties) AS deletedRel
CREATE (r:Report {id: id(deletedRel), type: apoc.rel.type(deletedRel)})
WITH r, deletedRelset r+=apoc.any.properties(deletedRel)"" ,
{phase:'before'})
By using phase 'afterAsync', there is no need to execute the functions apoc.trigger.toNode and apoc.trigger.toRelationship. This is because the rebuild of entities is executed automatically under the hood in this phase.
Cypher
Other examples
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('timestamp','UNWIND $createdNodes AS n SET n.ts = timestamp()', {});
CALL apoc.trigger.add('lowercase','UNWIND $createdNodes AS n SET n.id = toLower(n.name)', {});
CALL apoc.trigger.add('txInfo','UNWIND $createdNodes AS n SET n.txId = $transactionId, n.txTime = $commitTime', {phase:'after'});
CALL apoc.trigger.add('count-removed-rels','MATCH (c:Counter) SET c.count = c.count + size([r IN $deletedRelationships WHERE type(r) = ""X""])', {})
Table 3. Helper Functions
Phase
Description
before
The trigger will be activated right before the commit. If no phase is specified, it is the default.
rollback
The trigger will be activated right after the rollback
after
The trigger will be activated right after the commit
afterAsync
The trigger will be activated right after the commit and inside a new transaction and thread that will not impact the original one Heavy operations should be processed in this phase without blocking the original transaction Please note that 'after' and 'before' phases can sometimes block transactions, so generally, the afterAsync phase is preferred
Background Jobs
Database Introspection
Was this page helpful?"
https://neo4j.com/docs/apoc/5/background-operations/periodic-background;"Background Jobs
Qualified Name Type
apoc.periodic.list
apoc.periodic.list - list all jobs
Procedure
apoc.periodic.submit
apoc.periodic.submit('name',statement,params) - submit a one-off background statement; parameter 'params' is optional and can contain query parameters for Cypher statement
Procedure
apoc.periodic.countdown
apoc.periodic.countdown('name',statement,repeat-rate-in-seconds) submit a repeatedly-called background statement until it returns 0
Procedure
There are also static methods Jobs.submit, and Jobs.schedule, which can be used from other procedures.
The jobs list is checked / cleared every 10s for finished jobs.
Many procedures run in the background or asynchronously. The following setting overrides the default thread pool size (processors*2):
apoc.jobs.pool.num_threads=10
Many periodic procedures rely on a scheduled executor that has a pool of threads with a default fixed size (processors/4, at least 1). To configure the pool size, use the following configuration property:
apoc.jobs.scheduled.num_threads=10
This statement repeats until the termination is reached. The statement must return a numeric value and it should decrement (similar to a monotonically decreasing function). When the return value reaches 0 the iteration stops.
For example, to define a counter with a numeric property, use the following command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (counter:Counter) SET counter.c = 10
To decrement this property by 1 each second, use the following command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.countdown('decrement',""MATCH (counter:Counter) SET counter.c = counter.c - 1 RETURN counter.c as count"", 1)
Background Operations
Triggers
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.submit;"apoc.periodic.submit
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.periodic.submit(name String, statement String, params Map<String, Any>) - creates a background job which runs the given Cypher statement once.
Signature
None
Copy to Clipboard
apoc.periodic.submit(name :: STRING?, statement :: STRING?, params = {} :: MAP?) :: (name :: STRING?, delay :: INTEGER?, rate :: INTEGER?, done :: BOOLEAN?, cancelled :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
statement
STRING?
null
params
MAP?
{}
Output parameters
Name Type
name
STRING?
delay
INTEGER?
rate
INTEGER?
done
BOOLEAN?
cancelled
BOOLEAN?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.submit(
  ""create-person"",
  ""CREATE (:Person {name: 'Michael Hunger'})""
);
Table 1. Results
name delay rate done cancelled
""create-person""
0
0
FALSE
FALSE
apoc.periodic.repeat
apoc.periodic.truncate
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.truncate;"apoc.periodic.truncate
Contents
Signature
Input parameters
Config parameters
Procedure
apoc.periodic.truncate(config Map<String, Any>) - removes all entities (and optionally indexes and constraints) from the database using the apoc.periodic.iterate procedure.
Signature
None
Copy to Clipboard
apoc.periodic.truncate(config = {} :: MAP?) :: VOID
Input parameters
Name Type Default
config
MAP?
{}
Config parameters
The procedure supports the same configurations as the apoc.periodic.iterate procedure.
Moreover, it supports the following config parameters:
Table 1. Config parameters
name type default description
dropSchema
boolean
true
drops all indexes and constraints
apoc.periodic.submit
apoc.refactor
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.iterate;"apoc.periodic.iterate
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Batch mode: BATCH_SINGLE
Procedure
apoc.periodic.iterate(cypherIterate String, cypherAction String, config Map<String, Any>) - runs the second statement for each item returned by the first statement. This procedure returns the number of batches and the total number of processed rows.
Signature
None
Copy to Clipboard
apoc.periodic.iterate(cypherIterate :: STRING?, cypherAction :: STRING?, config :: MAP?) :: (batches :: INTEGER?, total :: INTEGER?, timeTaken :: INTEGER?, committedOperations :: INTEGER?, failedOperations :: INTEGER?, failedBatches :: INTEGER?, retries :: INTEGER?, errorMessages :: MAP?, batch :: MAP?, operations :: MAP?, wasTerminated :: BOOLEAN?, failedParams :: MAP?, updateStatistics :: MAP?)
Input parameters
Name Type Default
cypherIterate
STRING?
null
cypherAction
STRING?
null
config
MAP?
null
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
batchSize
Long
10000
run the specified number of operation statements in a single tx - params: {_count, _batch}
parallel
boolean
false
run operation statements in parallel (note that statements might deadlock if conflicting).
Please note that, in case of parallel: false, APOC is designed to reuse the same java.util.concurrent.ThreadPoolExecutor with a maximum pool size equal 1, in order to prevent parallelism; this means that if you want to execute multiple apoc.periodic.iterate each one will be executed when the previous one has been completed. Instead, with parallel: true, APOC will use a ThreadPoolExecutor with a configurable maximum pool size via the apoc.jobs.pool.num_threads config or as default with the number of available processor * 2. Therefore, if we execute multiple apoc.periodic.iterate each one will be executed in parallel if the queue pool size can accept new tasks. Furthermore, to be noted that running in parallel affects all databases, and not the single database you are using. So with e.g. 2 databases db1 and db2, the apoc.periodic.iterate on db1 will impact on performance if we execute an apoc.periodic.iterate on db2.
retries
Long
0
if the operation statement fails with an error, sleep 100ms and retry until retries-count is reached - param {_retry}
batchMode
String
""BATCH""
how data-driven statements should be processed by operation statement. Valid values are:
""BATCH"" - execute operation statement once per batchSize. Operation statement is prefixed with the following, which extracts each field returned in the data-driven statement from the $_batch parameter:
UNWIND $_batch AS _batch
WITH _batch.field1 AS field1, _batch.field2 AS field2
""SINGLE"" - execute operation statement one at a time
""BATCH_SINGLE"" - execute operation statement once per batchSize, but leaves unpacking of batch to the operation statement. The operation query can access the batched values via the $_batch parameter.
params
Map
{}
externally pass in map of params
concurrency
Long
Number of processors available
number of concurrent tasks are generated when using parallel:true
failedParams
Long
-1
if set to a non-negative value, each failed batch up to failedParams parameter sets are returned in yield failedParams.
planner
Enum[DEFAULT, COST, IDP, DP]
DEFAULT
Any planner other than DEFAULT will be prepended to the second statement as cypher planner=[VALUE_OF_CONFIG] (or insert planner=[VALUE_OF_CONFIG] with any existing query options). This planner value (except for DEFAULT) has higher precedence than the planner defined in the query (if any).
In APOC versions 4.0.0.11 and earlier, the iterateList config key was used to control the batching of values returned by the data-driven statement. This was replaced by batchMode in version 4.0.0.12. These config keys are treated as follows:
If batchMode is provided, its value takes precedence over iterateList
If batchMode is not provided and iterateList is provided, the value of iterateList will be translated as described in the table below.
If neither batchMode nor iterateList are provided, batchMode defaults to BATCH, which is the same as iterateList:true
Table 2. Deprecated Config
param default description
iterateList
true
execute operation statements once per batchSize (whole batchSize list is passed in as parameter {_batch})
A value of true is equivalent to batchMode: ""BATCH""
A value of false is equivalent to batchMode: ""SINGLE""
Output parameters
Name Type
batches
INTEGER?
total
INTEGER?
timeTaken
INTEGER?
committedOperations
INTEGER?
failedOperations
INTEGER?
failedBatches
INTEGER?
retries
INTEGER?
errorMessages
MAP?
batch
MAP?
operations
MAP?
wasTerminated
BOOLEAN?
failedParams
MAP?
updateStatistics
MAP?
Usage Examples
Let’s go through some examples.
If you were to add an :Actor label to several million :Person nodes, you could run the following code:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (p:Person) WHERE (p)-[:ACTED_IN]->() RETURN p"",
  ""SET p:Actor"",
  {batchSize:10000, parallel:true})
Let’s break down the parameters passed to the procedure:
Our first Cypher statement selects all the Person nodes with an ACTED_IN relationship to another node and returns those persons. This is the data-driven portion where we select the data that we want to change.
Our second Cypher statement sets the :Actor label on each of the Person nodes selected. This is the operation portion where we apply the change to the data from our first statement.
And finally, we specify any configuration we want the procedure to use. We have defined a batchSize of 10,000 and to run the statements in parallel.
Executing this procedure would take all of our Person nodes gathered in the first Cypher statement and update each of them with the second Cypher statement. It divides the work into batches - taking 10,000 Person nodes from the stream and updating them in a single transaction. If we have 30,000 Person nodes in our graph with an ACTED_IN relationship, then it would break this down into 3 batches.
Finally, it runs those in parallel, as updating node labels or properties do not conflict.
For more complex operations like updating or removing relationships, either do not use parallel: true OR make sure that you batch the work in a way that each subgraph of data is updated in one operation, such as by transferring the root objects. If you attempt complex operations, also enable retrying failed operations, e.g. with retries:3.
Now let us look at a more complex example.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (o:Order) WHERE o.date > '2016-10-13' RETURN o"",
  ""MATCH (o)-[:HAS_ITEM]->(i) WITH o, sum(i.value) as value SET o.value = value"",
  {batchSize:100, parallel:true})
Let’s break down the parameters passed to the procedure:
Our first Cypher statement selects all the Order nodes that have an order date greater than October 13, 2016 (first Cypher statement).
Our second Cypher statement takes those groups and finds the nodes that have a HAS_ITEM relationship to other nodes, then sums up the value of those items and sets that sum as a property (o.value) for the total order value.
Our configuration will batch those nodes into groups of 100 (batchSize:100) and run the batches in parallel for the second statement to process.
Batch mode: BATCH_SINGLE
If our operation statement calls a procedure that takes in a batch of values, we can use batchMode: ""BATCH_SINGLE"" to get access to a batch of values to pass to that procedure. When we use BATCH_SINGLE, the operation statement will have access to the $_batch parameter, which will contain a list of the fields returned in the data-driven statement.
For example, if the data driven statement is:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN 'mark' AS a, 'michael' AS b
UNION
RETURN 'jennifer' AS a, 'andrea' AS b
The contents of the $_batch variable passed to the operation statement would be:
Text
Copy to Clipboard
[
  {a: ""mark"", b: ""michael""},
  {a: ""jennifer"", b: ""andrea""}
]
Let’s see an example of this in action. We’ll start by creating some nodes:
Cypher
The following query creates 100,000 nodes with the label Person and property id
Copy to Clipboard
Run in Neo4j Browser
UNWIND range(1,100000) as id create (:Person {id: id})
We can delete these nodes using the apoc.nodes.delete procedure. See Deleting data.
This procedure takes in a list of nodes, which we can extract from the $_batch parameter.
Cypher
The following query streams all the Person nodes and deletes them in batches of 100
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (p:Person) RETURN p"",
  // Extract `p` variable using list comprehension
  ""CALL apoc.nodes.delete([item in $_batch | item.p], size($_batch))"",
  {batchMode: ""BATCH_SINGLE"", batchSize: 100}
)
YIELD batch, operations;
The contents of the $_batch parameter that is used in the operation statement would be as follows:
Text
Copy to Clipboard
[
  {p: Node<1>},
  {p: Node<2>},
  ...
]
We can use a list comprehension to extract the p variable from each item in the list.
If we run this query, we’ll see the following output:
Table 3. Results
batch operations
{total: 1000, committed: 1000, failed: 0, errors: {}}
{total: 100000, committed: 100000, failed: 0, errors: {}}
apoc.periodic.countdown
apoc.periodic.list
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates/data-deletion;"Deleting data
Contents
Procedure for deleting data
Example
The APOC library contains a procedure that that can be used to delete graph data.
Procedure for deleting data
Qualified Name Type
apoc.nodes.delete
apoc.nodes.delete(nodes Any, batchSize Integer) - deletes all nodes with the given ids.
Procedure
Example
The below example will further explain this procedure.
Cypher
The following deletes all nodes with given id in batches of 1000:
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.nodes.delete(s, 1000) YIELD value
RETURN value
The procedure apoc.nodes.delete calls the Cypher query DETACH DELETE to delete nodes in batches.
Cypher can also be used to delete nodes with a given id in batches.
Cypher
The following deletes all nodes with the given id in batches of 1000:
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL {
    WITH s
    DETACH DELETE s
} IN TRANSACTIONS OF 1000 ROWS
Locks
Data Structures
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates/locks;"Locks
Contents
Procedures to aquire locks on nodes and relationships
The Apoc library contains procedures that can be used to acquire locks on nodes and relationships.
Procedures to aquire locks on nodes and relationships
Qualified Name Type
apoc.lock.all
apoc.lock.all(nodes [Node], rels [Rel]) - acquires a write lock on the given nodes and relationships.
Procedure
apoc.lock.nodes
apoc.lock.nodes(nodes [Node]) - acquires a write lock on the given nodes
Procedure
apoc.lock.read.nodes
apoc.lock.read.nodes(nodes [Node]) - acquires a read lock on the given nodes.
Procedure
apoc.lock.read.rels
apoc.lock.read.rels(rels [Rel]) - acquires a read lock on the given relationships.
Procedure
apoc.lock.rels
apoc.lock.rels(rels [Rels]) - acquires a write lock on the given relationships.
Procedure
Atomic property updates
Deleting data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock/apoc.lock.nodes;"apoc.lock.nodes
Contents
Signature
Input parameters
Procedure
apoc.lock.nodes(nodes [Node]) - acquires a write lock on the given nodes.
Signature
None
Copy to Clipboard
apoc.lock.nodes(nodes :: LIST? OF NODE?) :: VOID
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
More documentation of apoc.lock.nodes
apoc.lock.all
apoc.lock.read.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock/apoc.lock.all;"apoc.lock.all
Contents
Signature
Input parameters
Procedure
apoc.lock.all(nodes [Node], rels [Rel]) - acquires a write lock on the given nodes and relationships.
Signature
None
Copy to Clipboard
apoc.lock.all(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?) :: VOID
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
More documentation of apoc.lock.all
apoc.lock
apoc.lock.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock;"apoc.lock
Qualified Name Type
apoc.lock.all
apoc.lock.all(nodes [Node], rels [Rel]) - acquires a write lock on the given nodes and relationships.
Procedure
apoc.lock.nodes
apoc.lock.nodes(nodes [Node]) - acquires a write lock on the given nodes.
Procedure
apoc.lock.read.nodes
apoc.lock.read.nodes(nodes [Node]) - acquires a read lock on the given nodes.
Procedure
apoc.lock.read.rels
apoc.lock.read.rels(rels [Rel]) - acquires a read lock on the given relationships.
Procedure
apoc.lock.rels
apoc.lock.rels(rels [Rels]) - acquires a write lock on the given relationships.
Procedure
apoc.load.xml
apoc.lock.all
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.xml;"apoc.load.xml
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Import from local file
Import from GitHub
xPath expressions
Avoid OOM using Xpath
Extracting data structures
Binary file
Procedure
apoc.load.xml(urlOrBinary Any, path String, config Map<String, Any>, simple Boolean) - loads a single nested map from an XML URL (e.g. web-API).
Signature
None
Copy to Clipboard
apoc.load.xml(urlOrBinary :: ANY?, path = / :: STRING?, config = {} :: MAP?, simple = false :: BOOLEAN?) :: (value :: MAP?)
Input parameters
Name Type Default
urlOrBinary
ANY?
null
path
STRING?
/
config
MAP?
{}
simple
BOOLEAN?
false
Output parameters
Name Type
value
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the Microsoft book.xml file.
Xml
book.xml
Copy to Clipboard
<?xml version=""1.0""?>
<catalog>
   <book id=""bk101"">
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications
      with XML.</description>
   </book>
   <book id=""bk102"">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      <genre>Fantasy</genre>
      5.95
      2000-12-16
      A former architect battles corporate zombies,
...
View all (4 more lines)
This file can be downloaded from GitHub.
Import from local file
The books.xml file described below contains the first two books from the Microsoft Books XML file. We’ll use the smaller file in this section to simplify our examples.
Xml
books.xml
Copy to Clipboard
<?xml version=""1.0""?>
<catalog>
   <book id=""bk101"">
      <author>Gambardella, Matthew</author>
      <author>Arciniegas, Fabio</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications
      with XML.</description>
   </book>
   <book id=""bk102"">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      Fantasy
      5.95
      2000-12-16
      A former architect battles corporate zombies,
      an evil sorceress, and her own childhood to become queen
      of the world.
   
View all (9 more lines)
We’ll place this file into the import directory of our Neo4j instance. Let’s now write a query using the apoc.load.xml procedure to explore this file.
Cypher
The following query processes books.xml and returns the content as Cypher data structures
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
RETURN value
Table 1. Results
value
{_type: ""catalog"", _children: [{_type: ""book"", _children: [{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}, {_type: ""title"", _text: ""XML Developer’s Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""44.95""}, {_type: ""publish_date"", _text: ""2000-10-01""}, {_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}], id: ""bk101""}, {_type: ""book"", _children: [{_type: ""author"", _text: ""Ralls, Kim""}, {_type: ""title"", _text: ""Midnight Rain""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-12-16""}, {_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}], id: ""bk102""}]}
We get back a map representing the XML structure. Every time an XML element is nested inside another one, it is accessible via the .children property. We can write the following query to get a better understanding of what our file contains.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
UNWIND value._children AS book
RETURN book.id AS bookId,
       [item in book._children WHERE item._type = ""title""][0] AS title,
       [item in book._children WHERE item._type = ""description""][0] AS description,
       [item in book._children WHERE item._type = ""author""] AS authors,
       [item in book._children WHERE item._type = ""genre""][0] AS genre;
Table 2. Results
bookId title description authors genre
""bk101""
{_type: ""title"", _text: ""XML Developer’s Guide""}
{_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}
[{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}]
{_type: ""genre"", _text: ""Computer""}
""bk102""
{_type: ""title"", _text: ""Midnight Rain""}
{_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}
[{_type: ""author"", _text: ""Ralls, Kim""}]
{_type: ""genre"", _text: ""Fantasy""}
Let’s now create a graph of books and their metadata, authors, and genres.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
UNWIND value._children AS book

WITH book.id AS bookId,
     [item in book._children WHERE item._type = ""title""][0] AS title,
     [item in book._children WHERE item._type = ""description""][0] AS description,
     [item in book._children WHERE item._type = ""author""] AS authors,
     [item in book._children WHERE item._type = ""genre""][0] AS genre

MERGE (b:Book {id: bookId})
SET b.title = title._text, b.description = description._text

MERGE (g:Genre {name: genre._text})
MERGE (b)-[:HAS_GENRE]->(g)

 b, authors
 authors  author
 (a: {name:author._text})
 (a)-[:]->(b);
View all (5 more lines)
The Neo4j Browser visualization below shows the imported graph:
Import from GitHub
We can also process XML files from HTTP or HTTPS URIs. Let’s start by processing the books.xml file hosted on GitHub.
This time we’ll pass in true as the 4th argument of the procedure. This means that the XML will be parsed in simple mode.
Cypher
The following query loads the books.xml file from GitHub using simple mode
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
RETURN value;
Table 3. Results
value
{_type: ""catalog"", _catalog: [{_type: ""book"", _book: [{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}, {_type: ""title"", _text: ""XML Developer’s Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""44.95""}, {_type: ""publish_date"", _text: ""2000-10-01""}, {_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}], id: ""bk101""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Ralls, Kim""}, {_type: ""title"", _text: ""Midnight Rain""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-12-16""}, {_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}], id: ""bk102""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""Maeve Ascendant""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-11-17""}, {_type: ""description"", _text: ""After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.""}], id: ""bk103""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""Oberon’s Legacy""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2001-03-10""}, {_type: ""description"", _text: ""In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.""}], id: ""bk104""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""The Sundered Grail""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2001-09-10""}, {_type: ""description"", _text: ""The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon’s Legacy.""}], id: ""bk105""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Randall, Cynthia""}, {_type: ""title"", _text: ""Lover Birds""}, {_type: ""genre"", _text: ""Romance""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-09-02""}, {_type: ""description"", _text: ""When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.""}], id: ""bk106""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Thurman, Paula""}, {_type: ""title"", _text: ""Splish Splash""}, {_type: ""genre"", _text: ""Romance""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-11-02""}, {_type: ""description"", _text: ""A deep sea diver finds true love twenty thousand leagues beneath the sea.""}], id: ""bk107""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Knorr, Stefan""}, {_type: ""title"", _text: ""Creepy Crawlies""}, {_type: ""genre"", _text: ""Horror""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-12-06""}, {_type: ""description"", _text: ""An anthology of horror stories about roaches, centipedes, scorpions and other insects.""}], id: ""bk108""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Kress, Peter""}, {_type: ""title"", _text: ""Paradox Lost""}, {_type: ""genre"", _text: ""Science Fiction""}, {_type: ""price"", _text: ""6.95""}, {_type: ""publish_date"", _text: ""2000-11-02""}, {_type: ""description"", _text: ""After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.""}], id: ""bk109""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""O’Brien, Tim""}, {_type: ""title"", _text: ""Microsoft .NET: The Programming Bible""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""36.95""}, {_type: ""publish_date"", _text: ""2000-12-09""}, {_type: ""description"", _text: ""Microsoft’s .NET initiative is explored in detail in this deep programmer’s reference.""}], id: ""bk110""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""O’Brien, Tim""}, {_type: ""title"", _text: ""MSXML3: A Comprehensive Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""36.95""}, {_type: ""publish_date"", _text: ""2000-12-01""}, {_type: ""description"", _text: ""The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.""}], id: ""bk111""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Galos, Mike""}, {_type: ""title"", _text: ""Visual Studio 7: A Comprehensive Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""49.95""}, {_type: ""publish_date"", _text: ""2001-04-16""}, {_type: ""description"", _text: ""Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C+, C#, and ASP are integrated into a comprehensive development environment.""}], id: ""bk112""}]}
We again get back back a map representing the XML structure, but the structure is different than when we don’t use simple mode. This time nested XML elements are accessible via a property of the element name prefixed with an _.
We can write the following query to get a better understanding of what our file contains.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/4.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
UNWIND value._catalog AS catalog
RETURN catalog.id AS bookId,
       [item in catalog._book WHERE item._type = ""title""][0] AS title,
       [item in catalog._book WHERE item._type = ""description""][0] AS description,
       [item in catalog._book WHERE item._type = ""author""] AS authors,
       [item in catalog._book WHERE item._type = ""genre""][0] AS genre;
Table 4. Results
bookId title description authors genre
""bk101""
{_type: ""title"", _text: ""XML Developer’s Guide""}
{_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}
[{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}]
{_type: ""genre"", _text: ""Computer""}
""bk102""
{_type: ""title"", _text: ""Midnight Rain""}
{_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}
[{_type: ""author"", _text: ""Ralls, Kim""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk103""
{_type: ""title"", _text: ""Maeve Ascendant""}
{_type: ""description"", _text: ""After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk104""
{_type: ""title"", _text: ""Oberon’s Legacy""}
{_type: ""description"", _text: ""In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk105""
{_type: ""title"", _text: ""The Sundered Grail""}
{_type: ""description"", _text: ""The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon’s Legacy.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk106""
{_type: ""title"", _text: ""Lover Birds""}
{_type: ""description"", _text: ""When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.""}
[{_type: ""author"", _text: ""Randall, Cynthia""}]
{_type: ""genre"", _text: ""Romance""}
""bk107""
{_type: ""title"", _text: ""Splish Splash""}
{_type: ""description"", _text: ""A deep sea diver finds true love twenty thousand leagues beneath the sea.""}
[{_type: ""author"", _text: ""Thurman, Paula""}]
{_type: ""genre"", _text: ""Romance""}
""bk108""
{_type: ""title"", _text: ""Creepy Crawlies""}
{_type: ""description"", _text: ""An anthology of horror stories about roaches, centipedes, scorpions and other insects.""}
[{_type: ""author"", _text: ""Knorr, Stefan""}]
{_type: ""genre"", _text: ""Horror""}
""bk109""
{_type: ""title"", _text: ""Paradox Lost""}
{_type: ""description"", _text: ""After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.""}
[{_type: ""author"", _text: ""Kress, Peter""}]
{_type: ""genre"", _text: ""Science Fiction""}
""bk110""
{_type: ""title"", _text: ""Microsoft .NET: The Programming Bible""}
{_type: ""description"", _text: ""Microsoft’s .NET initiative is explored in detail in this deep programmer’s reference.""}
[{_type: ""author"", _text: ""O’Brien, Tim""}]
{_type: ""genre"", _text: ""Computer""}
""bk111""
{_type: ""title"", _text: ""MSXML3: A Comprehensive Guide""}
{_type: ""description"", _text: ""The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.""}
[{_type: ""author"", _text: ""O’Brien, Tim""}]
{_type: ""genre"", _text: ""Computer""}
""bk112""
{_type: ""title"", _text: ""Visual Studio 7: A Comprehensive Guide""}
{_type: ""description"", _text: ""Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C+, C#, and ASP are integrated into a comprehensive development environment.""}
[{_type: ""author"", _text: ""Galos, Mike""}]
{_type: ""genre"", _text: ""Computer""}
Rather than just returning that data, we can create a graph of books and their metadata, authors, and genres.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/4.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
UNWIND value._catalog AS catalog
WITH catalog.id AS bookId,
       [item in catalog._book WHERE item._type = ""title""][0] AS title,
       [item in catalog._book WHERE item._type = ""description""][0] AS description,
       [item in catalog._book WHERE item._type = ""author""] AS authors,
       [item in catalog._book WHERE item._type = ""genre""][0] AS genre

MERGE (b:Book {id: bookId})
SET b.title = title._text, b.description = description._text

MERGE (g:Genre {name: genre._text})
MERGE (b)-[:HAS_GENRE]->(g)

 b, authors
 authors  author
 (a: {name:author._text})
 (a)-[:]->(b);
View all (5 more lines)
The Neo4j Browser visualization below shows the imported graph:
xPath expressions
We can also provide an xPath expression to select nodes from an XML document. If we only want to return books that have the Computer genre, we could write the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(
  ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"",
  '/catalog/book[genre=\""Computer\""]'
)
YIELD value as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['title','price'] | attr._text] as pairs
RETURN id, pairs[0] as title, pairs[1] as price;
Table 5. Results
id title price
""bk101""
""XML Developer’s Guide""
""44.95""
""bk110""
""Microsoft .NET: The Programming Bible""
""36.95""
""bk111""
""MSXML3: A Comprehensive Guide""
""36.95""
""bk112""
""Visual Studio 7: A Comprehensive Guide""
""49.95""
In this case we return only id, title and prize but we can return any other elements
We can also return just a single specific element. For example, the following query returns the author of the book with id = bg102
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(
  'https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml',
  '/catalog/book[@id=""bk102""]/author'
)
YIELD value as result
WITH result._text as author
RETURN author;
Table 6. Results
author
""Ralls, Kim""
Avoid OOM using Xpath
Generally, to avoid Heap Space Errors, to handle large files you should always try to return the result as a stream, and not as a unique result, to avoid java.lang.OutOfMemoryError: Java heap space, if possible For example, with a file like this: .book.xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!-- <graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd""> -->
<graphml name=""databases"">
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""labels"" for=""node"" attr.name=""labels""/>
<key id=""summary"" for=""edge"" attr.name=""summary""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
  <node id=""n0"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
  <node id=""n1"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1964</data><data key=""name"">Keanu Reeves</data></node>
  <node id=""n2"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Carrie-Anne Moss</data></node>
  <node id=""n3"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
  <node id=""n4"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1960</data><data key=""name"">Hugo Weaving</data></node>
  <node id=""n5"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Lilly Wachowski</data></node>
  <node id=""n6"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1965</data><data key=""name"">Lana Wachowski</data></node>
    // a lot of other node tags...

  <edge id=""e17"" source=""n3"" target=""n10"" label=""ACTED_IN""><data key=""label"">ACTED_IN</data><data key=""roles"">[""Morpheus""]</data></edge>
  <edge id=""e18"" source=""n4"" target=""n10"" label=""ACTED_IN""><data key=""label"">ACTED_IN</data><data key=""roles"">[""Agent Smith""]</data></edge>
    // a lot of other edge tags...

  <foo id=""id2"">foo2</foo>
  <foo id=""id3"">foo3</foo>
 // ...
</graph>
</graphml>
you can extract all the children of the graph tag via:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml('databases.xml', '/graphml/graph/*', {})
YIELD value RETURN value ORDER BY value.id
Table 7. Results
value
{""_children"":[{""_type"":""data"",""_text"":""ACTED_IN"",""key"":""label""},{""_type"":""data"",""_text"":""[""Morpheus""]"",""key"":""roles""}],""_type"":""edge"",""id"":""e17"",""label"":""ACTED_IN"",""source"":""n3"",""target"":""n10""}
{""_children"":[{""_type"":""data"",""_text"":""ACTED_IN"",""key"":""label""},{""_type"":""data"",""_text"":""[""Agent Smith""]"",""key"":""roles""}],""_type"":""edge"",""id"":""e18"",""label"":""ACTED_IN"",""source"":""n4"",""target"":""n10""}
{""_type"":""foo"",""id"":""id2"",""_text"":""foo2""}
{""_type"":""foo"",""id"":""id3"",""_text"":""foo3""}
{""_children"":[{""_type"":""data"",""_text"":"":Movie"",""key"":""labels""},{""_type"":""data"",""_text"":""The Matrix"",""key"":""title""},{""_type"":""data"",""_text"":""Welcome to the Real World"",""key"":""tagline""},{""_type"":""data"",""_text"":""1999"",""key"":""released""}],""_type"":""node"",""id"":""n0"",""labels"":"":Movie""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1964"",""key"":""born""},{""_type"":""data"",""_text"":""Keanu Reeves"",""key"":""name""}],""_type"":""node"",""id"":""n1"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Carrie-Anne Moss"",""key"":""name""}],""_type"":""node"",""id"":""n2"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1961"",""key"":""born""},{""_type"":""data"",""_text"":""Laurence Fishburne"",""key"":""name""}],""_type"":""node"",""id"":""n3"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1960"",""key"":""born""},{""_type"":""data"",""_text"":""Hugo Weaving"",""key"":""name""}],""_type"":""node"",""id"":""n4"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Lilly Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n5"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1965"",""key"":""born""},{""_type"":""data"",""_text"":""Lana Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n6"",""labels"":"":Person""}
Or if you want to include only node tag:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml('largeFile.xml', '/graphml/graph/node', {})
YIELD value RETURN value ORDER BY value.id
Table 8. Results
value
{""_children"":[{""_type"":""data"",""_text"":"":Movie"",""key"":""labels""},{""_type"":""data"",""_text"":""The Matrix"",""key"":""title""},{""_type"":""data"",""_text"":""Welcome to the Real World"",""key"":""tagline""},{""_type"":""data"",""_text"":""1999"",""key"":""released""}],""_type"":""node"",""id"":""n0"",""labels"":"":Movie""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1964"",""key"":""born""},{""_type"":""data"",""_text"":""Keanu Reeves"",""key"":""name""}],""_type"":""node"",""id"":""n1"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Carrie-Anne Moss"",""key"":""name""}],""_type"":""node"",""id"":""n2"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1961"",""key"":""born""},{""_type"":""data"",""_text"":""Laurence Fishburne"",""key"":""name""}],""_type"":""node"",""id"":""n3"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1960"",""key"":""born""},{""_type"":""data"",""_text"":""Hugo Weaving"",""key"":""name""}],""_type"":""node"",""id"":""n4"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Lilly Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n5"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1965"",""key"":""born""},{""_type"":""data"",""_text"":""Lana Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n6"",""labels"":"":Person""}
You can also include multiple tag names with or, e.g.:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml('largeFile.xml', 'graphml/graph/*[self::node or self::edge]', {})
YIELD value RETURN value ORDER BY value.id
Table 9. Results
value
{""_children"":[{""_type"":""data"",""_text"":""ACTED_IN"",""key"":""label""},{""_type"":""data"",""_text"":""[""Morpheus""]"",""key"":""roles""}],""_type"":""edge"",""id"":""e17"",""label"":""ACTED_IN"",""source"":""n3"",""target"":""n10""}
{""_children"":[{""_type"":""data"",""_text"":""ACTED_IN"",""key"":""label""},{""_type"":""data"",""_text"":""[""Agent Smith""]"",""key"":""roles""}],""_type"":""edge"",""id"":""e18"",""label"":""ACTED_IN"",""source"":""n4"",""target"":""n10""}
{""_children"":[{""_type"":""data"",""_text"":"":Movie"",""key"":""labels""},{""_type"":""data"",""_text"":""The Matrix"",""key"":""title""},{""_type"":""data"",""_text"":""Welcome to the Real World"",""key"":""tagline""},{""_type"":""data"",""_text"":""1999"",""key"":""released""}],""_type"":""node"",""id"":""n0"",""labels"":"":Movie""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1964"",""key"":""born""},{""_type"":""data"",""_text"":""Keanu Reeves"",""key"":""name""}],""_type"":""node"",""id"":""n1"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Carrie-Anne Moss"",""key"":""name""}],""_type"":""node"",""id"":""n2"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1961"",""key"":""born""},{""_type"":""data"",""_text"":""Laurence Fishburne"",""key"":""name""}],""_type"":""node"",""id"":""n3"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1960"",""key"":""born""},{""_type"":""data"",""_text"":""Hugo Weaving"",""key"":""name""}],""_type"":""node"",""id"":""n4"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1967"",""key"":""born""},{""_type"":""data"",""_text"":""Lilly Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n5"",""labels"":"":Person""}
{""_children"":[{""_type"":""data"",""_text"":"":Person"",""key"":""labels""},{""_type"":""data"",""_text"":""1965"",""key"":""born""},{""_type"":""data"",""_text"":""Lana Wachowski"",""key"":""name""}],""_type"":""node"",""id"":""n6"",""labels"":"":Person""}
See Java Xpath Doc and w3School tutorial for more examples and details.
Extracting data structures
We can turn values into a map using the apoc.map.fromPairs function.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.xml(""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"")
yield value as catalog
UNWIND catalog._children as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['author','title'] | [attr._type, attr._text]] as pairs
WITH id, apoc.map.fromPairs(pairs) AS value
RETURN id, value
Table 10. Results
id value
""bk101""
{title: ""XML Developer’s Guide"", author: ""Arciniegas, Fabio""}
""bk102""
{title: ""Midnight Rain"", author: ""Ralls, Kim""}
""bk103""
{title: ""Maeve Ascendant"", author: ""Corets, Eva""}
""bk104""
{title: ""Oberon’s Legacy"", author: ""Corets, Eva""}
""bk105""
{title: ""The Sundered Grail"", author: ""Corets, Eva""}
""bk106""
{title: ""Lover Birds"", author: ""Randall, Cynthia""}
""bk107""
{title: ""Splish Splash"", author: ""Thurman, Paula""}
""bk108""
{title: ""Creepy Crawlies"", author: ""Knorr, Stefan""}
""bk109""
{title: ""Paradox Lost"", author: ""Kress, Peter""}
""bk110""
{title: ""Microsoft .NET: The Programming Bible"", author: ""O’Brien, Tim""}
""bk111""
{title: ""MSXML3: A Comprehensive Guide"", author: ""O’Brien, Tim""}
""bk112""
{title: ""Visual Studio 7: A Comprehensive Guide"", author: ""Galos, Mike""}
And now we can cleanly access the attributes from the map.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.xml(""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"")
yield value as catalog
UNWIND catalog._children as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['author','title'] | [attr._type, attr._text]] as pairs
WITH id, apoc.map.fromPairs(pairs) AS value
RETURN id, value.title, value.author
Table 11. Results
id value.title value.author
""bk101""
""XML Developer’s Guide""
""Arciniegas, Fabio""
""bk102""
""Midnight Rain""
""Ralls, Kim""
""bk103""
""Maeve Ascendant""
""Corets, Eva""
""bk104""
""Oberon’s Legacy""
""Corets, Eva""
""bk105""
""The Sundered Grail""
""Corets, Eva""
""bk106""
""Lover Birds""
""Randall, Cynthia""
""bk107""
""Splish Splash""
""Thurman, Paula""
""bk108""
""Creepy Crawlies""
""Knorr, Stefan""
""bk109""
""Paradox Lost""
""Kress, Peter""
""bk110""
""Microsoft .NET: The Programming Bible""
""O’Brien, Tim""
""bk111""
""MSXML3: A Comprehensive Guide""
""O’Brien, Tim""
""bk112""
""Visual Studio 7: A Comprehensive Guide""
""Galos, Mike""
Binary file
You can also import a file from a binary byte[] (not compressed) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(`binaryGzipByteArray`, '/', {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(`binaryFileNotCompressed`, '/', {compression: 'NONE'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress('<?xml version=""1.0"" encoding=""UTF-8""?>
<parent name=""databases"">
    <child name=""Neo4j"">
        Neo4j is a graph database
    </child>
    <child name=""relational"">
        <grandchild name=""MySQL""><![CDATA[
            MySQL is a database & relational
            ]]>
        </grandchild>
        <grandchild name=""Postgres"">
            Postgres is a relational database
        </grandchild>
    </child>
</parent>', {compression: 'DEFLATE'}) as xmlCompressed

 apoc..xml(xmlCompressed, , {compression: })
 value
 value
View all (4 more lines)
Table 12. Results
value
[source,json] ---- { ""_type"": ""parent"", ""name"": ""databases"", ""_children"": [{ ""_type"": ""child"", ""name"": ""Neo4j"", ""_text"": ""Neo4j is a graph database"" }, { ""_type"": ""child"", ""name"": ""relational"", ""_children"": [{ ""_type"": ""grandchild"", ""name"": ""MySQL"", ""_text"": ""MySQL is a database & relational"" }, { ""_type"": ""grandchild"", ""name"": ""Postgres"", ""_text"": ""Postgres is a relational database"" } ] } ] } ----
More documentation of apoc.load.xml
apoc.load.jsonParams
apoc.lock
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.compress;"apoc.util.compress
Contents
Signature
Input parameters
Config parameters
Usage Examples
Function
apoc.util.compress(data String, config Map<String, Any>) - zips the given string.
Signature
None
Copy to Clipboard
apoc.util.compress(data :: STRING?, config = {} :: MAP?) :: (BYTEARRAY?)
Input parameters
Name Type Default
data
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
compression
enum
GZIP
The compression algorithm used to compress the string
Accepted values are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY, NONE (that is conversion to binary without compression)
charset
enum
UTF-8
The charset used to compress the string
Accepted values are: UTF-8, UTF-16, UTF-16BE, UTF-16LE, UTF-32, US-ASCII, ISO-8859-1
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.compress('Mätrix II 哈哈😄123', {charset: 'UTF-32'}) AS value
Table 2. Results
value
{""0"":31.0,""1"":-117.0,""2"":8.0,""3"":0.0,""4"":0.0,""5"":0.0,""6"":0.0,""7"":0.0,""8"":0.0,""9"":-1.0,""10"":99.0,""11"":96.0,""12"":96.0,""13"":-16.0,""14"":101.0,""15"":96.0,""16"":96.0,""17"":120.0,""18"":2.0,""19"":-60.0,""20"":37.0,""21"":64.0,""22"":92.0,""23"":4.0,""24"":-60.0,""25"":-103.0,""26"":64.0,""27"":92.0,""28"":1.0,""29"":-60.0,""30"":10.0,""31"":64.0,""32"":-20.0,""33"":9.0,""34"":-59.0,""35"":64.0,""36"":118.0,""37"":-56.0,""38"":9.0,""39"":48.0,""40"":102.0,""41"":-4.0,""42"":-58.0,""43"":2.0,""44"":-28.0,""45"":27.0,""46"":2.0,""47"":-79.0,""48"":17.0,""49"":16.0,""50"":27.0,""51"":3.0,""52"":0.0,""53"":113.0,""54"":-125.0,""55"":-33.0,""56"":46.0,""57"":64.0,""58"":0.0,""59"":0.0,""60"":0.0}
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.compress('Mätrix II 哈哈😄123', {compression: 'DEFLATE'}) AS value
Table 3. Results
value
{""0"":120.0,""1"":-100.0,""2"":-13.0,""3"":61.0,""4"":-68.0,""5"":-92.0,""6"":-92.0,""7"":40.0,""8"":-77.0,""9"":66.0,""10"":-63.0,""11"":-45.0,""12"":83.0,""13"":-31.0,""14"":-23.0,""15"":-28.0,""16"":14.0,""17"":32.0,""18"":-6.0,""19"":48.0,""20"":127.0,""21"":70.0,""22"":-117.0,""23"":-95.0,""24"":-111.0,""25"":49.0,""26"":0.0,""27"":-111.0,""28"":-127.0,""29"":11.0,""30"":-113.0}
Cypher
Copy to Clipboard
Run in Neo4j Browser
Return apoc.util.compress(""Example"", {charset: 'UTF-16'}) AS value
Table 4. Results
value
{""0"":31.0,""1"":-117.0,""2"":8.0,""3"":0.0,""4"":0.0,""5"":0.0,""6"":0.0,""7"":0.0,""8"":0.0,""9"":-1.0,""10"":-5.0,""11"":-9.0,""12"":-97.0,""13"":-63.0,""14"":-107.0,""15"":-95.0,""16"":-126.0,""17"":33.0,""18"":-111.0,""19"":33.0,""20"":-105.0,""21"":-95.0,""22"":-128.0,""23"":33.0,""24"":-121.0,""25"":33.0,""26"":21.0,""27"":0.0,""28"":9.0,""29"":100.0,""30"":12.0,""31"":-109.0,""32"":16.0,""33"":0.0,""34"":0.0,""35"":0.0}
apoc.util.validate
apoc.util.decompress
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.validate;"apoc.util.validate
Contents
Signature
Input parameters
Usage Examples
Procedure
apoc.util.validate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown.
Signature
None
Copy to Clipboard
apoc.util.validate(predicate :: BOOLEAN?, message :: STRING?, params :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
predicate
BOOLEAN?
null
message
STRING?
null
params
LIST? OF ANY?
null
Usage Examples
The following throws an exception because the predicate is true:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH true AS predicate
CALL apoc.util.validate(predicate,'message %d',[42])
RETURN count(*);
Table 1. Results
Failed to invoke procedure apoc.util.validate: Caused by: java.lang.RuntimeException: message 42
The following does nothing because the predicate is false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH false AS predicate
CALL apoc.util.validate(predicate,'message %d',[42])
RETURN count(*);
Table 2. Results
count(*)
1
apoc.util.sleep
apoc.util.compress
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.sleep;"apoc.util.sleep
Contents
Signature
Input parameters
Usage Examples
Procedure
apoc.util.sleep(duration Integer) - causes the currently running Cypher to sleep for the given duration of milliseconds (the transaction termination is honored).
Signature
None
Copy to Clipboard
apoc.util.sleep(duration :: INTEGER?) :: VOID
Input parameters
Name Type Default
duration
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.currentTimestamp() AS start
CALL apoc.util.sleep(1000)
WITH start, apoc.date.currentTimestamp() AS end
RETURN datetime({epochmillis: start}) AS start,
       datetime({epochmillis: end}) AS end;
Table 1. Results
start end
2021-01-19T12:19:11.978Z
2021-01-19T12:19:12.978Z
apoc.util
apoc.util.validate
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util;"apoc.util
Qualified Name Type
apoc.util.sleep
apoc.util.sleep(duration Integer) - causes the currently running Cypher to sleep for the given duration of milliseconds (the transaction termination is honored).
Procedure
apoc.util.validate
apoc.util.validate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown.
Procedure
apoc.util.compress
apoc.util.compress(data String, config Map<String, Any>) - zips the given string.
Function
apoc.util.decompress
apoc.util.decompress(data ByteArray, config Map<String, Any>) - unzips the given byte array.
Function
apoc.util.md5
apoc.util.md5(values [Any]) - returns the MD5 checksum of the concatenation of all string values in the given list. MD5 is a weak hashing algorithm which is unsuitable for cryptographic use-cases.
Function
apoc.util.sha1
apoc.util.sha1(values [Any]) - returns the SHA1 of the concatenation of all string values in the given list.
Function
apoc.util.sha256
apoc.util.sha256(values [Any]) - returns the SHA256 of the concatenation of all string values in the given list.
Function
apoc.util.sha384
apoc.util.sha384(values [Any]) - returns the SHA384 of the concatenation of all string values in the given list.
Function
apoc.util.sha512
apoc.util.sha512(values [Any]) - returns the SHA512 of the concatenation of all string values in the list.
Function
apoc.util.validatePredicate
apoc.util.validatePredicate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown, otherwise it returns true (for use inside WHERE subclauses).
Function
apoc.trigger.resume
apoc.util.sleep
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.validatePredicate;"apoc.util.validatePredicate
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.validatePredicate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown, otherwise it returns true (for use inside WHERE subclauses).
Signature
None
Copy to Clipboard
apoc.util.validatePredicate(predicate :: BOOLEAN?, message :: STRING?, params :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
predicate
BOOLEAN?
null
message
STRING?
null
params
LIST? OF ANY?
null
Usage Examples
The following throws an exception because the predicate is true:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a)
WHERE apoc.util.validatePredicate(true,'message %d',[42])
RETURN a
Table 1. Results
Failed to invoke procedure apoc.util.validatePredicate: Caused by: java.lang.RuntimeException: message 42
The following returns true because the predicate is false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.validatePredicate(false,'message %d',[42]) AS result
Table 2. Results
result
true
apoc.util.sha512
apoc.xml
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.xml;"apoc.xml
Qualified Name Type
apoc.xml.parse
apoc.xml.parse(data String, path String, config Map<String, Any>, simple Boolean) - parses the given XML string as a map.
Function
apoc.util.validatePredicate
apoc.xml.parse
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.xml/apoc.xml.parse;"apoc.xml.parse
Contents
Signature
Input parameters
Function
apoc.xml.parse(data String, path String, config Map<String, Any>, simple Boolean) - parses the given XML string as a map.
Signature
None
Copy to Clipboard
apoc.xml.parse(data :: STRING?, path = / :: STRING?, config = {} :: MAP?, simple = false :: BOOLEAN?) :: (MAP?)
Input parameters
Name Type Default
data
STRING?
null
path
STRING?
/
config
MAP?
{}
simple
BOOLEAN?
false
More documentation of apoc.xml.parse
apoc.xml
Configuration Options
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import/xml;"Load XML
Contents
Procedure and Function Overview
apoc.load.xml
apoc.xml.parse
apoc.import.xml
Importing from a file
Examples
Import from local file
Import from GitHub
xPath expressions
Extracting data structures
Import XML directly
Many existing enterprise applications, endpoints, and files use XML as data exchange format. The Load XML procedures allow us to process these files.
Procedure and Function Overview
The table below describes the available procedures and functions:
Qualified Name Type
apoc.load.xml
apoc.load.xml('http://example.com/test.xml', 'xPath',config, false) YIELD value as doc CREATE (p:Person) SET p.name = doc.name - load from XML URL (e.g. web-api) to import XML as single nested map with attributes and _type, _text and _childrenx fields.
Procedure
apoc.xml.parse
RETURN apoc.xml.parse(<xml string>, <xPath string>, config, false) AS value
Function
apoc.import.xml
apoc.import.xml(file,config) - imports graph from provided file
Procedure
apoc.load.xml
This procedure takes a file or HTTP URL and parses the XML into a map data structure.
signature
apoc.load.xml(urlOrBinary :: ANY?, path = / :: STRING?, config = {} :: MAP?, simple = false :: BOOLEAN?) :: (value :: MAP?)
The map is created using the following rules:
in simple mode, each type of children has its own entry in the parent map.
the element-type as key is prefixed with _ to prevent collisions with attributes.
if there is a single element, the entry will just have that element as value, not a collection.
if there is more than one element, there will be a list of values.
each child will still have its _type field to discern them.
This procedure supports the following config parameters:
Table 1. Config
name type default description
failOnError
boolean
true
fail if error encountered while parsing XML
headers
Map
{}
HTTP headers to be used when querying XML document
binary
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]`
null
If not null, allow to take binary data instead of a file name/url as first parameter. Similar to Binary file example
charset
java.nio.charset.Charset
UTF_8
The optional charset, with binary config not null and with string as file
apoc.xml.parse
If our dataset contains nodes with XML as property values, they can be parsed into maps with the apoc.xml.parse function.
signature
apoc.xml.parse(data :: STRING?, path = / :: STRING?, config = {} :: MAP?, simple = false :: BOOLEAN?) :: (MAP?)
This function supports the following config parameter:
Table 2. Config
name type default description
failOnError
boolean
true
fail if error encountered while parsing XML
Cypher
The following parses an XML string into a Cypher map
Copy to Clipboard
Run in Neo4j Browser
WITH '<?xml version=""1.0""?><table><tr><td><img src=""pix/logo-tl.gif""></img></td></tr></table>' AS xmlString
RETURN apoc.xml.parse(xmlString) AS value
Table 3. Results
value
{_type: ""table"", _children: [{_type: ""tr"", _children: [{_type: ""td"", _children: [{_type: ""img"", src: ""pix/logo-tl.gif""}]}]}]}
apoc.import.xml
If we don’t want to do any transformation of the XML before creating a graph structure, we can create a 1:1 mapping of XML into the graph using the apoc.import.xml procedure.
signature
apoc.import.xml(urlOrBinary :: ANY?, config = {} :: MAP?) :: (node :: NODE?)
This procedure will return a node representing the XML document containing nodes and relationships underneath mapping to the XML structure.
The following mapping rules are applied:
xml label properties
document
XmlDocument
_xmlVersion, _xmlEncoding
processing instruction
XmlProcessingInstruction
_piData, _piTarget
Element/Tag
XmlTag
_name
Attribute
n/a
property in the XmlTag node
Text
XmlWord
for each word a separate node is created
The nodes for the XML document are connected:
relationship type description
:IS_CHILD_OF
pointing to a nested xml element
:FIRST_CHILD_OF
pointing to the first child
:NEXT_SIBLING
pointing to the next xml element on the same nesting level
:NEXT
produces a linear chain through the full document
:NEXT_WORD
only produced if config map has createNextWordRelationships:true. Connects words in XML to a text flow.
This procedure supports the following config parameters:
Table 4. Config
config option default value description
connectCharacters
false
if true the xml text elements are child nodes of their tags, interconnected by relationships of type relType (see below)
filterLeadingWhitespace
false
if true leading whitespace is skipped for each line
delimiter
\s (regex whitespace)
if given, split text elements with the delimiter into separate nodes
label
XmlCharacter
label to use for text element representation
relType
NE
relationship type to be used for connecting the text elements into one linked list
charactersForTag
{}
map of tagname → string. For the given tag names an additional text element is added containing the value as text property. Useful e.g. for <lb/> tags in TEI-XML to be represented as <lb> </lb>.
Importing from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Examples
The examples in this section are based on the Microsoft book.xml file.
Xml
book.xml
Copy to Clipboard
<?xml version=""1.0""?>
<catalog>
   <book id=""bk101"">
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications
      with XML.</description>
   </book>
   <book id=""bk102"">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      <genre>Fantasy</genre>
      5.95
      2000-12-16
      A former architect battles corporate zombies,
...
View all (4 more lines)
This file can be downloaded from GitHub.
Import from local file
The books.xml file described below contains the first two books from the Microsoft Books XML file. We’ll use the smaller file in this section to simplify our examples.
Xml
books.xml
Copy to Clipboard
<?xml version=""1.0""?>
<catalog>
   <book id=""bk101"">
      <author>Gambardella, Matthew</author>
      <author>Arciniegas, Fabio</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications
      with XML.</description>
   </book>
   <book id=""bk102"">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      Fantasy
      5.95
      2000-12-16
      A former architect battles corporate zombies,
      an evil sorceress, and her own childhood to become queen
      of the world.
   
View all (9 more lines)
We’ll place this file into the import directory of our Neo4j instance. Let’s now write a query using the apoc.load.xml procedure to explore this file.
Cypher
The following query processes books.xml and returns the content as Cypher data structures
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
RETURN value
Table 5. Results
value
{_type: ""catalog"", _children: [{_type: ""book"", _children: [{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}, {_type: ""title"", _text: ""XML Developer’s Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""44.95""}, {_type: ""publish_date"", _text: ""2000-10-01""}, {_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}], id: ""bk101""}, {_type: ""book"", _children: [{_type: ""author"", _text: ""Ralls, Kim""}, {_type: ""title"", _text: ""Midnight Rain""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-12-16""}, {_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}], id: ""bk102""}]}
We get back a map representing the XML structure. Every time an XML element is nested inside another one, it is accessible via the .children property. We can write the following query to get a better understanding of what our file contains.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
UNWIND value._children AS book
RETURN book.id AS bookId,
       [item in book._children WHERE item._type = ""title""][0] AS title,
       [item in book._children WHERE item._type = ""description""][0] AS description,
       [item in book._children WHERE item._type = ""author""] AS authors,
       [item in book._children WHERE item._type = ""genre""][0] AS genre;
Table 6. Results
bookId title description authors genre
""bk101""
{_type: ""title"", _text: ""XML Developer’s Guide""}
{_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}
[{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}]
{_type: ""genre"", _text: ""Computer""}
""bk102""
{_type: ""title"", _text: ""Midnight Rain""}
{_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}
[{_type: ""author"", _text: ""Ralls, Kim""}]
{_type: ""genre"", _text: ""Fantasy""}
Let’s now create a graph of books and their metadata, authors, and genres.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""file:///books.xml"")
YIELD value
UNWIND value._children AS book

WITH book.id AS bookId,
     [item in book._children WHERE item._type = ""title""][0] AS title,
     [item in book._children WHERE item._type = ""description""][0] AS description,
     [item in book._children WHERE item._type = ""author""] AS authors,
     [item in book._children WHERE item._type = ""genre""][0] AS genre

MERGE (b:Book {id: bookId})
SET b.title = title._text, b.description = description._text

MERGE (g:Genre {name: genre._text})
MERGE (b)-[:HAS_GENRE]->(g)

 b, authors
 authors  author
 (a: {name:author._text})
 (a)-[:]->(b);
View all (5 more lines)
The Neo4j Browser visualization below shows the imported graph:
You can use failOnError configuration to handle the result in case of incorrect url or xml. For example, with the help of the apoc.when procedure, you can return nothingToDo as result with incorrect url:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(""MY_XML_URL"", '', {failOnError:false})
YIELD value
WITH value as valueXml
call apoc.do.when(valueXml[""_type""] is null, ""return 'nothingToDo' as result"", ""return valueXml as result"", {valueXml: valueXml})
YIELD value
UNWIND value[""result""] as result
RETURN result
Import from GitHub
We can also process XML files from HTTP or HTTPS URIs. Let’s start by processing the books.xml file hosted on GitHub.
This time we’ll pass in true as the 4th argument of the procedure. This means that the XML will be parsed in simple mode.
Cypher
The following query loads the books.xml file from GitHub using simple mode
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
RETURN value;
Table 7. Results
value
{_type: ""catalog"", _catalog: [{_type: ""book"", _book: [{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}, {_type: ""title"", _text: ""XML Developer’s Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""44.95""}, {_type: ""publish_date"", _text: ""2000-10-01""}, {_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}], id: ""bk101""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Ralls, Kim""}, {_type: ""title"", _text: ""Midnight Rain""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-12-16""}, {_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}], id: ""bk102""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""Maeve Ascendant""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2000-11-17""}, {_type: ""description"", _text: ""After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.""}], id: ""bk103""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""Oberon’s Legacy""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2001-03-10""}, {_type: ""description"", _text: ""In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.""}], id: ""bk104""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Corets, Eva""}, {_type: ""title"", _text: ""The Sundered Grail""}, {_type: ""genre"", _text: ""Fantasy""}, {_type: ""price"", _text: ""5.95""}, {_type: ""publish_date"", _text: ""2001-09-10""}, {_type: ""description"", _text: ""The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon’s Legacy.""}], id: ""bk105""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Randall, Cynthia""}, {_type: ""title"", _text: ""Lover Birds""}, {_type: ""genre"", _text: ""Romance""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-09-02""}, {_type: ""description"", _text: ""When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.""}], id: ""bk106""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Thurman, Paula""}, {_type: ""title"", _text: ""Splish Splash""}, {_type: ""genre"", _text: ""Romance""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-11-02""}, {_type: ""description"", _text: ""A deep sea diver finds true love twenty thousand leagues beneath the sea.""}], id: ""bk107""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Knorr, Stefan""}, {_type: ""title"", _text: ""Creepy Crawlies""}, {_type: ""genre"", _text: ""Horror""}, {_type: ""price"", _text: ""4.95""}, {_type: ""publish_date"", _text: ""2000-12-06""}, {_type: ""description"", _text: ""An anthology of horror stories about roaches, centipedes, scorpions and other insects.""}], id: ""bk108""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Kress, Peter""}, {_type: ""title"", _text: ""Paradox Lost""}, {_type: ""genre"", _text: ""Science Fiction""}, {_type: ""price"", _text: ""6.95""}, {_type: ""publish_date"", _text: ""2000-11-02""}, {_type: ""description"", _text: ""After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.""}], id: ""bk109""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""O’Brien, Tim""}, {_type: ""title"", _text: ""Microsoft .NET: The Programming Bible""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""36.95""}, {_type: ""publish_date"", _text: ""2000-12-09""}, {_type: ""description"", _text: ""Microsoft’s .NET initiative is explored in detail in this deep programmer’s reference.""}], id: ""bk110""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""O’Brien, Tim""}, {_type: ""title"", _text: ""MSXML3: A Comprehensive Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""36.95""}, {_type: ""publish_date"", _text: ""2000-12-01""}, {_type: ""description"", _text: ""The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.""}], id: ""bk111""}, {_type: ""book"", _book: [{_type: ""author"", _text: ""Galos, Mike""}, {_type: ""title"", _text: ""Visual Studio 7: A Comprehensive Guide""}, {_type: ""genre"", _text: ""Computer""}, {_type: ""price"", _text: ""49.95""}, {_type: ""publish_date"", _text: ""2001-04-16""}, {_type: ""description"", _text: ""Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C+, C#, and ASP are integrated into a comprehensive development environment.""}], id: ""bk112""}]}
We again get back back a map representing the XML structure, but the structure is different than when we don’t use simple mode. This time nested XML elements are accessible via a property of the element name prefixed with an _.
We can write the following query to get a better understanding of what our file contains.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/4.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
UNWIND value._catalog AS catalog
RETURN catalog.id AS bookId,
       [item in catalog._book WHERE item._type = ""title""][0] AS title,
       [item in catalog._book WHERE item._type = ""description""][0] AS description,
       [item in catalog._book WHERE item._type = ""author""] AS authors,
       [item in catalog._book WHERE item._type = ""genre""][0] AS genre;
Table 8. Results
bookId title description authors genre
""bk101""
{_type: ""title"", _text: ""XML Developer’s Guide""}
{_type: ""description"", _text: ""An in-depth look at creating applications with XML.""}
[{_type: ""author"", _text: ""Gambardella, Matthew""}, {_type: ""author"", _text: ""Arciniegas, Fabio""}]
{_type: ""genre"", _text: ""Computer""}
""bk102""
{_type: ""title"", _text: ""Midnight Rain""}
{_type: ""description"", _text: ""A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.""}
[{_type: ""author"", _text: ""Ralls, Kim""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk103""
{_type: ""title"", _text: ""Maeve Ascendant""}
{_type: ""description"", _text: ""After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk104""
{_type: ""title"", _text: ""Oberon’s Legacy""}
{_type: ""description"", _text: ""In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk105""
{_type: ""title"", _text: ""The Sundered Grail""}
{_type: ""description"", _text: ""The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon’s Legacy.""}
[{_type: ""author"", _text: ""Corets, Eva""}]
{_type: ""genre"", _text: ""Fantasy""}
""bk106""
{_type: ""title"", _text: ""Lover Birds""}
{_type: ""description"", _text: ""When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.""}
[{_type: ""author"", _text: ""Randall, Cynthia""}]
{_type: ""genre"", _text: ""Romance""}
""bk107""
{_type: ""title"", _text: ""Splish Splash""}
{_type: ""description"", _text: ""A deep sea diver finds true love twenty thousand leagues beneath the sea.""}
[{_type: ""author"", _text: ""Thurman, Paula""}]
{_type: ""genre"", _text: ""Romance""}
""bk108""
{_type: ""title"", _text: ""Creepy Crawlies""}
{_type: ""description"", _text: ""An anthology of horror stories about roaches, centipedes, scorpions and other insects.""}
[{_type: ""author"", _text: ""Knorr, Stefan""}]
{_type: ""genre"", _text: ""Horror""}
""bk109""
{_type: ""title"", _text: ""Paradox Lost""}
{_type: ""description"", _text: ""After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.""}
[{_type: ""author"", _text: ""Kress, Peter""}]
{_type: ""genre"", _text: ""Science Fiction""}
""bk110""
{_type: ""title"", _text: ""Microsoft .NET: The Programming Bible""}
{_type: ""description"", _text: ""Microsoft’s .NET initiative is explored in detail in this deep programmer’s reference.""}
[{_type: ""author"", _text: ""O’Brien, Tim""}]
{_type: ""genre"", _text: ""Computer""}
""bk111""
{_type: ""title"", _text: ""MSXML3: A Comprehensive Guide""}
{_type: ""description"", _text: ""The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.""}
[{_type: ""author"", _text: ""O’Brien, Tim""}]
{_type: ""genre"", _text: ""Computer""}
""bk112""
{_type: ""title"", _text: ""Visual Studio 7: A Comprehensive Guide""}
{_type: ""description"", _text: ""Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C+, C#, and ASP are integrated into a comprehensive development environment.""}
[{_type: ""author"", _text: ""Galos, Mike""}]
{_type: ""genre"", _text: ""Computer""}
Rather than just returning that data, we can create a graph of books and their metadata, authors, and genres.
Cypher
The following query processes book.xml and parses the results to pull out the title, description, genre, and authors
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://raw.githubusercontent.com/neo4j/apoc/4.0/src/test/resources/xml/books.xml"" AS uri
CALL apoc.load.xml(uri, '', {}, true)
YIELD value
UNWIND value._catalog AS catalog
WITH catalog.id AS bookId,
       [item in catalog._book WHERE item._type = ""title""][0] AS title,
       [item in catalog._book WHERE item._type = ""description""][0] AS description,
       [item in catalog._book WHERE item._type = ""author""] AS authors,
       [item in catalog._book WHERE item._type = ""genre""][0] AS genre

MERGE (b:Book {id: bookId})
SET b.title = title._text, b.description = description._text

MERGE (g:Genre {name: genre._text})
MERGE (b)-[:HAS_GENRE]->(g)

 b, authors
 authors  author
 (a: {name:author._text})
 (a)-[:]->(b);
View all (5 more lines)
The Neo4j Browser visualization below shows the imported graph:
xPath expressions
We can also provide an xPath expression to select nodes from an XML document. If we only want to return books that have the Computer genre, we could write the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(
  ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"",
  '/catalog/book[genre=\""Computer\""]'
)
YIELD value as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['title','price'] | attr._text] as pairs
RETURN id, pairs[0] as title, pairs[1] as price;
Table 9. Results
id title price
""bk101""
""XML Developer’s Guide""
""44.95""
""bk110""
""Microsoft .NET: The Programming Bible""
""36.95""
""bk111""
""MSXML3: A Comprehensive Guide""
""36.95""
""bk112""
""Visual Studio 7: A Comprehensive Guide""
""49.95""
In this case we return only id, title and prize but we can return any other elements
We can also return just a single specific element. For example, the following query returns the author of the book with id = bg102
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xml(
  'https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml',
  '/catalog/book[@id=""bk102""]/author'
)
YIELD value as result
WITH result._text as author
RETURN author;
Table 10. Results
author
""Ralls, Kim""
Extracting data structures
We can turn values into a map using the apoc.map.fromPairs function.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.xml(""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"")
yield value as catalog
UNWIND catalog._children as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['author','title'] | [attr._type, attr._text]] as pairs
WITH id, apoc.map.fromPairs(pairs) AS value
RETURN id, value
Table 11. Results
id value
""bk101""
{title: ""XML Developer’s Guide"", author: ""Arciniegas, Fabio""}
""bk102""
{title: ""Midnight Rain"", author: ""Ralls, Kim""}
""bk103""
{title: ""Maeve Ascendant"", author: ""Corets, Eva""}
""bk104""
{title: ""Oberon’s Legacy"", author: ""Corets, Eva""}
""bk105""
{title: ""The Sundered Grail"", author: ""Corets, Eva""}
""bk106""
{title: ""Lover Birds"", author: ""Randall, Cynthia""}
""bk107""
{title: ""Splish Splash"", author: ""Thurman, Paula""}
""bk108""
{title: ""Creepy Crawlies"", author: ""Knorr, Stefan""}
""bk109""
{title: ""Paradox Lost"", author: ""Kress, Peter""}
""bk110""
{title: ""Microsoft .NET: The Programming Bible"", author: ""O’Brien, Tim""}
""bk111""
{title: ""MSXML3: A Comprehensive Guide"", author: ""O’Brien, Tim""}
""bk112""
{title: ""Visual Studio 7: A Comprehensive Guide"", author: ""Galos, Mike""}
And now we can cleanly access the attributes from the map.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.xml(""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"")
yield value as catalog
UNWIND catalog._children as book
WITH book.id as id, [attr IN book._children WHERE attr._type IN ['author','title'] | [attr._type, attr._text]] as pairs
WITH id, apoc.map.fromPairs(pairs) AS value
RETURN id, value.title, value.author
Table 12. Results
id value.title value.author
""bk101""
""XML Developer’s Guide""
""Arciniegas, Fabio""
""bk102""
""Midnight Rain""
""Ralls, Kim""
""bk103""
""Maeve Ascendant""
""Corets, Eva""
""bk104""
""Oberon’s Legacy""
""Corets, Eva""
""bk105""
""The Sundered Grail""
""Corets, Eva""
""bk106""
""Lover Birds""
""Randall, Cynthia""
""bk107""
""Splish Splash""
""Thurman, Paula""
""bk108""
""Creepy Crawlies""
""Knorr, Stefan""
""bk109""
""Paradox Lost""
""Kress, Peter""
""bk110""
""Microsoft .NET: The Programming Bible""
""O’Brien, Tim""
""bk111""
""MSXML3: A Comprehensive Guide""
""O’Brien, Tim""
""bk112""
""Visual Studio 7: A Comprehensive Guide""
""Galos, Mike""
Import XML directly
We can write the following query to create a graph structure of the Microsoft books XML file.
Cypher
The following creates a graph structure based on the contents of books.xml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.xml(
  ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"",
  {relType:'NEXT_WORD', label:'XmlWord'}
)
YIELD node
RETURN node;
node
(:XmlDocument {_xmlVersion: ""1.0"", _xmlEncoding: ""UTF-8"", url: ""https://raw.githubusercontent.com/neo4j/apoc/4.0/src/test/resources/xml/books.xml""})
The Neo4j Browser visualization below shows the imported graph:
Import CSV
Import GraphML
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import/graphml;"Import GraphML
Contents
Available Procedures
Configuration parameters
Examples
Import simple GraphML file
Import GraphML file created by Export GraphML procedures
GraphML is used by other tools, like Gephi and CytoScape, to read graph data.
Available Procedures
The table below describes the available procedures:
Qualified Name Type
Configuration parameters
The procedure support the following config parameters:
Table 1. configuration options
param default description
readLabels
false
Creates node labels based on the value in the labels property of node elements
defaultRelationshipType
RELATED
The default relationship type to use if none is specified in the GraphML file
storeNodeIds
false
store the id property of node elements
batchSize
20000
The number of elements to process per transaction
Examples
This section includes examples showing how to use the import GraphML procedure.
Import simple GraphML file
The simple.graphml file contains a graph representation from the GraphML primer.
Xml
simple.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns
     http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
  <graph id=""G"" edgedefault=""undirected"">
    <node id=""n0""/>
    <node id=""n1""/>
    <node id=""n2""/>
    <node id=""n3""/>
    <node id=""n4""/>
    <node id=""n5""/>
    <node id=""n6""/>
    <node id=""n7""/>
    <node id=""n8""/>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  
View all (16 more lines)
Cypher
The following imports a graph based on simple.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""http://graphml.graphdrawing.org/primer/simple.graphml"", {})
If we run this query, we’ll see the following output:
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""http://graphml.graphdrawing.org/primer/simple.graphml""
""file""
""graphml""
11
12
0
618
0
-1
0
TRUE
NULL
We could also copy simple.graphml into Neo4j’s import directory, and import the file from there. If we take that approach, we’ll need to add the following entry to apoc.conf:
For reading from files we’ll have to enable the following config option:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
We can then run the import procedure in the following way:
Cypher
The following imports a graph based on simple.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""file://simple.graphml"", {})
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Simple Graph Visualization
Import GraphML file created by Export GraphML procedures
movies.graphml contains a subset of Neo4j’s movies graph, and was generated by the Export GraphML procedure.
Xml
movies.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""roles"" for=""edge"" attr.name=""roles""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n189"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1964</data><data key=""name"">Keanu Reeves</data></node>
<node id=""n190"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Carrie-Anne Moss</data></node>
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
:Person1960</data><data key=""name"">Hugo Weaving</data></node>
:Person1967</data><data key=""name"">Lilly Wachowski</data></node>
:Person1965</data><data key=""name"">Lana Wachowski</data></node>
:Person1952</data><data key=""name"">Joel Silver</data></node>
ACTED_IN</data><data key=""roles"">[""Neo""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Trinity""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Morpheus""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Agent Smith""]</data></edge>
DIRECTED</data></edge>
DIRECTED</data></edge>
PRODUCED</data></edge>
View all (14 more lines)
Cypher
The following imports a graph based on movies.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""movies.graphml"", {})
If we run this query, we’ll see the following output:
Table 3. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""file""
""graphml""
8
7
36
23
0
-1
0
TRUE
NULL
We can run the following query to see the imported graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=()-->()
RETURN p
Table 4. Results
p
({name: ""Laurence Fishburne"", born: ""1961"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Morpheus\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Carrie-Anne Moss"", born: ""1967"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Trinity\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", la bels: "":Movie""})
({name: ""Lana Wachowski"", born: ""1965"", labels: "":Person""})-[:DIRECTED {label: ""DIRECTED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Joel Silver"", born: ""1952"", labels: "":Person""})-[:PRODUCED {label: ""PRODUCED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Lilly Wachowski"", born: ""1967"", labels: "":Person""})-[:DIRECTED {label: ""DIRECTED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Keanu Reeves"", born: ""1964"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Neo\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "": Movie""})
({name: ""Hugo Weaving"", born: ""1960"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Agent Smith\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", la bels: "":Movie""})
The labels defined in the GraphML file have been added to the labels property on each node, rather than being added as a node label. We can set the config property readLabels: true to import native labels:
Cypher
The following imports a graph based on movies.graphml and stores node labels
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""movies.graphml"", {readLabels: true})
Table 5. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""file""
""graphml""
8
7
21
23
0
-1
0
TRUE
NULL
And now let’s re-run the query to see the imported graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=()-->()
RETURN;
Table 6. Results
p
(:Person {name: ""Lilly Wachowski"", born: ""1967""})-[:DIRECTED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Carrie-Anne Moss"", born: ""1967""})-[:ACTED_IN {roles: ""[\""Trinity\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Hugo Weaving"", born: ""1960""})-[:ACTED_IN {roles: ""[\""Agent Smith\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Laurence Fishburne"", born: ""1961""})-[:ACTED_IN {roles: ""[\""Morpheus\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Keanu Reeves"", born: ""1964""})-[:ACTED_IN {roles: ""[\""Neo\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Joel Silver"", born: ""1952""})-[:PRODUCED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Lana Wachowski"", born: ""1965""})-[:DIRECTED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
Load XML
Export
Was this page helpful?"
https://neo4j.com/docs/apoc/5/export/graphml;"Export to GraphML
Contents
Available Procedures
Configuration parameters
Exporting to a file
Exporting to S3
Using S3 protocol
Memory Requirements
Exporting a stream
Examples
Round trip separated GraphML files
With custom property key
Export whole database to GraphML
Export specified nodes and relationships to GraphML
Export results of Cypher query to GraphML
The export GraphML procedures export data into a format that’s used by other tools like Gephi and CytoScape to read graph data.
All Point or Temporal data types are exported formatted as a String
e.g:
Point 3d
{""crs"":""wgs-84-3d"",""latitude"":56.7,""longitude"":12.78,""height"":100.0}
Point 2d
{""crs"":""wgs-84-3d"",""latitude"":56.7,""longitude"":12.78,""height"":null}
Date
2018-10-10
LocalDateTime
2018-10-10T00:00
Note that, to perform a correct Point serialization, it is not recommended to export a point with coordinates x,y and crs: 'wgs-84', for example point({x: 56.7, y: 12.78, crs: 'wgs-84'}). Otherwise, the point will be exported with longitude and latitude (and heigth) instead of x and y (and z)
Available Procedures
The table below describes the available procedures:
Qualified Name Type
apoc.export.graphml.all
apoc.export.graphml.all(file,config) - exports whole database as graphml to the provided file
Procedure
apoc.export.graphml.data
apoc.export.graphml.data(nodes,rels,file,config) - exports given nodes and relationships as graphml to the provided file
Procedure
apoc.export.graphml.graph
apoc.export.graphml.graph(graph,file,config) - exports given graph object as graphml to the provided file
Procedure
apoc.export.graphml.query
apoc.export.graphml.query(query,file,config) - exports nodes and relationships from the cypher statement as graphml to the provided file
Procedure
The labels exported are ordered alphabetically. The output of labels() function is not sorted, use it in combination with apoc.coll.sort().
Configuration parameters
The procedures support the following config parameters:
Table 1. configuration options
param default description
format
gephi
In export to Graphml script define the export format. Possible value are: ""gephi"" and ""tinkerpop""
caption
It’s an array of string (i.e. ['name','title']) that define an ordered set of properties eligible as value for the Label value, if no match is found the there is a fallback to the node label, if the node label is missing the then the ID is used
useTypes
false
Write the attribute type information to the graphml output
batchSize
20000
define the batch size
delim
"",""
define the delimiter character (export csv)
arrayDelim
"";""
define the delimiter character for arrays (used in the bulk import)
useTypes
false
add type on file header (export csv and graphml export)
storeNodeIds
false
set nodes' ids (import/export graphml)
readLabels
false
read nodes' labels (import/export graphml)
defaultRelationshipType
""RELATED""
set relationship type (import/export graphml)
separateFiles
false
export results in separated file by type (nodes, relationships..)
stream
false
stream the xml directly to the client into the data field
useTypes
false
Write the attribute type information to the graphml output
source
Map<String,String>
Empty map
To be used together with target to import (via apoc.import.graphml) a relationships-only file. In this case the source and target attributes of edge tag are not based on an internal id of nodes but on a custom property value.
For example, with a path like (:Foo {name: ""aaa""})-[:KNOWS]→(:Bar {age: 666}), we can export the KNOWS rel with a config <edge id=""e2"" source=""aaa"" sourceType=""string"" target=""666"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data><data key=""id"">1</data></edge>. Note the additional sourceType/targetType to detect the right type during the import.
target
Map<String,String>
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting to S3
By default exporting to S3 is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, you can use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Memory Requirements
To support large uploads, the S3 uploading utility may use up to 2.25 GB of memory at a time. The actual usage will depend on the size of the upload, but will use a maximum of 2.25 GB.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Examples
This section includes examples showing how to use the export to Cypher procedures. These examples are based on a movies dataset, which can be imported by running the following Cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
Round trip separated GraphML files
With this dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo:Foo2:Foo0 {name:'foo', born:Date('2018-10-10'), place:point({ longitude: 56.7, latitude: 12.78, height: 100 })})-[:KNOWS]->(b:Bar {name:'bar',age:42, place:point({ longitude: 56.7, latitude: 12.78})});
CREATE (:Foo {name: 'zzz'})-[:KNOWS]->(:Bar {age: 0});
CREATE (:Foo {name: 'aaa'})-[:KNOWS {id: 1}]->(:Bar {age: 666});
we can execute these 3 export queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// Foo nodes
call apoc.export.graphml.query('MATCH (start:Foo)-[:KNOWS]->(:Bar) RETURN start', 'queryNodesFoo.graphml', {useTypes: true});

// Bar nodes
call apoc.export.graphml.query('MATCH (:Foo)-[:KNOWS]->(end:Bar) RETURN end', 'queryNodesBar.graphml', {useTypes: true});

// KNOWS rels
MATCH (:Foo)-[rel:KNOWS]->(:Bar)
WITH collect(rel) as rels
call apoc.export.graphml.data([], rels, 'queryRelationship.graphml', {useTypes: true})
YIELD nodes, relationships RETURN nodes, relationships;
In this case we will have these 3 files: .queryNodesFoo.graphml
Xml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born"" attr.type=""string""/>
<key id=""name"" for=""node"" attr.name=""name"" attr.type=""string""/>
<key id=""place"" for=""node"" attr.name=""place"" attr.type=""string""/>
<key id=""labels"" for=""node"" attr.name=""labels"" attr.type=""string""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n0"" labels="":Foo:Foo0:Foo2""><data key=""labels"">:Foo:Foo0:Foo2</data><data key=""born"">2018-10-10</data><data key=""name"">foo</data><data key=""place"">{""crs"":""wgs-84-3d"",""latitude"":12.78,""longitude"":56.7,""height"":100.0}</data></node>
<node id=""n3"" labels="":Foo""><data key=""labels"">:Foo</data><data key=""name"">zzz</data></node>
<node id=""n5"" labels="":Foo""><data key=""labels"">:Foo</data><data key=""name"">aaa</data></node>
</graph>
</graphml>
Xml
queryNodesBar.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""name"" for=""node"" attr.name=""name"" attr.type=""string""/>
<key id=""place"" for=""node"" attr.name=""place"" attr.type=""string""/>
<key id=""age"" for=""node"" attr.name=""age"" attr.type=""long""/>
<key id=""labels"" for=""node"" attr.name=""labels"" attr.type=""string""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n1"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""name"">bar</data><data key=""age"">42</data><data key=""place"">{""crs"":""wgs-84"",""latitude"":12.78,""longitude"":56.7,""height"":null}</data></node>
<node id=""n4"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""age"">0</data></node>
<node id=""n6"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""age"">666</data></node>
</graph>
</graphml>
Xml
queryRelationship.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""label"" for=""edge"" attr.name=""label"" attr.type=""string""/>
<key id=""id"" for=""edge"" attr.name=""id"" attr.type=""long""/>
<graph id=""G"" edgedefault=""directed"">
<edge id=""e0"" source=""n0"" target=""n1"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e1"" source=""n3"" target=""n4"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e2"" source=""n5"" target=""n6"" label=""KNOWS""><data key=""label"">KNOWS</data><data key=""id"">1</data></edge>
</graph>
</graphml>
So we can import, in another db, in this way, to recreate the original dataset, using these queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml('queryNodesFoo.graphml', {readLabels: true, storeNodeIds: true});
CALL apoc.import.graphml('queryNodesBar.graphml', {readLabels: true, storeNodeIds: true});
CALL apoc.import.graphml('queryRelationship.graphml', {readLabels: true, source: {label: 'Foo'}, target: {label: 'Bar'}});
Note that we have to execute the import of nodes before, and we used the useTypes: true to import the attribute id of node tags as a property and readLabels to populate nodes with labels.
With custom property key
Otherwise, we can leverage a custom property and avoid importing the id attribute (via useTypes:true) in this way (same dataset and nodes export query as before):
Cypher
Copy to Clipboard
Run in Neo4j Browser
// KNOWS rels
MATCH (:Foo)-[rel:KNOWS]->(:Bar)
WITH collect(rel) as rels
call apoc.export.graphml.data([], rels, 'queryRelationship.graphml',
  {useTypes: true, source: {id: 'name'}, label: {id: 'age'}})
YIELD nodes, relationships RETURN nodes, relationships;
Is strongly recommended using an unique constraint to ensure uniqueness, so in this case for label Foo and property name and for label Bar and property age
The above query generate this rel file:
Xml
queryRelationship.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""label"" for=""edge"" attr.name=""label"" attr.type=""string""/>
<key id=""id"" for=""edge"" attr.name=""id"" attr.type=""long""/>
<graph id=""G"" edgedefault=""directed"">
<edge id=""e0"" source=""foo"" sourceType=""string"" target=""42"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e1"" source=""zzz"" sourceType=""string"" target=""0"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e2"" source=""aaa"" sourceType=""string"" target=""666"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data><data key=""id"">1</data></edge>
</graph>
</graphml>
Finally, we can import the files using the same id (name and age) as above:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml('queryNodesFoo.graphml', {readLabels: true});
CALL apoc.import.graphml('queryNodesBar.graphml', {readLabels: true});
CALL apoc.import.graphml('queryRelationship.graphml',
  {readLabels: true, source: {label: 'Foo', id: 'name'}, target: {label: 'Bar', id: 'age'}});
Export whole database to GraphML
The apoc.export.graphml.all procedure exports the whole database to a GraphML file or as a stream.
Cypher
The following query exports the whole database to the file movies.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.graphml.all(""movies.graphml"", {})
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""database: nodes(8), rels(7)""
""graphml""
8
7
21
4
15
-1
0
TRUE
NULL
Xml
movies.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""roles"" for=""edge"" attr.name=""roles""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n189"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1964</data><data key=""name"">Keanu Reeves</data></node>
<node id=""n190"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Carrie-Anne Moss</data></node>
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
:Person1960</data><data key=""name"">Hugo Weaving</data></node>
:Person1967</data><data key=""name"">Lilly Wachowski</data></node>
:Person1965</data><data key=""name"">Lana Wachowski</data></node>
:Person1952</data><data key=""name"">Joel Silver</data></node>
ACTED_IN</data><data key=""roles"">[""Neo""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Trinity""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Morpheus""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Agent Smith""]</data></edge>
DIRECTED</data></edge>
DIRECTED</data></edge>
PRODUCED</data></edge>
View all (14 more lines)
Cypher
The following query returns a stream of the whole database in the data column
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.graphml.all(null, {stream:true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 3. Results
file nodes relationships properties data
NULL
8
7
21
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/XMLSchema-instance\""""
          xsi:schemaLocation=""\""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\"""">
   <key id=""\""born\"""" for=""\""node\"""" attr.name=""\""born\""""/>
   
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1964
       Keanu Reeves
     
     
       :Person
       1967
       Carrie-Anne Moss
     
     
       :Person
       1961
       Laurence Fishburne
     
     
       :Person
       1960
       Hugo Weaving
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       :Person
       1952
       Joel Silver
     
     
       ACTED_IN
       [\""Neo\""]
     
     
       ACTED_IN
       [\""Trinity\""]
     
     
       ACTED_IN
       [\""Morpheus\""]
     
     
       ACTED_IN
       [\""Agent Smith\""]
     
     
       DIRECTED
     
     
       DIRECTED
     
     
       PRODUCED
     
   
 
  ""
View all (137 more lines)
Export specified nodes and relationships to GraphML
The apoc.export.graphml.data procedure exports the specified nodes and relationships to a CSV file or as a stream.
Cypher
The following query exports all nodes with the :Person label with a name property that starts with L to the file movies-l.csv
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.name STARTS WITH ""L""
WITH collect(person) AS people
CALL apoc.export.graphml.data(people, [], ""movies-l.graphml"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 4. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-l.csv""
""data: nodes(3), rels(0)""
""csv""
3
0
6
2
3
20000
1
TRUE
NULL
Xml
movies-l.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
<node id=""n193"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Lilly Wachowski</data></node>
<node id=""n194"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1965</data><data key=""name"">Lana Wachowski</data></node>
</graph>
</graphml>
Cypher
The following query returns a stream of all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship in the data column
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.graphml.data(people + movies, actedInRels, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 5. Results
file nodes relationships properties data
NULL
5
4
15
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/XMLSchema-instance\""""
 xsi:schemaLocation=""\""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\"""">
   <key id=""\""born\"""" for=""\""node\"""" attr.name=""\""born\""""/>
   
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1964
       Keanu Reeves
     
     
       :Person
       1967
       Carrie-Anne Moss
     
     
       :Person
       1961
       Laurence Fishburne
     
     
       :Person
       1960
       Hugo Weaving
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       :Person
       1952
       Joel Silver
     
     
       ACTED_IN
       [\""Neo\""]
     
     
       ACTED_IN
       [\""Trinity\""]
     
     
       ACTED_IN
       [\""Morpheus\""]
     
     
       ACTED_IN
       [\""Agent Smith\""]
     
     
       DIRECTED
     
     
       DIRECTED
     
     
       PRODUCED
     
   
 ""
View all (136 more lines)
Export results of Cypher query to GraphML
The apoc.export.graphml.query procedure exports the results of a Cypher query to a CSV file or as a stream.
Cypher
The following query exports all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-directed.graphml
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[directed:DIRECTED]->(movie)
      RETURN person, directed, movie"" AS query
CALL apoc.export.graphml.query(query, ""movies-directed.graphml"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 6. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-directed.graphml""
""statement: nodes(3), rels(2)""
""graphml""
3
2
7
2
5
-1
0
TRUE
NULL
The contents of movies-directed.csv are shown below:
Xml
movies-directed.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n193"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Lilly Wachowski</data></node>
<node id=""n194"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1965</data><data key=""name"">Lana Wachowski</data></node>
<edge id=""e271"" source=""n193"" target=""n188"" label=""DIRECTED""><data key=""label"">DIRECTED</data></edge>
<edge id=""e272"" source=""n194"" target=""n188"" label=""DIRECTED""><data key=""label"">DIRECTED</data></edge>
</graph>
</graphml>
Cypher
The following query returns a stream of all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[directed:DIRECTED]->(movie)
      RETURN person, directed, movie"" AS query
CALL apoc.export.graphml.query(query, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 7. Results
file nodes relationships properties data
NULL
3
2
7
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/XMLSchema-instance\""""
          xsi:schemaLocation=""\""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\"""">
   <key id=""\""born\"""" for=""\""node\"""" attr.name=""\""born\""""/>
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       DIRECTED
     
     
       DIRECTED
     
   
 
  ""
View all (57 more lines)
You can also compress the files to export. See here for more information
Export to Cypher Script
Graph Refactoring
Was this page helpful?"
https://neo4j.com/docs/apoc/5/export/cypher;"Export to Cypher Script
Contents
Available Procedures
Configuration parameters
Exporting to a file
Exporting to S3
Using S3 protocol
Memory Requirements
Exporting a stream
Examples
Export to Cypher Shell format
Export to Neo4j Browser friendly format
Export using different Cypher update formats
Export to multiple files or columns
Export with multiple relationships with the same type
The export to Cypher procedures export data as Cypher statements that can then be used to import the data into another Neo4j instance.
When exporting nodes, if a node label does not contain a unique constraint the exporter will add a UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property to those nodes to ensure uniqueness of nodes when the export script is executed on a new database. The final step of the export script removes the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID, so they won’t exist in the new database once the script has finished executing.
If a node label does have a unique constraint, the property on which the unique constraint is defined will be used to ensure uniqueness.
Available Procedures
The table below describes the available procedures:
Qualified Name Type
apoc.export.cypher.all
apoc.export.cypher.all(file,config) - exports whole database incl. indexes as cypher statements to the provided file
Procedure
apoc.export.cypher.data
apoc.export.cypher.data(nodes,rels,file,config) - exports given nodes and relationships incl. indexes as cypher statements to the provided file
Procedure
apoc.export.cypher.graph
apoc.export.cypher.graph(graph,file,config) - exports given graph object incl. indexes as cypher statements to the provided file
Procedure
apoc.export.cypher.query
apoc.export.cypher.query(query,file,config) - exports nodes and relationships from the cypher statement incl. indexes as cypher statements to the provided file
Procedure
apoc.export.cypher.schema
apoc.export.cypher.schema(file,config) - exports all schema indexes and constraints to cypher
Procedure
The labels exported are ordered alphabetically. The output of labels() function is not sorted, use it in combination with apoc.coll.sort().
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
format
String
cypher-shell
Export format. The following values are supported:
cypher-shell - for import with Cypher Shell
neo4j-shell - for import with Neo4j Shell
plain - exports plain Cypher without begin, commit, or await commands. For import with Neo4j Browser
cypherFormat
String
create
Cypher update operation type. The following values are supported:
create - only uses the CREATE clause
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
useOptimizations
Map
{type: ""UNWIND_BATCH"", unwindBatchSize: 20}
Optimizations to use for Cypher statement generation. type supports the following values:
NONE - exports the file with CREATE statement
UNWIND_BATCH - exports the file by batching the entities with the UNWIND method as explained in Michael Hunger’s article on fast batched writes.
UNWIND_BATCH_PARAMS - similar to UNWIND_BATCH, but also uses parameters where appropriate
awaitForIndexes
Long
300
Timeout to use for db.awaitIndexes when using format: ""cypher-shell""
saveIndexNames
boolean
false
Save name indexes on export
saveConstraintNames
boolean
false
Save name constraints on export
multipleRelationshipsWithType
boolean
false
In case of multiple relationships of the same type between two nodes, add a UNIQUE IMPORT ID REL property in order to distinguish them when using MERGE.
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting to S3
By default exporting to S3 is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, you can use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Memory Requirements
To support large uploads, the S3 uploading utility may use up to 2.25 GB of memory at a time. The actual usage will depend on the size of the upload, but will use a maximum of 2.25 GB.
Exporting a stream
If we don’t want to export to a file, we can stream results back by providing a file name of null.
By default, all Cypher statements will be returned in a single row in the cypherStatements column.
Cypher
The following exports the whole database as a single row
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(null);
If we’re exporting a large database, we can batch these statements across multiple rows by providing the streamStatements:true config and configuring the batchSize config.
Cypher
The following exports the whole database across multiple rows based on batch size
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(null, {
    streamStatements: true,
    batchSize: 100
});
Examples
This section includes examples showing how to use the export to Cypher procedures. These examples are based on a movies' dataset, which can be imported by running the following Cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Export to Cypher Shell format
By default, the Cypher statements generated by the export to Cypher procedures are in the Cypher Shell format.
Cypher
The following query exports the whole database to all.cypher in the default cypher-shell format using the default UNWIND_BATCH optimization
Copy to Clipboard
Run in Neo4j Browser
// default config populated for illustration
CALL apoc.export.cypher.all(""all.cypher"", {
    format: ""cypher-shell"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 20}
})
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 2. Results
file batches source format nodes relationships properties time rows batchSize
""all.cypher""
1
""database: nodes(8), rels(7)""
""cypher""
8
7
21
10
15
20000
The contents of all.cypher, with extra lines added for readability, are shown below:
Cypher
all.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
:commit

:begin
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:1, properties:{born:1964, name:""Keanu Reeves""}}, {_id:2, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:3, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:4, properties:{born:1960, name:""Hugo Weaving""}}, {_id:5, properties:{born:1967, name:""Lilly Wachowski""}}, {_id:6, properties:{born:1965, name:""Lana Wachowski""}}, {_id:7, properties:{born:1952, name:""Joel Silver""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;
:commit

:begin
UNWIND [{start: {_id:1}, end: {_id:0}, properties:{roles:[""Neo""]}}, {start: {_id:2}, end: {_id:0}, properties:{roles:[""Trinity""]}}, {start: {_id:3}, end: {_id:0}, properties:{roles:[""Morpheus""]}}, {start: {_id:4}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (21 more lines)
This Cypher script executes 5 transactions, each surrounded by :begin and :commit commands. The transactions do the following:
Create a unique constraint on the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property
Import the Person and Movie nodes
Create ACTED_IN, PRODUCED, and DIRECTED relationships between these nodes
Remove the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property from the nodes
Drop the unique constraint on the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property
This script can be executed using the Cypher Shell command line tool.
For example, we could import the contents of all.cypher into a Neo4j Aura database by running the following command:
Bash
Copy to Clipboard
cat all.cypher | ./bin/cypher-shell -a <bolt-url> -u neo4j -p <password> --format verbose
Don’t forget to replace <bolt-url> and <password> with the appropriate credentials.
If we run this command against an empty database, we’ll see the following output:
Text
Copy to Clipboard
0 rows available after 70 ms, consumed after another 0 ms
Added 1 constraints
0 rows available after 16 ms, consumed after another 0 ms
Added 2 nodes, Set 8 properties, Added 4 labels
0 rows available after 40 ms, consumed after another 0 ms
Added 14 nodes, Set 42 properties, Added 28 labels
0 rows available after 51 ms, consumed after another 0 ms
Created 8 relationships, Set 8 properties
0 rows available after 38 ms, consumed after another 0 ms
Created 2 relationships
0 rows available after 38 ms, consumed after another 0 ms
Created 4 relationships
0 rows available after 20 ms, consumed after another 0 ms
Set 16 properties, Removed 16 labels
0 rows available after 3 ms, consumed after another 0 ms
Removed 1 constraints
Troubleshooting
If you are experimenting with imports that are failing you can add the --debug command line parameter, to see which statement was executed last and caused the failure.
Also check the memory configuration of your Neo4j instance, you might want to increase the HEAP size to 2–4GB using the dbms.memory.heap.max_size=2G setting in neo4j.conf.
We can also provide more memory to cypher-shell itself by prefixing the command with: JAVA_OPTS=-Xmx4G bin/cypher-shell …
If we don’t have file system access, or don’t want to write to a file for another reason, we can stream back the export statements.
Cypher
The following query streams back the whole database in the cypherStatements column
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(null, {
    batchSize: 5,
    streamStatements: true,
    format: ""cypher-shell"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 5}
})
YIELD nodes, relationships, properties, cypherStatements
RETURN nodes, relationships, properties, cypherStatements;
Table 3. Results
nodes relationships properties cypherStatements
16
0
34
"":begin CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.UNIQUE IMPORT ID) IS UNIQUE; :commit :begin UNWIND [{_id:0, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}, {_id:1, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Movie; UNWIND [{_id:35, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:36, properties:{born:1961, name:\""Laurence Fishburne\""}}, {_id:37, properties:{born:1965, name:\""Lana Wachowski\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:38, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:39, properties:{born:1952, name:\""Joel Silver\""}}, {_id:40, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:41, properties:{born:1967, name:\""Lilly Wachowski\""}}, {_id:42, properties:{born:1967, name:\""Carrie-Anne Moss\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:43, properties:{born:1965, name:\""Lana Wachowski\""}}, {_id:50, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:51, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:57, properties:{born:1967, name:\""Lilly Wachowski\""}}, {_id:58, properties:{born:1961, name:\""Laurence Fishburne\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:59, properties:{born:1952, name:\""Joel Silver\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit ""
16
14
42
"":begin UNWIND [{start: {_id:35}, end: {_id:0}, properties:{roles:[\""Trinity\""]}}, {start: {_id:36}, end: {_id:0}, properties:{roles:[\""Morpheus\""]}}, {start: {_id:50}, end: {_id:1}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:40}, end: {_id:0}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:51}, end: {_id:1}, properties:{roles:[\""Neo\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; :commit :begin UNWIND [{start: {_id:42}, end: {_id:1}, properties:{roles:[\""Trinity\""]}}, {start: {_id:38}, end: {_id:0}, properties:{roles:[\""Neo\""]}}, {start: {_id:58}, end: {_id:1}, properties:{roles:[\""Morpheus\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; UNWIND [{start: {_id:59}, end: {_id:1}, properties:{}}, {start: {_id:39}, end: {_id:0}, properties:{}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:PRODUCED]→(end) SET r += row.properties; :commit :begin UNWIND [{start: {_id:37}, end: {_id:0}, properties:{}}, {start: {_id:57}, end: {_id:0}, properties:{}}, {start: {_id:43}, end: {_id:1}, properties:{}}, {start: {_id:41}, end: {_id:1}, properties:{}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:DIRECTED]→(end) SET r += row.properties; :commit ""
16
14
42
"":begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin DROP CONSTRAINT uniqueConstraint; :commit ""
We can then copy/paste the content of the cypherStatements column (excluding the double quotes) into a Cypher Shell session, or into a local file that we stream into a Cypher Shell session.
Export to Neo4j Browser friendly format
The export to Cypher procedures support the config format: ""plain"", which is useful for later import using the Neo4j Browser.
Cypher
The following query exports the whole database to all-plain.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(""all-plain.cypher"", {
    format: ""plain"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 20}
})
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 4. Results
file batches source format nodes relationships properties time rows batchSize
""all-plain.cypher""
1
""database: nodes(8), rels(7)""
""cypher""
8
7
21
9
15
20000
The contents of all-plain.cypher, with extra lines added for readability, are shown below:
Cypher
all-plain.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;

UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:1, properties:{born:1964, name:""Keanu Reeves""}}, {_id:2, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:3, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:4, properties:{born:1960, name:""Hugo Weaving""}}, {_id:5, properties:{born:1967, name:""Lilly Wachowski""}}, {_id:6, properties:{born:1965, name:""Lana Wachowski""}}, {_id:7, properties:{born:1952, name:""Joel Silver""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:1}, end: {_id:0}, properties:{roles:[""Neo""]}}, {start: {_id:2}, end: {_id:0}, properties:{roles:[""Trinity""]}}, {start: {_id:3}, end: {_id:0}, properties:{roles:[""Morpheus""]}}, {start: {_id:4}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end) SET r += row.properties;

UNWIND [{start: {_id:7}, end: {_id:0}, properties:{}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (11 more lines)
We can then take the all-plain.cypher file and drag it onto the Neo4j Browser window. We should then see the following prompt:
Figure 1. Neo4j Browser prompt when we drag a file onto it
And if we click Paste in editor, the contents of the file will appear in the query editor:
Figure 2. Neo4j Browser query editor with the contents of all-plain.cypher
We can then press the play button next in the editor and the data will be imported.
Export using different Cypher update formats
The export to Cypher procedures generate Cypher statements using the CREATE, MATCH and MERGE clauses. The format is configured by the cypherFormat parameter. The following values are supported:
create - only uses the CREATE clause (default)
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
If we’re exporting a database for the first time we should use the default create format, but for subsequent exports the other formats may be more suitable.
Cypher
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-create.cypher using the create format
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-create.cypher"",
  { format: ""plain"", cypherFormat: ""create"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 5. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-create.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
2
9
20000
Cypher
export-cypher-format-create.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (5 more lines)
The creation of all graph entities uses the Cypher CREATE clause. If those entities may already exist in the destination database, we may choose to use another format. Using cypherFormat: ""updateAll"" means that the MERGE clause will be used instead of CREATE when creating entities.
Cypher
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-create.cypher using the updateAll format
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-updateAll.cypher"",
  { format: ""plain"", cypherFormat: ""updateAll"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 6. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-updateAll.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
8
9
20000
Cypher
export-cypher-format-updateAll.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (5 more lines)
If we already have the nodes in our destination database, we can use cypherFormat: ""addStructure"" to create Cypher CREATE statements for just the relationships.
Cypher
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-addStructure.cypher using the addStructure format
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-addStructure.cypher"",
  { format: ""plain"", cypherFormat: ""addStructure"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 7. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-addStructure.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
4
9
20000
Cypher
export-cypher-format-addStructure.cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Movie;

UNWIND [{_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}},
        {_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end)  SET r += row.properties;
In this example we’re using the MERGE clause to create a node if it doesn’t already exist, and are only creating properties if the node doesn’t already exist. In this example, relationships don’t exist in the destination database and need to be created.
If those relationships do exist but have properties that need to be updated, we can use cypherFormat: ""updateStructure"" to create our import script.
Cypher
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-updateStructure.cypher using the updateStructure format
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-updateStructure.cypher"",
  { format: ""plain"", cypherFormat: ""updateStructure"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 8. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-updateStructure.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
0
4
4
2
4
20000
Cypher
export-cypher-format-updateStructure.cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
MERGE (start)-[r:ACTED_IN]->(end) SET r += row.properties;
Export to multiple files or columns
The export to Cypher procedures all support writing to multiple files or multiple columns. We can enable this mode by passing in the config separateFiles: true
Cypher
The following query exports all the ACTED_IN relationships and corresponding nodes into files with an actedIn prefix
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.query(
  ""MATCH ()-[r:ACTED_IN]->()
   RETURN *"",
  ""actedIn.cypher"",
  { format: ""cypher-shell"", separateFiles: true })
YIELD file, batches, source, format, nodes, relationships, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, time, rows, batchSize;
Table 9. Results
file batches source format nodes relationships time rows batchSize
""actedIn.cypher""
1
""statement: nodes(10), rels(8)""
""cypher""
10
8
3
18
20000
This will result in the following files being created:
Table 10. Results
Name Size in bytes Number of lines
actedIn.cleanup.cypher
234
6
actedIn.nodes.cypher
893
6
actedIn.relationships.cypher
757
6
actedIn.schema.cypher
109
3
Each of those files contains one particular part of the graph. Let’s have a look at their content:
Cypher
actedIn.cleanup.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;
:commit
:begin
DROP CONSTRAINT uniqueConstraint;
:commit
Cypher
actedIn.nodes.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
UNWIND [{_id:28, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}, {_id:37, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;
UNWIND [{_id:31, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:30, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:42, properties:{born:1964, name:""Keanu Reeves""}}, {_id:0, properties:{born:1960, name:""Hugo Weaving""}}, {_id:29, properties:{born:1964, name:""Keanu Reeves""}}, {_id:38, properties:{born:1960, name:""Hugo Weaving""}}, {_id:43, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:57, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;
:commit
Cypher
actedIn.relationships.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
UNWIND [{start: {_id:31}, end: {_id:28}, properties:{roles:[""Morpheus""]}}, {start: {_id:42}, end: {_id:37}, properties:{roles:[""Neo""]}}, {start: {_id:38}, end: {_id:37}, properties:{roles:[""Agent Smith""]}}, {start: {_id:0}, end: {_id:28}, properties:{roles:[""Agent Smith""]}}, {start: {_id:29}, end: {_id:28}, properties:{roles:[""Neo""]}}, {start: {_id:43}, end: {_id:37}, properties:{roles:[""Trinity""]}}, {start: {_id:30}, end: {_id:28}, properties:{roles:[""Trinity""]}}, {start: {_id:57}, end: {_id:37}, properties:{roles:[""Morpheus""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end) SET r += row.properties;
:commit
Cypher
actedIn.schema.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
:commit
We can then apply these files to our destination Neo4j instance, either by streaming their contents into Cypher Shell or by using the procedures described in Running Cypher fragments.
We can also use the separateFiles when returning a stream of export statements. The results will appear in columns named nodeStatements, relationshipStatements, cleanupStatements, and schemaStatements rather than cypherStatements.
Cypher
The following query returns a stream all the ACTED_IN relationships and corresponding nodes
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.query(
  ""MATCH ()-[r:ACTED_IN]->()
   RETURN *"",
  null,
  { format: ""cypher-shell"", separateFiles: true })
YIELD nodes, relationships, properties, nodeStatements, relationshipStatements, cleanupStatements, schemaStatements
RETURN nodes, relationships, properties, nodeStatements, relationshipStatements, cleanupStatements, schemaStatements;
Table 11. Results
nodes relationships properties nodeStatements relationshipStatements cleanupStatements schemaStatements
10
8
30
"":begin UNWIND [{_id:28, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}, {_id:37, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Movie; UNWIND [{_id:0, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:42, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:31, properties:{born:1961, name:\""Laurence Fishburne\""}}, {_id:29, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:30, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:43, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:38, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:57, properties:{born:1961, name:\""Laurence Fishburne\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit ""
"":begin UNWIND [{start: {_id:31}, end: {_id:28}, properties:{roles:[\""Morpheus\""]}}, {start: {_id:38}, end: {_id:37}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:0}, end: {_id:28}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:30}, end: {_id:28}, properties:{roles:[\""Trinity\""]}}, {start: {_id:29}, end: {_id:28}, properties:{roles:[\""Neo\""]}}, {start: {_id:43}, end: {_id:37}, properties:{roles:[\""Trinity\""]}}, {start: {_id:42}, end: {_id:37}, properties:{roles:[\""Neo\""]}}, {start: {_id:57}, end: {_id:37}, properties:{roles:[\""Morpheus\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; :commit ""
"":begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin DROP CONSTRAINT uniqueConstraint; :commit ""
"":begin CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.UNIQUE IMPORT ID) IS UNIQUE; :commit ""
We can then copy/paste the content of each of these columns (excluding the double quotes) into a Cypher Shell session, or into a local file that we stream into a Cypher Shell session. If we want to export Cypher statements that can be pasted into the Neo4j Browser query editor, we need to use the config format: ""plain"", as described in Export to Neo4j Browser friendly format.
Export with multiple relationships with the same type
With the following dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (pers:Person {name: 'MyName'})-[:WORKS_FOR {id: 1}]->(proj:Project {a: 1}),
    (pers)-[:WORKS_FOR {id: 2}]->(proj),
    (pers)-[:WORKS_FOR {id: 2}]->(proj),
    (pers)-[:WORKS_FOR {id: 3}]->(proj),
    (pers)-[:WORKS_FOR {id: 4}]->(proj),
    (pers)-[:WORKS_FOR {id: 5}]->(proj),
    (pers)-[:IS_TEAM_MEMBER_OF {name: 'aaa'}]->(:Team {name: 'one'}),
    (pers)-[:IS_TEAM_MEMBER_OF {name: 'eee'}]->(:Team {name: 'two'})
We can see that between :Person and :Project nodes, there are several relationships with the same type (WORKS_FOR).
In these cases, if we export relationships via a MERGE clause, we must use the config {multipleRelationshipsWithType: true}, otherwise we cannot distinguish them, and a script would be exported which would create only one WORKS_FOR relationship.
For example, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(null, {stream: true, multipleRelationshipsWithType: true}) YIELD cypherStatements
Table 12. Results
cypherStatements
"":begin CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE; :commit CALL db.awaitIndexes(300); :begin UNWIND [{_id:1, properties:{a:1}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Project; UNWIND [{_id:2, properties:{name:""one""}}, {_id:3, properties:{name:""two""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Team; UNWIND [{_id:0, properties:{name:""MyName""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{start: {_id:0}, end: {_id:2}, properties:{name:""aaa""}}, {start: {_id:0}, end: {_id:3}, properties:{name:""eee""}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id}) CREATE (start)-[r:IS_TEAM_MEMBER_OF]→(end) SET r += row.properties; UNWIND [{start: {_id:0}, id: 0, end: {_id:1}, properties:{id:1}}, {start: {_id:0}, id: 1, end: {_id:1}, properties:{id:2}}, {start: {_id:0}, id: 2, end: {_id:1}, properties:{id:2}}, {start: {_id:0}, id: 3, end: {_id:1}, properties:{id:3}}, {start: {_id:0}, id: 4, end: {_id:1}, properties:{id:4}}, {start: {_id:0}, id: 5, end: {_id:1}, properties:{id:5}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id}) CREATE (start)-[r:WORKS_FOR{`UNIQUE IMPORT ID REL`:row.id}]→(end) SET r += row.properties; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`; :commit :begin DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE; :commit ""
Export to JSON
Export to GraphML
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.cypher.query;"apoc.export.cypher.query
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Usage Examples
Procedure
apoc.export.cypher.query(query String, file String, config Map<String, Any>) - exports the nodes and relationships from the given Cypher query (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Signature
None
Copy to Clipboard
apoc.export.cypher.query(query :: STRING?, file =  :: STRING?, config = {} :: MAP?) :: (file :: STRING?, batches :: INTEGER?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, cypherStatements :: STRING?, nodeStatements :: STRING?, relationshipStatements :: STRING?, schemaStatements :: STRING?, cleanupStatements :: STRING?)
Input parameters
Name Type Default
query
STRING?
null
file
STRING?
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
false
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
format
String
cypher-shell
Export format. The following values are supported:
cypher-shell - for import with Cypher Shell
neo4j-shell - for import with Neo4j Shell
plain - exports plain Cypher without begin, commit, or await commands. For import with Neo4j Browser
cypherFormat
String
create
Cypher update operation type. The following values are supported:
create - only uses the CREATE clause
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
useOptimizations
Map
{type: ""UNWIND_BATCH"", unwindBatchSize: 20}
Optimizations to use for Cypher statement generation. type supports the following values:
NONE - exports the file with CREATE statement
UNWIND_BATCH - exports the file by batching the entities with the UNWIND method as explained in Michael Hunger’s article on fast batched writes.
UNWIND_BATCH_PARAMS - similar to UNWIND_BATCH, but also uses parameters where appropriate
awaitForIndexes
Long
300
Timeout to use for db.awaitIndexes when using format: ""cypher-shell""
ifNotExists
boolean
false
If true adds the keyword IF NOT EXISTS to constraints and indexes
Output parameters
Name Type
file
STRING?
batches
INTEGER?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
cypherStatements
STRING?
nodeStatements
STRING?
relationshipStatements
STRING?
schemaStatements
STRING?
cleanupStatements
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The export to Cypher procedures all support writing to multiple files or multiple columns. We can enable this mode by passing in the config separateFiles: true
The following query exports all the ACTED_IN relationships and corresponding nodes into files with an actedIn prefix
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.query(
  ""MATCH ()-[r:ACTED_IN]->()
   RETURN *"",
  ""actedIn.cypher"",
  { format: ""cypher-shell"", separateFiles: true })
YIELD file, batches, source, format, nodes, relationships, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, time, rows, batchSize;
Table 2. Results
file batches source format nodes relationships time rows batchSize
""actedIn.cypher""
1
""statement: nodes(10), rels(8)""
""cypher""
10
8
3
18
20000
This will result in the following files being created:
Table 3. Results
Name Size in bytes Number of lines
actedIn.cleanup.cypher
234
6
actedIn.nodes.cypher
893
6
actedIn.relationships.cypher
757
6
actedIn.schema.cypher
109
3
Each of those files contains one particular part of the graph. Let’s have a look at their content:
Cypher
actedIn.cleanup.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;
:commit
:begin
DROP CONSTRAINT uniqueConstraint;
:commit
Cypher
actedIn.nodes.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
UNWIND [{_id:28, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}, {_id:37, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;
UNWIND [{_id:31, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:30, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:42, properties:{born:1964, name:""Keanu Reeves""}}, {_id:0, properties:{born:1960, name:""Hugo Weaving""}}, {_id:29, properties:{born:1964, name:""Keanu Reeves""}}, {_id:38, properties:{born:1960, name:""Hugo Weaving""}}, {_id:43, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:57, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;
:commit
Cypher
actedIn.relationships.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
UNWIND [{start: {_id:31}, end: {_id:28}, properties:{roles:[""Morpheus""]}}, {start: {_id:42}, end: {_id:37}, properties:{roles:[""Neo""]}}, {start: {_id:38}, end: {_id:37}, properties:{roles:[""Agent Smith""]}}, {start: {_id:0}, end: {_id:28}, properties:{roles:[""Agent Smith""]}}, {start: {_id:29}, end: {_id:28}, properties:{roles:[""Neo""]}}, {start: {_id:43}, end: {_id:37}, properties:{roles:[""Trinity""]}}, {start: {_id:30}, end: {_id:28}, properties:{roles:[""Trinity""]}}, {start: {_id:57}, end: {_id:37}, properties:{roles:[""Morpheus""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end) SET r += row.properties;
:commit
Cypher
actedIn.schema.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
:commit
We can then apply these files to our destination Neo4j instance, either by streaming their contents into Cypher Shell or by using the procedures described in Running Cypher fragments.
We can also use the separateFiles when returning a stream of export statements. The results will appear in columns named nodeStatements, relationshipStatements, cleanupStatements, and schemaStatements rather than cypherStatements.
The following query returns a stream all the ACTED_IN relationships and corresponding nodes
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.query(
  ""MATCH ()-[r:ACTED_IN]->()
   RETURN *"",
  null,
  { format: ""cypher-shell"", separateFiles: true })
YIELD nodes, relationships, properties, nodeStatements, relationshipStatements, cleanupStatements, schemaStatements
RETURN nodes, relationships, properties, nodeStatements, relationshipStatements, cleanupStatements, schemaStatements;
Table 4. Results
nodes relationships properties nodeStatements relationshipStatements cleanupStatements schemaStatements
10
8
30
"":begin UNWIND [{_id:28, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}, {_id:37, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Movie; UNWIND [{_id:0, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:42, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:31, properties:{born:1961, name:\""Laurence Fishburne\""}}, {_id:29, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:30, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:43, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:38, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:57, properties:{born:1961, name:\""Laurence Fishburne\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit ""
"":begin UNWIND [{start: {_id:31}, end: {_id:28}, properties:{roles:[\""Morpheus\""]}}, {start: {_id:38}, end: {_id:37}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:0}, end: {_id:28}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:30}, end: {_id:28}, properties:{roles:[\""Trinity\""]}}, {start: {_id:29}, end: {_id:28}, properties:{roles:[\""Neo\""]}}, {start: {_id:43}, end: {_id:37}, properties:{roles:[\""Trinity\""]}}, {start: {_id:42}, end: {_id:37}, properties:{roles:[\""Neo\""]}}, {start: {_id:57}, end: {_id:37}, properties:{roles:[\""Morpheus\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; :commit ""
"":begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin DROP CONSTRAINT uniqueConstraint; :commit ""
"":begin CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.UNIQUE IMPORT ID) IS UNIQUE; :commit ""
We can then copy/paste the content of each of these columns (excluding the double quotes) into a Cypher Shell session, or into a local file that we stream into a Cypher Shell session. If we want to export Cypher statements that can be pasted into the Neo4j Browser query editor, we need to use the config format: ""plain"".
More documentation of apoc.export.cypher.query
apoc.export.cypher.graph
apoc.export.cypher.schema
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.cypher.graph;"apoc.export.cypher.graph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.cypher.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Signature
None
Copy to Clipboard
apoc.export.cypher.graph(graph :: MAP?, file =  :: STRING?, config = {} :: MAP?) :: (file :: STRING?, batches :: INTEGER?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, cypherStatements :: STRING?, nodeStatements :: STRING?, relationshipStatements :: STRING?, schemaStatements :: STRING?, cleanupStatements :: STRING?)
Input parameters
Name Type Default
graph
MAP?
null
file
STRING?
config
MAP?
{}
Output parameters
Name Type
file
STRING?
batches
INTEGER?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
cypherStatements
STRING?
nodeStatements
STRING?
relationshipStatements
STRING?
schemaStatements
STRING?
cleanupStatements
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The apoc.export.cypher.graph procedure exports a virtual graph to a CSV file or as a stream.
The examples in this section are based on a virtual graph that contains all PRODUCED relationships and the nodes either side of that relationship. We can then export that virtual graph as Cypher statements to movies-producers.cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[produced:PRODUCED]->(:Movie)
WITH collect(path) AS paths
CALL apoc.graph.fromPaths(paths, ""producers"", {})
YIELD graph AS g
CALL apoc.export.cypher.graph(g, ""movies-producers.cypher"", {})
YIELD file, nodes, relationships, properties
RETURN file, nodes, relationships, properties;
Table 1. Results
file nodes relationships properties
""movies-producers.cypher""
2
1
5
Cypher
movies-producers.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
:commit
:begin
UNWIND [{_id:31450, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;
UNWIND [{_id:31457, properties:{born:1952, name:""Joel Silver""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;
:commit
:begin
UNWIND [{start: {_id:31457}, end: {_id:31450}, properties:{}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:PRODUCED]->(end) SET r += row.properties;
:commit
:begin
MATCH (n:` IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (6 more lines)
The following query returns a streams of the virtual graph from static value storage to the cypherStatements column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[produced:PRODUCED]->(:Movie)
WITH collect(path) AS paths
CALL apoc.graph.fromPaths(paths, ""producers"", {})
YIELD graph AS g
CALL apoc.export.cypher.graph(g, null, {stream: true})
YIELD file, nodes, relationships, properties, cypherStatements
RETURN file, nodes, relationships, properties, cypherStatements;
Table 2. Results
file nodes relationships properties cypherStatements
NULL
2
1
5
"":begin CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.UNIQUE IMPORT ID) IS UNIQUE; :commit :begin UNWIND [{_id:31450, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Movie; UNWIND [{_id:31457, properties:{born:1952, name:\""Joel Silver\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{start: {_id:31457}, end: {_id:31450}, properties:{}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:PRODUCED]→(end) SET r += row.properties; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin DROP CONSTRAINT uniqueConstraint; :commit ""
More documentation of apoc.export.cypher.graph
apoc.export.cypher.data
apoc.export.cypher.query
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.cypher.data;"apoc.export.cypher.data
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Usage Examples
Procedure
apoc.export.cypher.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Signature
None
Copy to Clipboard
apoc.export.cypher.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file =  :: STRING?, config = {} :: MAP?) :: (file :: STRING?, batches :: INTEGER?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, cypherStatements :: STRING?, nodeStatements :: STRING?, relationshipStatements :: STRING?, schemaStatements :: STRING?, cleanupStatements :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
file
STRING?
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
false
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
format
String
cypher-shell
Export format. The following values are supported:
cypher-shell - for import with Cypher Shell
neo4j-shell - for import with Neo4j Shell
plain - exports plain Cypher without begin, commit, or await commands. For import with Neo4j Browser
cypherFormat
String
create
Cypher update operation type. The following values are supported:
create - only uses the CREATE clause
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
useOptimizations
Map
{type: ""UNWIND_BATCH"", unwindBatchSize: 20}
Optimizations to use for Cypher statement generation. type supports the following values:
NONE - exports the file with CREATE statement
UNWIND_BATCH - exports the file by batching the entities with the UNWIND method as explained in Michael Hunger’s article on fast batched writes.
UNWIND_BATCH_PARAMS - similar to UNWIND_BATCH, but also uses parameters where appropriate
awaitForIndexes
Long
300
Timeout to use for db.awaitIndexes when using format: ""cypher-shell""
ifNotExists
boolean
false
If true adds the keyword IF NOT EXISTS to constraints and indexes
Output parameters
Name Type
file
STRING?
batches
INTEGER?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
cypherStatements
STRING?
nodeStatements
STRING?
relationshipStatements
STRING?
schemaStatements
STRING?
cleanupStatements
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The export to Cypher procedures generate Cypher statements using the CREATE, MATCH and MERGE clauses. The format is configured by the cypherFormat parameter. The following values are supported:
create - only uses the CREATE clause (default)
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
If we’re exporting a database for the first time we should use the default create format, but for subsequent exports the other formats may be more suitable.
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-create.cypher using the create format
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-create.cypher"",
  { format: ""plain"", cypherFormat: ""create"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 2. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-create.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
2
9
20000
Cypher
export-cypher-format-create.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (5 more lines)
The creation of all graph entities uses the Cypher CREATE clause. If those entities may already exist in the destination database, we may choose to use another format. Using cypherFormat: ""updateAll"" means that the MERGE clause will be used instead of CREATE when creating entities.
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-create.cypher using the updateAll format
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-updateAll.cypher"",
  { format: ""plain"", cypherFormat: ""updateAll"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 3. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-updateAll.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
8
9
20000
Cypher
export-cypher-format-updateAll.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (5 more lines)
If we already have the nodes in our destination database, we can use cypherFormat: ""addStructure"" to create Cypher CREATE statements for just the relationships.
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-addStructure.cypher using the addStructure format
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-addStructure.cypher"",
  { format: ""plain"", cypherFormat: ""addStructure"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 4. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-addStructure.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
5
4
15
4
9
20000
Cypher
export-cypher-format-addStructure.cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Movie;

UNWIND [{_id:7, properties:{born:1967, name:""Carrie-Anne Moss""}},
        {_id:27, properties:{born:1964, name:""Keanu Reeves""}},
        {_id:80, properties:{born:1960, name:""Hugo Weaving""}},
        {_id:44, properties:{born:1961, name:""Laurence Fishburne""}}] AS row
MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Person;

UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end)  SET r += row.properties;
In this example we’re using the MERGE clause to create a node if it doesn’t already exist, and are only creating properties if the node doesn’t already exist. In this example, relationships don’t exist in the destination database and need to be created.
If those relationships do exist but have properties that need to be updated, we can use cypherFormat: ""updateStructure"" to create our import script.
The following exports the ACTED_IN relationships and surrounding nodes to export-cypher-format-updateStructure.cypher using the updateStructure format
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person)-[r:ACTED_IN]->(movie)
WITH collect(DISTINCT person) + collect(DISTINCT  movie) AS importNodes, collect(r) AS importRels
CALL apoc.export.cypher.data(importNodes, importRels,
  ""export-cypher-format-updateStructure.cypher"",
  { format: ""plain"", cypherFormat: ""updateStructure"" })
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 5. Results
file batches source format nodes relationships properties time rows batchSize
""export-cypher-format-updateStructure.cypher""
1
""data: nodes(5), rels(4)""
""cypher""
0
4
4
2
4
20000
Cypher
export-cypher-format-updateStructure.cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND [{start: {_id:27}, end: {_id:0}, properties:{roles:[""Neo""]}},
        {start: {_id:7}, end: {_id:0}, properties:{roles:[""Trinity""]}},
        {start: {_id:44}, end: {_id:0}, properties:{roles:[""Morpheus""]}},
        {start: {_id:80}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
MERGE (start)-[r:ACTED_IN]->(end) SET r += row.properties;
More documentation of apoc.export.cypher.data
apoc.export.cypher.all
apoc.export.cypher.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.cypher.all;"apoc.export.cypher.all
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Usage Examples
Export to Cypher Shell format
Export to Neo4j Browser friendly format
Procedure
apoc.export.cypher.all(file String, config Map<String, Any>) - exports the full database (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Signature
None
Copy to Clipboard
apoc.export.cypher.all(file =  :: STRING?, config = {} :: MAP?) :: (file :: STRING?, batches :: INTEGER?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, cypherStatements :: STRING?, nodeStatements :: STRING?, relationshipStatements :: STRING?, schemaStatements :: STRING?, cleanupStatements :: STRING?)
Input parameters
Name Type Default
file
STRING?
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
false
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
format
String
cypher-shell
Export format. The following values are supported:
cypher-shell - for import with Cypher Shell
neo4j-shell - for import with Neo4j Shell
plain - exports plain Cypher without begin, commit, or await commands. For import with Neo4j Browser
cypherFormat
String
create
Cypher update operation type. The following values are supported:
create - only uses the CREATE clause
updateAll - uses MERGE instead of CREATE
addStructure - uses MATCH for nodes and MERGE for relationships
updateStructure - uses MERGE and MATCH for nodes and relationships
useOptimizations
Map
{type: ""UNWIND_BATCH"", unwindBatchSize: 20}
Optimizations to use for Cypher statement generation. type supports the following values:
NONE - exports the file with CREATE statement
UNWIND_BATCH - exports the file by batching the entities with the UNWIND method as explained in Michael Hunger’s article on fast batched writes.
UNWIND_BATCH_PARAMS - similar to UNWIND_BATCH, but also uses parameters where appropriate
awaitForIndexes
Long
300
Timeout to use for db.awaitIndexes when using format: ""cypher-shell""
ifNotExists
boolean
false
If true adds the keyword IF NOT EXISTS to constraints and indexes
Output parameters
Name Type
file
STRING?
batches
INTEGER?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
cypherStatements
STRING?
nodeStatements
STRING?
relationshipStatements
STRING?
schemaStatements
STRING?
cleanupStatements
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
Export to Cypher Shell format
By default, the Cypher statements generated by the export to Cypher procedures are in the Cypher Shell format.
The following query exports the whole database to all.cypher in the default cypher-shell format using the default UNWIND_BATCH optimization
Cypher
Copy to Clipboard
Run in Neo4j Browser
// default config populated for illustration
CALL apoc.export.cypher.all(""all.cypher"", {
    format: ""cypher-shell"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 20}
})
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 2. Results
file batches source format nodes relationships properties time rows batchSize
""all.cypher""
1
""database: nodes(8), rels(7)""
""cypher""
8
7
21
10
15
20000
The contents of all.cypher, with extra lines added for readability, are shown below:
Cypher
all.cypher
Copy to Clipboard
Run in Neo4j Browser
:begin
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;
:commit

:begin
UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:1, properties:{born:1964, name:""Keanu Reeves""}}, {_id:2, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:3, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:4, properties:{born:1960, name:""Hugo Weaving""}}, {_id:5, properties:{born:1967, name:""Lilly Wachowski""}}, {_id:6, properties:{born:1965, name:""Lana Wachowski""}}, {_id:7, properties:{born:1952, name:""Joel Silver""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;
:commit

:begin
UNWIND [{start: {_id:1}, end: {_id:0}, properties:{roles:[""Neo""]}}, {start: {_id:2}, end: {_id:0}, properties:{roles:[""Trinity""]}}, {start: {_id:3}, end: {_id:0}, properties:{roles:[""Morpheus""]}}, {start: {_id:4}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (21 more lines)
This Cypher script executes 5 transactions, each surrounded by :begin and :commit commands. The transactions do the following:
Create a unique constraint on the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property
Import the Person and Movie nodes
Create ACTED_IN, PRODUCED, and DIRECTED relationships between these nodes
Remove the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property from the nodes
Drop the unique constraint on the UNIQUE IMPORT LABEL label and UNIQUE IMPORT ID property
This script can be executed using the Cypher Shell command line tool.
For example, we could import the contents of all.cypher into a Neo4j Aura database by running the following command:
Bash
Copy to Clipboard
cat all.cypher | ./bin/cypher-shell -a <bolt-url> -u neo4j -p <password> --format verbose
Don’t forget to replace <bolt-url> and <password> with the appropriate credentials.
If we run this command against an empty database, we’ll see the following output:
Text
Copy to Clipboard
0 rows available after 70 ms, consumed after another 0 ms
Added 1 constraints
0 rows available after 16 ms, consumed after another 0 ms
Added 2 nodes, Set 8 properties, Added 4 labels
0 rows available after 40 ms, consumed after another 0 ms
Added 14 nodes, Set 42 properties, Added 28 labels
0 rows available after 51 ms, consumed after another 0 ms
Created 8 relationships, Set 8 properties
0 rows available after 38 ms, consumed after another 0 ms
Created 2 relationships
0 rows available after 38 ms, consumed after another 0 ms
Created 4 relationships
0 rows available after 20 ms, consumed after another 0 ms
Set 16 properties, Removed 16 labels
0 rows available after 3 ms, consumed after another 0 ms
Removed 1 constraints
Troubleshooting
If you are experimenting with imports that are failing you can add the --debug command line parameter, to see which statement was executed last and caused the failure.
Also check the memory configuration of your Neo4j instance, you might want to increase the HEAP size to 2–4GB using the dbms.memory.heap.max_size=2G setting in neo4j.conf.
We can also provide more memory to cypher-shell itself by prefixing the command with: JAVA_OPTS=-Xmx4G bin/cypher-shell …
If we don’t have file system access, or don’t want to write to a file for another reason, we can stream back the export statements.
The following query streams back the whole database in the cypherStatements column
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(null, {
    batchSize: 5,
    streamStatements: true,
    format: ""cypher-shell"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 5}
})
YIELD nodes, relationships, properties, cypherStatements
RETURN nodes, relationships, properties, cypherStatements;
Table 3. Results
nodes relationships properties cypherStatements
16
0
34
"":begin CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.UNIQUE IMPORT ID) IS UNIQUE; :commit :begin UNWIND [{_id:0, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}, {_id:1, properties:{tagline:\""Welcome to the Real World\"", title:\""The Matrix\"", released:1999}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Movie; UNWIND [{_id:35, properties:{born:1967, name:\""Carrie-Anne Moss\""}}, {_id:36, properties:{born:1961, name:\""Laurence Fishburne\""}}, {_id:37, properties:{born:1965, name:\""Lana Wachowski\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:38, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:39, properties:{born:1952, name:\""Joel Silver\""}}, {_id:40, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:41, properties:{born:1967, name:\""Lilly Wachowski\""}}, {_id:42, properties:{born:1967, name:\""Carrie-Anne Moss\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:43, properties:{born:1965, name:\""Lana Wachowski\""}}, {_id:50, properties:{born:1960, name:\""Hugo Weaving\""}}, {_id:51, properties:{born:1964, name:\""Keanu Reeves\""}}, {_id:57, properties:{born:1967, name:\""Lilly Wachowski\""}}, {_id:58, properties:{born:1961, name:\""Laurence Fishburne\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit :begin UNWIND [{_id:59, properties:{born:1952, name:\""Joel Silver\""}}] AS row CREATE (n:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row._id}) SET n += row.properties SET n:Person; :commit ""
16
14
42
"":begin UNWIND [{start: {_id:35}, end: {_id:0}, properties:{roles:[\""Trinity\""]}}, {start: {_id:36}, end: {_id:0}, properties:{roles:[\""Morpheus\""]}}, {start: {_id:50}, end: {_id:1}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:40}, end: {_id:0}, properties:{roles:[\""Agent Smith\""]}}, {start: {_id:51}, end: {_id:1}, properties:{roles:[\""Neo\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; :commit :begin UNWIND [{start: {_id:42}, end: {_id:1}, properties:{roles:[\""Trinity\""]}}, {start: {_id:38}, end: {_id:0}, properties:{roles:[\""Neo\""]}}, {start: {_id:58}, end: {_id:1}, properties:{roles:[\""Morpheus\""]}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:ACTED_IN]→(end) SET r += row.properties; UNWIND [{start: {_id:59}, end: {_id:1}, properties:{}}, {start: {_id:39}, end: {_id:0}, properties:{}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:PRODUCED]→(end) SET r += row.properties; :commit :begin UNWIND [{start: {_id:37}, end: {_id:0}, properties:{}}, {start: {_id:57}, end: {_id:0}, properties:{}}, {start: {_id:43}, end: {_id:1}, properties:{}}, {start: {_id:41}, end: {_id:1}, properties:{}}] AS row MATCH (start:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.start._id}) MATCH (end:`UNIQUE IMPORT LABEL`{UNIQUE IMPORT ID: row.end._id}) CREATE (start)-[r:DIRECTED]→(end) SET r += row.properties; :commit ""
16
14
42
"":begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin MATCH (n:`UNIQUE IMPORT LABEL`) WITH n LIMIT 5 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.UNIQUE IMPORT ID; :commit :begin DROP CONSTRAINT uniqueConstraint; :commit ""
We can then copy/paste the content of the cypherStatements column (excluding the double quotes) into a Cypher Shell session, or into a local file that we stream into a Cypher Shell session.
Export to Neo4j Browser friendly format
The export to Cypher procedures support the config format: ""plain"", which is useful for later import using the Neo4j Browser.
The following query exports the whole database to all-plain.cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.all(""all-plain.cypher"", {
    format: ""plain"",
    useOptimizations: {type: ""UNWIND_BATCH"", unwindBatchSize: 20}
})
YIELD file, batches, source, format, nodes, relationships, properties, time, rows, batchSize
RETURN file, batches, source, format, nodes, relationships, properties, time, rows, batchSize;
Table 4. Results
file batches source format nodes relationships properties time rows batchSize
""all-plain.cypher""
1
""database: nodes(8), rels(7)""
""cypher""
8
7
21
9
15
20000
The contents of all-plain.cypher, with extra lines added for readability, are shown below:
Cypher
all-plain.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (node:`UNIQUE IMPORT LABEL`) REQUIRE (node.`UNIQUE IMPORT ID`) IS UNIQUE;

UNWIND [{_id:0, properties:{tagline:""Welcome to the Real World"", title:""The Matrix"", released:1999}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Movie;

UNWIND [{_id:1, properties:{born:1964, name:""Keanu Reeves""}}, {_id:2, properties:{born:1967, name:""Carrie-Anne Moss""}}, {_id:3, properties:{born:1961, name:""Laurence Fishburne""}}, {_id:4, properties:{born:1960, name:""Hugo Weaving""}}, {_id:5, properties:{born:1967, name:""Lilly Wachowski""}}, {_id:6, properties:{born:1965, name:""Lana Wachowski""}}, {_id:7, properties:{born:1952, name:""Joel Silver""}}] AS row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Person;

UNWIND [{start: {_id:1}, end: {_id:0}, properties:{roles:[""Neo""]}}, {start: {_id:2}, end: {_id:0}, properties:{roles:[""Trinity""]}}, {start: {_id:3}, end: {_id:0}, properties:{roles:[""Morpheus""]}}, {start: {_id:4}, end: {_id:0}, properties:{roles:[""Agent Smith""]}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.end._id})
CREATE (start)-[r:ACTED_IN]->(end) SET r += row.properties;

UNWIND [{start: {_id:7}, end: {_id:0}, properties:{}}] AS row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:` IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT ID IMPORT LABEL IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID
View all (11 more lines)
We can then take the all-plain.cypher file and drag it onto the Neo4j Browser window. We should then see the following prompt:
Figure 2. Neo4j Browser prompt when we drag a file onto it
And if we click Paste in editor, the contents of the file will appear in the query editor:
Figure 3. Neo4j Browser query editor with the contents of all-plain.cypher
We can then press the play button next in the editor and the data will be imported.
More documentation of apoc.export.cypher.all
apoc.export.csv.query
apoc.export.cypher.data
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current;"The Neo4j Graph Data Science Library Manual v2.2
© 2022
License: Creative Commons 4.0
The manual covers the following areas:
Introduction — An introduction to the Neo4j Graph Data Science library.
Installation — Instructions for how to install and use the Neo4j Graph Data Science library.
Common usage — General usage patterns and recommendations for getting the most out of the Neo4j Graph Data Science library.
Graph management — A detailed guide to the graph catalog and utility procedures included in the Neo4j Graph Data Science library.
Graph algorithms — A detailed guide to each of the algorithms in their respective categories, including use-cases and examples.
Machine learning — A detailed guide to the machine learning procedures included in the Neo4j Graph Data Science library.
Production deployment — This chapter explains advanced details with regards to common Neo4j components.
Python client — Documentation of the Graph Data Science client for Python users.
Operations reference — Reference of all procedures contained in the Neo4j Graph Data Science library.
Migration from Graph Data Science library Version 1.x — Additional resources - migration guide, books, etc - to help using the Neo4j Graph Data Science library.
The source code of the library is available at GitHub. If you have a suggestion on how we can improve the library or want to report a problem, you can create a new issue.
Introduction
Was this page helpful?"
https://neo4j.com/labs/apoc/5/nlp;"Natural Language Processing (NLP)
The procedures described in this chapter act as wrappers around cloud based Natural Language APIs. These procedures extract entities, key phrases, categories, and sentiment from text stored as node properties.
This section includes:
Google Cloud Platform (GCP)
Amazon Web Services (AWS)
Microsoft Azure Cognitive Services
Was this page helpful?"
https://neo4j.com/labs/apoc/5/nlp/gcp;"Google Cloud Platform (GCP)
Contents
Procedure Overview
Entity Extraction
Classification
Install Dependencies
Setting up API Key
Batching Requests
Examples
Entity Extraction
Classification
Google Cloud Platform’s Natural Language API lets users derive insights from unstructured text using Google machine learning. The procedures in this chapter act as a wrapper around calls to this API to extract entities, categories, or sentiment from text stored as node properties.
Each procedure has two modes:
Stream - returns a map constructed from the JSON returned from the API
Graph - creates a graph or virtual graph based on the values returned by the API
The procedures described in this chapter make API calls and subsequent updates to the database on the calling thread. If we want to make parallel requests to the API and avoid out of memory errors from keeping too much transaction state in memory while running procedures that write to the database, see Batching Requests.
At the moment, GCP Natural Language API supports text input in more than 10 languages. For better results, make sure that your text is one of the supported languages by Natural Language API. If we input a text of an unsupported language, you might get a ""HTTP response code: 400"" error.
Procedure Overview
The procedures are described below:
Qualified Name Type Release
apoc.nlp.gcp.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
Apoc Extended
apoc.nlp.gcp.entities.stream
Returns a stream of entities for provided text
Procedure
Apoc Extended
apoc.nlp.gcp.classify.graph
Classifies a document into categories.
Procedure
Apoc Extended
apoc.nlp.gcp.classify.stream
Classifies a document into categories.
Procedure
Apoc Extended
Entity Extraction
The entity extraction procedures (apoc.nlp.gcp.entities.*) are wrappers around the documents.analyzeEntities method of the Google Natural Language API. This API method finds named entities (currently proper names and common nouns) in the text along with entity types, salience, mentions for each entity, and other properties.
The procedures are described below:
signature
apoc.nlp.gcp.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
apoc.nlp.gcp.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
key
String
null
API Key for Google Natural Language API
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.gcp.entities.graph supports the following config parameters:
Table 2. Config parameters
name type default description
scoreCutoff
Double
0.0
Lower limit for the salience score of an entity to be present in the graph. Value must be between 0 and 1.
Salience is an indicator of the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
write
Boolean
false
persist the graph of entities
writeRelationshipType
String
ENTITY
relationship type for relationships from source node to entity nodes
writeRelationshipProperty
String
score
relationship property for relationships from source node to entity nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.gcp.entities.stream(source:Node or List<Node>, {
  key: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.gcp.entities.graph(source:Node or List<Node>, {
  key: String,
  nodeProperty: String,
  scoreCutoff: Double,
  writeRelationshipType: String,
  writeRelationshipProperty: String,
  write: Boolean
})
YIELD graph
Classification
The entity extraction procedures (apoc.nlp.gcp.classify.*) are wrappers around the documents.classifyText method of the Google Natural Language API. This API method classifies a document into categories.
The procedures are described below:
signature
apoc.nlp.gcp.classify.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
apoc.nlp.gcp.classify.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
The procedures support the following config parameters:
Table 3. Config parameters
name type default description
key
String
null
API Key for Google Natural Language API
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.gcp.classify.graph supports the following config parameters:
Table 4. Config parameters
name type default description
scoreCutoff
Double
0.0
Lower limit for the confidence score of a category to be present in the graph. Value must be between 0 and 1.
Confidence is a number representing how certain the classifier is that this category represents the given text.
write
Boolean
false
persist the graph of entities
writeRelationshipType
String
CATEGORY
relationship type for relationships from source node to category nodes
writeRelationshipProperty
String
score
relationship property for relationships from source node to category nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.gcp.classify.stream(source:Node or List<Node>, {
  key: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.gcp.classify.graph(source:Node or List<Node>, {
  key: String,
  nodeProperty: String,
  scoreCutoff: Double,
  writeRelationshipType: String,
  writeRelationshipProperty: String,
  write: Boolean
})
YIELD graph
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API Key that has access to the Cloud Natural Language API by going to console.cloud.google.com/apis/credentials. Once we’ve created a key, we can populate and execute the following command to create a parameter that contains these details.
Cypher
The following defines the apiKey parameter
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"")
Alternatively we can add these credentials to apoc.conf and load them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.gcp.apiKey=<api-key-here>
Cypher
The following retrieves GCP credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""gcp"") AS gcp;
Table 5. Results
gcp
{apiKey: ""<api-key-here>""}
Batching Requests
Batching requests to the GCP API and the processing of results can be done using Periodic Iterate. This approach is useful if we want to make parallel requests to the GCP API and reduce the amount of transaction state kept in memory while running procedures that write to the database.
Cypher
The following creates an entity graph in batches of 25 nodes
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(""
  MATCH (n)
  WITH collect(n) as total
  CALL apoc.coll.partition(total, 25)
  YIELD value as nodes
  RETURN nodes"", ""
  CALL apoc.nlp.gcp.entities.graph(nodes, {
    key: $apiKey,
    nodeProperty: 'body',
    writeRelationshipType: 'GCP_ENTITY',
    write:true
  })
  YIELD graph
  RETURN distinct 'done'"", {
    batchSize: 1,
    params: { apiKey: $apiKey }
  }
);
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
Entity Extraction
Let’s start by extracting the entities from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 6. Results
entity
{name: ""card games"", salience: 0.17967656, metadata: {}, type: ""CONSUMER_GOOD"", mentions: [{type: ""COMMON"", text: {content: ""card games"", beginOffset: -1}}]}
{name: ""role playing games"", salience: 0.16441391, metadata: {}, type: ""OTHER"", mentions: [{type: ""COMMON"", text: {content: ""role playing games"", beginOffset: -1}}]}
{name: ""Switch"", salience: 0.143287, metadata: {}, type: ""OTHER"", mentions: [{type: ""COMMON"", text: {content: ""Switch"", beginOffset: -1}}]}
{name: ""friends"", salience: 0.13336793, metadata: {}, type: ""PERSON"", mentions: [{type: ""COMMON"", text: {content: ""friends"", beginOffset: -1}}]}
{name: ""Nintendo"", salience: 0.12601112, metadata: {mid: ""/g/1ymzszlpz""}, type: ""ORGANIZATION"", mentions: [{type: ""PROPER"", text: {content: ""Nintendo"", beginOffset: -1}}]}
{name: ""board games"", salience: 0.08861496, metadata: {}, type: ""CONSUMER_GOOD"", mentions: [{type: ""COMMON"", text: {content: ""board games"", beginOffset: -1}}]}
{name: ""tournaments"", salience: 0.0603245, metadata: {}, type: ""EVENT"", mentions: [{type: ""COMMON"", text: {content: ""tournaments"", beginOffset: -1}}]}
{name: ""offices"", salience: 0.034420907, metadata: {}, type: ""LOCATION"", mentions: [{type: ""COMMON"", text: {content: ""offices"", beginOffset: -1}}]}
{name: ""Mario Kart 8"", salience: 0.029095741, metadata: {wikipedia_url: ""https://en.wikipedia.org/wiki/Mario_Kart_8"", mid: ""/m/0119mf7q""}, type: ""PERSON"", mentions: [{type: ""PROPER"", text: {content: ""Mario Kart 8"", beginOffset: -1}}]}
{name: ""European"", salience: 0.020393685, metadata: {mid: ""/m/02j9z"", wikipedia_url: ""https://en.wikipedia.org/wiki/Europe""}, type: ""LOCATION"", mentions: [{type: ""PROPER"", text: {content: ""European"", beginOffset: -1}}]}
{name: ""Neo4j"", salience: 0.020393685, metadata: {mid: ""/m/0b76t3s"", wikipedia_url: ""https://en.wikipedia.org/wiki/Neo4j""}, type: ""ORGANIZATION"", mentions: [{type: ""PROPER"", text: {content: ""Neo4j"", beginOffset: -1}}]}
{name: ""8"", salience: 0, metadata: {value: ""8""}, type: ""NUMBER"", mentions: [{type: ""TYPE_UNKNOWN"", text: {content: ""8"", beginOffset: -1}}]}
We get back 12 different entities. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
Cypher
The following streams the entities for the Pokemon article and then creates nodes for each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
MERGE (e:Entity {name: entity.name})
SET e.type = entity.type
MERGE (a)-[:ENTITY]->(e)
Alternatively we can use the graph mode to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default a virtual graph is returned.
Cypher
The following returns a virtual graph of entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.graph(a, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon entities graph.
Figure 1. Pokemon entities graph
We can compute the entities for multiple nodes by passing a list of nodes to the procedure.
Cypher
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents importance of that entity in the entire document. We can specify a minimum cut off value for the score using the scoreCutoff property.
Cypher
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY"",
  scoreCutoff: 0.01
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with importance >= 0.01.
Figure 3. Pokemon and Nintendo Switch entities graph with importance >= 0.01
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
Cypher
The following creates a HAS_ENTITY relationship from the article to each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  scoreCutoff: 0.01,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""gcpEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e) | {entity: e.text, score: r.gcpEntityScore}] AS entities;
Table 7. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.020393685, entity: ""Neo4j""}, {score: 0.034420907, entity: ""offices""}, {score: 0.0603245, entity: ""tournaments""}, {score: 0.020393685, entity: ""European""}, {score: 0.029095741, entity: ""Mario Kart 8""}, {score: 0.12601112, entity: ""Nintendo""}, {score: 0.13336793, entity: ""friends""}, {score: 0.08861496, entity: ""board games""}, {score: 0.143287, entity: ""Switch""}, {score: 0.16441391, entity: ""role playing games""}, {score: 0.17967656, entity: ""card games""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.76108575, entity: ""Nintendo Switch""}, {score: 0.07424594, entity: ""Nintendo""}, {score: 0.015900765, entity: ""home console""}, {score: 0.012772448, entity: ""device""}, {score: 0.038113687, entity: ""regions""}, {score: 0.07299799, entity: ""Joy-Con Wheel""}]
Classification
Now let’s extract categories from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the categories for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.categories AS category
RETURN category;
Table 8. Results
category
{name: ""/Games"", confidence: 0.91}
We get back only one category We could then apply a Cypher statement that creates one node per category and a CATEGORY relationship from each of those nodes back to the Article node.
Cypher
The following streams the categories for the Pokemon article and then creates nodes for each category
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.categories AS category
MERGE (c:Category {name: category.name})
MERGE (a)-[:CATEGORY]->(c)
Alternatively we can use the graph mode to automatically create the category graph. As well as having the Category label, each category node will have another label based on the value of the type property. By default, a virtual graph is returned.
Cypher
The following returns a virtual graph of categories for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.graph(a, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""CATEGORY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon categories graph.
Figure 4. Pokemon categories graph
Cypher
The following creates a HAS_CATEGORY relationship from the article to each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.classify.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""HAS_CATEGORY"",
  writeRelationshipProperty: ""gcpCategoryScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_CATEGORY]->(c) | {category: c.text, score: r.gcpCategoryScore}] AS categories;
Table 9. Results
article categories
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{category: ""/Games"", score: 0.91}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{category: ""/Computers & Electronics/Consumer Electronics/Game Systems & Consoles"", score: 0.99}, {category: ""/Games/Computer & Video Games"", score: 0.99}]
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.gcp.classify.stream;"apoc.nlp.gcp.classify.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Classifies a document into categories.
Signature
None
Copy to Clipboard
apoc.nlp.gcp.classify.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API Key that has access to the Cloud Natural Language API by going to console.cloud.google.com/apis/credentials. Once we’ve created a key, we can populate and execute the following command to create a parameter that contains these details.
Cypher
The following defines the apiKey parameter
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"")
Alternatively we can add these credentials to apoc.conf and load them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.gcp.apiKey=<api-key-here>
Cypher
The following retrieves GCP credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""gcp"") AS gcp;
Table 1. Results
gcp
{apiKey: ""<api-key-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract categories from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the categories for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.categories AS category
RETURN category;
Table 2. Results
category
{name: ""/Games"", confidence: 0.91}
We get back only one category We could then apply a Cypher statement that creates one node per category and a CATEGORY relationship from each of those nodes back to the Article node.
The following streams the categories for the Pokemon article and then creates nodes for each category:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.categories AS category
MERGE (c:Category {name: category.name})
MERGE (a)-[:CATEGORY]->(c)
If we want to automatically create a category graph, see apoc.nlp.gcp.classify.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.gcp.classify.graph;"apoc.nlp.gcp.classify.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Classifies a document into categories.
Signature
None
Copy to Clipboard
apoc.nlp.gcp.classify.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API Key that has access to the Cloud Natural Language API by going to console.cloud.google.com/apis/credentials. Once we’ve created a key, we can populate and execute the following command to create a parameter that contains these details.
Cypher
The following defines the apiKey parameter
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"")
Alternatively we can add these credentials to apoc.conf and load them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.gcp.apiKey=<api-key-here>
Cypher
The following retrieves GCP credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""gcp"") AS gcp;
Table 1. Results
gcp
{apiKey: ""<api-key-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create the category graph. As well as having the Category label, each category node will have another label based on the value of the type property. By default, a virtual graph is returned.
The following returns a virtual graph of categories for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.classify.graph(a, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""CATEGORY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon categories graph.
Figure 1. Pokemon categories graph
The following creates a HAS_CATEGORY relationship from the article to each entity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.classify.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""HAS_CATEGORY"",
  writeRelationshipProperty: ""gcpCategoryScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_CATEGORY]->(c) | {category: c.text, score: r.gcpCategoryScore}] AS categories;
Table 2. Results
article categories
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{category: ""/Games"", score: 0.91}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{category: ""/Computers & Electronics/Consumer Electronics/Game Systems & Consoles"", score: 0.99}, {category: ""/Games/Computer & Video Games"", score: 0.99}]
If we want to stream back categories and apply custom logic to the results, see apoc.nlp.gcp.classify.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.gcp.entities.stream;"apoc.nlp.gcp.entities.stream
Contents
Signature
Input parameters
Config parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Returns a stream of entities for provided text
Signature
None
Copy to Clipboard
apoc.nlp.gcp.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
key
String
null
API Key for Google Natural Language API
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API Key that has access to the Cloud Natural Language API by going to console.cloud.google.com/apis/credentials. Once we’ve created a key, we can populate and execute the following command to create a parameter that contains these details.
Cypher
The following defines the apiKey parameter
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"")
Alternatively we can add these credentials to apoc.conf and load them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.gcp.apiKey=<api-key-here>
Cypher
The following retrieves GCP credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""gcp"") AS gcp;
Table 2. Results
gcp
{apiKey: ""<api-key-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the entities from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the entities for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 3. Results
entity
{name: ""card games"", salience: 0.17967656, metadata: {}, type: ""CONSUMER_GOOD"", mentions: [{type: ""COMMON"", text: {content: ""card games"", beginOffset: -1}}]}
{name: ""role playing games"", salience: 0.16441391, metadata: {}, type: ""OTHER"", mentions: [{type: ""COMMON"", text: {content: ""role playing games"", beginOffset: -1}}]}
{name: ""Switch"", salience: 0.143287, metadata: {}, type: ""OTHER"", mentions: [{type: ""COMMON"", text: {content: ""Switch"", beginOffset: -1}}]}
{name: ""friends"", salience: 0.13336793, metadata: {}, type: ""PERSON"", mentions: [{type: ""COMMON"", text: {content: ""friends"", beginOffset: -1}}]}
{name: ""Nintendo"", salience: 0.12601112, metadata: {mid: ""/g/1ymzszlpz""}, type: ""ORGANIZATION"", mentions: [{type: ""PROPER"", text: {content: ""Nintendo"", beginOffset: -1}}]}
{name: ""board games"", salience: 0.08861496, metadata: {}, type: ""CONSUMER_GOOD"", mentions: [{type: ""COMMON"", text: {content: ""board games"", beginOffset: -1}}]}
{name: ""tournaments"", salience: 0.0603245, metadata: {}, type: ""EVENT"", mentions: [{type: ""COMMON"", text: {content: ""tournaments"", beginOffset: -1}}]}
{name: ""offices"", salience: 0.034420907, metadata: {}, type: ""LOCATION"", mentions: [{type: ""COMMON"", text: {content: ""offices"", beginOffset: -1}}]}
{name: ""Mario Kart 8"", salience: 0.029095741, metadata: {wikipedia_url: ""https://en.wikipedia.org/wiki/Mario_Kart_8"", mid: ""/m/0119mf7q""}, type: ""PERSON"", mentions: [{type: ""PROPER"", text: {content: ""Mario Kart 8"", beginOffset: -1}}]}
{name: ""European"", salience: 0.020393685, metadata: {mid: ""/m/02j9z"", wikipedia_url: ""https://en.wikipedia.org/wiki/Europe""}, type: ""LOCATION"", mentions: [{type: ""PROPER"", text: {content: ""European"", beginOffset: -1}}]}
{name: ""Neo4j"", salience: 0.020393685, metadata: {mid: ""/m/0b76t3s"", wikipedia_url: ""https://en.wikipedia.org/wiki/Neo4j""}, type: ""ORGANIZATION"", mentions: [{type: ""PROPER"", text: {content: ""Neo4j"", beginOffset: -1}}]}
{name: ""8"", salience: 0, metadata: {value: ""8""}, type: ""NUMBER"", mentions: [{type: ""TYPE_UNKNOWN"", text: {content: ""8"", beginOffset: -1}}]}
We get back 12 different entities. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
The following streams the entities for the Pokemon article and then creates nodes for each entity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
MERGE (e:Entity {name: entity.name})
SET e.type = entity.type
MERGE (a)-[:ENTITY]->(e);
If we want to automatically create an entity graph, see apoc.nlp.gcp.entities.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.gcp.entities.graph;"apoc.nlp.gcp.entities.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) entity graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.gcp.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API Key that has access to the Cloud Natural Language API by going to console.cloud.google.com/apis/credentials. Once we’ve created a key, we can populate and execute the following command to create a parameter that contains these details.
Cypher
The following defines the apiKey parameter
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"")
Alternatively we can add these credentials to apoc.conf and load them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.gcp.apiKey=<api-key-here>
Cypher
The following retrieves GCP credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""gcp"") AS gcp;
Table 1. Results
gcp
{apiKey: ""<api-key-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default a virtual graph is returned.
The following returns a virtual graph of entities for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.gcp.entities.graph(a, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon entities graph.
Figure 1. Pokemon entities graph
We can compute the entities for multiple nodes by passing a list of nodes to the procedure.
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents importance of that entity in the entire document. We can specify a minimum cut off value for the score using the scoreCutoff property.
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY"",
  scoreCutoff: 0.01
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with importance >= 0.01.
Figure 3. Pokemon and Nintendo Switch entities graph with importance >= 0.01
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
The following creates a HAS_ENTITY relationship from the article to each entity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.gcp.entities.graph(articles, {
  key: $apiKey,
  nodeProperty: ""body"",
  scoreCutoff: 0.01,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""gcpEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
The following returns articles and their entities:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e) | {entity: e.text, score: r.gcpEntityScore}] AS entities;
Table 2. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.020393685, entity: ""Neo4j""}, {score: 0.034420907, entity: ""offices""}, {score: 0.0603245, entity: ""tournaments""}, {score: 0.020393685, entity: ""European""}, {score: 0.029095741, entity: ""Mario Kart 8""}, {score: 0.12601112, entity: ""Nintendo""}, {score: 0.13336793, entity: ""friends""}, {score: 0.08861496, entity: ""board games""}, {score: 0.143287, entity: ""Switch""}, {score: 0.16441391, entity: ""role playing games""}, {score: 0.17967656, entity: ""card games""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.76108575, entity: ""Nintendo Switch""}, {score: 0.07424594, entity: ""Nintendo""}, {score: 0.015900765, entity: ""home console""}, {score: 0.012772448, entity: ""device""}, {score: 0.038113687, entity: ""regions""}, {score: 0.07299799, entity: ""Joy-Con Wheel""}]
If we want to stream back entities and apply custom logic to the results, see apoc.nlp.gcp.entities.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/nlp/azure;"Microsoft Azure Cognitive Services
Contents
Procedure Overview
Entity Extraction
Key Phrases
Sentiment
Install Dependencies
Setting up API Key and URL
Examples
Entity Extraction
Key Phrases
Sentiment
The Microsoft Azure Cognitive Services API uses machine learning to find insights and relationships in text. The procedures in this chapter act as a wrapper around calls to this API to extract entities and key phrases and provide sentiment analysis from text stored as node properties.
Each procedure has two modes:
Stream - returns a map constructed from the JSON returned from the API
Procedure Overview
The procedures are described below:
Qualified Name Type Release
apoc.nlp.azure.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
Apoc Extended
apoc.nlp.azure.entities.stream
Provides a entity analysis for provided text
Procedure
Apoc Extended
apoc.nlp.azure.keyPhrases.graph
Creates a (virtual) key phrase graph for provided text
Procedure
Apoc Extended
apoc.nlp.azure.keyPhrases.stream
Provides a entity analysis for provided text
Procedure
Apoc Extended
apoc.nlp.azure.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
Apoc Extended
apoc.nlp.azure.sentiment.stream
Provides a sentiment analysis for provided text
Procedure
Apoc Extended
At the moment, Microsoft Azure Cognitive Services API supports text input in more than 10 languages. For better results, make sure that your text is one of the supported languages by Cognitive Services.
Entity Extraction
The entity extraction procedures (apoc.nlp.azure.entities.*) are wrappers around the Entities end point of the Azure Text Analytics API. This API method returns a list of known entities and general named entities (""Person"", ""Location"", ""Organization"" etc) in a given document.
The procedures are described below:
signature
apoc.nlp.azure.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
apoc.nlp.azure.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
The procedure supports the following config parameters:
Table 1. Config parameters
name type default description
key
String
null
Microsoft.CognitiveServicesTextAnalytics API Key
url
String
null
Microsoft.CognitiveServicesTextAnalytics Endpoint
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.azure.entities.graph supports the following config parameters:
Table 2. Config parameters
name type default description
scoreCutoff
Double
0.0
Lower limit for the score of an entity to be present in the graph. Value must be between 0 and 1.
Score is an indicator of the level of confidence that Amazon Comprehend has in the accuracy of the detection.
write
Boolean
false
persist the graph of entities
writeRelationshipType
String
ENTITY
relationship type for relationships from source node to entity nodes
writeRelationshipProperty
String
score
relationship property for relationships from source node to entity nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.entities.stream(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.entities.graph(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String,
  scoreCutoff: Double,
  writeRelationshipType: String,
  writeRelationshipProperty: String,
  write: Boolean
})
YIELD graph
Key Phrases
The key phrase procedures (apoc.nlp.azure.keyPhrases.*) are wrappers around the Key Phrases end point of the Azure Text Analytics API. A key phrase is a key talking point in the input text.
The procedure is described below:
signature
apoc.nlp.azure.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
apoc.nlp.azure.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
The procedure support the following config parameters:
Table 3. Config parameters
name type default description
key
String
null
Microsoft.CognitiveServicesTextAnalytics API Key
url
String
null
Microsoft.CognitiveServicesTextAnalytics Endpoint
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.azure.keyPhrases.graph supports the following config parameters:
Table 4. Config parameters
name type default description
write
Boolean
false
persist the graph of key phrases
writeRelationshipType
String
KEY_PHRASE
relationship type for relationships from source node to key phrase nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.keyPhrases.stream(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.keyPhrases.graph(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String,
  writeRelationshipType: String,
  write: Boolean
})
YIELD graph
Sentiment
The sentiment procedures (apoc.nlp.azure.sentiment.*) are wrappers around the Sentiment end point of the Azure Text Analytics API. The API returns a numeric score between 0 and 1. Scores close to 1 indicate positive sentiment, while scores close to 0 indicate negative sentiment. A score of 0.5 indicates the lack of sentiment (e.g. a factoid statement).
The procedures are described below:
signature
apoc.nlp.azure.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
apoc.nlp.azure.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
The procedures support the following config parameters:
Table 5. Config parameters
name type default description
key
String
null
Microsoft.CognitiveServicesTextAnalytics API Key
url
String
null
Microsoft.CognitiveServicesTextAnalytics Endpoint
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.azure.sentiment.graph supports the following config parameters:
Table 6. Config parameters
name type default description
write
Boolean
false
persist the graph of sentiment
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.sentiment.stream(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.azure.sentiment.graph(source:Node or List<Node>, {
  key: String,
  url: String,
  nodeProperty: String,
  write: Boolean
})
YIELD graph
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key and URL
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions. See Static Value Storage
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 7. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
Entity Extraction
Let’s start by extracting the entities from one of the Article nodes. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.entities.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 8. Results
entity
{name: ""Nintendo Switch"", wikipediaId: ""Nintendo Switch"", type: ""Other"", matches: [{length: 15, text: ""Nintendo Switch"", wikipediaScore: 0.8339868065025469, offset: 56}], bingId: ""b3d617ef-81fc-4188-9a2b-a5cf1f8534b5"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Nintendo_Switch""}
{name: ""Nintendo Switch"", type: ""Organization"", matches: [{length: 15, entityTypeScore: 0.94, text: ""Nintendo Switch"", offset: 56}]}
{name: ""Oberon Media"", wikipediaId: ""Oberon Media"", type: ""Organization"", matches: [{length: 6, text: ""I play"", wikipediaScore: 0.032446316016667254, offset: 76}], bingId: ""166f6e0f-33b7-8707-bb8b-5a932c498333"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Oberon_Media""}
{name: ""a week"", subType: ""Duration"", type: ""DateTime"", matches: [{length: 6, entityTypeScore: 0.8, text: ""a week"", offset: 166}]}
{name: ""Mario Kart 8"", wikipediaId: ""Mario Kart 8"", type: ""Other"", matches: [{length: 12, text: ""Mario Kart 8"", wikipediaScore: 0.7802000593632747, offset: 205}], bingId: ""ce6f55ec-d3d7-032a-0bf8-15ad3e8df3f4"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Mario_Kart_8""}
{name: ""Mario Kart"", type: ""Organization"", matches: [{length: 10, entityTypeScore: 0.72, text: ""Mario Kart"", offset: 205}]}
{name: ""8"", subType: ""Number"", type: ""Quantity"", matches: [{length: 1, entityTypeScore: 0.8, text: ""8"", offset: 216}]}
{name: ""Neo4j"", wikipediaId: ""Neo4j"", type: ""Other"", matches: [{length: 5, text: ""Neo4j"", wikipediaScore: 0.8150388253887939, offset: 242}], bingId: ""bc2f436b-8edd-6ba6-b2d3-69901348d653"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Neo4j""}
{name: ""Europe"", wikipediaId: ""Europe"", type: ""Location"", matches: [{length: 8, text: ""European"", wikipediaScore: 0.00591759926701263, offset: 248}], bingId: ""501457aa-5b70-cfba-cfd8-be882b4bac1e"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Europe""}
We get back 9 different entities, although we can see that some of them are referring to the same things, albeit with different type values. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
Cypher
The following streams the entities for the Pokemon article and then creates nodes for each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.entities.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
WITH a, entity.name AS entity, collect(entity.type) AS types
MERGE (e:Entity {name: entity})
SET e.type = types
MERGE (a)-[:ENTITY]->(e);
Alternatively we can use the graph mode to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default, a virtual graph is returned.
Cypher
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents the level of confidence that the API has in its detection of the entity. We can specify a minimum cut off value for the score using the scoreCutoff property.
Cypher
The following returns a virtual graph of entities with a score >= 0.7 for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with confidence >= 0.7.
Figure 3. Pokemon and Nintendo Switch entities graph with confidence >= 0.7
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
Cypher
The following creates a HAS_ENTITY relationship from the article to each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""azureEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e:Entity) | {text: e.text, score: r.azureEntityScore}] AS entities;
Table 9. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.72, text: ""Mario Kart""}, {score: 0.7802000593632747, text: ""Mario Kart 8""}, {score: 0.8, text: ""8""}, {score: 0.8, text: ""a week""}, {score: 0.94, text: ""Nintendo Switch""}, {score: 0.8150388253887939, text: ""Neo4j""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.9023679924293266, text: ""Joy-Con""}, {score: 0.98, text: ""Nintendo""}, {score: 0.8, text: ""March 3, 2017""}, {score: 0.9355623498560008, text: ""Nintendo Switch""}, {score: 0.92, text: ""Mario Kart""}, {score: 0.8, text: ""8""}, {score: 0.8863202650046607, text: ""Mario Kart 8""}, {score: 0.8, text: ""October 20, 2016""}]
Key Phrases
Let’s now extract the key phrases from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.keyPhrases.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.keyPhrases AS keyPhrase
RETURN keyPhrase;
Table 10. Results
keyPhrase
""board games""
""card games""
""tournaments""
""role""
""organised lunch-time Mario Kart""
""Neo4j European offices""
""Nintendo Switch""
""friends""
""feet""
""days""
Alternatively we can use the graph mode to automatically create a key phrase graph. One node with the KeyPhrase label will be created for each key phrase extracted.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration.
Cypher
The following returns a graph of key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.keyPhrases.graph(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  writeRelationshipType: ""KEY_PHRASE"",
  write: true
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon key phrases graph.
Figure 4. Pokemon key phrases graph
We can then write a query to return the key phrases that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
RETURN a.uri AS article,
       [(a)-[:KEY_PHRASE]->(k:KeyPhrase) | k.text] AS keyPhrases;
Table 11. Results
article keyPhrases
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[""card games"", ""board games"", ""friends"", ""feet"", ""Nintendo Switch"", ""days"", ""organised lunch-time Mario Kart"", ""tournaments"", ""Neo4j European offices"", ""role""]
Sentiment
Let’s now extract the sentiment for the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.sentiment.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
RETURN value;
Table 12. Results
value
{score: 0.5, id: ""0""}
Alternatively we can use the graph mode to automatically store the sentiment and its score.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration. The sentiment score is stored in the sentimentScore property.
Cypher
The following returns a graph with the sentiment for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.sentiment.graph(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  write: true
})
YIELD graph AS g
UNWIND g.nodes AS node
RETURN node {.uri, .sentimentScore} AS node;
Table 13. Results
node
{uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"", sentimentScore: 0.5}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.keyPhrases.graph;"apoc.nlp.azure.keyPhrases.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) key phrase graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create a key phrase graph. One node with the KeyPhrase label will be created for each key phrase extracted.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration.
Cypher
The following returns a graph of key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.keyPhrases.graph(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  writeRelationshipType: ""KEY_PHRASE"",
  write: true
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon key phrases graph.
Figure 2. Pokemon key phrases graph
We can then write a query to return the key phrases that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
RETURN a.uri AS article,
       [(a)-[:KEY_PHRASE]->(k:KeyPhrase) | k.text] AS keyPhrases;
Table 2. Results
article keyPhrases
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[""card games"", ""board games"", ""friends"", ""feet"", ""Nintendo Switch"", ""days"", ""organised lunch-time Mario Kart"", ""tournaments"", ""Neo4j European offices"", ""role""]
If we want to stream back key phrases and apply custom logic to the results, see apoc.nlp.azure.keyPhrases.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.keyPhrases.stream;"apoc.nlp.azure.keyPhrases.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Provides a entity analysis for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the key phrases from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the key phrases for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.keyPhrases.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.keyPhrases AS keyPhrase
RETURN keyPhrase;
Table 2. Results
keyPhrase
""board games""
""card games""
""tournaments""
""role""
""organised lunch-time Mario Kart""
""Neo4j European offices""
""Nintendo Switch""
""friends""
""feet""
""days""
If we want to automatically create a key phrase graph, see apoc.nlp.azure.keyPhrases.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.entities.graph;"apoc.nlp.azure.entities.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) entity graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default a virtual graph is returned.
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents the level of confidence that the API has in its detection of the entity. We can specify a minimum cut off value for the score using the scoreCutoff property.
The following returns a virtual graph of entities with a score >= 0.7 for the Pokemon and Nintendo Switch articles:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with confidence >= 0.7.
Figure 3. Pokemon and Nintendo Switch entities graph with confidence >= 0.7
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
The following creates a HAS_ENTITY relationship from the article to each entity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.azure.entities.graph(articles, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""azureEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
The following returns articles and their entities:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e:Entity) | {text: e.text, score: r.azureEntityScore}] AS entities;
Table 2. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.72, text: ""Mario Kart""}, {score: 0.7802000593632747, text: ""Mario Kart 8""}, {score: 0.8, text: ""8""}, {score: 0.8, text: ""a week""}, {score: 0.94, text: ""Nintendo Switch""}, {score: 0.8150388253887939, text: ""Neo4j""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.9023679924293266, text: ""Joy-Con""}, {score: 0.98, text: ""Nintendo""}, {score: 0.8, text: ""March 3, 2017""}, {score: 0.9355623498560008, text: ""Nintendo Switch""}, {score: 0.92, text: ""Mario Kart""}, {score: 0.8, text: ""8""}, {score: 0.8863202650046607, text: ""Mario Kart 8""}, {score: 0.8, text: ""October 20, 2016""}]
If we want to stream back entities and apply custom logic to the results, see apoc.nlp.azure.entities.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.entities.stream;"apoc.nlp.azure.entities.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Provides a entity analysis for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the entities from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the entities for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.entities.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 2. Results
entity
{name: ""Nintendo Switch"", wikipediaId: ""Nintendo Switch"", type: ""Other"", matches: [{length: 15, text: ""Nintendo Switch"", wikipediaScore: 0.8339868065025469, offset: 56}], bingId: ""b3d617ef-81fc-4188-9a2b-a5cf1f8534b5"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Nintendo_Switch""}
{name: ""Nintendo Switch"", type: ""Organization"", matches: [{length: 15, entityTypeScore: 0.94, text: ""Nintendo Switch"", offset: 56}]}
{name: ""Oberon Media"", wikipediaId: ""Oberon Media"", type: ""Organization"", matches: [{length: 6, text: ""I play"", wikipediaScore: 0.032446316016667254, offset: 76}], bingId: ""166f6e0f-33b7-8707-bb8b-5a932c498333"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Oberon_Media""}
{name: ""a week"", subType: ""Duration"", type: ""DateTime"", matches: [{length: 6, entityTypeScore: 0.8, text: ""a week"", offset: 166}]}
{name: ""Mario Kart 8"", wikipediaId: ""Mario Kart 8"", type: ""Other"", matches: [{length: 12, text: ""Mario Kart 8"", wikipediaScore: 0.7802000593632747, offset: 205}], bingId: ""ce6f55ec-d3d7-032a-0bf8-15ad3e8df3f4"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Mario_Kart_8""}
{name: ""Mario Kart"", type: ""Organization"", matches: [{length: 10, entityTypeScore: 0.72, text: ""Mario Kart"", offset: 205}]}
{name: ""8"", subType: ""Number"", type: ""Quantity"", matches: [{length: 1, entityTypeScore: 0.8, text: ""8"", offset: 216}]}
{name: ""Neo4j"", wikipediaId: ""Neo4j"", type: ""Other"", matches: [{length: 5, text: ""Neo4j"", wikipediaScore: 0.8150388253887939, offset: 242}], bingId: ""bc2f436b-8edd-6ba6-b2d3-69901348d653"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Neo4j""}
{name: ""Europe"", wikipediaId: ""Europe"", type: ""Location"", matches: [{length: 8, text: ""European"", wikipediaScore: 0.00591759926701263, offset: 248}], bingId: ""501457aa-5b70-cfba-cfd8-be882b4bac1e"", wikipediaLanguage: ""en"", wikipediaUrl: ""https://en.wikipedia.org/wiki/Europe""}
We get back 9 different entities, although we can see that some of them are referring to the same things, albeit with different type values. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
The following streams the entities for the Pokemon article and then creates nodes for each entity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.entities.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
WITH a, entity.name AS entity, collect(entity.type) AS types
MERGE (e:Entity {name: entity})
SET e.type = types
MERGE (a)-[:ENTITY]->(e);
If we want to automatically create an entity graph, see apoc.nlp.azure.entities.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.sentiment.graph;"apoc.nlp.azure.sentiment.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) sentiment graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically store the sentiment and its score.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration. The sentiment is stored in the sentiment property and the score for that sentiment in the sentimentScore property.
The following returns a graph with the sentiment for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.sentiment.graph(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body"",
  write: true
})
YIELD graph AS g
UNWIND g.nodes AS node
RETURN node {.uri, .sentimentScore} AS node;
Table 2. Results
node
{uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"", sentimentScore: 0.5}
If we want to stream back the sentiment and apply custom logic to the results, see apoc.nlp.azure.sentiment.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.azure.sentiment.stream;"apoc.nlp.azure.sentiment.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Provides a sentiment analysis for provided text
Signature
None
Copy to Clipboard
apoc.nlp.azure.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an API key and URL by following the instructions in the Quickstart: Use the Text Analytics client library article. Once we’ve done that, we should be able to see a page listing our credentials, similar to the screenshot below:
Figure 1. Azure Text Analytics credentials
In this case our API URL is https://neo4j-nlp-text-analytics.cognitiveservices.azure.com/, and we can use either of the hidden keys.
Let’s populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiUrl => (""<api-url-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.azure.apiKey=<api-key-here>
apoc.static.azure.apiUrl=<api-url-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""azure"") AS azure;
Table 1. Results
azure
{apiKey: ""<api-key-here>"", apiUrl: ""<api-url-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the sentiment for the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the key phrases for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.azure.sentiment.stream(a, {
  key: $apiKey,
  url: $apiUrl,
  nodeProperty: ""body""
})
YIELD value
RETURN value;
Table 2. Results
value
{score: 0.5, id: ""0""}
If we want to automatically store the sentiment, see apoc.nlp.azure.sentiment.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/misc/static-values;"Static Value Storage
Contents
Working with API Credentials
Caching Query Results
The library has support for storing and retrieving static values, functionality that can be used to work with API credentials or cache query results.
Qualified Name Type Release
apoc.static.get
apoc.static.get(name) - returns statically stored value from config (apoc.static.<key>) or server lifetime storage
Function
Apoc Extended
apoc.static.getAll
apoc.static.getAll(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Function
Apoc Extended
apoc.static.set
apoc.static.set(name, value) - stores value under key for server lifetime storage, returns previously stored or configured value
Procedure
Apoc Extended
This section includes the following sub sections:
Working with API Credentials
Caching Query Results
Working with API Credentials
The examples below assume that we have the following entries in the APOC configuration file (conf/apoc.conf):
apoc.static.twitter.bearer=ABCDEF
apoc.static.twitter.url=https://api.twitter.com/1.1/search/tweets.json?count=100&result_type=recent&lang=en&q=
Cypher
The following returns the apoc.static.twitter.bearer value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.get(""twitter.bearer"") AS value
Table 1. Results
value
""ABCDEF""
Cypher
The following returns all values with the twitter prefix
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""twitter"") AS value
Table 2. Results
value
{""bearer"":""ABCDEF"",""url"":""https://api.twitter.com/1.1/search/tweets.json?count=100&result_type=recent&lang=en&q=""}
Cypher
The following stores an in memory value that lasts for the lifetime of the server:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.static.set(""twitter.user"", ""Michael"")
Table 3. Results
value
null
Caching Query Results
We can also use these procedures and functions to cache the results of queries.
Cypher
The following creates a sample graph
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Mark""})
CREATE (:Person {name: ""Michael""})
CREATE (:Person {name: ""Karin""})
CREATE (:Person {name: ""Jennifer""})
Cypher
The following finds people whose name does not start with the letter m and stores them as a static value:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE not (p.name starts with ""M"")
WITH collect(p) AS people
CALL apoc.static.set(""cached.people"", people)
YIELD value
RETURN value
Cypher
The following retrieves those people from the cached.people static value:
Copy to Clipboard
Run in Neo4j Browser
UNWIND apoc.static.get(""cached.people"") AS person
RETURN person, labels(person) AS label, apoc.meta.cypher.type(person) AS type
Table 4. Results
person label type
{""name"":""Karin""}
[""Person""]
""NODE""
{""name"":""Jennifer""}
[""Person""]
""NODE""
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.static/apoc.static.getAll;"apoc.static.getAll
Contents
Signature
Input parameters
Usage Examples
Function Apoc Extended
apoc.static.getAll(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Signature
None
Copy to Clipboard
apoc.static.getAll(prefix :: STRING?) :: (MAP?)
Input parameters
Name Type Default
prefix
STRING?
null
Usage Examples
The examples in this section assume that we have the following entries in the APOC configuration file (conf/apoc.conf):
apoc.static.twitter.bearer=ABCDEF
apoc.static.twitter.url=https://api.twitter.com/1.1/search/tweets.json?count=100&result_type=recent&lang=en&q=
The following returns all values with the twitter prefix:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""twitter"") AS value
Table 1. Results
value
{""bearer"":""ABCDEF"",""url"":""https://api.twitter.com/1.1/search/tweets.json?count=100&result_type=recent&lang=en&q=""}
More documentation of apoc.static.getAll
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.static/apoc.static.set;"apoc.static.set
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.static.set(name, value) - stores value under key for server lifetime storage, returns previously stored or configured value
Signature
None
Copy to Clipboard
apoc.static.set(key :: STRING?, value :: ANY?) :: (value :: ANY?)
Input parameters
Name Type Default
key
STRING?
null
value
ANY?
null
Output parameters
Name Type
value
ANY?
Usage Examples
The following stores an in memory value that lasts for the lifetime of the server:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.static.set(""twitter.user"", ""Michael"");
Table 1. Results
value
null
We can retrieve static values using apoc.static.get and apoc.static.getAll.
More documentation of apoc.static.set
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.static/apoc.static.get;"apoc.static.get
Contents
Signature
Input parameters
Usage Examples
Function Apoc Extended
apoc.static.get(name) - returns statically stored value from config (apoc.static.<key>) or server lifetime storage
Signature
None
Copy to Clipboard
apoc.static.get(key :: STRING?) :: (ANY?)
Input parameters
Name Type Default
key
STRING?
null
Usage Examples
The examples in this section assume that we have the following entries in the APOC configuration file (conf/apoc.conf):
apoc.static.twitter.bearer=ABCDEF
apoc.static.twitter.url=https://api.twitter.com/1.1/search/tweets.json?count=100&result_type=recent&lang=en&q=
The following returns the apoc.static.twitter.bearer value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.get(""twitter.bearer"") AS value;
Table 1. Results
value
""ABCDEF""
More documentation of apoc.static.get
Was this page helpful?"
https://neo4j.com/labs/apoc/5/nlp/aws;"Amazon Web Services (AWS)
Contents
Procedure Overview
Entity Extraction
Key Phrases
Sentiment
Install Dependencies
Setting up API Key and Secret
Batching Requests
Examples
Entity Extraction
Key Phrases
Sentiment
The Amazon Web Services (AWS) Comprehend Natural Language API uses machine learning to find insights and relationships in text. The procedures in this chapter act as a wrapper around calls to this API to extract entities and key phrases from text stored as node properties.
Each procedure has two modes:
Stream - returns a map constructed from the JSON returned from the API
Graph - creates a graph or virtual graph based on the values returned by the API
The procedures described in this chapter make API calls and subsequent updates to the database on the calling thread. If we want to make parallel requests to the API and avoid out of memory errors from keeping too much transaction state in memory while running procedures that write to the database, see Batching Requests.
Procedure Overview
The procedures are described below:
Qualified Name Type Release
apoc.nlp.aws.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
Apoc Extended
apoc.nlp.aws.entities.stream
Returns a stream of entities for provided text
Procedure
Apoc Extended
apoc.nlp.aws.keyPhrases.graph
Creates a (virtual) key phrases graph for provided text
Procedure
Apoc Extended
apoc.nlp.aws.keyPhrases.stream
Returns a stream of key phrases for provided text
Procedure
Apoc Extended
apoc.nlp.aws.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
Apoc Extended
apoc.nlp.aws.sentiment.stream
Returns stream of sentiment for items in provided text
Procedure
Apoc Extended
At the moment, Amazon Comprehend API supports text input in more than 10 languages. For better results, make sure that your text is one of the supported languages by Amazon Comprehend.
Entity Extraction
The entity extraction procedures (apoc.nlp.aws.entities.*) are wrappers around the Detect Entities operations of the AWS Comprehend Natural Language API. This API method finds entities in the text, which are defined as a textual reference to the unique name of a real-world object such as people, places, and commercial items, and to precise references to measures such as dates and quantities.
The procedures are described below:
signature
apoc.nlp.aws.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
apoc.nlp.aws.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
key
String
null
AWS Access Control Key
secret
String
null
AWS Access Control Secret
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.aws.entities.graph supports the following config parameters:
Table 2. Config parameters
name type default description
scoreCutoff
Double
0.0
Lower limit for the score of an entity to be present in the graph. Value must be between 0 and 1.
Score is an indicator of the level of confidence that Amazon Comprehend has in the accuracy of the detection.
write
Boolean
false
persist the graph of entities
writeRelationshipType
String
ENTITY
relationship type for relationships from source node to entity nodes
writeRelationshipProperty
String
score
relationship property for relationships from source node to entity nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.entities.stream(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.entities.graph(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String,
  scoreCutoff: Double,
  writeRelationshipType: String,
  writeRelationshipProperty: String,
  write: Boolean
})
YIELD graph
Key Phrases
The key phrase procedures (apoc.nlp.aws.keyPhrases.*) are wrappers around the Detect Key Phrases operations of the AWS Comprehend Natural Language API. A key phrase is a string containing a noun phrase that describes a particular thing. It generally consists of a noun and the modifiers that distinguish it.
The procedures are described below:
signature
apoc.nlp.aws.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
apoc.nlp.aws.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
The procedures support the following config parameters:
Table 3. Config parameters
name type default description
key
String
null
AWS Access Control Key
secret
String
null
AWS Access Control Secret
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.aws.keyPhrases.graph supports the following config parameters:
Table 4. Config parameters
name type default description
scoreCutoff
Double
0.0
Lower limit for the score of an entity to be present in the graph. Value must be between 0 and 1.
Score is an indicator of the level of confidence that Amazon Comprehend has in the accuracy of the detection.
write
Boolean
false
persist the graph of key phrases
writeRelationshipType
String
KEY_PHRASE
relationship type for relationships from source node to key phrase nodes
writeRelationshipProperty
String
score
relationship property for relationships from source node to key phrase nodes
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.keyPhrases.stream(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.keyPhrases.graph(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String,
  scoreCutoff: Double,
  writeRelationshipType: String,
  writeRelationshipProperty: String,
  write: Boolean
})
YIELD graph
Sentiment
The sentiment procedures (apoc.nlp.aws.sentiment.*) are wrappers around the Determine Sentiment operations of the AWS Comprehend Natural Language API. You can determine if the sentiment is positive, negative, neutral, or mixed.
The procedures are described below:
signature
apoc.nlp.aws.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
apoc.nlp.aws.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
The procedures support the following config parameters:
Table 5. Config parameters
name type default description
key
String
null
AWS Access Control Key
secret
String
null
AWS Access Control Secret
nodeProperty
String
text
The property on the provided node that contains the unstructured text to be analyzed
In addition, apoc.nlp.aws.sentiment.graph supports the following config parameters:
Table 6. Config parameters
name type default description
write
Boolean
false
persist the graph of sentiment
Cypher
Streaming mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.sentiment.stream(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String
})
YIELD value
Cypher
Graph mode
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nlp.aws.sentiment.graph(source:Node or List<Node>, {
  key: String,
  secret: String,
  nodeProperty: String,
  writeRelationshipType: String,
  write: Boolean
})
YIELD graph
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key and Secret
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions. See Static Value Storage.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 7. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Batching Requests
Batching requests to the AWS API and the processing of results can be done using Periodic Iterate. This approach is useful if we want to make parallel requests to the AWS API and reduce the amount of transaction state kept in memory while running procedures that write to the database.
The AWS Comprehend API processes a maximum of 25 documents in one request, so for optimal performance we should pass in lists that are a multiple of this size. Keep in mind that if we pass in big lists this will result in more transaction state when writing to the database and may cause out of memory exceptions.
Cypher
The following creates an entity graph in batches of 25 nodes
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(""
  MATCH (n)
  WITH collect(n) as total
  CALL apoc.coll.partition(total, 25)
  YIELD value as nodes
  RETURN nodes"", ""
  CALL apoc.nlp.aws.entities.graph(nodes, {
    key: $apiKey,
    secret: $apiSecret,
    nodeProperty: 'body',
    writeRelationshipType: 'AWS_ENTITY',
    write:true
  })
  YIELD graph
  RETURN distinct 'done'"", {
    batchSize: ,
    params: { apiKey: $apiKey, apiSecret: $apiSecret }
  }
);
View all (4 more lines)
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
Entity Extraction
Let’s start by extracting the entities from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 8. Results
entity
{score: 0.780032217502594, endOffset: 71, text: ""Nintendo Switch"", type: ""COMMERCIAL_ITEM"", beginOffset: 56}
{score: 0.8155304193496704, endOffset: 151, text: ""at least"", type: ""QUANTITY"", beginOffset: 143}
{score: 0.7507548332214355, endOffset: 156, text: ""once"", type: ""QUANTITY"", beginOffset: 152}
{score: 0.8760746717453003, endOffset: 172, text: ""twice a week"", type: ""QUANTITY"", beginOffset: 160}
{score: 0.9944096803665161, endOffset: 217, text: ""Mario Kart 8"", type: ""TITLE"", beginOffset: 205}
{score: 0.9946564435958862, endOffset: 247, text: ""Neo4j"", type: ""ORGANIZATION"", beginOffset: 242}
{score: 0.6274040937423706, endOffset: 256, text: ""European"", type: ""LOCATION"", beginOffset: 248}
We get back 7 different entities. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
Cypher
The following streams the entities for the Pokemon article and then creates nodes for each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
MERGE (e:Entity {name: entity.text})
SET e.type = entity.type
MERGE (a)-[:ENTITY]->(e)
Alternatively we can use the graph mode to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default, a virtual graph is returned.
Cypher
The following returns a virtual graph of entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon entities graph.
Figure 1. Pokemon entities graph
We can compute the entities for multiple nodes by passing a list of nodes to the procedure.
Cypher
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents the level of confidence that the API has in its detection of the entity. We can specify a minimum cut off value for the score using the scoreCutoff property.
Cypher
The following returns a virtual graph of entities with a score >= 0.7 for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with confidence >= 0.7.
Figure 3. Pokemon and Nintendo Switch entities graph with confidence >= 0.7
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
Cypher
The following creates a HAS_ENTITY relationship from the article to each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""awsEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e:Entity) | {text: e.text, score: r.awsEntityScore}] AS entities;
Table 9. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.9944096803665161, text: ""Mario Kart 8""}, {score: 0.8760746717453003, text: ""twice a week""}, {score: 0.9946564435958862, text: ""Neo4j""}, {score: 0.7507548332214355, text: ""once""}, {score: 0.8155304193496704, text: ""at least""}, {score: 0.780032217502594, text: ""Nintendo Switch""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.9990180134773254, text: ""Mario Kart 8""}, {score: 0.9997879862785339, text: ""March 3, 2017""}, {score: 0.9958534240722656, text: ""Nintendo""}, {score: 0.9998348355293274, text: ""October 20, 2016""}, {score: 0.753325343132019, text: ""Nintendo Switch""}]
Key Phrases
Let’s now extract the key phrases from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.keyPhrases.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.keyPhrases AS keyPhrase
RETURN keyPhrase;
Table 10. Results
keyPhrase
{score: 0.9999966621398926, endOffset: 10, text: ""These days"", beginOffset: 0}
{score: 0.9867414236068726, endOffset: 42, text: ""more than a few feet"", beginOffset: 22}
{score: 0.9999999403953552, endOffset: 71, text: ""my Nintendo Switch"", beginOffset: 53}
{score: 0.9999997019767761, endOffset: 94, text: ""board games"", beginOffset: 83}
{score: 0.9999964237213135, endOffset: 106, text: ""card games"", beginOffset: 96}
{score: 0.9998161792755127, endOffset: 129, text: ""role playing games"", beginOffset: 111}
{score: 1.0, endOffset: 142, text: ""friends"", beginOffset: 135}
{score: 0.8642383217811584, endOffset: 172, text: ""a week"", beginOffset: 166}
{score: 0.9999430179595947, endOffset: 215, text: ""lunch-time Mario Kart"", beginOffset: 194}
{score: 0.9983567595481873, endOffset: 229, text: ""8 tournaments"", beginOffset: 216}
{score: 0.999997615814209, endOffset: 264, text: ""the Neo4j European offices"", beginOffset: 238}
Alternatively we can use the graph mode to automatically create a key phrase graph. One node with the KeyPhrase label will be created for each key phrase extracted.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration.
Cypher
The following returns a graph of key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.keyPhrases.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""KEY_PHRASE"",
  write: true
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon key phrases graph.
Figure 4. Pokemon key phrases graph
We can then write a query to return the key phrases that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
RETURN a.uri AS article,
       [(a)-[:KEY_PHRASE]->(k:KeyPhrase) | k.text] AS keyPhrases;
Table 11. Results
article keyPhrases
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[""the Neo4j European offices"", ""a week"", ""friends"", ""8 tournaments"", ""lunch-time Mario Kart"", ""card games"", ""board games"", ""role playing games"", ""my Nintendo Switch"", ""more than a few feet"", ""These days""]
Sentiment
Let’s now extract the sentiment for the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
Cypher
The following streams the key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.sentiment.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
RETURN value;
Table 12. Results
value
{index: 0, sentiment: ""POSITIVE"", sentimentScore: {neutral: 0.33138760924339294, negative: 0.0026062370743602514, mixed: 3.5950531582784606E-6, positive: 0.6660025119781494}}
Alternatively we can use the graph mode to automatically store the sentiment and its score.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration. The sentiment is stored in the sentiment property and the score for that sentiment in the sentimentScore property.
Cypher
The following returns a graph with the sentiment for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.sentiment.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  write: true
})
YIELD graph AS g
UNWIND g.nodes AS node
RETURN node {.uri, .sentiment, .sentimentScore} AS node;
Table 13. Results
node
{sentiment: ""Positive"", sentimentScore: 0.6660025119781494, uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.sentiment.stream;"apoc.nlp.aws.sentiment.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Returns stream of sentiment for items in provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the sentiment for the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the key phrases for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.sentiment.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
RETURN value;
Table 2. Results
value
{index: 0, sentiment: ""POSITIVE"", sentimentScore: {neutral: 0.33138760924339294, negative: 0.0026062370743602514, mixed: 3.5950531582784606E-6, positive: 0.6660025119781494}}
If we want to automatically store the sentiment, see apoc.nlp.aws.sentiment.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.sentiment.graph;"apoc.nlp.aws.sentiment.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) sentiment graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically store the sentiment and its score.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration. The sentiment is stored in the sentiment property and the score for that sentiment in the sentimentScore property.
The following returns a graph with the sentiment for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.sentiment.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  write: true
})
YIELD graph AS g
UNWIND g.nodes AS node
RETURN node {.uri, .sentiment, .sentimentScore} AS node;
Table 2. Results
node
{sentiment: ""Positive"", sentimentScore: 0.6660025119781494, uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""}
If we want to stream back the sentiment and apply custom logic to the results, see apoc.nlp.aws.sentiment.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.keyPhrases.graph;"apoc.nlp.aws.keyPhrases.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) key phrases graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create a key phrase graph. One node with the KeyPhrase label will be created for each key phrase extracted.
By default, a virtual graph is returned, but the graph can be persisted by specifying the write: true configuration.
Cypher
The following returns a graph of key phrases for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.keyPhrases.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""KEY_PHRASE"",
  write: true
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon key phrases graph.
Figure 1. Pokemon key phrases graph
We can then write a query to return the key phrases that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
RETURN a.uri AS article,
       [(a)-[:KEY_PHRASE]->(k:KeyPhrase) | k.text] AS keyPhrases;
Table 2. Results
article keyPhrases
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[""the Neo4j European offices"", ""a week"", ""friends"", ""8 tournaments"", ""lunch-time Mario Kart"", ""card games"", ""board games"", ""role playing games"", ""my Nintendo Switch"", ""more than a few feet"", ""These days""]
If we want to stream back key phrases and apply custom logic to the results, see apoc.nlp.aws.keyPhrases.stream.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.keyPhrases.stream;"apoc.nlp.aws.keyPhrases.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Returns a stream of key phrases for provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the key phrases from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the key phrases for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.keyPhrases.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.keyPhrases AS keyPhrase
RETURN keyPhrase;
Table 2. Results
keyPhrase
{score: 0.9999966621398926, endOffset: 10, text: ""These days"", beginOffset: 0}
{score: 0.9867414236068726, endOffset: 42, text: ""more than a few feet"", beginOffset: 22}
{score: 0.9999999403953552, endOffset: 71, text: ""my Nintendo Switch"", beginOffset: 53}
{score: 0.9999997019767761, endOffset: 94, text: ""board games"", beginOffset: 83}
{score: 0.9999964237213135, endOffset: 106, text: ""card games"", beginOffset: 96}
{score: 0.9998161792755127, endOffset: 129, text: ""role playing games"", beginOffset: 111}
{score: 1.0, endOffset: 142, text: ""friends"", beginOffset: 135}
{score: 0.8642383217811584, endOffset: 172, text: ""a week"", beginOffset: 166}
{score: 0.9999430179595947, endOffset: 215, text: ""lunch-time Mario Kart"", beginOffset: 194}
{score: 0.9983567595481873, endOffset: 229, text: ""8 tournaments"", beginOffset: 216}
{score: 0.999997615814209, endOffset: 264, text: ""the Neo4j European offices"", beginOffset: 238}
If we want to automatically create a key phrase graph, see apoc.nlp.aws.keyPhrases.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.entities.stream;"apoc.nlp.aws.entities.stream
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Returns a stream of entities for provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
value
MAP?
error
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to extract the entities from the Article node. The text that we want to analyze is stored in the body property of the node, so we’ll need to specify that via the nodeProperty configuration parameter.
The following streams the entities for the Pokemon article:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
Table 2. Results
entity
{score: 0.780032217502594, endOffset: 71, text: ""Nintendo Switch"", type: ""COMMERCIAL_ITEM"", beginOffset: 56}
{score: 0.8155304193496704, endOffset: 151, text: ""at least"", type: ""QUANTITY"", beginOffset: 143}
{score: 0.7507548332214355, endOffset: 156, text: ""once"", type: ""QUANTITY"", beginOffset: 152}
{score: 0.8760746717453003, endOffset: 172, text: ""twice a week"", type: ""QUANTITY"", beginOffset: 160}
{score: 0.9944096803665161, endOffset: 217, text: ""Mario Kart 8"", type: ""TITLE"", beginOffset: 205}
{score: 0.9946564435958862, endOffset: 247, text: ""Neo4j"", type: ""ORGANIZATION"", beginOffset: 242}
{score: 0.6274040937423706, endOffset: 256, text: ""European"", type: ""LOCATION"", beginOffset: 248}
We get back 7 different entities. We could then apply a Cypher statement that creates one node per entity and an ENTITY relationship from each of those nodes back to the Article node.
Cypher
The following streams the entities for the Pokemon article and then creates nodes for each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.stream(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body""
})
YIELD value
UNWIND value.entities AS entity
MERGE (e:Entity {name: entity.text})
SET e.type = entity.type
MERGE (a)-[:ENTITY]->(e)
If we want to automatically create a key phrase graph, see apoc.nlp.aws.entities.graph.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp/apoc.nlp.aws.entities.graph;"apoc.nlp.aws.entities.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Setting up API Key
Usage Examples
Procedure Apoc Extended
Creates a (virtual) entity graph for provided text
Signature
None
Copy to Clipboard
apoc.nlp.aws.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
source
ANY?
null
config
MAP?
{}
Output parameters
Name Type
graph
MAP?
Install Dependencies
The NLP procedures have dependencies on Kotlin and client libraries that are not included in the APOC Extended library.
These dependencies are included in apoc-nlp-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Setting up API Key
We can generate an Access Key and Secret by following the instructions at docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html. Once we’ve done that, we can populate and execute the following commands to create parameters that contains these details.
Cypher
The following define the apiKey and apiSecret parameters
Copy to Clipboard
Run in Neo4j Browser
:param apiKey => (""<api-key-here>"");
:param apiSecret => (""<api-secret-here>"");
Alternatively we can add these credentials to apoc.conf and retrieve them using the static value storage functions.
Properties
apoc.conf
Copy to Clipboard
apoc.static.aws.apiKey=<api-key-here>
apoc.static.aws.apiSecret=<api-secret-here>
Cypher
The following retrieves AWS credentials from apoc.conf
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.static.getAll(""aws"") AS aws;
Table 1. Results
aws
{apiKey: ""<api-key-here>"", apiSecret: ""<api-secret-here>""}
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Article {
  uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"",
  body: ""These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!""
});

CREATE (:Article {
  uri: ""https://en.wikipedia.org/wiki/Nintendo_Switch"",
  body: ""The Nintendo Switch is a video game console developed by Nintendo, released worldwide in most regions on March 3, 2017. It is a hybrid console that can be used as a home console and portable device. The Nintendo Switch was unveiled on October 20, 2016. Nintendo offers a Joy-Con Wheel, a small steering wheel-like unit that a Joy-Con can slot into, allowing it to be used for racing games such as Mario Kart 8.""
});
We can use this procedure to automatically create the entity graph. As well as having the Entity label, each entity node will have another label based on the value of the type property. By default a virtual graph is returned.
Cypher
The following returns a virtual graph of entities for the Pokemon article
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article {uri: ""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""})
CALL apoc.nlp.aws.entities.graph(a, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g;
We can see a Neo4j Browser visualization of the virtual graph in Pokemon entities graph.
Figure 1. Pokemon entities graph
We can compute the entities for multiple nodes by passing a list of nodes to the procedure.
Cypher
The following returns a virtual graph of entities for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph.
Figure 2. Pokemon and Nintendo Switch entities graph
On this visualization we can also see the score for each entity node. This score represents the level of confidence that the API has in its detection of the entity. We can specify a minimum cut off value for the score using the scoreCutoff property.
Cypher
The following returns a virtual graph of entities with a score >= 0.7 for the Pokemon and Nintendo Switch articles
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""ENTITY""
})
YIELD graph AS g
RETURN g
We can see a Neo4j Browser visualization of the virtual graph in Pokemon and Nintendo Switch entities graph with confidence >= 0.7.
Figure 3. Pokemon and Nintendo Switch entities graph with confidence >= 0.7
If we’re happy with this graph and would like to persist it in Neo4j, we can do this by specifying the write: true configuration.
Cypher
The following creates a HAS_ENTITY relationship from the article to each entity
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Article)
WITH collect(a) AS articles
CALL apoc.nlp.aws.entities.graph(articles, {
  key: $apiKey,
  secret: $apiSecret,
  nodeProperty: ""body"",
  scoreCutoff: 0.7,
  writeRelationshipType: ""HAS_ENTITY"",
  writeRelationshipProperty: ""awsEntityScore"",
  write: true
})
YIELD graph AS g
RETURN g;
We can then write a query to return the entities that have been created.
Cypher
The following returns articles and their entities
Copy to Clipboard
Run in Neo4j Browser
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[r:HAS_ENTITY]->(e:Entity) | {text: e.text, score: r.awsEntityScore}] AS entities;
Table 2. Results
article entities
""https://neo4j.com/blog/pokegraph-gotta-graph-em-all/""
[{score: 0.9944096803665161, text: ""Mario Kart 8""}, {score: 0.8760746717453003, text: ""twice a week""}, {score: 0.9946564435958862, text: ""Neo4j""}, {score: 0.7507548332214355, text: ""once""}, {score: 0.8155304193496704, text: ""at least""}, {score: 0.780032217502594, text: ""Nintendo Switch""}]
""https://en.wikipedia.org/wiki/Nintendo_Switch""
[{score: 0.9990180134773254, text: ""Mario Kart 8""}, {score: 0.9997879862785339, text: ""March 3, 2017""}, {score: 0.9958534240722656, text: ""Nintendo""}, {score: 0.9998348355293274, text: ""October 20, 2016""}, {score: 0.753325343132019, text: ""Nintendo Switch""}]
If we want to stream back entities and apply custom logic to the results, see apoc.nlp.aws.entities.stream.
Was this page helpful?"
https://neo4j.com/docs/apoc/5/misc;"Miscellaneous
Cypher brings along some basic functions for math, text, collections and maps.
Text Functions
Spatial
Utilities
Warmup
Text Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/operational/warmup;"Warmup
Qualified Name Type
apoc.warmup.run
apoc.warmup.run(loadProperties=false,loadDynamicProperties=false,loadIndexes=false) - quickly loads all nodes and rels into memory by skipping one page at a time
Procedure
Cypher init script
Miscellaneous
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.warmup/apoc.warmup.run;"apoc.warmup.run
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Deprecated
apoc.warmup.run(loadProperties Boolean, loadDynamicProperties Boolean, loadIndexes Boolean) - loads all nodes and relationships in the database into memory.
Signature
None
Copy to Clipboard
apoc.warmup.run(loadProperties = false :: BOOLEAN?, loadDynamicProperties = false :: BOOLEAN?, loadIndexes = false :: BOOLEAN?) :: (pageSize :: INTEGER?, totalTime :: INTEGER?, transactionWasTerminated :: BOOLEAN?, nodesPerPage :: INTEGER?, nodesTotal :: INTEGER?, nodePages :: INTEGER?, nodesTime :: INTEGER?, relsPerPage :: INTEGER?, relsTotal :: INTEGER?, relPages :: INTEGER?, relsTime :: INTEGER?, relGroupsPerPage :: INTEGER?, relGroupsTotal :: INTEGER?, relGroupPages :: INTEGER?, relGroupsTime :: INTEGER?, propertiesLoaded :: BOOLEAN?, dynamicPropertiesLoaded :: BOOLEAN?, propsPerPage :: INTEGER?, propRecordsTotal :: INTEGER?, propPages :: INTEGER?, propsTime :: INTEGER?, stringPropsPerPage :: INTEGER?, stringPropRecordsTotal :: INTEGER?, stringPropPages :: INTEGER?, stringPropsTime :: INTEGER?, arrayPropsPerPage :: INTEGER?, arrayPropRecordsTotal :: INTEGER?, arrayPropPages :: INTEGER?, arrayPropsTime :: INTEGER?, indexesLoaded :: BOOLEAN?, indexPages :: INTEGER?, indexTime :: INTEGER?)
Input parameters
Name Type Default
loadProperties
BOOLEAN?
false
loadDynamicProperties
BOOLEAN?
false
loadIndexes
BOOLEAN?
false
Output parameters
Name Type
pageSize
INTEGER?
totalTime
INTEGER?
transactionWasTerminated
BOOLEAN?
nodesPerPage
INTEGER?
nodesTotal
INTEGER?
nodePages
INTEGER?
nodesTime
INTEGER?
relsPerPage
INTEGER?
relsTotal
INTEGER?
relPages
INTEGER?
relsTime
INTEGER?
relGroupsPerPage
INTEGER?
relGroupsTotal
INTEGER?
relGroupPages
INTEGER?
relGroupsTime
INTEGER?
propertiesLoaded
BOOLEAN?
dynamicPropertiesLoaded
BOOLEAN?
propsPerPage
INTEGER?
propRecordsTotal
INTEGER?
propPages
INTEGER?
propsTime
INTEGER?
stringPropsPerPage
INTEGER?
stringPropRecordsTotal
INTEGER?
stringPropPages
INTEGER?
stringPropsTime
INTEGER?
arrayPropsPerPage
INTEGER?
arrayPropRecordsTotal
INTEGER?
arrayPropPages
INTEGER?
arrayPropsTime
INTEGER?
indexesLoaded
BOOLEAN?
indexPages
INTEGER?
indexTime
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 10000) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}
RETURN friends;
Table 1. Results
friends
10001
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.warmup.run()
YIELD nodesTotal, nodePages, relsTotal, relPages, propPages, propertiesLoaded
RETURN nodesTotal, nodePages, relsTotal, relPages, propPages, propertiesLoaded;
Table 2. Results
nodesTotal nodePages relsTotal relPages propPages propertiesLoaded
10002
184
10001
417
503
FALSE
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.warmup.run(true, true, false)
YIELD nodesTotal, nodePages, relsTotal, relPages, propPages, propertiesLoaded
RETURN nodesTotal, nodePages, relsTotal, relPages, propPages, propertiesLoaded;
Table 3. Results
nodesTotal nodePages relsTotal relPages propPages propertiesLoaded
10002
184
10001
417
503
TRUE
This procedure can only be used with a Database record format of standard, aligned or high_limit. The record format is set using the Neo4j configuration setting db.format.
Was this page helpful?"
https://neo4j.com/docs/apoc/5/operational/init-script;"Cypher init script
Apoc optionally allows you to run cypher commands after database initialization is finished. This can e.g. be used to ensure indexes/constraints are created up front.
The initializers are defined by Configuration Options using the following naming convention:
Config
Copy to Clipboard
apoc.initializer.<database_name>.<identifier> = <some cypher string>
For each database all initializer strings are ordered by <identifier> and each of them is executed in a separate transaction. If you only have one single initializer for a given database you can omit <identifier>.
As an example we want to
create another db user in system db
create a index for :Person in default db neo4j
add two person nodes in default db neo4j
This is achieved by
Config
Copy to Clipboard
apoc.initializer.system=create user dummy set password 'abc'
apoc.initializer.neo4j.0=create index person_index for (p:Person) on (p.name)
apoc.initializer.neo4j.1=create (:Person{name:'foo'})
apoc.initializer.neo4j.2=create (:Person{name:'bar'})
Operational
Warmup
Was this page helpful?"
https://neo4j.com/docs/apoc/5/operational;"Operational
For more information on how to use these procedures, see:
Cypher init script
Warmup
Meta Graph
Cypher init script
Was this page helpful?"
https://neo4j.com/docs/apoc/5/database-introspection/meta;"Meta Graph
Returns a virtual graph that represents the labels and relationship-types available in your database and how they are connected.
Table 1. Procedures
Qualified Name Type
apoc.meta.graphSample
apoc.meta.graphSample() - examines the database statistics to build the meta graph, very fast, might report extra relationships
Procedure
apoc.meta.graph
apoc.meta.graph - examines the full graph to create the meta-graph
Procedure
apoc.meta.graph.of
`apoc.meta.graph.of({graph}, {config}) ` - examines a subset of the graph to provide a graph meta information
Procedure
apoc.meta.subGraph
apoc.meta.subGraph({labels:[labels],rels:[rel-types], excludes:[labels,rel-types]}) - examines a sample sub graph to create the meta-graph
Procedure
apoc.meta.data
`apoc.meta.data({config}) ` - examines a subset of the graph to provide a tabular meta information
Procedure
apoc.meta.schema
`apoc.meta.schema({config}) ` - examines a subset of the graph to provide a map-like meta information
Procedure
apoc.meta.stats
apoc.meta.stats yield labelCount, relTypeCount, propertyKeyCount, nodeCount, relCount, labels, relTypes, stats | returns the information stored in the transactional database statistics
Procedure
apoc.meta.nodeTypeProperties
apoc.meta.nodeTypeProperties()
Procedure
apoc.meta.relTypeProperties
apoc.meta.relTypeProperties()
Procedure
Table 2. Functions
Qualified Name Type
apoc.meta.cypher.type
apoc.meta.cypher.type(value) - type name of a value (INTEGER,FLOAT,STRING,BOOLEAN,RELATIONSHIP,NODE,PATH,NULL,MAP,LIST OF <TYPE>,POINT,DATE,DATE_TIME,LOCAL_TIME,LOCAL_DATE_TIME,TIME,DURATION)
Function
apoc.meta.cypher.isType
apoc.meta.cypher.isType(value,type) - returns a row if type name matches none if not (INTEGER,FLOAT,STRING,BOOLEAN,RELATIONSHIP,NODE,PATH,NULL,MAP,LIST OF <TYPE>,POINT,DATE,DATE_TIME,LOCAL_TIME,LOCAL_DATE_TIME,TIME,DURATION)
Function
apoc.meta.cypher.types
`apoc.meta.cypher.types(node-relationship-map) ` - returns a map of keys to types
Function
In the case of LIST you may have many results, depending on the content. In the event that all contents are of the same type, will you have the LIST OF <TYPE>, otherwise if the type is different, will you get LIST OF ANY
If no type was found, the function return name of the class.
Database Introspection
Operational
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.data;"apoc.meta.data
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.meta.data(config Map<String, Any>) - examines the full graph and returns a table of metadata.
Signature
None
Copy to Clipboard
apoc.meta.data(config = {} :: MAP?) :: (label :: STRING?, property :: STRING?, count :: INTEGER?, unique :: BOOLEAN?, index :: BOOLEAN?, existence :: BOOLEAN?, type :: STRING?, array :: BOOLEAN?, sample :: LIST? OF ANY?, left :: INTEGER?, right :: INTEGER?, other :: LIST? OF STRING?, otherLabels :: LIST? OF STRING?, elementType :: STRING?)
Input parameters
Name Type Default
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
includeLabels
List<String>
[]
labels to include. Default is to include all labels
includeRels
List<String>
[]
relationship types to include. Default is to include all relationship types
excludesLabels
List<String>
[]
labels to include. Default is to include all relationship types
sample
Long
1000
number of nodes to sample per label
maxRels
Long
100
number of relationships to sample per relationship type
Table 2. Deprecated parameters
name type default description
labels
List<String>
[]
deprecated, use includeLabels
rels
List<String>
[]
deprecated, use includeRels
excludes
List<String>
[]
deprecated, use excludesLabels
Output parameters
Name Type
label
STRING?
property
STRING?
count
INTEGER?
unique
BOOLEAN?
index
BOOLEAN?
existence
BOOLEAN?
type
STRING?
array
BOOLEAN?
sample
LIST? OF ANY?
left
INTEGER?
right
INTEGER?
other
LIST? OF STRING?
otherLabels
LIST? OF STRING?
elementType
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})
CREATE (Something:Something:Else {foo: 'bar'})

 (YouveGotMail: {title:, released:, tagline:})
 (SleeplessInSeattle: {title:, released:, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
 (ThatThingYouDo: {title:, released:, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
 (CloudAtlas: {title:, released:, tagline:})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)

 (Keanu)-[: {rate:}]->(Carrie)
 (Keanu)-[: {rate:}]->(TomH)
 (Keanu)-[: {rate:}]->(Laurence)
 (Keanu)-[: {rate:}]->(Hugo)
 (Keanu)-[: {rate:}]->(LillyW)
 (Keanu)-[: {rate:}]->(LanaW)
 (Keanu)-[: {rate:}]->(TheMatrix)
 (Carrie)-[: {rate:}]->(Keanu)

 (Something)-[: {rate:}]->(TheMatrix)
 (Keanu)-[: {rate:}]->(TheMatrix)
 (Keanu)-[: {rate:}]->(TheMatrixReloaded)
 (Keanu)-[: {rate:}]->(TheMatrixRevolutions)
 (Carrie)-[: {rate:}]->(TheMatrix)
 (TheMatrix)-[: {rate:}]->(Laurence)
 (TheMatrixReloaded)-[: {rate:}]->(LanaW)
View all (32 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.data();
Table 3. Results
label property count unique index existence type array sample left right other otherLabels elementType
""ACTED_IN""
""Person""
2
false
false
false
""RELATIONSHIP""
true
null
4
0
[""Movie""]
[]
""relationship""
""ACTED_IN""
""roles""
0
false
false
false
""LIST""
true
null
0
0
[]
[]
""relationship""
""LIKES""
""Person""
2
false
false
false
""RELATIONSHIP""
true
null
4
1
[""Movie"", ""Person""]
[]
""relationship""
""LIKES""
""rate""
0
false
false
false
""INTEGER""
false
null
0
0
[]
[]
""relationship""
""RELATED_TO""
""Person""
2
false
false
false
""RELATIONSHIP""
true
null
2
0
[""Movie""]
[]
""relationship""
""RELATED_TO""
""rate""
0
false
false
false
""INTEGER""
false
null
0
0
[]
[]
""relationship""
""RELATED_TO""
""Movie""
2
false
false
false
""RELATIONSHIP""
false
null
1
2
[""Person""]
[]
""relationship""
""RELATED_TO""
""Something""
1
false
false
false
""RELATIONSHIP""
false
null
1
0
[""Movie""]
[]
""relationship""
""RELATED_TO""
""Else""
1
false
false
false
""RELATIONSHIP""
false
null
1
0
[""Movie""]
[]
""relationship""
""Person""
""RELATED_TO""
2
false
false
false
""RELATIONSHIP""
true
null
2
0
[""Movie""]
[]
""node""
""Person""
""ACTED_IN""
2
false
false
false
""RELATIONSHIP""
true
null
4
0
[""Movie""]
[]
""node""
""Person""
""LIKES""
2
false
false
false
""RELATIONSHIP""
true
null
4
1
[""Movie"", ""Person""]
[]
""node""
""Person""
""born""
0
false
false
false
""INTEGER""
false
null
0
0
[]
[]
""node""
""Person""
""name""
0
false
false
false
""STRING""
false
null
0
0
[]
[]
""node""
""Movie""
""RELATED_TO""
2
false
false
false
""RELATIONSHIP""
false
null
1
2
[""Person""]
[]
""node""
""Movie""
""title""
0
false
false
false
""STRING""
false
null
0
0
[]
[]
""node""
""Movie""
""tagline""
0
false
false
false
""STRING""
false
null
0
0
[]
[]
""node""
""Movie""
""released""
0
false
false
false
""INTEGER""
false
null
0
0
[]
[]
""node""
""Something""
""RELATED_TO""
1
false
false
false
""RELATIONSHIP""
false
null
1
0
[""Movie""]
[]
""node""
""Something""
""foo""
0
false
false
false
""STRING""
false
null
0
0
[]
[]
""node""
""Else""
""RELATED_TO""
1
false
false
false
""RELATIONSHIP""
false
null
1
0
[""Movie""]
[]
""node""
""Else""
""foo""
0
false
false
false
""STRING""
false
null
0
0
[]
[]
""node""
The unique column shows if there is an unique constraint in that specific label and property. Similarly, the index column show if there is an index or not, while the existence looks for an existence constraint.
The array column check if the row is of type array and, in case type columns is ""RELATIONSHIP"", the result will be true if there is at least one node with 2 outgoing relationships with the type of relation given by label or property column, so ACTED_IN in the example above.
The left, right and count columns regard only rows with column type equals to ""RELATIONSHIP"" (otherwise they are equal to 0). Please note that, because we examine a sample, these counts are just estimates to give an overview and proximity to actual values depends on the dataset and the sample set (default 100).
In particular the count column indicates the number of nodes with an outgoing relationship (e.g. the row with label = ACTED_IN and property = Person has count 2 because there are 2 nodes (node:Person)-[:ACTED_IN]→(), i.e. (Keanu) and (TomH)).
The left value represents the ratio (rounded down) of the count of the outgoing patterns for a certain label and a specific type of relationship to count. In cypher, it corresponds to:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(start:`<LABEL>`)-[:`<TYPE>`]->()
WITH count(distinct start) as nodes, count(p) as counts
RETURN CASE when nodes = 0 then 0 else counts / nodes end
For example, regarding the row with label = RELATED_TO and property = Movie, there are 2 relationships (:Movie)-[rel:RELATED_TO]→(), i.e (TheMatrix)-[:RELATED_TO {rate:34}]→(Laurence) and (TheMatrixReloaded)-[:RELATED_TO {rate:345}]→(LanaW). So the left value is 1 (2 relationships divided by 2 nodes found).
Instead, regarding the row with label = LIKES and property = Person, there are 8 relationships (:Person)-[rel:LIKES]→(), 7 starting from (Keanu) node, and 1 from (Carrie). Then the left value is 4 (8 relationships divided by 2 nodes found).
The right value is the ratio (rounded down) of the count of the incoming patterns for a certain label and a specific type of relationship to count, where the patterns included in the count are those in which there is an equivalent outgoing relationship. In cypher it corresponds to:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(start:`<LABEL>`)<-[:`<TYPE>`]-()
WHERE exists((start:`<LABEL>`)-[:`<TYPE>`]->())
WITH count(distinct start) as nodes, count(p) as counts
RETURN CASE when nodes = 0 then 0 else counts / nodes end
For example, regarding the row with label = RELATED_TO and property = Movie, the (TheMatrix) node, which has an outgoing RELATED_TO relationship, has 3 incoming relationships as well, while the TheMatrixReloaded node has 1 incoming relationship. So the right value is 2, that is 4 divided by 2 node founds.
Therefore, via the right and left values, we provide a dataset estimate of the possible degree averages.
apoc.meta
apoc.meta.data.of
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta;"apoc.meta
Qualified Name Type
apoc.meta.data
apoc.meta.data(config Map<String, Any>) - examines the full graph and returns a table of metadata.
Procedure
apoc.meta.data.of
apoc.meta.data.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a table of metadata.
Procedure
apoc.meta.graph
apoc.meta.graph(config Map<String, Any>) - examines the full graph and returns a meta-graph.
Procedure
apoc.meta.graph.of
apoc.meta.graph.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Procedure
apoc.meta.graphSample
apoc.meta.graphSample(config Map<String, Any>) - examines the full graph and returns a meta-graph. Unlike apoc.meta.graph, this procedure does not filter away non-existing paths.
Procedure
apoc.meta.nodeTypeProperties
apoc.meta.nodeTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the nodes therein.
Procedure
apoc.meta.relTypeProperties
apoc.meta.relTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the relationships therein.
Procedure
apoc.meta.schema
apoc.meta.schema(config Map<String, Any>) - examines the given sub-graph and returns metadata as a map.
Procedure
apoc.meta.stats
apoc.meta.stats() - returns the metadata stored in the transactional database statistics.
Procedure
apoc.meta.subGraph
apoc.meta.subGraph(config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Procedure
apoc.meta.cypher.isType
apoc.meta.cypher.isType(value Any, type String) - returns true if the given value matches the given type.
Function
apoc.meta.cypher.type
apoc.meta.cypher.type(value Any) - returns the type name of the given value.
Function
apoc.meta.cypher.types
apoc.meta.cypher.types(props Any) - returns a map containing the type names of the given values.
Function
apoc.meta.nodes.count
apoc.meta.nodes.count(nodes [String], config Map<String, Any>) - returns the sum of the nodes with the given labels in the list.
Function
apoc.merge.relationshipWithStats.eager
apoc.meta.data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.nodeTypeProperties;"apoc.meta.nodeTypeProperties
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.meta.nodeTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the nodes therein.
Signature
None
Copy to Clipboard
apoc.meta.nodeTypeProperties(config = {} :: MAP?) :: (nodeType :: STRING?, nodeLabels :: LIST? OF STRING?, propertyName :: STRING?, propertyTypes :: LIST? OF STRING?, mandatory :: BOOLEAN?, propertyObservations :: INTEGER?, totalObservations :: INTEGER?)
Input parameters
Name Type Default
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
includeLabels
List<String>
[]
labels to include. Default is to include all labels
includeRels
List<String>
[]
relationship types to include. Default is to include all relationship types
excludesLabels
List<String>
[]
labels to include. Default is to include all relationship types
sample
Long
1000
number of nodes to sample per label
maxRels
Long
100
number of relationships to sample per relationship type
Table 2. Deprecated parameters
name type default description
labels
List<String>
[]
deprecated, use includeLabels
rels
List<String>
[]
deprecated, use includeRels
excludes
List<String>
[]
deprecated, use excludesLabels
Output parameters
Name Type
nodeType
STRING?
nodeLabels
LIST? OF STRING?
propertyName
STRING?
propertyTypes
LIST? OF STRING?
mandatory
BOOLEAN?
propertyObservations
INTEGER?
totalObservations
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas);
View all (9 more lines)
We can return the metadata of the database from a sample of the database contents, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.nodeTypeProperties();
Table 3. Results
nodeType nodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`Person`""
[""Person""]
""name""
[""String""]
FALSE
2
2
"":`Person`""
[""Person""]
""born""
[""Long""]
FALSE
2
2
"":`Movie`""
[""Movie""]
""title""
[""String""]
FALSE
9
9
"":`Movie`""
[""Movie""]
""tagline""
[""String""]
FALSE
8
9
"":`Movie`""
[""Movie""]
""released""
[""Long""]
FALSE
9
9
We can return metadata for a subset of labels by specifying the labels config parameter. The following returns the metadata for the Person label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.nodeTypeProperties({labels: [""Person""]});
Table 4. Results
nodeType nodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`Person`""
[""Person""]
""name""
[""String""]
FALSE
2
2
"":`Person`""
[""Person""]
""born""
[""Long""]
FALSE
2
2
We can control the sampling rate by specifying the sample parameter. The following returns metadata based on sampling up to 3 nodes per label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.nodeTypeProperties({sample: 3});
Table 5. Results
nodeType nodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`Person`""
[""Person""]
""name""
[""String""]
FALSE
2
2
"":`Person`""
[""Person""]
""born""
[""Long""]
FALSE
2
2
"":`Movie`""
[""Movie""]
""title""
[""String""]
FALSE
3
3
"":`Movie`""
[""Movie""]
""tagline""
[""String""]
FALSE
3
3
"":`Movie`""
[""Movie""]
""released""
[""Long""]
FALSE
3
3
apoc.meta.graphSample
apoc.meta.relTypeProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.graphSample;"apoc.meta.graphSample
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.meta.graphSample(config Map<String, Any>) - examines the full graph and returns a meta-graph. Unlike apoc.meta.graph, this procedure does not filter away non-existing paths.
Signature
None
Copy to Clipboard
apoc.meta.graphSample(config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
config
MAP?
{}
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas);
View all (9 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.graphSample()
Figure 1. Meta Graph
apoc.meta.graph.of
apoc.meta.nodeTypeProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.graph.of;"apoc.meta.graph.of
Contents
Signature
Input parameters
Output parameters
Usage Examples
Type of supported input graphs
Procedure
apoc.meta.graph.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Signature
None
Copy to Clipboard
apoc.meta.graph.of(graph = {} :: ANY?, config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
graph
ANY?
{}
config
MAP?
{}
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
Type of supported input graphs
Type Description
String
a Cypher query
Virtual Graph
a Virtual Graph returned by apoc.graph.*
Map
a map with two field nodes (a list of nodes, mandatory), relationships (a list of relationships)
If you have a quite complex Graph, and you want to analyze and get some info about a specific sub-graph in it, you can leverage the apoc.meta.graph.of procedure.
So for the given Graph Model:
You can leverage the apoc.meta.graph.of procedure in this way:
That will extract the Meta Graph of the provided query, with some stats like the count for each node involved into the query.
If you want more details you can also look at apoc.meta.graph documentation
apoc.meta.graph
apoc.meta.graphSample
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.graph;"apoc.meta.graph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.meta.graph(config Map<String, Any>) - examines the full graph and returns a meta-graph.
Signature
None
Copy to Clipboard
apoc.meta.graph(config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
config
MAP?
{}
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas);
View all (9 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.graph()
Figure 1. Meta Graph
apoc.meta.data.of
apoc.meta.graph.of
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.data.of;"apoc.meta.data.of
Contents
Signature
Input parameters
Output parameters
Usage Examples
Type of supported input graphs
Procedure
apoc.meta.data.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a table of metadata.
Signature
None
Copy to Clipboard
apoc.meta.data.of(graph :: ANY?, config = {} :: MAP?) :: (label :: STRING?, property :: STRING?, count :: INTEGER?, unique :: BOOLEAN?, index :: BOOLEAN?, existence :: BOOLEAN?, type :: STRING?, array :: BOOLEAN?, sample :: LIST? OF ANY?, left :: INTEGER?, right :: INTEGER?, other :: LIST? OF STRING?, otherLabels :: LIST? OF STRING?, elementType :: STRING?)
Input parameters
Name Type Default
graph
ANY?
null
config
MAP?
{}
Output parameters
Name Type
label
STRING?
property
STRING?
count
INTEGER?
unique
BOOLEAN?
index
BOOLEAN?
existence
BOOLEAN?
type
STRING?
array
BOOLEAN?
sample
LIST? OF ANY?
left
INTEGER?
right
INTEGER?
other
LIST? OF STRING?
otherLabels
LIST? OF STRING?
elementType
STRING?
Usage Examples
Type of supported input graphs
Type Description
String
a Cypher query
Virtual Graph
a Virtual Graph returned by apoc.graph.*
Map
a map with two field nodes (a list of nodes, mandatory), relationships (a list of relationships)
If you want more details you can look at apoc.meta.data documentation
apoc.meta.data
apoc.meta.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.relTypeProperties;"apoc.meta.relTypeProperties
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.meta.relTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the relationships therein.
Signature
None
Copy to Clipboard
apoc.meta.relTypeProperties(config = {} :: MAP?) :: (relType :: STRING?, sourceNodeLabels :: LIST? OF STRING?, targetNodeLabels :: LIST? OF STRING?, propertyName :: STRING?, propertyTypes :: LIST? OF STRING?, mandatory :: BOOLEAN?, propertyObservations :: INTEGER?, totalObservations :: INTEGER?)
Input parameters
Name Type Default
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
includeLabels
List<String>
[]
labels to include. Default is to include all labels
includeRels
List<String>
[]
relationship types to include. Default is to include all relationship types
excludesLabels
List<String>
[]
labels to include. Default is to include all relationship types
sample
Long
1000
number of nodes to sample per label
maxRels
Long
100
number of relationships to sample per relationship type
Table 2. Deprecated parameters
name type default description
labels
List<String>
[]
deprecated, use includeLabels
rels
List<String>
[]
deprecated, use includeRels
excludes
List<String>
[]
deprecated, use excludesLabels
Output parameters
Name Type
relType
STRING?
sourceNodeLabels
LIST? OF STRING?
targetNodeLabels
LIST? OF STRING?
propertyName
STRING?
propertyTypes
LIST? OF STRING?
mandatory
BOOLEAN?
propertyObservations
INTEGER?
totalObservations
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)

 (LillyW)-[:]->(TheMatrix);
View all (12 more lines)
We can return the metadata of the database from a sample of the database contents, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.relTypeProperties();
Table 3. Results
relType sourceNodeLabels targetNodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`ACTED_IN`""
[""Person""]
[""Movie""]
""roles""
[""StringArray""]
FALSE
9
9
"":`DIRECTED`""
[""Person""]
[""Movie""]
NULL
NULL
FALSE
0
1
We can return metadata for a subset of relationship types by specifying the rels config parameter. The following returns the metadata for the ACTED_IN label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.relTypeProperties({rels: [""ACTED_IN""]});
Table 4. Results
relType sourceNodeLabels targetNodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`ACTED_IN`""
[""Person""]
[""Movie""]
""roles""
[""StringArray""]
FALSE
9
9
We can control the number of relationships sampled by specifying the maxRels parameter. The following returns metadata based on sampling up to 3 relationships per relationship type:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.relTypeProperties({maxRels: 3});
Table 5. Results
relType sourceNodeLabels targetNodeLabels propertyName propertyTypes mandatory propertyObservations totalObservations
"":`ACTED_IN`""
[""Person""]
[""Movie""]
""roles""
[""StringArray""]
FALSE
3
9
"":`DIRECTED`""
[""Person""]
[""Movie""]
NULL
NULL
FALSE
0
1
apoc.meta.nodeTypeProperties
apoc.meta.schema
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.schema;"apoc.meta.schema
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.meta.schema(config Map<String, Any>) - examines the given sub-graph and returns metadata as a map.
Signature
None
Copy to Clipboard
apoc.meta.schema(config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
config
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)

 (s0:{id:}) -[r0: {alfa: }] -> (t0:{id:});
View all (11 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.schema()
YIELD value
UNWIND keys(value) AS key
RETURN key, value[key] AS value;
Note that, in case of relationship type and node label with the same name, the relationships will be distinguished by the suffix "" (RELATIONSHIP)""
Table 1. Results
key value
""Movie""
{count: 9, relationships: {ACTED_IN: {count: 41, properties: {roles: {existence: FALSE, type: ""LIST"", array: TRUE}}, direction: ""in"", labels: [""Person""]}}, type: ""node"", properties: {tagline: {existence: FALSE, type: ""STRING"", indexed: FALSE, unique: FALSE}, title: {existence: FALSE, type: ""STRING"", indexed: FALSE, unique: FALSE}, released: {existence: FALSE, type: ""INTEGER"", indexed: FALSE, unique: FALSE}}, labels: []}
""ACTED_IN""
{count: 9, type: ""relationship"", properties: {roles: {existence: FALSE, type: ""LIST"", array: TRUE}}}
""Person""
{count: 2, relationships: {ACTED_IN: {count: 9, properties: {roles: {existence: FALSE, type: ""LIST"", array: TRUE}}, direction: ""out"", labels: [""Movie""]}}, type: ""node"", properties: {name: {existence: FALSE, type: ""STRING"", indexed: FALSE, unique: FALSE}, born: {existence: FALSE, type: ""INTEGER"", indexed: FALSE, unique: FALSE}}, labels: []}
""sameName (RELATIONSHIP)""
{""count"":1,""type"":""relationship"",""properties"":{""alfa"":{""existence"":false,""type"":""STRING"",""array"":false}}}
""sameName""
{count: 2, relationships: {""sameName"": {count: 1, properties: {alfa: {existence: false, type: ""STRING"", array: false}}, direction: ""out"", labels: [""sameName""]}}, type:""node"", properties: {id: {existence: false,type: ""INTEGER"", indexed: false,unique: false}},labels: []}
Because the count stores return an incomplete picture of the data, we have to cross check the results with the actual data to filter out false positives.
We use a subset of the data to analyze by specifying the sample parameter (1000 by default).
Through this parameter, for each label we split data for each node-label into batches of (total / sample) ± rand where total is the total number of nodes with that label and rand is a number between 0 and total / sample / 10
So, we pick a percentage of nodes with that label of roughly sample / total * 100% to check against.
We pick the first node of each batch and we analyze the properties and the relationships.
For example, given the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Foo), (:Other)-[:REL_0]->(:Other), (:Other)-[:REL_1]->(:Other)<-[:REL_2 {baz: 'baa'}]-(:Other), (:Other {alpha: 'beta'}), (:Other {foo:'bar'})-[:REL_3]->(:Other)
Without sample parameter we receive:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.schema()
YIELD value RETURN value[""Other""] as value;
Table 2. Results
value
Json
Copy to Clipboard
{
    ""count"": 8,
    ""relationships"": {
        ""REL_2"": {
            ""count"": 1,
            ""properties"": {
                ""baz"": {
                    ""existence"": false,
                    ""type"": ""STRING"",
                    ""array"": false
                }
            },
            ""direction"": ""out"",
            ""labels"": [
                ""Other"",
                
            ]
        },
        : {
            : ,
            : {

            },
            : ,
            : [
                ,
                
            ]
        },
        : {
            : ,
            : {

            },
            : ,
            : [
                ,
                
            ]
        },
        : {
            : ,
            : {

            },
            : ,
            : [
                ,
                
            ]
        }
    },
    : ,
    : {
        : {
            : ,
            : ,
            : ,
            : 
        },
        : {
            : ,
            : ,
            : ,
            : 
        }
    },
    : []
}
View all (54 more lines)
Otherwise, with sample: 2 we obtain (the result can change):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.schema({sample: 2})
YIELD value RETURN value[""Other""] as value
Table 3. Results
value
Json
Copy to Clipboard
{
  ""count"": 8,
  ""relationships"": {
    ""REL_1"": {
      ""count"": 1,
      ""properties"": {},
      ""direction"": ""out"",
      ""labels"": [
        ""Other"",
        ""Other""
      ]
    }
  },
  ""type"": ""node"",
  ""properties"": {
    : {
      : ,
      : ,
      : ,
      : 
    }
  },
  : []
}
View all (9 more lines)
apoc.meta.relTypeProperties
apoc.meta.stats
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.stats;"apoc.meta.stats
Contents
Signature
Output parameters
Usage Examples
Procedure
apoc.meta.stats() - returns the metadata stored in the transactional database statistics.
Signature
None
Copy to Clipboard
apoc.meta.stats() :: (labelCount :: INTEGER?, relTypeCount :: INTEGER?, propertyKeyCount :: INTEGER?, nodeCount :: INTEGER?, relCount :: INTEGER?, labels :: MAP?, relTypes :: MAP?, relTypesCount :: MAP?, stats :: MAP?)
Output parameters
Name Type
labelCount
INTEGER?
relTypeCount
INTEGER?
propertyKeyCount
INTEGER?
nodeCount
INTEGER?
relCount
INTEGER?
labels
MAP?
relTypes
MAP?
relTypesCount
MAP?
stats
MAP?
Usage Examples
The example below is based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas);
View all (9 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.stats();
Table 1. Results
labelCount relTypeCount propertyKeyCount nodeCount relCount labels relTypes relTypesCount stats
9
5
17
11
9
{Movie: 9, Person: 2}
{(:Person)-[:ACTED_IN]→(): 9, ()-[:ACTED_IN]→(:Movie): 9, ()-[:ACTED_IN]→(): 9}
{ACTED_IN: 9}
{relTypeCount: 5, propertyKeyCount: 17, labelCount: 9, nodeCount: 11, relCount: 9, labels: {Movie: 9, Person: 2}, relTypes: {(:Person)-[:ACTED_IN]→(): 9, ()-[:ACTED_IN]→(:Movie): 9, ()-[:ACTED_IN]→(): 9}}
Note that the relTypesCount field returns a count equal to MATCH ()-[r:RELATIONSHIP_TYPE]→() RETURN count(r) for each relationship type (unique relationships versus unique patterns).
apoc.meta.schema
apoc.meta.subGraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.subGraph;"apoc.meta.subGraph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.meta.subGraph(config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Signature
None
Copy to Clipboard
apoc.meta.subGraph(config :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
config
MAP?
null
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)

 (LillyW)-[:]->(TheMatrix);
View all (12 more lines)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.subGraph({
  includeLabels: [""Person"", ""Movie""],
  includeRels: [""DIRECTED""]
});
Figure 1. Meta Sub Graph
apoc.meta.stats
apoc.meta.cypher.isType
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.cypher.isType;"apoc.meta.cypher.isType
Contents
Signature
Input parameters
Usage Examples
Function
apoc.meta.cypher.isType(value Any, type String) - returns true if the given value matches the given type.
Signature
None
Copy to Clipboard
apoc.meta.cypher.isType(value :: ANY?, type :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
value
ANY?
null
type
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.isType(1, ""NODE"") AS output;
Table 1. Results
output
FALSE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.isType(datetime(), ""DATE_TIME"") AS output;
Table 2. Results
output
TRUE
apoc.meta.subGraph
apoc.meta.cypher.type
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.cypher.type;"apoc.meta.cypher.type
Contents
Signature
Input parameters
Usage Examples
Function
apoc.meta.cypher.type(value Any) - returns the type name of the given value.
Signature
None
Copy to Clipboard
apoc.meta.cypher.type(value :: ANY?) :: (STRING?)
Input parameters
Name Type Default
value
ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type(1) AS output;
Table 1. Results
output
""INTEGER""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type(""Michael"") AS output;
Table 2. Results
output
""STRING""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type(true) AS output;
Table 3. Results
output
""BOOLEAN""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type(datetime()) AS output;
Table 4. Results
output
""DATE_TIME""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type([""Neo4j"", 2020]) AS output;
Table 5. Results
output
""LIST OF ANY""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.type([""Neo4j"", ""Bloom""]) AS output;
Table 6. Results
output
""LIST OF STRING""
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (node1:Person)-[rel:FRIENDS]->(node2:Person)
RETURN apoc.meta.cypher.type(node1) AS node1Type,
       apoc.meta.cypher.type(rel) AS relType,
       apoc.meta.cypher.type(node2) AS node2Type;
Table 7. Results
node1Type relType node2Type
""NODE""
""RELATIONSHIP""
""NODE""
apoc.meta.cypher.isType
apoc.meta.cypher.types
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.cypher.types;"apoc.meta.cypher.types
Contents
Signature
Input parameters
Usage Examples
Function
apoc.meta.cypher.type(value Any) - returns the type name of the given value.
Signature
None
Copy to Clipboard
apoc.meta.cypher.types(properties :: ANY?) :: (MAP?)
Input parameters
Name Type Default
properties
ANY?
null
Usage Examples
Calling the function with a map input will return a map with the same keys, where the value of each key is the type of the value it had in the input map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.types({
  item1: 2,
  item2: datetime(),
  item3: ""Michael""
}) AS output;
Table 1. Results
output
{item2: ""DATE_TIME"", item1: ""INTEGER"", item3: ""STRING""}
Calling the function with an empty map will return an empty map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.types({}) AS output;
Table 2. Results
output
{}
Calling the function with an input value that is not a map, will return an empty map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.cypher.types(1) AS output;
Table 3. Results
output
{}
apoc.meta.cypher.type
apoc.meta.nodes.count
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.meta/apoc.meta.nodes.count;"apoc.meta.nodes.count
Contents
Signature
Input parameters
Config parameters
Usage Examples
Function
apoc.meta.nodes.count(nodes [String], config Map<String, Any>) - returns the sum of the nodes with the given labels in the list.
Signature
None
Copy to Clipboard
apoc.meta.nodes.count(nodes = [] :: LIST? OF STRING?, config = {} :: MAP?) :: (INTEGER?)
Input parameters
Name Type Default
nodes
LIST? OF STRING?
[]
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
rels
Set<String>
EmptySet
The rel types to consider in the count. We can add to the suffix > or < to the rel type name to indicate an outgoing or incoming relationship.
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:MyCountLabel {id: 1}), (:MyCountLabel {id: 2}), (m:ThirdLabel {id: 3})
WITH n,m
CREATE (n)-[:MY_COUNT_REL]->(m), (n)-[:ANOTHER_MY_COUNT_REL]->(m), (n)<-[:ANOTHER_MY_COUNT_REL]-(m)
We can return all nodes with a label MyCountLabel or a label ThirdLabel
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.nodes.count(['MyCountLabel', 'ThirdLabel']) AS count;
Table 2. Results
count
3
The following example returns all nodes with a label MyCountLabel and a relationship MY_COUNT_REL through the config parameter rel:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.nodes.count(['MyCountLabel'], {rels: ['MY_COUNT_REL']}) AS count;
Table 3. Results
count
1
The following example returns all nodes with an outgoing relationship MY_COUNT_REL (with the suffix >):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.nodes.count(['MyCountLabel'], {rels: ['MY_COUNT_REL>']}) AS count;
Table 4. Results
count
1
The following example returns all nodes with an incoming relationship MY_COUNT_REL (with the suffix <):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.meta.nodes.count(['MyCountLabel'], {rels: ['MY_COUNT_REL<']}) AS count;
Table 5. Results
count
0
apoc.meta.cypher.types
apoc.neighbors
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors;"apoc.neighbors
Qualified Name Type
apoc.neighbors.athop
apoc.neighbors.athop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types at the specified distance.
Procedure
apoc.neighbors.athop.count
apoc.neighbors.athop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types at the specified distance.
Procedure
apoc.neighbors.byhop
apoc.neighbors.byhop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Returns lists of nodes, where each path of nodes represents one row of lists.
Procedure
apoc.neighbors.byhop.count
apoc.neighbors.byhop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types within the specified distance.
Procedure
apoc.neighbors.tohop
apoc.neighbors.tohop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Nodes are returned individually for each row.
Procedure
apoc.neighbors.tohop.count
apoc.neighbors.tohop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationships in the pattern within the specified distance.
Procedure
apoc.meta.nodes.count
apoc.neighbors.athop
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.athop.count;"apoc.neighbors.athop.count
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.athop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types at the specified distance.
Signature
None
Copy to Clipboard
apoc.neighbors.athop.count(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (value :: INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
value
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
This procedure computes a node’s neighborhood at a specific hop count.
The following returns the number of people that Emil KNOWS at 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop.count(p, ""KNOWS"", 2)
YIELD value
RETURN value
Table 1. Results
value
2
As expected we get a count of 2, those people being Praveena and Lju!
If we also want to know which nodes are in our neighborhood, we can do that as well. See apoc.neighbors.athop.
More documentation of apoc.neighbors.athop.count
apoc.neighbors.athop
apoc.neighbors.byhop
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.athop;"apoc.neighbors.athop
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.athop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types at the specified distance.
Signature
None
Copy to Clipboard
apoc.neighbors.athop(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (node :: NODE?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
This procedure computes a node’s neighborhood at a specific hop count.
The following returns the people that Emil KNOWS at 1 hop:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop(p, ""KNOWS"", 1)
YIELD node
RETURN node
Table 1. Results
node
(:Person {name: ""Michael""})
Emil only has a direct KNOWS relationship to Michael, so Michael is the only node returned by this query.
The following returns the people that Emil KNOWS at 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop(p, ""KNOWS"", 2)
YIELD node
RETURN node
Table 2. Results
node
(:Person {name: ""Praveena""})
(:Person {name: ""Lju""})
Michael also KNOWS Praveena and Lju, and since Emil doesn’t KNOW either of those directly, he only KNOWS them at a hop distance of 2.
If we aren’t interested in knowing which nodes are in our neighborhood, but just want a count of the number, we can do that as well. See apoc.neighbors.athop.count.
More documentation of apoc.neighbors.athop
apoc.neighbors
apoc.neighbors.athop.count
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/neighborhood;"Neighbor Functions
Contents
Available Procedures
Relationship Filters
Examples
Find neighbors at specified hop count
Find neighbors at specified hop counts
Find neighbors up to specified hop count
The Neighborhood search procedures enable quick discovery of surrounding nodes based on a specific relationship type and number of hops.
Available Procedures
The table below describes the available procedures:
Qualified Name Type
apoc.neighbors.athop
apoc.neighbors.athop(node, rel-direction-pattern, distance) - returns distinct nodes of the given relationships in the pattern at a distance, can use '>' or '<' for all outgoing or incoming relationships
Procedure
apoc.neighbors.byhop
apoc.neighbors.byhop(node, rel-direction-pattern, distance) - returns distinct nodes of the given relationships in the pattern at each distance, can use '>' or '<' for all outgoing or incoming relationships
Procedure
apoc.neighbors.tohop
apoc.neighbors.tohop(node, rel-direction-pattern, distance) - returns distinct nodes of the given relationships in the pattern up to a certain distance, can use '>' or '<' for all outgoing or incoming relationships
Procedure
Relationship Filters
The 2nd parameter in each of the neighborhood search procedures is a relationship filter. A relationship filter is a | separated list of relationship types, using the following syntax:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Relationship filters are white space sensitive, so check for trailing white spaces (and then remove them!) if you’re not seeing expected results.
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
The KNOWS relationship type is considered to be bidirectional, where if Michael knows Emil, we can imply that Emil knows Michael. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Find neighbors at specified hop count
The apoc.neighbors.athop procedures compute a node’s neighborhood at a specific hop count.
Cypher
The following returns the people that Emil KNOWS at 1 hop
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop(p, ""KNOWS"", 1)
YIELD node
RETURN node
Table 1. Results
node
(:Person {name: ""Michael""})
Emil only has a direct KNOWS relationship to Michael, so Michael is the only node returned by this query.
Cypher
The following returns the people that Emil KNOWS at 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop(p, ""KNOWS"", 2)
YIELD node
RETURN node
Table 2. Results
node
(:Person {name: ""Praveena""})
(:Person {name: ""Lju""})
Michael also KNOWS Praveena and Lju, and since Emil doesn’t KNOW either of those directly, he only KNOWS them at a hop distance of 2. If we aren’t interested in knowing which nodes are in our neighborhood, but just want a count of the number, we can do that as well.
Cypher
The following returns the number of people that Emil KNOWS at 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.athop.count(p, ""KNOWS"", 2)
YIELD value
RETURN value
Table 3. Results
value
2
As expected we get a count of 2, those people being Praveena and Lju!
Find neighbors at specified hop counts
The apoc.neighbors.byhop procedures compute a node’s neighborhood at multiple hop counts.
Cypher
The following returns the people that Emil KNOWS up to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop(p, ""KNOWS"", 2)
YIELD nodes
RETURN nodes
Table 4. Results
nodes
[(:Person {name: ""Michael""})]
[(:Person {name: ""Praveena""}), (:Person {name: ""Lju""})]
From these results we can see that at level 1 Emil KNOWS Michael, and at level 2 Emil KNOWS Lju and Praveena. The following graph patterns describe how Emil knows the different people:
Level 1
(emil)-[:KNOWS]-(michael)
Level 2
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(lju)
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(praveena)
We can also use multiple relationship types when searching the neighborhood.
Let’s say that as well as finding the people that Emil knows, we also want to find the people that follow him. We can specify a direction to the relationship types, by using < to indicate an incoming relationship, or > to indicate an outgoing relationship. So to find people that follow Emil, we’d use <FOLLOWS.
Cypher
The following returns the people that Emil KNOWS and those that have FOLLOWS relationships to him, at up to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop(p, ""KNOWS|<FOLLOWS"", 3)
YIELD nodes
RETURN nodes
Table 5. Results
nodes
[(:Person {name: ""Mark""}), (:Person {name: ""Michael""})]
[(:Person {name: ""Praveena""}), (:Person {name: ""Joe""}), (:Person {name: ""Lju""})]
[(:Person {name: ""Ryan""})]
We’ve got some more results this time. Mark is in Emil’s level 1 neighborhood, Joe is in his level 2 neighborhood, and Ryan is in his level 3 neighborhood.
The following graph patterns describe how Emil knows the different people:
Level 1
(emil)-[:KNOWS]-(michael)
(mark)-[:FOLLOWS]→(emil)
Level 2
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(lju)
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(praveena)
(joe)-[:FOLLOWS]→(mark)-[:FOLLOWS]→(emil)
Level 3
(ryan)-[:FOLLOWS]→(joe)-[:FOLLOWS]→(mark)-[:FOLLOWS]→(emil)
And, as with the apoc.neighbors.athop procedure, we can also return just the neighborhood size at each hop.
Cypher
The following returns the number of people that Emil KNOWS and the number that have FOLLOWS relationships to him, at up to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN value
Table 6. Results
value
[2, 3, 1]
And as expected we have a count of 2 at level 1, 3 at level 2, and 1 at level 3.
We could even turn that list of numbers into a map with the key being the number of hops and the value the neighborhood size. The following query shows how to do this using the apoc.map.fromLists function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN apoc.map.fromLists(
         [value in range(1, size(value)) | toString(value)],
         value) AS value
Table 7. Results
value
{1: 2, 2: 3, 3: 1}
Find neighbors up to specified hop count
The apoc.neighbors.tohop procedures compute a node’s neighborhood up to a specified hop count.
Cypher
The following returns the people that Praveena FOLLOWS up to 1 hop
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop(p, ""FOLLOWS>"", 1)
YIELD node
RETURN node
Table 8. Results
nodes
(:Person {name: ""Joe""})
The only person that Praveena follows is Joe, so that’s the only node returned. What about if we include people at up to 2 hops?
Cypher
The following returns the people that Praveena FOLLOWS up to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop(p, ""FOLLOWS>"", 2)
YIELD node
RETURN node
Table 9. Results
nodes
(:Person {name: ""Mark""})
(:Person {name: ""Joe""})
Now Mark is returned as well. The following graph patterns describe how Emil knows the different people:
(praveena)-[:FOLLOWS]-(joe)
(praveena)-[:FOLLOWS]-(joe)-[:FOLLOWS]→(mark)
And if we just want a count of the number of people, we can use the count variant.
Cypher
The following returns the number of people that Praveena FOLLOWS up to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop.count(p, ""FOLLOWS>"", 2)
YIELD value
RETURN value
Table 10. Results
value
2
Expand a spanning tree
Path Manipulation
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.tohop;"apoc.neighbors.tohop
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.tohop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Nodes are returned individually for each row.
Signature
None
Copy to Clipboard
apoc.neighbors.tohop(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (node :: NODE?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
The apoc.neighbors.tohop procedure compute a node’s neighborhood up to a specified hop count.
The following returns the people that Praveena FOLLOWS up to 1 hop:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop(p, ""FOLLOWS>"", 1)
YIELD node
RETURN node
Table 1. Results
nodes
(:Person {name: ""Joe""})
The only person that Praveena follows is Joe, so that’s the only node returned. What about if we include people at up to 2 hops?
The following returns the people that Praveena FOLLOWS up to 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop(p, ""FOLLOWS>"", 2)
YIELD node
RETURN node
Table 2. Results
nodes
(:Person {name: ""Mark""})
(:Person {name: ""Joe""})
Now Mark is returned as well. The following graph patterns describe how Emil knows the different people:
(praveena)-[:FOLLOWS]-(joe)
(praveena)-[:FOLLOWS]-(joe)-[:FOLLOWS]→(mark)
And if we just want a count of the number of people, we can use the count variant.
The following returns the number of people that Praveena FOLLOWS up to 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop.count(p, ""FOLLOWS>"", 2)
YIELD value
RETURN value
Table 3. Results
value
2
If we aren’t interested in knowing which nodes are in our neighborhood, but just want a count of the number, we can do that as well. See apoc.neighbors.tohop.count.
More documentation of apoc.neighbors.tohop
apoc.neighbors.byhop.count
apoc.neighbors.tohop.count
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.byhop.count;"apoc.neighbors.byhop.count
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.byhop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types within the specified distance.
Signature
None
Copy to Clipboard
apoc.neighbors.byhop.count(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
value
LIST? OF ANY?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
This procedure computes a node’s neighborhood at multiple hop counts.
The following returns the number of people that Emil KNOWS and the number that have FOLLOWS relationships to him, at up to 3 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN value
Table 1. Results
value
[2, 3, 1]
And as expected we have a count of 2 at level 1, 3 at level 2, and 1 at level 3.
We could even turn that list of numbers into a map with the key being the number of hops and the value the neighborhood size. The following query shows how to do this using the apoc.map.fromLists function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN apoc.map.fromLists(
         [value in range(1, size(value)) | toString(value)],
         value) AS value
Table 2. Results
value
{1: 2, 2: 3, 3: 1}
If we also want to know which nodes are in our neighborhood, we can do that as well. See apoc.neighbors.byhop.
More documentation of apoc.neighbors.byhop.count
apoc.neighbors.byhop
apoc.neighbors.tohop
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.byhop;"apoc.neighbors.byhop
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.byhop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Returns lists of nodes, where each path of nodes represents one row of lists.
Signature
None
Copy to Clipboard
apoc.neighbors.byhop(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (nodes :: LIST? OF NODE?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
nodes
LIST? OF NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
The apoc.neighbors.byhop procedure compute a node’s neighborhood at multiple hop counts.
The following returns the people that Emil KNOWS up to 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop(p, ""KNOWS"", 2)
YIELD nodes
RETURN nodes
Table 1. Results
nodes
[(:Person {name: ""Michael""})]
[(:Person {name: ""Praveena""}), (:Person {name: ""Lju""})]
From these results we can see that at level 1 Emil KNOWS Michael, and at level 2 Emil KNOWS Lju and Praveena. The following graph patterns describe how Emil knows the different people:
Level 1
(emil)-[:KNOWS]-(michael)
Level 2
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(lju)
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(praveena)
We can also use multiple relationship types when searching the neighborhood.
Let’s say that as well as finding the people that Emil knows, we also want to find the people that follow him. We can specify a direction to the relationship types, by using < to indicate an incoming relationship, or > to indicate an outgoing relationship. So to find people that follow Emil, we’d use <FOLLOWS.
The following returns the people that Emil KNOWS and those that have FOLLOWS relationships to him, at up to 3 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop(p, ""KNOWS|<FOLLOWS"", 3)
YIELD nodes
RETURN nodes
Table 2. Results
nodes
[(:Person {name: ""Mark""}), (:Person {name: ""Michael""})]
[(:Person {name: ""Praveena""}), (:Person {name: ""Joe""}), (:Person {name: ""Lju""})]
[(:Person {name: ""Ryan""})]
We’ve got some more results this time. Mark is in Emil’s level 1 neighborhood, Joe is in his level 2 neighborhood, and Ryan is in his level 3 neighborhood.
The following graph patterns describe how Emil knows the different people:
Level 1
(emil)-[:KNOWS]-(michael)
(mark)-[:FOLLOWS]→(emil)
Level 2
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(lju)
(emil)-[:KNOWS]-(michael)-[:KNOWS]-(praveena)
(joe)-[:FOLLOWS]→(mark)-[:FOLLOWS]→(emil)
Level 3
(ryan)-[:FOLLOWS]→(joe)-[:FOLLOWS]→(mark)-[:FOLLOWS]→(emil)
And, as with the apoc.neighbors.athop procedure, we can also return just the neighborhood size at each hop.
The following returns the number of people that Emil KNOWS and the number that have FOLLOWS relationships to him, at up to 3 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN value
Table 3. Results
value
[2, 3, 1]
And as expected we have a count of 2 at level 1, 3 at level 2, and 1 at level 3.
We could even turn that list of numbers into a map with the key being the number of hops and the value the neighborhood size. The following query shows how to do this using the apoc.map.fromLists function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Emil""})
CALL apoc.neighbors.byhop.count(p, ""KNOWS|<FOLLOWS"", 3)
YIELD value
RETURN apoc.map.fromLists(
         [value in range(1, size(value)) | toString(value)],
         value) AS value
Table 4. Results
value
{1: 2, 2: 3, 3: 1}
If we aren’t interested in knowing which nodes are in our neighborhood, but just want a count of the number, we can do that as well. See apoc.neighbors.byhop.count.
More documentation of apoc.neighbors.byhop
apoc.neighbors.athop.count
apoc.neighbors.byhop.count
Was this page helpful?"
https://neo4j.com/docs/apoc/5/data-structures/map-functions;"Map Functions
Qualified Name Type
apoc.map.fromNodes
apoc.map.fromNodes(label, property)
Function
apoc.map.fromPairs
apoc.map.fromPairs([[key,value],[key2,value2],…])
Function
apoc.map.fromLists
apoc.map.fromLists([keys],[values])
Function
apoc.map.fromValues
apoc.map.fromValues([key1,value1,key2,value2,…])
Function
apoc.map.merge
apoc.map.merge(first,second) - merges two maps
Function
apoc.map.mergeList
apoc.map.mergeList([{maps}]) yield value - merges all maps in the list into one
Function
apoc.map.setKey
apoc.map.setKey(map,key,value)
Function
apoc.map.removeKey
apoc.map.removeKey(map,key,{recursive:true/false}) - remove the key from the map (recursively if recursive is true)
Function
apoc.map.removeKeys
apoc.map.removeKeys(map,[keys],{recursive:true/false}) - remove the keys from the map (recursively if recursive is true)
Function
apoc.map.clean
apoc.map.clean(map,[skip,keys],[skip,values]) yield map filters the keys and values contained in those lists, good for data cleaning from CSV/JSON
Function
apoc.map.groupBy
apoc.map.groupBy([maps/nodes/relationships],'key') yield value - creates a map of the list keyed by the given property, with single values
Function
apoc.map.groupByMulti
apoc.map.groupByMulti([maps/nodes/relationships],'key') yield value - creates a map of the list keyed by the given property, with list values
Function
apoc.map.sortedProperties
apoc.map.sortedProperties(map, ignoreCase:true) - returns a list of key/value list pairs, with pairs sorted by keys alphabetically, with optional case sensitivity
Function
apoc.map.updateTree
apoc.map.updateTree(tree,key,) returns map - adds the {data} map on each level of the nested tree, where the key-value pairs match
Function
apoc.map.values
apoc.map.values(map, [key1,key2,key3,…],[addNullsForMissing]) returns list of values indicated by the keys
Function
apoc.map.submap
`apoc.map.submap(map,keys,[defaults],[fail=true]) ` - returns submap for keys or throws exception if one of the key doesn’t exist and no default value given at that position
Function
apoc.map.mget
`apoc.map.mget(map,key,[defaults],[fail=true]) ` - returns list of values for keys or throws exception if one of the key doesn’t exist and no default value given at that position
Function
apoc.map.get
apoc.map.get(map,key,[default],[fail=true]) - returns value for key or throws exception if key doesn’t exist and no default given
Function
Conversion Functions
Collection Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.setKey;"apoc.map.setKey
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.setKey(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Signature
None
Copy to Clipboard
apoc.map.setKey(map :: MAP?, key :: STRING?, value :: ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
key
STRING?
null
value
ANY?
null
Usage Examples
The following updates a key in a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.setKey(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    ""dob"",
    date(""1986-02-06"")
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Portugal"",
  ""dob"": ""1986-02-06""
}
apoc.map.setEntry
apoc.map.setLists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.setEntry;"apoc.map.setEntry
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.setEntry(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Signature
None
Copy to Clipboard
apoc.map.setEntry(map :: MAP?, key :: STRING?, value :: ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
key
STRING?
null
value
ANY?
null
Usage Examples
The following updates a key in a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.setEntry(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    ""dob"",
    date(""1986-02-06"")
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Portugal"",
  ""dob"": ""1986-02-06""
}
apoc.map.removeKeys
apoc.map.setKey
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.removeKeys;"apoc.map.removeKeys
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.removeKeys(map Map<String, Any>, keys [String], config Map<String, Any>) - removes the given keys from the map (recursively if recursive is true).
Signature
None
Copy to Clipboard
apoc.map.removeKeys(map :: MAP?, keys :: LIST? OF STRING?, config = {} :: MAP?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
null
config
MAP?
{}
Usage Examples
The following removes keys from a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.removeKeys(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    [""dob"", ""country""]
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo""
}
apoc.map.removeKey
apoc.map.setEntry
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.removeKey;"apoc.map.removeKey
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.removeKey(map Map<String, Any>, key String, config Map<String, Any>) - removes the given key from the map (recursively if recursive is true).
Signature
None
Copy to Clipboard
apoc.map.removeKey(map :: MAP?, key :: STRING?, config = {} :: MAP?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
key
STRING?
null
config
MAP?
{}
Usage Examples
The following removes a key from a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.removeKey(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    ""dob""
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Portugal""
}
apoc.map.mget
apoc.map.removeKeys
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.mget;"apoc.map.mget
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.mget(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a list of values for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Signature
None
Copy to Clipboard
apoc.map.mget(map :: MAP?, keys :: LIST? OF STRING?, values = [] :: LIST? OF ANY?, fail = true :: BOOLEAN?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
[]
fail
BOOLEAN?
true
Usage Examples
The following returns a list of values for keys name and country:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")} AS map
RETURN apoc.map.mget(map, [""name"", ""country""]) AS output;
Table 1. Results
Output
[""Cristiano Ronaldo"", ""Portugal""]
The following returns a list of values for keys name and country, and default value defaultValue for missing key missingKey:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")} AS map
RETURN apoc.map.mget(
    map,
    [""name"", ""country"", ""missingKey""],
    [null, null, ""defaultValue""]
) AS output;
Table 2. Results
Output
[""Cristiano Ronaldo"", ""Portugal"", ""defaultValue""]
apoc.map.mergeList
apoc.map.removeKey
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.mergeList;"apoc.map.mergeList
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.mergeList(maps [Map<String, Value>]) - merges all maps in the given list into one map.
Signature
None
Copy to Clipboard
apoc.map.mergeList(maps :: LIST? OF MAP?) :: (MAP?)
Input parameters
Name Type Default
maps
LIST? OF MAP?
null
Usage Examples
The following merges multiple maps:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.mergeList([
    {name: ""Cristiano Ronaldo""},
    {dob: date(""1985-02-05"")},
    {country: ""Portugal""}
]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Portugal"",
  ""dob"": ""1985-02-05""
}
apoc.map.merge
apoc.map.mget
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.merge;"apoc.map.merge
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.merge(map1 Map<String, Any>, map2 Map<String, Any>) - merges the two given maps into one map.
Signature
None
Copy to Clipboard
apoc.map.merge(first :: MAP?, second :: MAP?) :: (MAP?)
Input parameters
Name Type Default
first
MAP?
null
second
MAP?
null
Usage Examples
The following merges two maps:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.merge(
    {name: ""Cristiano Ronaldo"", dob: date(""1985-02-05"")},
    {country: ""Portugal""}
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Portugal"",
  ""dob"": ""1985-02-05""
}
apoc.map.groupByMulti
apoc.map.mergeList
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.groupByMulti;"apoc.map.groupByMulti
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.groupByMulti(values [Any], key String) - creates a map of the lists keyed by the given property, with the list values.
Signature
None
Copy to Clipboard
apoc.map.groupByMulti(values :: LIST? OF ANY?, key :: STRING?) :: (MAP?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
key
STRING?
null
Usage Examples
The following creates a map keyed by club, with list values:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.groupByMulti([
 {name: ""Cristiano Ronaldo"", club: ""Juventus""},
    {name: ""Lionel Messi"", club: ""Barcelona""},
    {name: ""Aaron Ramsey"", club: ""Juventus""},
    {name: ""Luiz Suarez"", club: ""Barcelona""}
], ""club"") AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
    ""Juventus"": [
      {
        ""name"": ""Cristiano Ronaldo"",
        ""club"": ""Juventus""
      },
      {
        ""name"": ""Aaron Ramsey"",
        ""club"": ""Juventus""
      }
    ],
    ""Barcelona"": [
      {
        ""name"": ""Lionel Messi"",
        ""club"": ""Barcelona""
      },
      {
        : ,
        : 
      }
    ]
  }
View all (8 more lines)
apoc.map.groupBy
apoc.map.merge
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.groupBy;"apoc.map.groupBy
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.groupBy(values [Any], key String) - creates a map of the list keyed by the given property, with single values.
Signature
None
Copy to Clipboard
apoc.map.groupBy(values :: LIST? OF ANY?, key :: STRING?) :: (MAP?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
key
STRING?
null
Usage Examples
The following creates a map keyed by club, with a single value
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.groupBy([
 {name: ""Cristiano Ronaldo"", club: ""Juventus""},
    {name: ""Lionel Messi"", club: ""Barcelona""},
    {name: ""Aaron Ramsey"", club: ""Juventus""},
    {name: ""Luiz Suarez"", club: ""Barcelona""}
], ""club"") AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""Juventus"": {
    ""name"": ""Aaron Ramsey"",
    ""club"": ""Juventus""
  },
  ""Barcelona"": {
    ""name"": ""Luiz Suarez"",
    ""club"": ""Barcelona""
  }
}
apoc.map.get
apoc.map.groupByMulti
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.get;"apoc.map.get
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.get(map Map<String, Any>, key String, value Any, fail Boolean) - returns a value for the given key. If the given key does not exist, or lacks a default value, this function will throw an exception.
Signature
None
Copy to Clipboard
apoc.map.get(map :: MAP?, key :: STRING?, value = null :: ANY?, fail = true :: BOOLEAN?) :: (ANY?)
Input parameters
Name Type Default
map
MAP?
null
key
STRING?
null
value
ANY?
null
fail
BOOLEAN?
true
Usage Examples
The following throws an exception when attempting to look up missing key missingKey with no default value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")} AS map
RETURN apoc.map.get(map, ""missingKey"") AS output;
Table 1. Results
Output
Neo.ClientError.Procedure.ProcedureCallFailed: Failed to invoke function apoc.map.get: Caused by: java.lang.IllegalArgumentException: Key missingKey is not of one of the existing keys [country, dob, name]
The following returns default value defaultValue when attempting to look up missing key missingKey:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"", country:""Portugal"", dob:date(""1985-02-05"")} AS map
RETURN apoc.map.get(map, ""missingKey"", ""defaultValue"") AS output;
Table 2. Results
Output
""defaultValue""
apoc.map.fromValues
apoc.map.groupBy
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.fromValues;"apoc.map.fromValues
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.fromValues(values [Any]) - creates a map from the alternating keys and values in the given list.
Signature
None
Copy to Clipboard
apoc.map.fromValues(values :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
The following creates a map from alternating keys and values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.fromValues([
    ""name"", ""Cristiano Ronaldo"",
    ""age"", date(""1985-02-05"")
]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""age"": ""1985-02-05""
}
apoc.map.fromPairs
apoc.map.get
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.fromPairs;"apoc.map.fromPairs
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.fromPairs(pairs [[key Any, value Any]]) - creates a map from the given list of key-value pairs.
Signature
None
Copy to Clipboard
apoc.map.fromPairs(pairs :: LIST? OF LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
pairs
LIST? OF LIST? OF ANY?
null
Usage Examples
The following creates a map from list of key-value pairs:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.fromPairs([
    [""name"", ""Cristiano Ronaldo""],
    [""age"", date(""1985-02-05"")]
]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""age"": ""1985-02-05""
}
apoc.map.fromNodes
apoc.map.fromValues
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.fromNodes;"apoc.map.fromNodes
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.fromNodes(label String, prop String) - returns a map of the given prop to the node of the given label.
Signature
None
Copy to Clipboard
apoc.map.fromNodes(label :: STRING?, property :: STRING?) :: (MAP?)
Input parameters
Name Type Default
label
STRING?
null
property
STRING?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.fromNodes(""Movie"", ""title"");
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""The Matrix Revolutions"": {
    ""identity"": 14,
    ""labels"": [
      ""Movie""
    ],
    ""properties"": {
    ""tagline"": ""Everything that has a beginning has an end"",
    ""title"": ""The Matrix Revolutions"",
    ""released"": 2003
    }
  },
  ""Sleepless in Seattle"": {
    ""identity"": 16,
    ""labels"": [
      
    ],
    : {
    : ,
    : ,
    : 
    }
  },
  : {
    : ,
    : [
      
    ],
    : {
    : ,
    : ,
    : 
    }
  }
}
View all (21 more lines)
apoc.map.fromLists
apoc.map.fromPairs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.fromLists;"apoc.map.fromLists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.fromLists(keys [String], values [Any]) - creates a map from the keys and values in the given lists.
Signature
None
Copy to Clipboard
apoc.map.fromLists(keys :: LIST? OF STRING?, values :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
null
Usage Examples
The following creates a map from keys and values lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.fromLists(
    [""name"", ""dob""],
    [""Cristiano Ronaldo"", date(""1985-02-05"")]
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""dob"": ""1985-02-05""
}
apoc.map.flatten
apoc.map.fromNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.flatten;"apoc.map.flatten
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.flatten(map Map<String, Any>, delimiter String) - flattens nested items in the given map. This function is the reverse of the apoc.map.unflatten function.
Signature
None
Copy to Clipboard
apoc.map.flatten(map :: MAP?, delimiter = . :: STRING?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
delimiter
STRING?
.
Usage Examples
The following flattens a nested map using the default . delimiter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.flatten({
  person: {
    name: ""Cristiano Ronaldo"",
    club: {
      name: ""Juventus"",
      founded: 1897
    }
  }
}) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""person.name"": ""Cristiano Ronaldo"",
  ""person.club.founded"": 1897,
  ""person.club.name"": ""Juventus""
}
The following flattens a nested map using the / delimiter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.flatten({
  person: {
    name: ""Cristiano Ronaldo"",
    club: {
      name: ""Juventus"",
      founded: 1897
    }
  }
}, ""/"") AS output;
Table 2. Results
Output
Json
Copy to Clipboard
{
  ""person/club/name"": ""Juventus"",
  ""person/club/founded"": 1897,
  ""person/name"": ""Cristiano Ronaldo""
}
apoc.map.clean
apoc.map.fromLists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.clean;"apoc.map.clean
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.clean(map Map<String, Any>, keys [String], values [Any]) - filters the keys and values contained in the given lists.
Signature
None
Copy to Clipboard
apoc.map.clean(map :: MAP?, keys :: LIST? OF STRING?, values :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
null
Usage Examples
The following removes empty string values from a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.clean({name: ""Cristiano Ronaldo"", club: """"}, [], [""""]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo""
}
The following removes empty string values and the keys dob and country from a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.clean(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05""), club: """"},
    [""dob"", ""country""],
    [""""]
) AS output;
Table 2. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo""
}
apoc.map
apoc.map.flatten
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map;"apoc.map
Qualified Name Type
apoc.map.clean
apoc.map.clean(map Map<String, Any>, keys [String], values [Any]) - filters the keys and values contained in the given lists.
Function
apoc.map.flatten
apoc.map.flatten(map Map<String, Any>, delimiter String) - flattens nested items in the given map. This function is the reverse of the apoc.map.unflatten function.
Function
apoc.map.fromLists
apoc.map.fromLists(keys [String], values [Any]) - creates a map from the keys and values in the given lists.
Function
apoc.map.fromNodes
apoc.map.fromNodes(label String, prop String) - returns a map of the given prop to the node of the given label.
Function
apoc.map.fromPairs
apoc.map.updateTree(tree Map<String, Any>, key String, data [[key Any, value Any]])- adds the data map on each level of the nested tree, where the key-value pairs match.
Function
apoc.map.fromValues
apoc.map.fromValues(values [Any]) - creates a map from the alternating keys and values in the given list.
Function
apoc.map.get
apoc.map.get(map Map<String, Any>, key String, value Any, fail Boolean) - returns a value for the given key. If the given key does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.groupBy
apoc.map.groupBy(values [Any], key String) - creates a map of the list keyed by the given property, with single values.
Function
apoc.map.groupByMulti
apoc.map.groupByMulti(values [Any], key String) - creates a map of the lists keyed by the given property, with the list values.
Function
apoc.map.merge
apoc.map.merge(map1 Map<String, Any>, map2 Map<String, Any>) - merges the two given maps into one map.
Function
apoc.map.mergeList
apoc.map.mergeList(maps [Map<String, Value>]) - merges all maps in the given list into one map.
Function
apoc.map.mget
apoc.map.mget(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a list of values for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.removeKey
apoc.map.removeKey(map Map<String, Any>, key String, config Map<String, Any>) - removes the given key from the map (recursively if recursive is true).
Function
apoc.map.removeKeys
apoc.map.removeKeys(map Map<String, Any>, keys [String], config Map<String, Any>) - removes the given keys from the map (recursively if recursive is true).
Function
apoc.map.setEntry
apoc.map.setEntry(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Function
apoc.map.setKey
apoc.map.setKey(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Function
apoc.map.setLists
apoc.map.setLists(map Map<String, Any>, keys [String], values [Any]) - adds or updates the given keys/value pairs provided in list format (e.g. [key1, key2],[value1, value2]) in a map.
Function
apoc.map.setPairs
apoc.map.setPairs(map Map<String, Any>, pairs [[key Any, value Any]]) - adds or updates the given key/value pairs (e.g. [key1,value1],[key2,value2]) in a map.
Function
apoc.map.setValues
apoc.map.setValues(map Map<String, Any>, pairs [key Any, value Any]) - adds or updates the alternating key/value pairs (e.g. [key1,value1,key2,value2]) in a map.
Function
apoc.map.sortedProperties
apoc.map.sortedProperties(map Map<String, Any>, ignoreCase Boolean) - returns a list of key/value pairs. The pairs are sorted by alphabetically by key, with optional case sensitivity.
Function
apoc.map.submap
apoc.map.submap(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a sub-map for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.unflatten
apoc.map.unflatten(map Map<String, Any>, delimiter String) - unflattens items in the given map to nested items. This function is the reverse of the apoc.map.flatten function.
Function
apoc.map.updateTree
apoc.map.updateTree(tree Map<String, Any>, key String, data [[key Any, value Any]])- adds the data map on each level of the nested tree, where the key-value pairs match.
Function
apoc.map.values
apoc.map.values(map Map<String, Any>, keys [String], addNullsForMissing Boolean) - returns a list of values indicated by the given keys (returns a null value if a given key is missing).
Function
apoc.log.stream
apoc.map.clean
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.setLists;"apoc.map.setLists
Contents
Input parameters
Usage Examples
Function
apoc.map.setLists(map Map<String, Any>, keys [String], values [Any]) - adds or updates the given keys/value pairs provided in list format (e.g. [key1, key2],[value1, value2]) in a map. == Signature
None
Copy to Clipboard
apoc.map.setLists(map :: MAP?, keys :: LIST? OF STRING?, values :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
null
Usage Examples
The following updates a key in a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.setLists(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    [""dob"", ""country""],
    [date(""1986-02-06""), ""Spain""]
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Spain"",
  ""dob"": ""1986-02-06""
}
apoc.map.setKey
apoc.map.setPairs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.setPairs;"apoc.map.setPairs
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.setPairs(map Map<String, Any>, pairs [[key Any, value Any]]) - adds or updates the given key/value pairs (e.g. [key1,value1],[key2,value2]) in a map.
Signature
None
Copy to Clipboard
apoc.map.setPairs(map :: MAP?, pairs :: LIST? OF LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
pairs
LIST? OF LIST? OF ANY?
null
Usage Examples
The following updates a key in a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.setPairs(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    [ [""dob"", date(""1986-02-06"")],
      [""country"", ""Spain""]
    ]
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Spain"",
  ""dob"": ""1986-02-06""
}
apoc.map.setLists
apoc.map.setValues
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.setValues;"apoc.map.setValues
Contents
Input parameters
Usage Examples
Function
apoc.map.setValues(map Map<String, Any>, pairs [key Any, value Any]) - adds or updates the alternating key/value pairs (e.g. [key1,value1,key2,value2]) in a map. == Signature
None
Copy to Clipboard
apoc.map.setValues(map :: MAP?, pairs :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
pairs
LIST? OF ANY?
null
Usage Examples
The following updates a key in a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.setValues(
    {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")},
    [""dob"", date(""1986-02-06""), ""country"", ""Spain""]
) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""name"": ""Cristiano Ronaldo"",
  ""country"": ""Spain"",
  ""dob"": ""1986-02-06""
}
apoc.map.setPairs
apoc.map.sortedProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.sortedProperties;"apoc.map.sortedProperties
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.sortedProperties(map Map<String, Any>, ignoreCase Boolean) - returns a list of key/value pairs. The pairs are sorted by alphabetically by key, with optional case sensitivity.
Signature
None
Copy to Clipboard
apoc.map.sortedProperties(map :: MAP?, ignoreCase = true :: BOOLEAN?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
map
MAP?
null
ignoreCase
BOOLEAN?
true
Usage Examples
The following returns a list of key/value list pairs with pairs sorted by key alphabetically:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")} AS map
RETURN apoc.map.sortedProperties(map) AS output;
Table 1. Results
Output
[[""country"",""Portugal""],[""dob"",""1985-02-05""],[""name"",""Cristiano Ronaldo""]]
apoc.map.setValues
apoc.map.submap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.submap;"apoc.map.submap
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.submap(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a sub-map for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Signature
None
Copy to Clipboard
apoc.map.submap(map :: MAP?, keys :: LIST? OF STRING?, values = [] :: LIST? OF ANY?, fail = true :: BOOLEAN?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
[]
fail
BOOLEAN?
true
Usage Examples
The following returns a map containing only the key a:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.submap({a:1,b:1},['a']) AS output;
Table 1. Results
Output
{a: 1}
The following throw an exception because the map doesn’t contain the key c:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.submap({a:1,b:1},['c']) AS output;
Table 2. Results
Failed to invoke function apoc.map.submap: Caused by: java.lang.IllegalArgumentException: Key c is not of one of the existing keys [a, b]
The following returns a map containing a default value of 42 for the missing key c:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.submap({a:1,b:1},['c'], [42]) AS output;
Table 3. Results
Output
{c: 42}
The following returns a map containing a null value for the missing key c:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.submap({a:1,b:1},['c'], null, false) AS output;
Table 4. Results
Output
{c: NULL}
apoc.map.sortedProperties
apoc.map.unflatten
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.unflatten;"apoc.map.unflatten
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.unflatten(map Map<String, Any>, delimiter String) - unflattens items in the given map to nested items. This function is the reverse of the apoc.map.flatten function.
Signature
None
Copy to Clipboard
apoc.map.unflatten(map :: MAP?, delimiter = . :: STRING?) :: (MAP?)
Input parameters
Name Type Default
map
MAP?
null
delimiter
STRING?
.
Usage Examples
Using the following map and the default . delimiter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.unflatten({
  `person.name`: ""Cristiano Ronaldo"",
  `person.club.founded`: 1897,
  `person.club.name`: ""Juventus""
}) AS output;
will be returned:
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""person"": {
    ""club"": {
      ""founded"": 1897,
      ""name"": ""Juventus""
    },
    ""name"": ""Cristiano Ronaldo""
  }
}
Using the following map and a custom delimiter, that is /é哈:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.unflatten({
  `person/é哈firstName`: ""Cristiano"",
  `person/é哈lastName`: ""Ronaldo"",
  `person/é哈club/é哈founded`: 1897,
  `person/é哈club/é哈name`: ""Juventus""
}, '/é哈') AS output;
will be returned:
Table 2. Results
Output
Json
Copy to Clipboard
{
  ""person"": {
    ""club"": {
      ""name"": ""Juventus"",
      ""founded"": 1897
    },
    ""firstName"": ""Cristiano"",
    ""lastName"": ""Ronaldo""
  }
}
apoc.map.submap
apoc.map.updateTree
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.updateTree;"apoc.map.updateTree
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.updateTree(tree Map<String, Any>, key String, data [[key Any, value Any]])- adds the data map on each level of the nested tree, where the key-value pairs match.
Signature
None
Copy to Clipboard
apoc.map.updateTree(tree :: MAP?, key :: STRING?, data :: LIST? OF LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
tree
MAP?
null
key
STRING?
null
data
LIST? OF LIST? OF ANY?
null
Usage Examples
The following updates a nested map, adding additional key/values based on the value of the id key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.map.updateTree({
  id:1,
  c:{
    id:2
  },
  d:[
    {id:3},
    {id:4}
  ],
  e: {notId: 5}
},'id',[
  [1,{description: ""Added where id=1""}],
  [2,{description: ""Added where id=2""}],
  [3,{description: ""Added where id=3""}],
  [4,{description: ""Added where id=4""}]
]) AS value;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""id"": 1,
  ""description"": ""Added where id=1"",
  ""c"": {
    ""id"": 2,
    ""description"": ""Added where id=2""
  },
  ""d"": [
    {
      ""id"": 3,
      ""description"": ""Added where id=3""
    },
    {
      ""id"": 4,
      ""description"": ""Added where id=4""
    }
  ],
  : {
    : 
  }
}
View all (6 more lines)
apoc.map.unflatten
apoc.map.values
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.map/apoc.map.values;"apoc.map.values
Contents
Signature
Input parameters
Usage Examples
Function
apoc.map.values(map Map<String, Any>, keys [String], addNullsForMissing Boolean) - returns a list of values indicated by the given keys (returns a null value if a given key is missing).
Signature
None
Copy to Clipboard
apoc.map.values(map :: MAP?, keys = [] :: LIST? OF STRING?, addNullsForMissing = false :: BOOLEAN?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
map
MAP?
null
keys
LIST? OF STRING?
[]
addNullsForMissing
BOOLEAN?
false
Usage Examples
The following returns a list of values for keys name and country, and a null value for missing key missingKey:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {name:""Cristiano Ronaldo"",country:""Portugal"",dob:date(""1985-02-05"")} AS map
RETURN apoc.map.values(map, [""name"", ""country"", ""missingKey""], true) AS output;
Table 1. Results
Output
[""Cristiano Ronaldo"",""Portugal"",null]
apoc.map.updateTree
apoc.math
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math;"apoc.math
Qualified Name Type
apoc.math.regr
apoc.math.regr(label String, propertyY String, propertyX String) - returns the coefficient of determination (R-squared) for the values of propertyY and propertyX in the given label.
Procedure
apoc.math.cosh
apoc.math.cosh(value Float) - returns the hyperbolic cosine.
Function
apoc.math.coth
apoc.math.coth(value Float) - returns the hyperbolic cotangent.
Function
apoc.math.csch
apoc.math.csch(value Float) - returns the hyperbolic cosecant.
Function
apoc.math.maxByte
apoc.math.maxByte() - returns the maximum value of a byte.
Function
apoc.math.maxDouble
apoc.math.maxDouble() - returns the largest positive finite value of type double.
Function
apoc.math.maxInt
apoc.math.maxInt() - returns the maximum value of an integer.
Function
apoc.math.maxLong
apoc.math.maxLong() - returns the maximum value of a long.
Function
apoc.math.minByte
apoc.math.minByte() - returns the minimum value of a byte.
Function
apoc.math.minDouble
apoc.math.minDouble() - returns the smallest positive non-zero value of type double.
Function
apoc.math.minInt
apoc.math.minInt() - returns the minimum value of an integer.
Function
apoc.math.minLong
apoc.math.minLong() - returns the minimum value of a long.
Function
apoc.math.sech
apoc.math.sech(value Float) - returns the hyperbolic secant of the given value.
Function
apoc.math.sigmoid
apoc.math.sigmoid(value Float) - returns the sigmoid of the given value.
Function
apoc.math.sigmoidPrime
apoc.math.sigmoidPrime(value Float) - returns the sigmoid prime [ sigmoid(val) * (1 - sigmoid(val)) ] of the given value.
Function
apoc.math.sinh
apoc.math.sinh(value Float) - returns the hyperbolic sine of the given value.
Function
apoc.math.tanh
apoc.math.tanh(value Float) - returns the hyperbolic tangent of the given value.
Function
apoc.map.values
apoc.math.regr
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.sinh;"apoc.math.sinh
Contents
Signature
Input parameters
Function
apoc.math.sinh(value Float) - returns the hyperbolic sine of the given value.
Signature
None
Copy to Clipboard
apoc.math.sinh(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.sigmoidPrime
apoc.math.tanh
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical/sigmoid-hyperbolic-operations;"Sigmoid & Hyperbolic Operations
Contents
Functions for sigmoid and hyperbolic operations
Examples
The APOC library provides a set of functions useful for machine learning purposes. These functions return a double value.
Functions for sigmoid and hyperbolic operations
Qualified Name Type
apoc.math.cosh
apoc.math.cosh(value Float) - returns the hyperbolic cosine.
Function
apoc.math.coth
apoc.math.coth(value Float) - returns the hyperbolic cotangent.
Function
apoc.math.csch
apoc.math.csch(value Float) - returns the hyperbolic cosecant.
Function
apoc.math.sech
apoc.math.sech(value Float) - returns the hyperbolic secant of the given value.
Function
apoc.math.sigmoid
apoc.math.sigmoid(value Float) - returns the sigmoid of the given value.
Function
apoc.math.sigmoidPrime
apoc.math.sigmoidPrime(value Float) - returns the sigmoid prime [ sigmoid(val) * (1 - sigmoid(val)) ] of the given value.
Function
apoc.math.sinh
apoc.math.sinh(value Float) - returns the hyperbolic sine of the given value.
Function
apoc.math.tanh
apoc.math.tanh(value Float) - returns the hyperbolic tangent of the given value.
Function
Examples
Cypher
The following returns the hyperbolic cosecant
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.csch(1.5) AS output;
Table 1. Results
Output
0.47
Cypher
The following returns the hyperbolic secant
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.sech(1.5) AS output;
Table 2. Results
Output
0.43
Cypher
The following returns the hyperbolic cosin
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.cosh(1.5) AS output;
Table 3. Results
Output
2.35
Cypher
The following returns the hyperbolic sin
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.sinh(1.5) AS output;
Table 4. Results
Output
2.13
Cypher
The following returns the hyperbolic cotangent
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.coth(3.5) AS output;
Table 5. Results
Output
1.00
Cypher
The following returns the hyperbolic tangent
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.tanh(1.5) AS output;
Table 6. Results
Output
0.90
Cypher
The following returns the sigmoid prime
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.sigmoidPrime(2.5) AS output;
Table 7. Results
Output
0.70
Cypher
The following returns the sigmoid
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.sigmoidPrime(2.5) AS output;
Table 8. Results
Output
0.92
Number Format Conversions
Advanced Graph Querying
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical/number-conversions;"Number Format Conversions
Contents
Functions for number format conversions
Examples
Functions for number format conversions
Qualified Name Type
apoc.number.format
apoc.number.format(number Any, pattern String, language String) - formats the given long or double using the given pattern and language to produce a string.
Function
apoc.number.parseFloat
apoc.number.parseFloat(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a double.
Function
apoc.number.parseInt
apoc.number.parseInt(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a long.
Function
For the full list of supported values for the pattern and language parameters, see Java’s DecimalFormat page.
Examples
Cypher
The following formats a double value using the default system pattern:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format(12345.67) as value;
Table 1. Results
Value
12,345.67
Cypher
The following formats a double value, using . as thousand separator, , as decimal separator, rounding down:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format(12345, '#,##0.00;(#,##0.00)', 'it') as value;
Table 2. Results
Value
12.345,00
Cypher
The following formats a double value, using . as thousand separator and , as decimal separator:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format(12345.67, '#,##0.00;(#,##0.00)', 'it') as value;
Table 3. Results
Value
12.345,67
Cypher
The following parses a formatted value as an int:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseInt('12.345', '#,##0.00;(#,##0.00)', 'it') as value;
Table 4. Results
Value
12345
Cypher
The following parses a formatted value as a float:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseFloat('12.345,67', '#,##0.00;(#,##0.00)', 'it') as value;
Table 5. Results
Value
12345.67
Cypher
The following formats a non numeric value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format('aaa') AS value;
Table 6. Results
Value
null
Cypher
The following parses a non numeric value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseInt('aaa') AS value;
Table 7. Results
Value
null
Mathematical Functions
Sigmoid & Hyperbolic Operations
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.parseInt;"apoc.number.parseInt
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.parseInt(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a long.
Signature
None
Copy to Clipboard
apoc.number.parseInt(text :: STRING?, pattern =  :: STRING?, lang =  :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
text
STRING?
null
pattern
STRING?
lang
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseInt('12,345') AS output;
Table 1. Results
output
12345
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseInt('12,345', '#,##0.00;(#,##0.00)') AS output;
Table 2. Results
output
12345
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseInt('12.345', '' ,'it') AS output;
Table 3. Results
output
12345
apoc.number.parseFloat
apoc.number.romanToArabic
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.parseFloat;"apoc.number.parseFloat
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.parseFloat(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a double.
Signature
None
Copy to Clipboard
apoc.number.parseFloat(text :: STRING?, pattern =  :: STRING?, lang =  :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
text
STRING?
null
pattern
STRING?
lang
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseFloat('12,345.67') AS output;
Table 1. Results
output
12345.67
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.parseFloat('12.345,67', '', 'it') AS output;
Table 2. Results
output
12345.67
apoc.number.format
apoc.number.parseInt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.format;"apoc.number.format
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.format(number Any, pattern String, language String) - formats the given long or double using the given pattern and language to produce a string.
Signature
None
Copy to Clipboard
apoc.number.format(number :: ANY?, pattern =  :: STRING?, lang =  :: STRING?) :: (STRING?)
Input parameters
Name Type Default
number
ANY?
null
pattern
STRING?
lang
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format(1234567.87)  as output;
Table 1. Results
output
""1,234,567.87""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format(12345, '#,##0.00;(#,##0.00)', 'it') AS output;
Table 2. Results
output
""12.345,00""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.format('aaa')  as output;
Table 3. Results
output
NULL
apoc.number.exact.toInteger
apoc.number.parseFloat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.toInteger;"apoc.number.exact.toInteger
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.toInteger(string String, precision Integer, roundingMode String) - returns the integer value of the given large number (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.toInteger(stringA :: STRING?, precision = 0 :: INTEGER?, roundingMode = HALF_UP :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
stringA
STRING?
null
precision
INTEGER?
0
roundingMode
STRING?
HALF_UP
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toInteger('504238974', 5, 'HALF_DOWN') as output;
Table 1. Results
output
504238974
apoc.number.exact.toFloat
apoc.number.format
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.toFloat;"apoc.number.exact.toFloat
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.toFloat(string String, precision Integer, roundingMode String) - returns the float value of the given large number (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.toFloat(stringA :: STRING?, precision = 0 :: INTEGER?, roundingMode = HALF_UP :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
stringA
STRING?
null
precision
INTEGER?
0
roundingMode
STRING?
HALF_UP
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toFloat('50423.1656', 10) as output;
Table 1. Results
output
50423.1656
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toFloat('50423.1656', 3) as output;
Table 2. Results
output
50400.0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toFloat('50423.1656', 5, ""CEILING"") as output;
Table 3. Results
output
50424.0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toFloat('50423.1656', 5, ""FLOOR"") as output;
Table 4. Results
output
50423.0
apoc.number.exact.toExact
apoc.number.exact.toInteger
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.toExact;"apoc.number.exact.toExact
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.toExact(number Integer) - returns the exact value of the given number (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.toExact(number :: INTEGER?) :: (INTEGER?)
Input parameters
Name Type Default
number
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.toExact(1213669989) as output;
Table 1. Results
output
RETURN apoc.number.exact.toExact('1213669989') as output;
apoc.number.exact.sub
apoc.number.exact.toFloat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.sub;"apoc.number.exact.sub
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.sub(stringA String, stringB String) - returns the result of subtracting a given large number from another given large number (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.sub(stringA :: STRING?, stringB :: STRING?) :: (STRING?)
Input parameters
Name Type Default
stringA
STRING?
null
stringB
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.sub('1238126387','1213669989') as output;
Table 1. Results
output
""24456398""
apoc.number.exact.mul
apoc.number.exact.toExact
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.mul;"apoc.number.exact.mul
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.mul(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of multiplying two given large numbers (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.mul(stringA :: STRING?, stringB :: STRING?, precision = 0 :: INTEGER?, roundingMode = HALF_UP :: STRING?) :: (STRING?)
Input parameters
Name Type Default
stringA
STRING?
null
stringB
STRING?
null
precision
INTEGER?
0
roundingMode
STRING?
HALF_UP
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.mul('550058444','662557', 15, 'HALF_DOWN') as output;
Table 1. Results
output
""364445072481308""
apoc.number.exact.div
apoc.number.exact.sub
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.div;"apoc.number.exact.div
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.div(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of dividing a given large number with another given large number (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.div(stringA :: STRING?, stringB :: STRING?, precision = 0 :: INTEGER?, roundingMode = HALF_UP :: STRING?) :: (STRING?)
Input parameters
Name Type Default
stringA
STRING?
null
stringB
STRING?
null
precision
INTEGER?
0
roundingMode
STRING?
HALF_UP
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.div('550058444','662557', 18, 'HALF_DOWN') as output;
Table 1. Results
output
""830.205467605051339""
apoc.number.exact.add
apoc.number.exact.mul
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.exact.add;"apoc.number.exact.add
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.exact.add(stringA String, stringB String) - returns the result of adding the two given large numbers (using Java BigDecimal).
Signature
None
Copy to Clipboard
apoc.number.exact.add(stringA :: STRING?, stringB :: STRING?) :: (STRING?)
Input parameters
Name Type Default
stringA
STRING?
null
stringB
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.add('1213669989','1238126387') as output;
Table 1. Results
output
""2451796376""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.add(null,'1238126387') as output;
Table 2. Results
output
NULL
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.add('1E6','1E6') as value;
Table 3. Results
Value
""2000000""
apoc.number.arabicToRoman
apoc.number.exact.div
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.arabicToRoman;"apoc.number.arabicToRoman
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.arabicToRoman(number Any) - converts the given Arabic numbers to Roman numbers.
Signature
None
Copy to Clipboard
apoc.number.arabicToRoman(number :: ANY?) :: (STRING?)
Input parameters
Name Type Default
number
ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.arabicToRoman(2010) AS output;
Table 1. Results
output
""MMX""
More documentation of apoc.number.arabicToRoman
apoc.number
apoc.number.exact.add
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number;"apoc.number
Qualified Name Type
apoc.number.arabicToRoman
apoc.number.arabicToRoman(number Any) - converts the given Arabic numbers to Roman numbers.
Function
apoc.number.exact.add
apoc.number.exact.add(stringA String, stringB String) - returns the result of adding the two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.div
apoc.number.exact.div(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of dividing a given large number with another given large number (using Java BigDecimal).
Function
apoc.number.exact.mul
apoc.number.exact.mul(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of multiplying two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.sub
apoc.number.exact.sub(stringA String, stringB String) - returns the result of subtracting a given large number from another given large number (using Java BigDecimal).
Function
apoc.number.exact.toExact
apoc.number.exact.toExact(number Integer) - returns the exact value of the given number (using Java BigDecimal).
Function
apoc.number.exact.toFloat
apoc.number.exact.toFloat(string String, precision Integer, roundingMode String) - returns the float value of the given large number (using Java BigDecimal).
Function
apoc.number.exact.toInteger
apoc.number.exact.toInteger(string String, precision Integer, roundingMode String) - returns the integer value of the given large number (using Java BigDecimal).
Function
apoc.number.format
apoc.number.format(number Any, pattern String, language String) - formats the given long or double using the given pattern and language to produce a string.
Function
apoc.number.parseFloat
apoc.number.parseFloat(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a double.
Function
apoc.number.parseInt
apoc.number.parseInt(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a long.
Function
apoc.number.romanToArabic
apoc.number.romanToArabic(romanNumber String) - converts the given Roman numbers to Arabic numbers.
Function
apoc.nodes.relationships.exist
apoc.number.arabicToRoman
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.number/apoc.number.romanToArabic;"apoc.number.romanToArabic
Contents
Signature
Input parameters
Usage Examples
Function
apoc.number.romanToArabic(romanNumber String) - converts the given Roman numbers to Arabic numbers.
Signature
None
Copy to Clipboard
apoc.number.romanToArabic(romanNumber :: STRING?) :: (NUMBER?)
Input parameters
Name Type Default
romanNumber
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.romanToArabic(""MCMXXXII"") AS output;
Table 1. Results
output
1932
More documentation of apoc.number.romanToArabic
apoc.number.parseInt
apoc.path
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path;"apoc.path
Qualified Name Type
apoc.path.expand
apoc.path.expand(startNode Any, relFilter String, labelFilter String, minDepth Integer, maxDepth Integer) - returns paths expanded from the start node following the given relationship types from min-depth to max-depth.
Procedure
apoc.path.expandConfig
apoc.path.expandConfig(startNode Any, config Map<String, Any>) - returns paths expanded from the start node the given relationship types from min-depth to max-depth.
Procedure
apoc.path.spanningTree
apoc.path.spanningTree(startNode Any, config Map<String, Any>) - returns spanning tree paths expanded from the start node following the given relationship types to max-depth.
Procedure
apoc.path.subgraphAll
apoc.path.subgraphAll(startNode Any, config Map<String, Any>) - returns the sub-graph reachable from the start node following the given relationship types to max-depth.
Procedure
apoc.path.subgraphNodes
apoc.path.subgraphNodes(startNode Any, config Map<String, Any>) - returns the nodes in the sub-graph reachable from the start node following the given relationship types to max-depth.
Procedure
apoc.path.combine
apoc.path.combine(path1 Path, path2 Path) - combines the two given paths into one path.
Function
apoc.path.create
apoc.path.create(startNode Node, rels [Rel]) - returns a path from the given start node and a list of relationships.
Function
apoc.path.elements
apoc.path.elements(path Path) - converts the given path into a list of nodes and relationships.
Function
apoc.path.slice
apoc.path.slice(path Path, offset Integer, length Integer) - returns a sub-path of the given length and offset from the given path.
Function
apoc.number.romanToArabic
apoc.path.expand
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.spanningTree;"apoc.path.spanningTree
Contents
Signature
Input parameters
Config parameters
Relationship Filters
Label Filters
Output parameters
Usage Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
Procedure
apoc.path.spanningTree(startNode Any, config Map<String, Any>) - returns spanning tree paths expanded from the start node following the given relationship types to max-depth.
Signature
None
Copy to Clipboard
apoc.path.spanningTree(start :: ANY?, config :: MAP?) :: (path :: PATH?)
Input parameters
Name Type Default
start
ANY?
null
config
MAP?
null
Config parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Output parameters
Name Type
path
PATH?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the spanning tree starting from Praveena and traversing the KNOWS relationship type for 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Praveena.
Figure 2. Spanning tree from Praveena
The spanning tree contains 4 nodes apart from Praveena. Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re also included in the spanning tree.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the spanning tree starting from Praveena and traversing the KNOWS relationship type for 1 to 2 hops, only includin Engineering nodes
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Praveena to engineering nodes.
Figure 3. Spanning tree from Praveena to engineering nodes
We lose Lju and Stefan from the spanning tree because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia.
Figure 4. Spanning tree from Alicia
This query returns paths to 11 of the 12 people in the graph, which indicates that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia terminating at Engineering nodes.
Figure 5. Spanning tree from Alicia terminating at Engineering nodes
Our spanning tree has been reduced to only 3 other nodes apart from Alicia. But this query doesn’t capture the complete spanning tree from Alicia containing nodes with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia to Engineering nodes.
Figure 6. Spanning tree from Alicia to Engineering nodes
The spanning tree now also reaches Martin, via a relationship from Zhen.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want the returned spanning tree to stop as soon as the Mark, Joe, Zhen, or Praveena nodes are reached. We can do that by passing those nodes to the terminatorNodes parameter.
Cypher
The following returns the spanning tree of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (terminator:Person)
WHERE terminator.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(terminator) AS terminatorNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: terminatorNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia, terminating at Mark, Joe, Zhen, or Rik.
Figure 7. Spanning tree from Alicia, terminating at Mark, Joe, Zhen, or Rik
Mark and Joe are included in the spanning tree, but Rik and Zhen can’t be reached. This could be because there is no path to Zhen and Rik that doesn’t go through Mark and Joe, or it could mean that there’s no path based on the other traversal criteria.
We can find out whether Mark, Joe, Zhen, or Rik are reachable by passing these nodes to the endNodes parameter.
Cypher
The following returns the spanning tree of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, ending as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(end) AS endNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Alicia, ending at Mark, Joe, Zhen, or Rik.
Figure 8. Spanning tree from Alicia, ending at Mark, Joe, Zhen, or Rik
Our spanning tree now includes Joe, Mark, and Zhen, but Rik is still unreachable.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns the spanning tree reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning Tree from Alicia where paths to nodes include Mark, Jonny, or Zhen.
Figure 9. Spanning Tree from Alicia where paths to nodes include Mark, Jonny, or Zhen
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns the spanning tree reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Alicia where paths to nodes can’t go via Joe.
Figure 10. Spanning tree from Alicia where paths to nodes can’t go via Joe
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Joe via alternate FOLLOWS and KNOWS relationship types.
Figure 11. Spanning tree from Joe via alternate FOLLOWS and KNOWS relationship types
More documentation of apoc.path.spanningTree
apoc.path.expandConfig
apoc.path.subgraphAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.expandConfig;"apoc.path.expandConfig
Contents
Signature
Input parameters
Config parameters
Relationship Filters
Label Filters
Uniqueness
Specifying Sequences of node labels and relationship types
Output parameters
Usage Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Breadth First Search and Depth First Search
Uniqueness
Sequences of relationship types
Sequences of node labels
Procedure
apoc.path.expandConfig(startNode Any, config Map<String, Any>) - returns paths expanded from the start node the given relationship types from min-depth to max-depth.
Signature
None
Copy to Clipboard
apoc.path.expandConfig(start :: ANY?, config :: MAP?) :: (path :: PATH?)
Input parameters
Name Type Default
start
ANY?
null
config
MAP?
null
Config parameters
This procedure support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
sequence
String
null
comma-separated alternating label and relationship filters, for each step in a repeating sequence. If present, labelFilter, and relationshipFilter are ignored, as this takes priority.
See Specifying Sequences of node labels and relationship types.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
uniqueness
String
RELATIONSHIP_PATH
the strategy to use when expanding relationships in a traversal.
See Uniqueness.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given.
optional
Boolean
false
is path expansion optional? If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Uniqueness
Uniqueness of nodes and relationships guides the expansion and the returned results. The table below describes the available values:
value description
RELATIONSHIP_PATH
For each returned node there’s a (relationship wise) unique path from the start node to it. This is Cypher’s default expansion mode.
NODE_GLOBAL
A node cannot be traversed more than once. This is what the legacy traversal framework does.
NODE_LEVEL
Entities on the same level are guaranteed to be unique.
NODE_PATH
For each returned node there’s a unique path from the start node to it.
NODE_RECENT
This is like NODE_GLOBAL, but only guarantees uniqueness among the most recent visited nodes, with a configurable count. Traversing a huge graph is quite memory intensive in that it keeps track of all the nodes it has visited. For huge graphs a traverser can hog all the memory in the JVM, causing OutOfMemoryError. Together with this Uniqueness you can supply a count, which is the number of most recent visited nodes. This can cause a node to be visited more than once, but scales infinitely.
RELATIONSHIP_GLOBAL
A relationship cannot be traversed more than once, whereas nodes can.
RELATIONSHIP_LEVEL
Entities on the same level are guaranteed to be unique.
RELATIONSHIP_RECENT
Same as for NODE_RECENT, but for relationships.
NONE
No restriction (the user will have to manage it)
Specifying Sequences of node labels and relationship types
Path expander procedures can expand on repeating sequences of labels, relationship types, or both. Sequences can be defined as follows:
If only using label sequences, use the labelFilter, but use commas to separate the filtering for each step in the repeating sequence.
If only using relationship sequences, use the relationshipFilter, but use commas to separate the filtering for each step of the repeating sequence.
If using sequences of both relationships and labels, use the sequence parameter.
Usage config param description syntax explanation
label sequences only
labelFilter
Same syntax and filters, but uses commas (,) to separate the filters for each step in the sequence.
labelFilter:'Post|-Blocked,Reply,>Admin'
Start node must be a :Post node that isn’t :Blocked, next node must be a :Reply, and the next must be an :Admin, then repeat if able. Only paths ending with the :Admin node in that position of the sequence will be returned.
relationship sequences only
relationshipFilter
Same syntax, but uses commas (,) to separate the filters for each relationship traversal in the sequence.
relationshipFilter:'NEXT>,<FROM,POSTED>|REPLIED>'
Expansion will first expand NEXT> from the start node, then <FROM, then either POSTED> or REPLIED>, then repeat if able.
sequences of both labels and relationships
sequence
A string of comma-separated alternating label and relationship filters, for each step in a repeating sequence. The sequence should begin with a label filter, and end with a relationship filter. If present, labelFilter, and relationshipFilter are ignored, as this takes priority.
sequence:'Post|-Blocked, NEXT>, Reply, <FROM, >Admin, POSTED>|REPLIED>'
Combines the behaviors above.
There are some uses cases where the sequence does not begin at the start node, but at one node distant.
The config parameter beginSequenceAtStart toggles this behavior. Its default value is true. If set to false, this changes the expected values for labelFilter, relationshipFilter, and sequence as noted below:
sequence altered behavior example explanation
labelFilter
The start node is not considered part of the sequence. The sequence begins one node off from the start node.
beginSequenceAtStart:false, labelFilter:'Post|-Blocked,Reply,>Admin'
The next node(s) out from the start node begins the sequence (and must be a :Post node that isn’t :Blocked), and only paths ending with Admin nodes returned.
relationshipFilter
The first relationship filter in the sequence string will not be considered part of the repeating sequence, and will only be used for the first relationship from the start node to the node that will be the actual start of the sequence.
beginSequenceAtStart:false, relationshipFilter:'FIRST>,NEXT>,<FROM,POSTED>|REPLIED>'
FIRST> will be traversed just from the start node to the node that will be the start of the repeating NEXT>,<FROM,POSTED>|REPLIED> sequence.
sequence
Combines the above two behaviors.
beginSequenceAtStart:false, sequence:'FIRST>, Post|-Blocked, NEXT>, Reply, <FROM, >Admin, POSTED>|REPLIED>'
Combines the behaviors above.
Sequence tips
Label filtering in sequences work together with the endNodes+terminatorNodes, though inclusion of a node must be unanimous.
If you need to limit the number of times a sequence repeats, this can be done with the maxLevel config param (multiply the number of iterations with the size of the nodes in the sequence).
Output parameters
Name Type
path
PATH?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the paths to people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 2. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re 2 hops away from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns paths containing only Engineering people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 3. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
We lose the paths that ended with Lju and Stefan because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 4. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This query returns 19 paths, Alicia is very well connected!
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia.
Figure 2. Paths from Alicia
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 5. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
We’re now down to only two paths. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 6. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Our query now also returns paths going through Praveena and Zhen, one going to Martin, and other others going back to Zhen and Praveena!
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to stop as soon as the Joe node is encountered, which we can do by passing the Joe node to the terminatorNodes parameter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Joe is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 7. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
Alicia FOLLOWS Joe, but there’s also another path that goes via Jonny and Anthony.
The terminator nodes approach doesn’t necessarily find all the paths that exist between Alicia and Joe. There might be other paths that go through the Joe node twice. We can find these paths by passing the Joe node to the endNodes parameter. If we use this parameter, all returned paths will end at the Joe node, but expansion will continue past this node to try and find other paths that end at Joe.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end when they reach Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 8. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
We’ve got the two paths we got with the terminator nodes approach, from Alicia to Joe, and from Alicia to Jonny to Jonny to Joe. But we’ve also got an extra path that goes from Alicia to Joe to Praveena to Joe.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns paths from Alicia following the FOLLOWS or KNOWS relationship types from 1 to 3 hops, only including paths that contain Mark, Joe, Zhen, and Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Mark"", ""Joe"", ""Zhen"", ""Praveena""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 9. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Out of the white list, the only person with a direct connection to Alicia is Joe, so all paths go through him. We then go from Joe to the others, and then between each other for the paths of 3 hops.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia to Mark, Joe, Zhen, and Praveena.
Figure 3. Paths from Alicia to Mark, Joe, Zhen, and Praveena
A blacklist is used to exclude nodes from the returned paths. If we want to exclude paths that contain Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, excluding paths that include Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 10. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This returns a very small set of paths since Joe was a very pivotal node in connecting Alicia to the rest of the graph.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia that don’t include Joe.
Figure 4. Paths from Alicia that don’t include Joe
Breadth First Search and Depth First Search
We can control whether the traversal uses the Breadth First Search (BFS), by specifying bfs: true, or Depth First Search algorithm (DFS), by specifying bfs: false. This is often combined with the limit parameter to find the nearest nodes based on the chosen algorithm.
Cypher
The following returns 10 paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, using BFS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 5,
    bfs: true,
    limit: 10
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 11. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
From these results we can see that paths are completely expanded at each level before going onto the next one. For example, we first expand from:
Alicia → Joe
Alicia → Jonny
Alicia → Jake
Before then following relationships from those nodes. And once it’s expanded everything at level 2, it will then explore level 3.
Figure 5. Paths from Alicia using Breadth First Search
If we use the Depth First Search algorithm, the traversal will go as far as it can (up to the maxLevel of hops) down a particular path, before going back up and exploring other ones.
Cypher
The following returns 10 paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, using DFS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    bfs: false,
    limit: 10
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 12. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Now we have a different set of paths returned. We don’t even see the paths from Alicia to Jonny or Alicia to Jake because our limit of 10 paths is completely taken up with paths going through Joe.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia using Depth First Search.
Figure 6. Paths from Alicia using Depth First Search
Uniqueness
We can specify the uniqueness strategy to be used by the traversal through the uniqueness parameter. See Uniqueness for a list of valid strategies. The default value is RELATIONSHIP_PATH.
In this section we’re going to write queries that start from Joe and traverse the FOLLOWS relationship.
Cypher
The following returns the nodes in paths starting from Joe and traversing the FOLLOWS relationship type from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>"",
    minLevel: 1,
    maxLevel: 3,
    uniqueness: ""RELATIONSHIP_PATH"" // default
})
YIELD path
RETURN [node in nodes(path) | node.name] AS nodes, length(path) AS hops
ORDER BY hops;
Table 13. Results
nodes hops
[""Joe"", ""Zhen""]
1
[""Joe"", ""Praveena""]
1
[""Joe"", ""Mark""]
1
[""Joe"", ""Zhen"", ""John""]
2
[""Joe"", ""Praveena"", ""Joe""]
2
[""Joe"", ""Mark"", ""Stefan""]
2
[""Joe"", ""Praveena"", ""Joe"", ""Zhen""]
3
[""Joe"", ""Praveena"", ""Joe"", ""Mark""]
3
[""Joe"", ""Mark"", ""Stefan"", ""Joe""]
3
Several of the paths returned contain the Joe node twice. If we want to ensure that the nodes in a path are unique, we can use the NODE_PATH strategy.
Cypher
The following returns the nodes in paths starting from Joe and traversing the FOLLOWS relationship type from 1 to 3 hops, using the NODE_PATH strategy
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>"",
    minLevel: 1,
    maxLevel: 3,
    uniqueness: ""NODE_PATH""
})
YIELD path
RETURN [node in nodes(path) | node.name] AS nodes, length(path) AS hops
ORDER BY hops;
Table 14. Results
nodes hops
[""Joe"", ""Zhen""]
1
[""Joe"", ""Praveena""]
1
[""Joe"", ""Mark""]
1
[""Joe"", ""Zhen"", ""John""]
2
[""Joe"", ""Mark"", ""Stefan""]
2
The paths returned now have unique lists of nodes.
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the paths of 1 to 4 hops from Joe where the relationship types alternate between FOLLOWS and KNOWS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 15. Results
path hops
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
4
The minLevel and maxLevel values refer to the number of relationships in the path. Using a minLevel of 1 means that paths one hop from Joe with the FOLLOWS relationship type will be returned. If we want to ensure that the relationship type sequence defined in this relationshipFilter is matched at least once, we need to use a minLevel of 2 since there are two relationship types in the filter.
Cypher
The following returns the paths of 2 to 4 hops from Joe where the relationship types alternate between FOLLOWS and KNOWS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 16. Results
path hops
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
4
This config can also be used in combination with beginSequenceAtStart: false, which means that the sequence will start one hop away from the starting node. If we use this config, it means that the first relationship type defined in relationshipFilter will only apply to the starting node.
Cypher
The following returns the paths of 3 to 5 hops from Jake where the relationship types alternate between FOLLOWS and KNOWS, after first following KNOWS relationships from Jake
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Jake""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS,FOLLOWS>,KNOWS"",
 beginSequenceAtStart: false,
 minLevel: 3,
 maxLevel: 7
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 17. Results
path hops
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
3
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
4
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
4
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
5
Sequences of node labels
Sequences of node labels can be specified by comma separating values passed to labelFilter. This is usually used in combination with beginSequenceAtStart: false, which means that sequences will start one hop away from the starting node.
For example, if we start from the Praveena node and want to return the paths that contain alternating Field and DevRel nodes, we can specify a label filter of ""+Field,+DevRel"".
Cypher
The following returns the paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field and DevRel labels.
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 18. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})
1
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
The minLevel and maxLevel values refer to the number of relationships in the path. Using a minLevel of 1 means that paths where the node one hop from Praveena has the Field label will be returned. If we want to ensure that the label sequence defined in this labelFilter is matched at least once, we need to use a minLevel of 2.
Cypher
The following returns the paths of 2 to 4 hops from Praveena where the nodes alternate between having the Field and DevRel labels.
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 19. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
The paths that only contain a relationship from Praveena to Joe have now been filtered out.
But what if we don’t want to specify multiple labels exist, but instead want to find paths where a node doesn’t have a label? To find paths that contain alternating Field and not Field nodes, we can specify a label filter of ""+Field,-Field"".
Cypher
The following returns the paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field label and not having the Field label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,-Field"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 20. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Sales {name: ""Anthony""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Product {name: ""Alicia""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Engineering {name: ""Praveena""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Sales {name: ""Anthony""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Product {name: ""Alicia""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})←[:FOLLOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
4
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})←[:FOLLOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
4
We’ve got a lot more paths, with path lengths between 2 and 4 hops. These paths have the following labels:
2 hops - Field → Not Field
3 hops - Field → Not Field → Field
4 hops - Field → Not Field → Field → Not Field
These paths are a bit difficult to read, so we can simplify the output by using the nodes function to just return the nodes. We’ll also filter the results so that we only return paths that match the complete +Field,-Field label filter. We can do this by only returning paths of even length:
Cypher
The following returns nodes of paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field label and not having the Field label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,-Field"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
WHERE length(path) % 2 = 0

// Remove the Praveena node from the returned path
RETURN nodes(path)[1..] AS nodes, length(path) AS hops

ORDER BY hops;
Table 21. Results
nodes hops
[(:Person:Field {name: ""Joe""}), (:Person:Sales {name: ""Anthony""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Product {name: ""Alicia""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Praveena""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Sales {name: ""Anthony""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Product {name: ""Alicia""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Praveena""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""}), (:Person:Field {name: ""Stefan""}), (:Person:DevRel {name: ""Mark""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Field {name: ""Stefan""}), (:Person:Engineering {name: ""Zhen""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""}), (:Person:Field {name: ""Stefan""}), (:Person:DevRel {name: ""Mark""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Field {name: ""Stefan""}), (:Person:Engineering {name: ""Zhen""})]
4
The * character can be used as a wildcard in a node sequence to indicate that any label can appear in that position. If we want to match a sequence of nodes with any label followed by one with the DevRel label, we can specify the label filter *,+DevRel
Cypher
The following returns nodes of paths of 2 to 4 hops from Praveena where the nodes alternate between having any label and the DevRel label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""*,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
WHERE length(path) % 2 = 0

// Remove the Praveena node from the returned path
RETURN nodes(path)[1..] AS nodes, length(path) AS hops

ORDER BY hops;
Table 22. Results
nodes hops
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Engineering {name: ""Zhen""}), (:Person:DevRel {name: ""Lju""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Lju""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Lju""})]
4
[(:Person:Engineering {name: ""Zhen""}), (:Person:DevRel {name: ""Lju""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Mark""})]
4
More documentation of apoc.path.expandConfig
apoc.path.expand
apoc.path.spanningTree
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.expand;"apoc.path.expand
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.path.expand(startNode Any, relFilter String, labelFilter String, minDepth Integer, maxDepth Integer) - returns paths expanded from the start node following the given relationship types from min-depth to max-depth.
Signature
None
Copy to Clipboard
apoc.path.expand(start :: ANY?, relationshipFilter :: STRING?, labelFilter :: STRING?, minLevel :: INTEGER?, maxLevel :: INTEGER?) :: (path :: PATH?)
Input parameters
Name Type Default
start
ANY?
null
relationshipFilter
STRING?
null
labelFilter
STRING?
null
minLevel
INTEGER?
null
maxLevel
INTEGER?
null
Output parameters
Name Type
path
PATH?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (jake:Person:Product {name: ""Jake""})

MERGE (zhen)-[:KNOWS]-(stefan)
MERGE (zhen)-[:KNOWS]-(lju)
MERGE (zhen)-[:KNOWS]-(praveena)
MERGE (zhen)-[:KNOWS]-(martin)
MERGE (mark)-[:KNOWS]-(jake)
 (alicia)-[:]-(jake)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
View all (9 more lines)
The Neo4j Browser visualization below shows the sample graph:
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationship filter.
Cypher
The following returns the paths to people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expand(p, ""KNOWS"", null, 1, 2)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 1. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re 2 hops away from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. The following query only returns paths where every node has the Engineering label.
Cypher
The following returns paths containing only Engineering people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expand(p, ""KNOWS"", ""+Engineering"", 1, 2)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 2. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
We lose the paths that ended with Lju and Stefan because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", """", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 3. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This query returns 19 paths, Alicia is very well connected!
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", ""/Engineering"", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 4. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
We’re now down to only two paths. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", "">Engineering"", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 5. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Our query now also returns paths going through Praveena and Zhen, one going to Martin, and other others going back to Zhen and Praveena!
More documentation of apoc.path.expand
apoc.path
apoc.path.expandConfig
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/expand-paths;"Expand paths
Contents
Procedure Overview
Parameter Syntax
Examples
The expand paths procedure is the most basic of the path expanders. This procedure enables path traversals based on relationship filters and node filters. See Expand paths with config if more control is required over the traversal.
Procedure Overview
The procedure is described below:
Qualified Name Type
apoc.path.expand
apoc.path.expand(startNode <id>|Node|list, 'TYPE|TYPE_OUT>|<TYPE_IN', '+YesLabel|-NoLabel', minLevel, maxLevel ) yield path - expand from start node following the given relationships from min to max-level adhering to the label filters
Procedure
Parameter Syntax
This procedure takes the following parameters:
start - a list of nodes or node ids
relationshipFilter - the relationship types to be expanded
labelFilter - the node labels to be expanded
minLevel - the minimum number of hops in our traversal
maxLevel - the maximum number of hops in our traversal
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (jake:Person:Product {name: ""Jake""})

MERGE (zhen)-[:KNOWS]-(stefan)
MERGE (zhen)-[:KNOWS]-(lju)
MERGE (zhen)-[:KNOWS]-(praveena)
MERGE (zhen)-[:KNOWS]-(martin)
MERGE (mark)-[:KNOWS]-(jake)
 (alicia)-[:]-(jake)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
View all (9 more lines)
The Neo4j Browser visualization below shows the sample graph:
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationship filter.
Cypher
The following returns the paths to people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expand(p, ""KNOWS"", null, 1, 2)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 1. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re 2 hops away from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. The following query only returns paths where every node has the Engineering label.
Cypher
The following returns paths containing only Engineering people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expand(p, ""KNOWS"", ""+Engineering"", 1, 2)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 2. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
We lose the paths that ended with Lju and Stefan because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", """", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 3. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This query returns 19 paths, Alicia is very well connected!
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", ""/Engineering"", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 4. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
We’re now down to only two paths. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expand(p, ""FOLLOWS>|KNOWS"", "">Engineering"", 1, 3)
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 5. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Our query now also returns paths going through Praveena and Zhen, one going to Martin, and other others going back to Zhen and Praveena!
Path Expander Overview
Expand paths with config
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/path-expander;"Path Expander Overview
The Cypher query language supports variable-length pattern matching, but path expansion is limited to relationship types. The path expander procedures enable more powerful variable length path traversals, where users can specify the following:
the direction of the relationship per relationship type.
a list of label names which act as a ""whitelist"" or a ""blacklist"".
end nodes for the expansion.
This functionality is supported by five procedures:
Procedure Description Documentation
apoc.path.expand()
expands paths using Cypher’s default expansion modes (bfs and 'RELATIONSHIP_PATH' uniqueness).
Expand paths
apoc.path.expandConfig()
expands paths with more flexible configuration of parameters and expansion modes.
Expand paths with config
apoc.path.subgraphNodes()
expands to nodes of a subgraph.
Expand to nodes in a subgraph
apoc.path.subgraphAll()
expands to nodes of a subgraph and also returns all relationships in the subgraph.
Expand to subgraph
apoc.path.spanningTree()
expands to paths collectively forming a spanning tree.
Expand a spanning tree
Advanced Graph Querying
Expand paths
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/expand-subgraph;"Expand to subgraph
Contents
Procedure Overview
Configuration parameters
Relationship Filters
Label Filters
Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
The expand to subgraph procedure expands to subgraph nodes reachable from the start node following relationships to max-level adhering to the label filters. Returns the collection of nodes in the subgraph, and the collection of relationships between all subgraph nodes. It allows fine grained control over the traversals that expand these subgraphs.
Procedure Overview
The procedure is described below:
Qualified Name Type
apoc.path.subgraphAll
apoc.path.subgraphAll(startNode <id>|Node|list, {maxLevel,relationshipFilter,labelFilter,bfs:true, filterStartNode:false, limit:-1, endNodes:[], terminatorNodes:[], sequence, beginSequenceAtStart:true}) yield nodes, relationships - expand the subgraph reachable from start node following relationships to max-level adhering to the label filters, and also return all relationships within the subgraph
Procedure
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the subgraph reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Praveena.
Figure 2. Subgraph from Praveena
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the subgraph o Engineering people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph of Engineering nodes from Praveena.
Figure 3. Subgraph of Engineering nodes from Praveena
We lose Lju and Stefan because those nodes don’t have the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the subgraph of people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia.
Figure 4. Subgraph from Alicia
This subgraph includes all but one of the people in our graph, which means that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the subgraph reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia terminating at Engineering nodes.
Figure 5. Subgraph from Alicia terminating at Engineering nodes
We’re now down to only 2 people - Zhen and Praveena. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns the subgraph of Engineering people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia ending at Engineering nodes.
Figure 6. Subgraph from Alicia ending at Engineering nodes
Our subgraph now also includes Martin, who is reached via a relationship from Zhen.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want the returned subgraph to stop as soon as the Mark, Joe, Zhen, or Praveena nodes are reached. We can do that by passing those nodes to the terminatorNodes parameter.
Cypher
The following returns the subgraph of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (terminator:Person)
WHERE terminator.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(terminator) AS terminatorNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: terminatorNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia terminating at Mark, Joe, Zhen, or Rik.
Figure 7. Subgraph from Alicia terminating at Mark, Joe, Zhen, or Rik
We have paths to Mark and Joe, but Zhen and Rik can’t be reached This could be because there is no path to Zhen and Rik that doesn’t go through Mark and Joe, or it could mean that there’s no path based on the other traversal criteria.
We can find out whether Mark, Joe, Zhen, or Rik are reachable by passing these nodes to the endNodes parameter.
Cypher
The following returns the subgraph of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, ending as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(end) AS endNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia ending at Mark, Joe, Zhen, or Rik.
Figure 8. Subgraph from Alicia ending at Mark, Joe, Zhen, or Rik
We can now reach Joe, Mark, and Zhen, but Rik is still unreachable.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia where paths to nodes include Mark, Jonny, or Zhen.
Figure 9. Subgraph from Alicia where paths to nodes include Mark, Jonny, or Zhen
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia where paths to nodes can’t go via Joe.
Figure 10. Subgraph from Alicia where paths to nodes can’t go via Joe
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Joe via alternate FOLLOWS and KNOWS relationship types.
Figure 11. Subgraph from Joe via alternate FOLLOWS and KNOWS relationship types
Expand to nodes in a subgraph
Expand a spanning tree
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/expand-subgraph-nodes;"Expand to nodes in a subgraph
Contents
Procedure Overview
Configuration parameters
Relationship Filters
Label Filters
Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
This procedure expands to subgraph nodes reachable from the start node following relationships to max-level adhering to the label filters. It allows fine grained control over the traversals that expand the subgraph.
Procedure Overview
The procedure is described below:
Qualified Name Type
apoc.path.subgraphNodes
apoc.path.subgraphNodes(startNode <id>|Node|list, {maxLevel,relationshipFilter,labelFilter,bfs:true, filterStartNode:false, limit:-1, optional:false, endNodes:[], terminatorNodes:[], sequence, beginSequenceAtStart:true}) yield node - expand the subgraph nodes reachable from start node following relationships to max-level adhering to the label filters
Procedure
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
Relationship Filters are a comma-separated sequence of filters. Individual filters are one or more patterns separated by |.
The simplest Relationship Filters have only one filter that is applied to every relationship traversed. We’ll discuss the behaviour of longer sequences later.
The syntax for individual relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
Label Filters are a comma-separated sequence of filters. Individual filters are one or more patterns separated by |.
The simplest Label Filters have only one filter that is applied to every node visited. We’ll discuss the behaviour of longer sequences later.
The syntax for individual label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD node
RETURN node;
Table 3. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
(:Person:Field {name: ""Stefan""})
4 people are reachable from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the Engineering people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD node
RETURN node;
Table 4. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Martin""})
We lose Lju and Stefan because those nodes don’t have the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 5. Results
node
(:Person:Sales {name: ""Jonny""})
(:Person:Field {name: ""Joe""})
(:Person:Product {name: ""Jake""})
(:Person:Sales {name: ""Anthony""})
(:Person:Engineering {name: ""Praveena""})
(:Person:DevRel {name: ""Mark""})
(:Person:Engineering {name: ""Zhen""})
(:Person:Field {name: ""Stefan""})
(:Person:Product {name: ""John""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
This list includes all but one of the people in our graph, which means that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 6. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Praveena""})
We’re now down to only 2 people - Zhen and Praveena. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns nodes that have the Engineering label
continues expansion to end nodes after that, looking for more nodes that have the Engineering label
Cypher
The following returns Engineering people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 7. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Praveena""})
(:Person:Engineering {name: ""Martin""})
Our query now also returns Martin, who must have been reachable via either Zhen or Praveena.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes. For this procedure, these parameters both behave the same way - the procedure will determine whether any of the nodes provided as terminator or end nodes are reachable from the start node.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want to know whether there’s a way to get from Alicia to Joe, which we can do by passing the Joe node to the terminatorNodes parameter.
Cypher
The following returns the terminator nodes reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: [joe]
})
YIELD node
RETURN node;
Table 8. Results
node
(:Person:Field {name: ""Joe""})
We do indeed have a path from Alicia to Joe.
And we know from an earlier example that Alicia can actually reach all other nodes in the graph using the KNOWS or FOLLOWS relationships. But what if we want to determine whether Mark, Joe, Zhen, and Praveena are reachable using only the KNOWS relationship?
Cypher
The following returns the end nodes reachable by the KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Praveena""]
WITH p, collect(end) AS endNodes
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD node
RETURN node;
Table 9. Results
node
(:Person:DevRel {name: ""Mark""})
Only Mark is reachable!
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the query that found people that Alicia KNOWS or FOLLOWS. We want to find the nodes reachable via paths that only include Jonny, Mark, or Zhen. We can do this by passing those odes to the parameter whitelistNodes.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD node
RETURN node;
Table 10. Results
node
(:Person:Sales {name: ""Jonny""})
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD node
RETURN node;
Table 11. Results
node
(:Person:Sales {name: ""Jonny""})
(:Person:Product {name: ""Jake""})
(:Person:Sales {name: ""Anthony""})
(:Person:DevRel {name: ""Mark""})
(:Person:Field {name: ""Stefan""})
Only 5 nodes are reachable without going through the Joe node. If we remember back to an earlier example, 11 nodes were reachable when we didn’t specify a blacklist. This indicates that Joe is an important connector in this graph.
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD node
RETURN node;
Table 12. Results
node
(:Person:Engineering {name: ""Praveena""})
(:Person:DevRel {name: ""Mark""})
(:Person:Engineering {name: ""Zhen""})
(:Person:Product {name: ""Jake""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
(:Person:Field {name: ""Stefan""})
Expand paths with config
Expand to subgraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.subgraphNodes;"apoc.path.subgraphNodes
Contents
Signature
Input parameters
Config parameters
Relationship Filters
Label Filters
Output parameters
Usage Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
Procedure
apoc.path.subgraphNodes(startNode Any, config Map<String, Any>) - returns the nodes in the sub-graph reachable from the start node following the given relationship types to max-depth.
Signature
None
Copy to Clipboard
apoc.path.subgraphNodes(start :: ANY?, config :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
start
ANY?
null
config
MAP?
null
Config parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD node
RETURN node;
Table 3. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
(:Person:Field {name: ""Stefan""})
4 people are reachable from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the Engineering people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD node
RETURN node;
Table 4. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Martin""})
We lose Lju and Stefan because those nodes don’t have the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 5. Results
node
(:Person:Sales {name: ""Jonny""})
(:Person:Field {name: ""Joe""})
(:Person:Product {name: ""Jake""})
(:Person:Sales {name: ""Anthony""})
(:Person:Engineering {name: ""Praveena""})
(:Person:DevRel {name: ""Mark""})
(:Person:Engineering {name: ""Zhen""})
(:Person:Field {name: ""Stefan""})
(:Person:Product {name: ""John""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
This list includes all but one of the people in our graph, which means that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 6. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Praveena""})
We’re now down to only 2 people - Zhen and Praveena. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns nodes that have the Engineering label
continues expansion to end nodes after that, looking for more nodes that have the Engineering label
Cypher
The following returns Engineering people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD node
RETURN node;
Table 7. Results
node
(:Person:Engineering {name: ""Zhen""})
(:Person:Engineering {name: ""Praveena""})
(:Person:Engineering {name: ""Martin""})
Our query now also returns Martin, who must have been reachable via either Zhen or Praveena.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes. For this procedure, these parameters both behave the same way - the procedure will determine whether any of the nodes provided as terminator or end nodes are reachable from the start node.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want to know whether there’s a way to get from Alicia to Joe, which we can do by passing the Joe node to the terminatorNodes parameter.
Cypher
The following returns the terminator nodes reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: [joe]
})
YIELD node
RETURN node;
Table 8. Results
node
(:Person:Field {name: ""Joe""})
We do indeed have a path from Alicia to Joe.
And we know from an earlier example that Alicia can actually reach all other nodes in the graph using the KNOWS or FOLLOWS relationships. But what if we want to determine whether Mark, Joe, Zhen, and Praveena are reachable using only the KNOWS relationship?
Cypher
The following returns the end nodes reachable by the KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Praveena""]
WITH p, collect(end) AS endNodes
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD node
RETURN node;
Table 9. Results
node
(:Person:DevRel {name: ""Mark""})
Only Mark is reachable!
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the query that found people that Alicia KNOWS or FOLLOWS. We want to find the nodes reachable via paths that only include Jonny, Mark, or Zhen. We can do this by passing those odes to the parameter whitelistNodes.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD node
RETURN node;
Table 10. Results
node
(:Person:Sales {name: ""Jonny""})
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD node
RETURN node;
Table 11. Results
node
(:Person:Sales {name: ""Jonny""})
(:Person:Product {name: ""Jake""})
(:Person:Sales {name: ""Anthony""})
(:Person:DevRel {name: ""Mark""})
(:Person:Field {name: ""Stefan""})
Only 5 nodes are reachable without going through the Joe node. If we remember back to an earlier example, 11 nodes were reachable when we didn’t specify a blacklist. This indicates that Joe is an important connector in this graph.
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.subgraphNodes(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD node
RETURN node;
Table 12. Results
node
(:Person:Engineering {name: ""Praveena""})
(:Person:DevRel {name: ""Mark""})
(:Person:Engineering {name: ""Zhen""})
(:Person:Product {name: ""Jake""})
(:Person:Engineering {name: ""Martin""})
(:Person:DevRel {name: ""Lju""})
(:Person:Field {name: ""Stefan""})
More documentation of apoc.path.subgraphNodes
apoc.path.subgraphAll
apoc.path.combine
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.combine;"apoc.path.combine
Contents
Signature
Input parameters
Usage Examples
Function
apoc.path.combine(path1 Path, path2 Path) - combines the two given paths into one path.
Signature
None
Copy to Clipboard
apoc.path.combine(first :: PATH?, second :: PATH?) :: (PATH?)
Input parameters
Name Type Default
first
PATH?
null
second
PATH?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (manUtd:Club {name: 'Man Utd'})
MERGE (juventus:Club {name: 'Juventus'})
MERGE (flamengo:Club {name: 'Flamengo'})

MERGE (premierLeague:League {name: 'Premier League'})
MERGE (serieA:League {name: 'Serie A'})
MERGE (brasileirao:League {name: 'Brasileirão'})

MERGE (england:Country {name: 'England'})
MERGE (brazil:Country {name: 'Brazil'})

MERGE (uefa:Confederation {name: 'UEFA'})

MERGE (manUtd)-[:IN_LEAGUE]->(premierLeague)
MERGE (premierLeague)-[:IN_COUNTRY]->(england)
 (england)-[:]->(uefa)

 (juventus)-[:]->(serieA)

 (flamengo)-[:]->(brasileirao)
 (brasileirao)-[:]->(brazil);
View all (6 more lines)
If we want to create a path from a query that contains two OPTIONAL MATCH clauses, we can use the apoc.path.combine function.
The following returns a path that combines the (club)-[:IN_LEAGUE]→(league) and (league)-[:IN_COUNTRY]→(country) paths:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
RETURN club.name, apoc.path.combine(path1, path2) AS path
ORDER BY length(path);
Table 1. Results
club.name path
""Juventus""
(:Club {name: ""Juventus""})-[:IN_LEAGUE]→(:League {name: ""Serie A""})
""Man Utd""
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
""Flamengo""
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
If we want to combine more than two OPTIONAL MATCH paths, see apoc.path.create.
More documentation of apoc.path.combine
apoc.path.subgraphNodes
apoc.path.create
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.create;"apoc.path.create
Contents
Signature
Input parameters
Usage Examples
Function
apoc.path.create(startNode Node, rels [Rel]) - returns a path from the given start node and a list of relationships.
Signature
None
Copy to Clipboard
apoc.path.create(startNode :: NODE?, rels = [] :: LIST? OF RELATIONSHIP?) :: (PATH?)
Input parameters
Name Type Default
startNode
NODE?
null
rels
LIST? OF RELATIONSHIP?
[]
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (manUtd:Club {name: 'Man Utd'})
MERGE (juventus:Club {name: 'Juventus'})
MERGE (flamengo:Club {name: 'Flamengo'})

MERGE (premierLeague:League {name: 'Premier League'})
MERGE (serieA:League {name: 'Serie A'})
MERGE (brasileirao:League {name: 'Brasileirão'})

MERGE (england:Country {name: 'England'})
MERGE (brazil:Country {name: 'Brazil'})

MERGE (uefa:Confederation {name: 'UEFA'})

MERGE (manUtd)-[:IN_LEAGUE]->(premierLeague)
MERGE (premierLeague)-[:IN_COUNTRY]->(england)
 (england)-[:]->(uefa)

 (juventus)-[:]->(serieA)

 (flamengo)-[:]->(brasileirao)
 (brasileirao)-[:]->(brazil);
View all (6 more lines)
The apoc.path.create function creates paths from a start node and a list of relationships. One use case for this function is combining relationships from OPTIONAL MATCH clauses.
The following query creates a path from relationships returned by OPTIONAL MATCH clauses:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH (club)-[inLeague:IN_LEAGUE]->(league)
OPTIONAL MATCH (league)-[inCountry:IN_COUNTRY]->(country)
OPTIONAL MATCH (country)-[inConfederation:IN_CONFEDERATION]->(confederation)
RETURN club.name, apoc.path.create(club, [inLeague, inCountry, inConfederation]) AS path
ORDER BY length(path);
Table 1. Results
club.name path
""Juventus""
(:Club {name: ""Juventus""})-[:IN_LEAGUE]→(:League {name: ""Serie A""})
""Flamengo""
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
""Man Utd""
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})-[:IN_CONFEDERATION]→(:Confederation {name: ""UEFA""})
More documentation of apoc.path.create
apoc.path.combine
apoc.path.elements
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/path-querying;"Path Manipulation
Contents
Function Overview
Examples
The functions in this section can be used to create, combine and split paths.
Function Overview
The available functions are described below:
Qualified Name Type
apoc.path.create
apoc.path.create(startNode,[rels]) - creates a path instance of the given elements
Function
apoc.path.combine
apoc.path.combine(path1, path2) - combines the paths into one if the connecting node matches
Function
apoc.path.slice
apoc.path.slice(path, [offset], [length]) - creates a sub-path with the given offset and length
Function
apoc.path.elements
apoc.path.elements(path) - returns a list of node-relationship-node-…
Function
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (manUtd:Club {name: 'Man Utd'})
MERGE (juventus:Club {name: 'Juventus'})
MERGE (flamengo:Club {name: 'Flamengo'})

MERGE (premierLeague:League {name: 'Premier League'})
MERGE (serieA:League {name: 'Serie A'})
MERGE (brasileirao:League {name: 'Brasileirão'})

MERGE (england:Country {name: 'England'})
MERGE (brazil:Country {name: 'Brazil'})

MERGE (uefa:Confederation {name: 'UEFA'})

MERGE (manUtd)-[:IN_LEAGUE]->(premierLeague)
MERGE (premierLeague)-[:IN_COUNTRY]->(england)
 (england)-[:]->(uefa)

 (juventus)-[:]->(serieA)

 (flamengo)-[:]->(brasileirao)
 (brasileirao)-[:]->(brazil);
View all (6 more lines)
The apoc.path.create function creates paths from a start node and a list of relationhips. One use case for this function is combining relationships from OPTIONAL MATCH clauses.
Cypher
The following query creates a path from relationships returned by OPTIONAL MATCH clauses
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH (club)-[inLeague:IN_LEAGUE]->(league)
OPTIONAL MATCH (league)-[inCountry:IN_COUNTRY]->(country)
OPTIONAL MATCH (country)-[inConfederation:IN_CONFEDERATION]->(confederation)
RETURN club.name, apoc.path.create(club, [inLeague, inCountry, inConfederation]) AS path
ORDER BY length(path);
Table 1. Results
club.name path
""Juventus""
(:Club {name: ""Juventus""})-[:IN_LEAGUE]→(:League {name: ""Serie A""})
""Flamengo""
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
""Man Utd""
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})-[:IN_CONFEDERATION]→(:Confederation {name: ""UEFA""})
If we want to create a path from a query that contains two OPTIONAL MATCH clauses, we can instead use the apoc.path.combine function.
Cypher
The following returns a path that combines the (club)-[:IN_LEAGUE]→(league) and (league)-[:IN_COUNTRY]→(country) paths
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
RETURN club.name, apoc.path.combine(path1, path2) AS path
ORDER BY length(path);
Table 2. Results
club.name path
""Juventus""
(:Club {name: ""Juventus""})-[:IN_LEAGUE]→(:League {name: ""Serie A""})
""Man Utd""
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
""Flamengo""
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
The apoc.path.slice function returns a subset of a path starting from a specified offset for a specified number of elements.
Cypher
The following returns a subset of the combined path, starting from an offset of 1 for a length of 1
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
WITH apoc.path.combine(path1, path2) AS path
RETURN apoc.path.slice(path, 1, 1);
Table 3. Results
apoc.path.slice(path, 1, 1)
(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
(:League {name: ""Serie A""})
(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
The apoc.path.elements function converts a path into a list of nodes and relationships.
Cypher
The following returns a list of entities in the (club)-[:IN_LEAGUE]→(league)-[:IN_COUNTRY]→(country) path
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (club:Club)-[:IN_LEAGUE]->(league)-[:IN_COUNTRY]->(country)
RETURN path, apoc.path.elements(path);
Table 4. Results
path apoc.path.elements(path)
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
[(:Club {name: ""Man Utd""}), [:IN_LEAGUE], (:League {name: ""Premier League""}), [:IN_COUNTRY], (:Country {name: ""England""})]
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
[(:Club {name: ""Flamengo""}), [:IN_LEAGUE], (:League {name: ""Brasileirão""}), [:IN_COUNTRY], (:Country {name: ""Brazil""})]
We can use this function to return a stream of triples representing the nodes and relationships contained in paths.
Cypher
The following returns triples of (subject, predicate, object)
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
WITH apoc.path.combine(path1, path2) AS path
WITH apoc.path.elements(path) AS elements
UNWIND range(0, size(elements)-2) AS index
WITH elements, index
WHERE index %2 = 0
RETURN elements[index] AS subject, elements[index+1] AS predicate, elements[index+2] AS object;
Table 5. Results
subject predicate object
(:Club {name: ""Man Utd""})
[:IN_LEAGUE]
(:League {name: ""Premier League""})
(:League {name: ""Premier League""})
[:IN_COUNTRY]
(:Country {name: ""England""})
(:Club {name: ""Juventus""})
[:IN_LEAGUE]
(:League {name: ""Serie A""})
(:Club {name: ""Flamengo""})
[:IN_LEAGUE]
(:League {name: ""Brasileirão""})
(:League {name: ""Brasileirão""})
[:IN_COUNTRY]
(:Country {name: ""Brazil""})
Neighbor Functions
Relationship Querying
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.elements;"apoc.path.elements
Contents
Signature
Input parameters
Usage Examples
Function
apoc.path.elements(path Path) - converts the given path into a list of nodes and relationships.
Signature
None
Copy to Clipboard
apoc.path.elements(path :: PATH?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
path
PATH?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (manUtd:Club {name: 'Man Utd'})
MERGE (juventus:Club {name: 'Juventus'})
MERGE (flamengo:Club {name: 'Flamengo'})

MERGE (premierLeague:League {name: 'Premier League'})
MERGE (serieA:League {name: 'Serie A'})
MERGE (brasileirao:League {name: 'Brasileirão'})

MERGE (england:Country {name: 'England'})
MERGE (brazil:Country {name: 'Brazil'})

MERGE (uefa:Confederation {name: 'UEFA'})

MERGE (manUtd)-[:IN_LEAGUE]->(premierLeague)
MERGE (premierLeague)-[:IN_COUNTRY]->(england)
 (england)-[:]->(uefa)

 (juventus)-[:]->(serieA)

 (flamengo)-[:]->(brasileirao)
 (brasileirao)-[:]->(brazil);
View all (6 more lines)
The apoc.path.elements function converts a path into a list of nodes and relationships.
Cypher
The following returns a list of entities in the (club)-[:IN_LEAGUE]→(league)-[:IN_COUNTRY]→(country) path
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (club:Club)-[:IN_LEAGUE]->(league)-[:IN_COUNTRY]->(country)
RETURN path, apoc.path.elements(path);
Table 1. Results
path apoc.path.elements(path)
(:Club {name: ""Man Utd""})-[:IN_LEAGUE]→(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
[(:Club {name: ""Man Utd""}), [:IN_LEAGUE], (:League {name: ""Premier League""}), [:IN_COUNTRY], (:Country {name: ""England""})]
(:Club {name: ""Flamengo""})-[:IN_LEAGUE]→(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
[(:Club {name: ""Flamengo""}), [:IN_LEAGUE], (:League {name: ""Brasileirão""}), [:IN_COUNTRY], (:Country {name: ""Brazil""})]
We can use this function to return a stream of triples representing the nodes and relationships contained in paths.
The following returns triples of (subject, predicate, object):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
WITH apoc.path.combine(path1, path2) AS path
WITH apoc.path.elements(path) AS elements
UNWIND range(0, size(elements)-2) AS index
WITH elements, index
WHERE index %2 = 0
RETURN elements[index] AS subject, elements[index+1] AS predicate, elements[index+2] AS object;
Table 2. Results
subject predicate object
(:Club {name: ""Man Utd""})
[:IN_LEAGUE]
(:League {name: ""Premier League""})
(:League {name: ""Premier League""})
[:IN_COUNTRY]
(:Country {name: ""England""})
(:Club {name: ""Juventus""})
[:IN_LEAGUE]
(:League {name: ""Serie A""})
(:Club {name: ""Flamengo""})
[:IN_LEAGUE]
(:League {name: ""Brasileirão""})
(:League {name: ""Brasileirão""})
[:IN_COUNTRY]
(:Country {name: ""Brazil""})
More documentation of apoc.path.elements
apoc.path.create
apoc.path.slice
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.slice;"apoc.path.slice
Contents
Signature
Input parameters
Usage Examples
Function
apoc.path.slice(path Path, offset Integer, length Integer) - returns a sub-path of the given length and offset from the given path.
Signature
None
Copy to Clipboard
apoc.path.slice(path :: PATH?, offset = 0 :: INTEGER?, length = -1 :: INTEGER?) :: (PATH?)
Input parameters
Name Type Default
path
PATH?
null
offset
INTEGER?
0
length
INTEGER?
-1
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (manUtd:Club {name: 'Man Utd'})
MERGE (juventus:Club {name: 'Juventus'})
MERGE (flamengo:Club {name: 'Flamengo'})

MERGE (premierLeague:League {name: 'Premier League'})
MERGE (serieA:League {name: 'Serie A'})
MERGE (brasileirao:League {name: 'Brasileirão'})

MERGE (england:Country {name: 'England'})
MERGE (brazil:Country {name: 'Brazil'})

MERGE (uefa:Confederation {name: 'UEFA'})

MERGE (manUtd)-[:IN_LEAGUE]->(premierLeague)
MERGE (premierLeague)-[:IN_COUNTRY]->(england)
 (england)-[:]->(uefa)

 (juventus)-[:]->(serieA)

 (flamengo)-[:]->(brasileirao)
 (brasileirao)-[:]->(brazil);
View all (6 more lines)
The apoc.path.slice function returns a subset of a path starting from a specified offset for a specified number of elements.
The following returns a subset of the combined path, starting from an offset of 1 for a length of 1:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (club:Club)
OPTIONAL MATCH path1 = (club)-[:IN_LEAGUE]->(league)
OPTIONAL MATCH path2 = (league)-[:IN_COUNTRY]->(country)
WITH apoc.path.combine(path1, path2) AS path
RETURN apoc.path.slice(path, 1, 1);
Table 1. Results
apoc.path.slice(path, 1, 1)
(:League {name: ""Premier League""})-[:IN_COUNTRY]→(:Country {name: ""England""})
(:League {name: ""Serie A""})
(:League {name: ""Brasileirão""})-[:IN_COUNTRY]→(:Country {name: ""Brazil""})
More documentation of apoc.path.slice
apoc.path.elements
apoc.periodic
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic;"apoc.periodic
Qualified Name Type
apoc.periodic.cancel
apoc.periodic.cancel(name String) - cancels the given background job. Background jobs are created using apoc.periodic.submit.
Procedure
apoc.periodic.commit
apoc.periodic.commit(statement String, params Map<String, Any>) - runs the given statement in separate batched transactions.
Procedure
apoc.periodic.countdown
apoc.periodic.countdown(name String, statement String, rate Integer) - runs a repeatedly called background statement until it returns 0.
Procedure
apoc.periodic.iterate
apoc.periodic.iterate(cypherIterate String, cypherAction String, config Map<String, Any>) - runs the second statement for each item returned by the first statement. This procedure returns the number of batches and the total number of processed rows.
Procedure
apoc.periodic.list
apoc.periodic.list() - returns a list of all background jobs.
Procedure
apoc.periodic.repeat
apoc.periodic.repeat(name String, statement String, rate Integer, config Map<String, Any>) - runs a repeatedly called background job. To stop this procedure, use apoc.periodic.cancel.
Procedure
apoc.periodic.submit
apoc.periodic.submit(name String, statement String, params Map<String, Any>) - creates a background job which runs the given Cypher statement once.
Procedure
apoc.periodic.truncate
apoc.periodic.truncate(config Map<String, Any>) - removes all entities (and optionally indexes and constraints) from the database using the apoc.periodic.iterate procedure.
Procedure
apoc.path.slice
apoc.periodic.cancel
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.cancel;"apoc.periodic.cancel
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.periodic.cancel(name String) - cancels the given background job. Background jobs are created using apoc.periodic.submit.
Signature
None
Copy to Clipboard
apoc.periodic.cancel(name :: STRING?) :: (name :: STRING?, delay :: INTEGER?, rate :: INTEGER?, done :: BOOLEAN?, cancelled :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
delay
INTEGER?
rate
INTEGER?
done
BOOLEAN?
cancelled
BOOLEAN?
Usage Examples
If we want to cancel the job submitted by the example in apoc.periodic.repeat, we can run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.cancel(""create-people"");
Table 1. Results
name delay rate done cancelled
""create-people""
0
0
TRUE
TRUE
apoc.periodic
apoc.periodic.commit
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.commit;"apoc.periodic.commit
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.periodic.commit(statement String, params Map<String, Any>) - runs the given statement in separate batched transactions.
Signature
None
Copy to Clipboard
apoc.periodic.commit(statement :: STRING?, params = {} :: MAP?) :: (updates :: INTEGER?, executions :: INTEGER?, runtime :: INTEGER?, batches :: INTEGER?, failedBatches :: INTEGER?, batchErrors :: MAP?, failedCommits :: INTEGER?, commitErrors :: MAP?, wasTerminated :: BOOLEAN?)
Input parameters
Name Type Default
statement
STRING?
null
params
MAP?
{}
Output parameters
Name Type
updates
INTEGER?
executions
INTEGER?
runtime
INTEGER?
batches
INTEGER?
failedBatches
INTEGER?
batchErrors
MAP?
failedCommits
INTEGER?
commitErrors
MAP?
wasTerminated
BOOLEAN?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH [""London"", ""Manchester"", ""Cardiff"", ""Birmingham"", ""Coventry"", ""Edinburgh""] AS cities
UNWIND range(1, 10000) AS id
MERGE (p:Person {id: id})
WITH cities, p, toInteger(rand() * size(cities)) AS index
SET p.city = cities[index];
If we want to convert the city property to a node, we can do this in batches of 1,000, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.commit(
  ""MATCH (person:Person)
   WHERE person.city IS NOT NULL
   WITH person limit $limit
   MERGE (city:City {name:person.city})
   MERGE (person)-[:LIVES_IN]->(city)
   REMOVE person.city
   RETURN count(*)"",
  {limit:1000});
Table 1. Results
updates executions runtime batches failedBatches batchErrors failedCommits commitErrors wasTerminated
10000
10
0
11
0
{}
0
{}
FALSE
We can check that the refactoring has been done by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN p.city IS NOT NULL as exists, count(*);
Table 2. Results
exists count(*)
FALSE
10000
apoc.periodic.cancel
apoc.periodic.countdown
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.countdown;"apoc.periodic.countdown
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.periodic.countdown(name String, statement String, rate Integer) - runs a repeatedly called background statement until it returns 0.
Signature
None
Copy to Clipboard
apoc.periodic.countdown(name :: STRING?, statement :: STRING?, rate :: INTEGER?) :: (name :: STRING?, delay :: INTEGER?, rate :: INTEGER?, done :: BOOLEAN?, cancelled :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
statement
STRING?
null
rate
INTEGER?
null
Output parameters
Name Type
name
STRING?
delay
INTEGER?
rate
INTEGER?
done
BOOLEAN?
cancelled
BOOLEAN?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Counter {value: 10000});
Cypher
The following decrements the value once a second until it gets to 0:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.countdown(
  ""decrement"",
  ""MATCH (counter:Counter)
   SET counter.value = counter.value - 1
   RETURN counter.value as count"",
  1);
apoc.periodic.commit
apoc.periodic.iterate
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.repeat;"apoc.periodic.repeat
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.periodic.repeat(name String, statement String, rate Integer, config Map<String, Any>) - runs a repeatedly called background job. To stop this procedure, use apoc.periodic.cancel.
Signature
None
Copy to Clipboard
apoc.periodic.repeat(name :: STRING?, statement :: STRING?, rate :: INTEGER?, config = {} :: MAP?) :: (name :: STRING?, delay :: INTEGER?, rate :: INTEGER?, done :: BOOLEAN?, cancelled :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
statement
STRING?
null
rate
INTEGER?
null
config
MAP?
{}
Output parameters
Name Type
name
STRING?
delay
INTEGER?
rate
INTEGER?
done
BOOLEAN?
cancelled
BOOLEAN?
Usage Examples
We can create 10 Person nodes every second by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.repeat(
  ""create-people"",
  ""UNWIND range(1,10) AS id CREATE (:Person {uuid: apoc.create.uuid()})"",
   1
);
Table 1. Results
name delay rate done cancelled
""create-people""
0
1
FALSE
FALSE
We can check how many nodes have been created by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)
RETURN count(*) AS count;
Table 2. Results
count
110
If we want to cancel this job, we can use the apoc.periodic.cancel procedure.
apoc.periodic.list
apoc.periodic.submit
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.periodic/apoc.periodic.list;"apoc.periodic.list
Contents
Signature
Output parameters
Usage Examples
Procedure
apoc.periodic.list() - returns a list of all background jobs.
Signature
None
Copy to Clipboard
apoc.periodic.list() :: (name :: STRING?, delay :: INTEGER?, rate :: INTEGER?, done :: BOOLEAN?, cancelled :: BOOLEAN?)
Output parameters
Name Type
name
STRING?
delay
INTEGER?
rate
INTEGER?
done
BOOLEAN?
cancelled
BOOLEAN?
Usage Examples
While the example from apoc.periodic.countdown is in progress, we’ll see the following output from this procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.list();
Table 1. Results
name delay rate done cancelled
""decrement""
0
0
TRUE
FALSE
apoc.periodic.iterate
apoc.periodic.repeat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/relationship-querying;"Relationship Querying
Table 1. Functions
apoc.rel.id(rel)
returns id for (virtual) relationships
apoc.rel.type(rel)
returns type for (virtual) relationships
apoc.any.properties(rel, )
returns properties for virtual and real rels. Optionally restrict via keys.
apoc.any.property(rel)
returns property for virtual and real rels
Table 2. Procedures
CALL apoc.nodes.rels(rel|id|[ids])
quickly returns all relationships with these ids
Path Manipulation
Node Querying
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/node-querying;"Node Querying
Contents
Rel-direction-pattern Syntax:
Table 1. Functions
Qualified Name Type
apoc.nodes.isDense
apoc.nodes.isDense(node) - returns true if it is a dense node
Function
apoc.nodes.connected
apoc.nodes.connected(start, end, rel-direction-pattern) - returns true when the node is connected to the other node, optimized for dense nodes
Function
apoc.node.relationship.exists
apoc.node.relationship.exists(node, rel-direction-pattern) - returns true when the node has the relationships of the pattern
Function
apoc.node.relationships.exist
apoc.node.relationships.exist(node, rel-direction-pattern) - returns a map with rel-pattern, boolean for the given relationship patterns
Function
apoc.nodes.relationships.exist
apoc.nodes.relationships.exist(node|nodes|id|[ids], rel-direction-pattern) - returns a list of maps where each one has two fields: node which is the node subject of the analysis and exists which is a map with rel-pattern, boolean for the given relationship patterns
Function
apoc.node.relationship.types
apoc.node.relationship.types(node, rel-direction-pattern) - returns a list of distinct relationship types
Function
apoc.nodes.relationship.types
apoc.nodes.relationship.types(node|nodes|id|[ids], rel-direction-pattern) - returns a list of maps where each one has two fields: node which is the node subject of the analysis and types which is a list of distinct relationship types
Function
apoc.node.degree
apoc.node.degree(node, rel-direction-pattern) - returns total degrees of the given relationships in the pattern, can use '>' or '<' for all outgoing or incoming relationships
Function
apoc.node.id
returns id for (virtual) nodes
Function
apoc.node.degree.in
apoc.node.degree.in(node, relationshipName) - returns total number number of incoming relationships
Function
apoc.node.degree.out
apoc.node.degree.out(node, relationshipName) - returns total number number of outgoing relationships
Function
apoc.node.labels
returns labels for (virtual) nodes
Function
apoc.any.properties
returns properties for virtual and real, nodes, rels and maps
Function
apoc.any.property
returns property for virtual and real, nodes, rels and maps
Function
apoc.label.exists
apoc.label.exists(element, label) - returns true or false related to label existance
Function
Rel-direction-pattern Syntax:
[<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
Example: 'FRIEND|MENTORS>|<REPORTS_TO' will match to :FRIEND relationships in either direction, outgoing :MENTORS relationships, and incoming :REPORTS_TO relationships.
Table 2. Procedures
Qualified Name Type
apoc.nodes.get
apoc.nodes.get(node|nodes|id|[ids]) - quickly returns all nodes with these ids
Procedure
Relationship Querying
Parallel Node Search
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.connected;"apoc.nodes.connected
Contents
Signature
Input parameters
Usage Examples
Function
apoc.nodes.connected(startNode Node, endNode Node, types String) - returns true when a given node is directly connected to another given node. This function is optimized for dense nodes.
Signature
None
Copy to Clipboard
apoc.nodes.connected(start :: NODE?, start :: NODE?, types =  :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
start
NODE?
null
start
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
MATCH (p2:Person {name: ""Person60""})
RETURN apoc.nodes.connected(p1, p2) AS output;
Table 2. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
MATCH (p2:Person {name: ""Person60""})
RETURN apoc.nodes.connected(p1, p2, ""FOLLOWS"") AS output;
Table 3. Results
output
FALSE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
MATCH (p2:Person {name: ""Person60""})
RETURN apoc.nodes.connected(p1, p2, ""FOLLOWS>|KNOWS"") AS output;
Table 4. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
MATCH (p2:Person {name: ""Person30""})
RETURN apoc.nodes.connected(p1, p2, ""FOLLOWS>"") AS output;
Table 5. Results
output
TRUE
More documentation of apoc.nodes.connected
apoc.nodes.rels
apoc.nodes.isDense
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.isDense;"apoc.nodes.isDense
Contents
Signature
Input parameters
Usage Examples
Function
apoc.nodes.isDense(node Node) - returns true if the given node is a dense node.
Signature
None
Copy to Clipboard
apoc.nodes.isDense(node :: NODE?) :: (BOOLEAN?)
Input parameters
Name Type Default
node
NODE?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}
RETURN friends;
Table 1. Results
friends
101
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.nodes.isDense(p) AS output;
Table 2. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Person1""})
RETURN apoc.nodes.isDense(p) AS output;
Table 3. Results
output
FALSE
More documentation of apoc.nodes.isDense
apoc.nodes.connected
apoc.nodes.relationship.types
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.relationship.types;"apoc.nodes.relationship.types
Contents
Signature
Input parameters
Usage Examples
Function
apoc.nodes.relationship.types(nodes Any, types String) - returns a list of distinct relationship types from the given list of nodes.
Signature
None
Copy to Clipboard
apoc.nodes.relationship.types(ids :: ANY?, types =  :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
ids
ANY?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person)
WHERE p1.name IN [""Michael"", ""Person30"", ""Person60""]
WITH collect(p1) AS people
UNWIND apoc.nodes.relationship.types(people, ""KNOWS>|FOLLOWS"") AS output
RETURN output;
Table 2. Results
output
{node: (:Person {name: ""Michael""}), types: [""KNOWS"", ""FOLLOWS""]}
{node: (:Person {name: ""Person30""}), types: [""FOLLOWS""]}
{node: (:Person {name: ""Person60""}), types: []}
More documentation of apoc.nodes.relationship.types
apoc.nodes.isDense
apoc.nodes.relationships.exist
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.relationships.exist;"apoc.nodes.relationships.exist
Contents
Signature
Input parameters
Usage Examples
Function
apoc.nodes.relationships.exist(nodes Any, types String) - returns a boolean based on whether or not the given nodes have the given relationships.
Signature
None
Copy to Clipboard
apoc.nodes.relationships.exist(ids :: ANY?, types =  :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
ids
ANY?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person)
WHERE p1.name IN [""Michael"", ""Person30"", ""Person60""]
WITH collect(p1) AS people
UNWIND apoc.nodes.relationships.exist(people, ""KNOWS>|FOLLOWS"") AS output
RETURN output;
Table 2. Results
output
{node: (:Person {name: ""Michael""}), exists: {KNOWS>: TRUE, FOLLOWS: TRUE}}
{node: (:Person {name: ""Person30""}), exists: {KNOWS>: FALSE, FOLLOWS: TRUE}}
{node: (:Person {name: ""Person60""}), exists: {KNOWS>: FALSE, FOLLOWS: FALSE}}
More documentation of apoc.nodes.relationships.exist
apoc.nodes.relationship.types
apoc.number
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.rels;"apoc.nodes.rels
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.nodes.rels(rels Any) - returns all relationships with the given ids.
Signature
None
Copy to Clipboard
apoc.nodes.rels(relationships :: ANY?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
relationships
ANY?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix);
We can return the internal IDs of these nodes using the id function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r]->()
RETURN id(r) AS id;
Table 1. Results
id
499367
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.rels([499367]);
Table 2. Results
rel
[:ACTED_IN {roles: [""Neo""]}]
More documentation of apoc.nodes.rels
apoc.nodes.link
apoc.nodes.connected
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.link;"apoc.nodes.link
Contents
Signature
Input parameters
Config parameters
Usage Examples
Procedure
apoc.nodes.link(nodes [Node], type String, config Map<String, Any>) - creates a linked list of the given nodes connected by the given relationship type.
Signature
None
Copy to Clipboard
apoc.nodes.link(nodes :: LIST? OF NODE?, type :: STRING?, config = {} :: MAP?) :: VOID
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
type
STRING?
null
config
MAP?
{}
Config parameters
This procedure supports the following config parameters:
Table 1. Config parameters
name type default description
avoidDuplicates
boolean
false
If true, the relationship will not be created, if it already exists
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Event {name: ""Event 1"", date: datetime(""2019-06-01"")})
CREATE (:Event {name: ""Event 2"", date: datetime(""2019-06-04"")})
CREATE (:Event {name: ""Event 3"", date: datetime(""2019-06-08"")});
We can create a linked list of these events, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (e:Event)
WITH e ORDER BY e.date
WITH collect(e) AS events
CALL apoc.nodes.link(events, ""NEXT"")
RETURN count(*);
We can check for relationship existence using the {avoidDuplicates: true} configuration; calling the previous query twice, 2 relations of type ""NEXT"" will be created between the nodes, instead, by executing CALL apoc.nodes.link(events, ""NEXT"", {avoidDuplicates: true}) only one relationship of type ""NEXT"" will be created.
More documentation of apoc.nodes.link
apoc.nodes.group
apoc.nodes.rels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.group;"apoc.nodes.group
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.nodes.group(labels [String], groupByProperties [String], aggregations [Map<String, Any>], config Map<String, Any>) - allows for the aggregation of nodes based on the given properties. This procedure returns virtual nodes.
Signature
None
Copy to Clipboard
apoc.nodes.group(labels :: LIST? OF STRING?, groupByProperties :: LIST? OF STRING?, aggregations = [{*=count}, {*=count}] :: LIST? OF MAP?, config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?, node :: NODE?, relationship :: RELATIONSHIP?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
groupByProperties
LIST? OF STRING?
null
aggregations
LIST? OF MAP?
[{`*`:""count""},{`*`:""count""}]
config
MAP?
{}
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
node
NODE?
relationship
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE
 (alice:Person {name:'Alice', gender:'female', age:32, kids:1}),
 (bob:Person   {name:'Bob',   gender:'male',   age:42, kids:3}),
 (eve:Person   {name:'Eve',   gender:'female', age:28, kids:2}),
 (graphs:Forum {name:'Graphs',    members:23}),
 (dbs:Forum    {name:'Databases', members:42}),
 (alice)-[:KNOWS {since:2017}]->(bob),
 (eve)-[:KNOWS   {since:2018}]->(bob),
 (alice)-[:MEMBER_OF]->(graphs),
 (alice)-[:MEMBER_OF]->(dbs),
 (bob)-[:MEMBER_OF]->(dbs),
 (eve)-[:MEMBER_OF]->(graphs);
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.group(
  ['*'],
  ['gender'],
  [{`*`:'count', age:'min'}, {`*`:'count'} ]
)
YIELD relationships
UNWIND relationships as rel
RETURN apoc.rel.startNode(rel) AS start, rel, apoc.rel.endNode(rel) AS end;
Table 1. Results
start rel end
(:Person {gender: ""female"", min_age: 28, `count_*`: 2})
[:MEMBER_OF {`count_*`: 3}]
(:Forum {gender: NULL, `count_*`: 2})
(:Person {gender: ""female"", min_age: 28, `count_*`: 2})
[:KNOWS {`count_*`: 2}]
(:Person {gender: ""male"", min_age: 42, `count_*`: 1})
(:Person {gender: ""female"", min_age: 28, `count_*`: 2})
[:KNOWS {`count_*`: 2}]
(:Person {gender: ""male"", min_age: 42, `count_*`: 1})
(:Person {gender: ""male"", min_age: 42, `count_*`: 1})
[:MEMBER_OF {`count_*`: 1}]
(:Forum {gender: NULL, `count_*`: 2})
More documentation of apoc.nodes.group
apoc.nodes.get
apoc.nodes.link
Was this page helpful?"
https://neo4j.com/docs/apoc/5/virtual/graph-grouping;"Graph Grouping
Contents
Usage
Grouping Operators
Configuration
Example
Large graphs are often hard to understand or visualize.
Tabular results can be aggregated for overviews, e.g. in charts with sums, counts etc.
Grouping nodes by property values into virtual nodes helps to do the same with graph visualizations.
When doing that, relationships between those groups are aggregated too, so you only see the summary information.
This functionality is inspired by the work of Martin Junghanns in the Grouping Demo for the Gradoop Graph Processing system.
Basically you can use any (entity)<-->(entity) graph for the grouping, support for graph projections is on the roadmap.
Here is an example using the dataset from :play movies.
Cypher
Example on movie graph
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
SET n.century = toInteger(coalesce(n.born,n.released)/100) * 100;

CALL apoc.nodes.group(['Person','Movie'],['century']);
Sometimes an UI has an issue with the return values of the grouping (list of nodes and list of relationships), then it might help to run:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.group(['Person','Movie'],['century'])
YIELD nodes, relationships
UNWIND nodes as node
UNWIND relationships as rel
RETURN node, rel;
Usage
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.group(labels,properties, [grouping], [config])
The only required parameters are a label-list (can also be ['*']) and a list of property names to group by (both for rels/nodes).
Optionally you can also provide grouping operators by field and a number of configuration options.
Grouping Operators
For grouping operators, you provide a map of operations per field in this form: {fieldName: [operators]}
One map for nodes and one for relationships: [{nodeOperators},{relOperators}]
Possible operators:
count_*
count
sum
min/max
avg
collect
The default is: [{`*`:""count""},{`*`:""count""}] which just counts nodes and relationships.
Configuration
In the config there are more options:
option default description
selfRels
true
show self-relationships in resulting graph
orphans
true
show orphan nodes in resulting graph
limitNodes
-1
limit to maximum of nodes
limitRels
-1
limit to maximum of rels
relsPerNode
-1
limit number of relationships per node
filter
null
a min/max filter by property value, e.g. {User.count_*.min:2} see below
The filter config option is a map of {Label/TYPE.operator_property.min/max: number} where the Label/TYPE. prefix is optional.
So you can e.g. filter only for people with a min-age in the grouping of 21: Person.min_age.min: 21 or having at most 10 KNOWS relationships in common: KNOWS.count_*.max:10.
Example
Cypher
Graph Setup
Copy to Clipboard
Run in Neo4j Browser
CREATE
 (alice:Person {name:'Alice', gender:'female', age:32, kids:1}),
 (bob:Person   {name:'Bob',   gender:'male',   age:42, kids:3}),
 (eve:Person   {name:'Eve',   gender:'female', age:28, kids:2}),
 (graphs:Forum {name:'Graphs',    members:23}),
 (dbs:Forum    {name:'Databases', members:42}),
 (alice)-[:KNOWS {since:2017}]->(bob),
 (eve)-[:KNOWS   {since:2018}]->(bob),
 (alice)-[:MEMBER_OF]->(graphs),
 (alice)-[:MEMBER_OF]->(dbs),
 (bob)-[:MEMBER_OF]->(dbs),
 (eve)-[:MEMBER_OF]->(graphs)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.group(['*'],['gender'],
  [{`*`:'count', age:'min'}, {`*`:'count'} ])
Table 1. Results
nodes relationships node relationship
[{""identity"":-45,""labels"":[""Person""],""properties"":{""gender"":""female"",""min_age"":28,""count_*"":2}}]
[{""identity"":-68,""start"":-45,""end"":-44,""type"":""MEMBER_OF"",""properties"":{""count_*"":3}},{""identity"":-69,""start"":-45,""end"":-46,""type"":""KNOWS"",""properties"":{""count_*"":2}}]
{""identity"":-45,""labels"":[""Person""],""properties"":{""gender"":""female"",""min_age"":28,""count_*"":2}}
{""identity"":-68,""start"":-45,""end"":-44,""type"":""MEMBER_OF"",""properties"":{""count_*"":3}}
[{""identity"":-45,""labels"":[""Person""],""properties"":{""gender"":""female"",""min_age"":28,""count_*"":2}}]
[{""identity"":-69,""start"":-45,""end"":-46,""type"":""KNOWS"",""properties"":{""count_*"":2}}]
{""identity"":-45,""labels"":[""Person""],""properties"":{""gender"":""female"",""min_age"":28,""count_*"":2}}
{""identity"":-69,""start"":-45,""end"":-46,""type"":""KNOWS"",""properties"":{""count_*"":2}}
[{""identity"":-46,""labels"":[""Person""],""properties"":{""gender"":""male"",""min_age"":42,""count_*"":1}}]
[{""identity"":-70,""start"":-46,""end"":-44,""type"":""MEMBER_OF"",""properties"":{""count_*"":1}}]
{""identity"":-46,""labels"":[""Person""],""properties"":{""gender"":""male"",""min_age"":42,""count_*"":1}}
{""identity"":-70,""start"":-46,""end"":-44,""type"":""MEMBER_OF"",""properties"":{""count_*"":1}}
[{""identity"":-44,""labels"":[""Forum""],""properties"":{""gender"":null,""count_*"":2}}]
[]
{""identity"":-44,""labels"":[""Forum""],""properties"":{""gender"":null,""count_*"":2}}
null
Note that this query doesn’t work in Neo4j Browser in ""Graph"" mode but only in ""Table"" mode (or also in cypher-shell) because, since Forum does not have the gender property, in node result there will be a ""gender"": null property which is not supported and returns a TypeError. Instead, the query below also works in ""Graph"" mode:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.group(
        ['Person'],['gender'],
        [{`*`:'count', kids:'sum', age:['min', 'max', 'avg'], gender:'collect'},
         {`*`:'count', since:['min', 'max']}]);
Larger Example
Setup
with [""US"",""DE"",""UK"",""FR"",""CA"",""BR"",""SE""] as tld
unwind range(1,1000) as id
create (u:User {id:id, age : id % 100, female: rand() < 0.5, name: ""Name ""+id, country:tld[toInteger(rand()*size(tld))]})
with collect(u) as users
unwind users as u
with u, users[toInteger(rand()*size(users))] as u2
where u <> u2
merge (u)-[:KNOWS]-(u2);
call apoc.nodes.group(['*'], ['country'])
yield node, relationship return *
call apoc.nodes.group(['*'], ['country'], null,
    {selfRels:false, orphans:false,
     filter:{`User.count_*.min`:130,`KNOWS.count_*.max`:200}})
yield node, relationship return *
To visualize this result in Neo4j Browser it’s useful to have a custom Graph Style Sheet (GRASS) that renders the grouped properties with some of the aggregations.
Css
Copy to Clipboard
node {
  diameter: 50px;
  color: #A5ABB6;
  border-color: #9AA1AC;
  border-width: 2px;
  text-color-internal: #FFFFFF;
  font-size: 10px;
}

relationship {
  color: #A5ABB6;
  shaft-width: 3px;
  font-size: 8px;
  padding: 3px;
  text-color-external: #000000;
  : ;
  : ;
}

 {
  : ;
  : ;
  : ;
  : ;
  : ;
}
View all (11 more lines)
Virtual Graph
Background Operations
Was this page helpful?"
https://neo4j.com/docs/apoc/5/background-operations;"Background Operations
In certain cases, it may be desirable to schedule execution of Cypher statements to run regularly in the background or asynchronously (""fire & forget""). This can also be useful in cloud environments that limit the runtime of statements (e.g. to 2 or 5 minutes) by scheduling execution in the background.
The apoc.periodic.* procedures provide such capabilities.
Background Jobs
Triggers
Graph Grouping
Background Jobs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/virtual/virtual-graph;"Virtual Graph
Contents
apoc.graph.fromDocument
apoc.graph.validateDocument
Virtual Graph Examples
Create a graph object (map) from information that’s passed in.
Its basic structure is: {name:""Name"",properties:{properties},nodes:[nodes],relationships:[relationships]}
Qualified Name Type
apoc.graph.from
apoc.graph.from(data,'name',{properties}) | creates a virtual graph object for later processing it tries its best to extract the graph information from the data you pass in
Procedure
apoc.graph.fromData
apoc.graph.fromData([nodes],[relationships],'name',{properties}) | creates a virtual graph object for later processing
Procedure
apoc.graph.fromPaths
apoc.graph.fromPaths([paths],'name',{properties}) - creates a virtual graph object for later processing
Procedure
apoc.graph.fromDB
apoc.graph.fromDB('name',{properties}) - creates a virtual graph object for later processing
Procedure
apoc.graph.fromCypher
apoc.graph.fromCypher('kernelTransaction',{params},'name',{properties}) - creates a virtual graph object for later processing
Procedure
apoc.graph.fromDocument
apoc.graph.fromDocument({json}, {config}) yield graph - transform JSON documents into graph structures
Procedure
apoc.graph.validateDocument
apoc.graph.validateDocument({json}, {config}) yield row - validates the json, return the result of the validation
Procedure
apoc.graph.fromDocument
The procedure apoc.graph.fromDocument transforms a JSON into a graph structure. It takes two arguments:
json, type Object: the JSON that must be transformed. Every entry must have an id and a type (name of Label), configurable via the config params.
The value can be a String, or Cypher Map or List of Maps.
config, type Map: the configuration params
Currently spatial and datetime properties are not handled yet. More advanced configuration for mapping the document is coming in future versions.
The config is composed by the following parameters:
write, type boolean: persist the graph otherwise return a Virtual Graph, default false
labelField, type String: the field name that became the label of the node, default type
idField, type String: the document field name that will become the id field of the created nodes (used for node resolution when you create relationships between nodes), default id
generateId, type boolean: in case of missing id-field value it generates a UUID for it, default true
defaultLabel, type String: in case of missing label-field value is uses the provided default label, default is empty
skipValidation, type boolean: in case you want skip the validation process into the apoc.graph.fromDocument procedure false
mappings, type Map<String, String>: you can use a JSON path like syntax for:
include properties
defining document properties as value objects, by prepending the @ to the property name
define custom/composite keys per Labels, by prepending the ! to the property name
Following an example of configuration with mappings:
Cypher
Copy to Clipboard
Run in Neo4j Browser
{
    write: false,
    idField: ""id"",
    mappings: {
      `$`: 'Person:Reader{*,@size}'
      `$.books`: 'Book{!title, released}'
    }
}
Lets describe the mappings:
$: 'Person:Reader{*,@size}': this means that at the root object will be applied two labels Person and Reader, all properties are included and the size property will be transformed into a value objects as you can see no id is specified so we will consider as id the property defined into the idField
$.books: 'Book{!title, released}': this means that at the books property of the root object will transformed into a node with label Book composed by two properties title considered as id (it’s marked with !) and released moreover the property will be connected to the parent node of type Person:Reader via the BOOKS relationship
Json
Copy to Clipboard
{
    ""id"": 1,
    ""type"": ""artist"",
    ""name"": ""Genesis"",
    ""members"": [""Tony Banks"", ""Mike Rutherford"", ""Phil Collins""],
    ""years"": [1967, 1998, 1999, 2000, 2006]
}
In this case it create one Node with labels Artist
It also accepts list of documents:
Json
Copy to Clipboard
[{
    ""id"": 1,
    ""type"": ""artist"",
    ""name"": ""Genesis"",
    ""members"": [""Tony Banks"", ""Mike Rutherford"", ""Phil Collins""],
    ""years"": [1967, 1998, 1999, 2000, 2006]
}, {
    ""id"": 2,
    ""type"": ""artist"",
    ""name"": ""Daft Punk"",
    ""members"": [""Guy-Manuel de Homem-Christo"", ""Thomas Bangalter.""],
    ""years"": [1987, 1993, 1999, 2004, 2008, 2011]
}]
In this case it create 2 Node with labels Artist
JSON Tree to graph:
Json
Copy to Clipboard
{
 ""id"": 1,
 ""type"": ""artist"",
 ""name"": ""Genesis"",
 ""albums"": [{
  ""type"": ""album"",
  ""id"": 1,
  ""producer"": ""Jonathan King"",
  ""title"": ""From Genesis to Revelation""
 }]
}
In this case it will create 2 Node, one Artist and one Album connected to each other by the ALBUMS Relationship
apoc.graph.validateDocument
The procedure apoc.graph.validateDocument validate the JSON and returns information about required fields violations.
It takes same arguments as apoc.graph.fromDocument
Virtual Graph Examples
We create a dataset for our examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:Actor {name:'Tom Hanks'})-[r:ACTED_IN {roles:'Forrest'}]->(m:Movie {title:'Forrest Gump'})
RETURN *
Cypher
Virtual graph from data
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)-[r]->(m) CALL apoc.graph.fromData([n,m],[r],'test',{answer:42})
YIELD graph
RETURN *
Cypher
Virtual graph from path
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (n)-[r]->(m) CALL apoc.graph.fromPath(path,'test',{answer:42})
YIELD graph
RETURN *
Cypher
Virtual graph from paths
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (n)-[r]->(m) CALL apoc.graph.fromPaths([path],'test',{answer:42})
YIELD graph
RETURN *
Cypher
Virtual graph from DB
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDB('test',{answer:42})
YIELD graph
RETURN *
Cypher
Virtual graph from Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromCypher('MATCH (n)-[r]->(m) RETURN *',null,'test',{answer:42})
YIELD graph
RETURN *
As a result we have a virtual graph object for later processing
Cypher
Virtual graph from JSON
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument(""{'id': 1,'type': 'artist','name':'Genesis','members': ['Tony Banks','Mike Rutherford','Phil Collins'],'years': [1967, 1998, 1999, 2000, 2006],'albums': [{'type': 'album','id': 1,'producer': 'Jonathan King','title': 'From Genesis to Revelation'}]}"", {write: false})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with labelField
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""id"":10,""myCustomType"":""labelArtist"",""name"":""Genesis"",""albums"":[{""myCustomType"":""labelAlbum"",""producer"":""Jonathan King"",""id"":20,""title"":""From Genesis to Revelation""}]}', {labelField: ""myCustomType""})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with labelField and idField
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""myCustomType"":""labelArtist"",""name"":""Genesis"",""myCustomId"":1,""albums"":[{""myCustomType"":""labelAlbum"",""producer"":""Jonathan King"",""myCustomId"":1,""title"":""From Genesis to Revelation""}]}',
{labelField: ""myCustomType"", idField: ""myCustomId""})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with mappings
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""id"":1,""type"":""Person"",""name"":""Andrea"",""sizes"":{""weight"":{""value"":70,""um"":""Kg""},""height"":{""value"":174,""um"":""cm""},""array"":[""foo"",""bar""]},""books"":[{""title"":""Flow My Tears, the Policeman Said"",""released"":1974},{""title"":""The man in the High Castle"",""released"":1962}]}',
{mappings:{`$`:""Person:Reader{*,@sizes}"",`$.books`:""Book{!title, released}""}})
yield graph
RETURN *
As a result we have a virtual graph with three nodes and two relationship:
In case this json:
Json
Copy to Clipboard
{
    ""id"": 1,
    ""type"": ""Person"",
    ""name"": ""Andrea"",
    ""sizes"": {
        ""weight"": {
            ""value"": 70,
            ""um"": ""Kg""
        },
        ""height"": {
            ""value"": 174,
            ""um"": ""cm""
        }
    }
}
You can manage the sizes property as value object so you manage it as follows:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.graph.validateDocument(<json>, {mappings: {`$`: ""Person{*,@sizes}""}})
So the procedure will create a node with the following properties:
Json
Copy to Clipboard
{
    ""id"": 1,
    ""type"": ""Person"",
    ""name"": ""Andrea"",
    ""sizes.weight.value"": 70,
    ""sizes.weight.um"": ""Kg"",
    ""sizes.height.value"": 174,
    ""sizes.height.um"": ""cm""
}
As specified you can also provide a set of value-object properties for a Label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.graph.validateDocument(<json>, {mappings: {`$`: ""Person{*,@sizes}""}})
You can also do a pre-validation over the document with the apoc.graph.validateDocument procedure that will return the record with invalid data.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.graph.validateDocument('[{""foo"": ""foo""}, {""bar"": ""bar"", ""id"": 1, ""type"": ""label""}, {""fooBar"": ""fooBar"", ""id"": 1}]')
or
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.graph.validateDocument([{foo: ""foo""}, {bar: ""bar"", id: 1, type: ""label""}, {fooBar: ""fooBar"", id: 1}])
Will display the following result:
Collapse Nodes
Graph Grouping
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromDB;"apoc.graph.fromDB
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromDB(name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given database.
Signature
None
Copy to Clipboard
apoc.graph.fromDB(name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDB(""all"", {});
Table 1. Results
graph
{name: ""all"", relationships: [[:ACTED_IN {roles: [""Neo""]}], [:ACTED_IN {roles: [""Trinity""]}], [:ACTED_IN {roles: [""Morpheus""]}], [:ACTED_IN {roles: [""Agent Smith""]}], [:DIRECTED], [:DIRECTED], [:PRODUCED]], nodes: [(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Keanu Reeves"", born: 1964}), (:Person {name: ""Carrie-Anne Moss"", born: 1967}), (:Person {name: ""Laurence Fishburne"", born: 1961}), (:Person {name: ""Hugo Weaving"", born: 1960}), (:Person {name: ""Lilly Wachowski"", born: 1967}), (:Person {name: ""Lana Wachowski"", born: 1965}), (:Person {name: ""Joel Silver"", born: 1952})], properties: {}}
More documentation of apoc.graph.fromDB
apoc.graph.fromCypher
apoc.graph.fromData
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromCypher;"apoc.graph.fromCypher
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromCypher(statement String, params Map<String, Any>, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given Cypher statement.
Signature
None
Copy to Clipboard
apoc.graph.fromCypher(kernelTransaction :: STRING?, params :: MAP?, name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
kernelTransaction
STRING?
null
params
MAP?
null
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromCypher(
  'MATCH (p:Person)-[r:DIRECTED]->(m:Movie) RETURN *',
  {},
  'directors',
  {description: ""Virtual Graph of all directorships""}
)
YIELD graph AS g
RETURN g;
Table 1. Results
g
{name: ""directors"", relationships: [[:DIRECTED], [:DIRECTED]], nodes: [(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Lilly Wachowski"", born: 1967}), (:Person {name: ""Lana Wachowski"", born: 1965})], properties: {description: ""Virtual Graph of all directorships""}}
More documentation of apoc.graph.fromCypher
apoc.graph.from
apoc.graph.fromDB
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.from;"apoc.graph.from
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.from(data Any, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Signature
None
Copy to Clipboard
apoc.graph.from(data :: ANY?, name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
data
ANY?
null
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
WITH collect(m) AS movies
CALL apoc.graph.from(movies, ""movies"", {})
YIELD graph AS g
RETURN g;
Table 1. Results
graph
{name: ""movies"", relationships: [], nodes: [(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999})], properties: {}}
More documentation of apoc.graph.from
apoc.graph
apoc.graph.fromCypher
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph;"apoc.graph
Qualified Name Type
apoc.graph.from
apoc.graph.from(data Any, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Procedure
apoc.graph.fromCypher
apoc.graph.fromCypher(statement String, params Map<String, Any>, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given Cypher statement.
Procedure
apoc.graph.fromData
apoc.graph.fromData(nodes [Node],rels [Rel], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Procedure
apoc.graph.fromDB
apoc.graph.fromDB(name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given database.
Procedure
apoc.graph.fromDocument
apoc.graph.fromDocument(json Any, config Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given JSON file.
Procedure
apoc.graph.fromPath
apoc.graph.fromPath(path Path, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given path.
Procedure
apoc.graph.fromPaths
apoc.graph.fromPaths(paths [Path], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given paths.
Procedure
apoc.graph.validateDocument
apoc.graph.validateDocument(json Any, config Map<String, Any>) - validates the JSON file and returns the result of the validation.
Procedure
apoc.export.json.query
apoc.graph.from
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.json.query;"apoc.export.json.query
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Procedure
apoc.export.json.query(statement String, file String, config Map<String, Any>) - exports the results from the Cypher statement to the provided JSON file.
Signature
None
Copy to Clipboard
apoc.export.json.query(query :: STRING?, file :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
query
STRING?
null
file
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
true
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
More documentation of apoc.export.json.query
apoc.export.json.graph
apoc.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/export/json;"Export to JSON
Contents
Available Procedures
Exporting to a file
Exporting to S3
Using S3 protocol
Memory Requirements
Exporting a stream
Examples
Export whole database to JSON
Export specified nodes and relationships to JSON
Export results of Cypher query to JSON
The export JSON procedures export data into a format that’s supported by JavaScript based visualisation tools. We may also want to export data into JSON format for importing into other tools or for general sharing of query results. The procedures described in this section support exporting to a file or as a stream.
The format used is jsonlines or JSONL, a streaming format that contains one JSON object per line, in our case a node or relationship.
Available Procedures
The table below describes the available procedures:
Qualified Name Type
apoc.export.json.all
apoc.export.json.all(file,config) - exports whole database as json to the provided file
Procedure
apoc.export.json.data
apoc.export.json.data(nodes,rels,file,config) - exports given nodes and relationships as json to the provided file
Procedure
apoc.export.json.graph
apoc.export.json.graph(graph,file,config) - exports given graph object as json to the provided file
Procedure
apoc.export.json.query
apoc.export.json.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as json to the provided file
Procedure
Table 1. Config
name type default description
writeNodeProperties
boolean
true
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
jsonFormat
enum[JSON_LINES, ARRAY_JSON, JSON, JSON_ID_AS_KEYS]
JSON_LINES
the format of the exported json
Table 2. jsonFormat types
name description
JSON_LINES
the data will be exported as JSON lines
ARRAY_JSON
the data will be exported as array of json: [{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}},…]
JSON
the data will be exported as json with two (array) fields nodes and rels: {""nodes"":[{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{…}},…],""rels"":[{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""since"":1993},""start"":{""id"":""0"",""labels"":[""User""]},""end"":{""id"":""1"",""labels"":[""User""]}},…]}
JSON_ID_AS_KEYS
the data will be exported as json with two (map) fields nodes and rels where the key is the neo4j internal id and the value is the graph entity value: {""nodes"":{""0"":{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{…},""1"":{…},""2"":{…},""rels"":{""0"":{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{…},""start"":{""id"":""0"",""labels"":[""User""]},""end"":{""id"":""1"",""labels"":[""User""]}}}}
The labels exported are ordered alphabetically. The output of labels() function is not sorted, use it in combination with apoc.coll.sort().
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting to S3
By default exporting to S3 is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, you can use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Memory Requirements
To support large uploads, the S3 uploading utility may use up to 2.25 GB of memory at a time. The actual usage will depend on the size of the upload, but will use a maximum of 2.25 GB.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Examples
This section includes examples showing how to use the export to JSON procedures. These examples are based on a people dataset, which can be imported by running the following Cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:User {
    name:'Adam', age:42, male:true, kids:['Sam','Anna','Grace'],
    born:localdatetime('2015185T19:32:24'),
    place:point({latitude: 13.1, longitude: 33.46789})
})
CREATE (b:User {name:'Jim', age:42})
CREATE (c:User {age:12})

CREATE (a)-[:KNOWS {since: 1993}]->(b)
The Neo4j Browser visualization below shows the imported graph:
Note that, to perform a correct Point serialization, it is not recommended to export a point with coordinates x,y and crs: 'wgs-84', for example point({x: 56.7, y: 12.78, crs: 'wgs-84'}). Otherwise, the point will be exported with longitude and latitude (and heigth) instead of x and y (and z)
Export whole database to JSON
The apoc.export.json.all procedure exports the whole database to a JSON file or as a stream.
Cypher
The following query exports the whole database to the file all.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.all(""all.json"",{useTypes:true})
Table 3. Results
file source format nodes relationships properties time rows batchSize batches done data
""all.json""
""database: nodes(3), rels(1)""
""json""
3
1
10
7
0
-1
0
TRUE
NULL
The contents of all.json are shown below:
Json
all.json
Copy to Clipboard
{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}
{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}
{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}
{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
Cypher
The following query returns a stream of the whole database in the data column
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.all(null,{useTypes:true, stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 4. Results
file nodes relationships properties data
NULL
3
1
10
""{\""type\"":\""node\"",\""id\"":\""0\"",\""labels\"":[\""User\""],\""properties\"":{\""born\"":\""2015-07-04T19:32:24\"",\""name\"":\""Adam\"",\""place\"":{\""crs\"":\""wgs-84\"",\""latitude\"":13.1,\""longitude\"":33.46789,\""height\"":null},\""age\"":42,\""male\"":true,\""kids\"":[\""Sam\"",\""Anna\"",\""Grace\""]}} {\""type\"":\""node\"",\""id\"":\""1\"",\""labels\"":[\""User\""],\""properties\"":{\""name\"":\""Jim\"",\""age\"":42}} {\""type\"":\""node\"",\""id\"":\""2\"",\""labels\"":[\""User\""],\""properties\"":{\""age\"":12}} {\""id\"":\""50000\"",\""type\"":\""relationship\"",\""label\"":\""KNOWS\"",\""properties\"":{\""since\"":1993},\""start\"":{\""id\"":\""0\"",\""labels\"":[\""User\""]},\""end\"":{\""id\"":\""1\"",\""labels\"":[\""User\""]}}""
Export specified nodes and relationships to JSON
The apoc.export.json.data procedure exports the specified nodes and relationships to a JSON file or as a stream.
Cypher
The following query exports all KNOWS relationships and User nodes to the file knows.json
Copy to Clipboard
Run in Neo4j Browser
MATCH (nod:User)
MATCH ()-[rels:KNOWS]->()
WITH collect(nod) as a, collect(rels) as b
CALL apoc.export.json.data(a, b, ""knows.json"", null)
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 5. Results
file source format nodes relationships properties time rows batchSize batches done data
""knows.json""
""data: nodes(3), rels(3)""
""json""
3
1
10
1
0
-1
0
TRUE
NULL
The contents of knows.json are shown below:
Json
knows.json
Copy to Clipboard
{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}
{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}
{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}
{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
Cypher
The following query return a stream of all KNOWS relationships and User nodes in the data column
Copy to Clipboard
Run in Neo4j Browser
MATCH (nod:User)
MATCH ()-[rels:KNOWS]->()
WITH collect(nod) as a, collect(rels) as b
CALL apoc.export.json.data(a, b, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 6. Results
file nodes relationships properties data
NULL
3
1
10
""{\""type\"":\""node\"",\""id\"":\""0\"",\""labels\"":[\""User\""],\""properties\"":{\""born\"":\""2015-07-04T19:32:24\"",\""name\"":\""Adam\"",\""place\"":{\""crs\"":\""wgs-84\"",\""latitude\"":13.1,\""longitude\"":33.46789 ,\""height\"":null},\""age\"":42,\""male\"":true,\""kids\"":[\""Sam\"",\""Anna\"",\""Grace\""]}} {\""type\"":\""node\"",\""id\"":\""1\"",\""labels\"":[\""User\""],\""properties\"":{\""name\"":\""Jim\"",\""age\"":42}} {\""type\"":\""node\"",\""id\"":\""2\"",\""labels\"":[\""User\""],\""properties\"":{\""age\"":12}} {\""id\"":\""50000\"",\""type\"":\""rel
Export results of Cypher query to JSON
The apoc.export.json.query procedure exports the results of a Cypher query to a JSON file or as a stream.
Cypher
The following query exports all User nodes with an age property greater than 10 to the file users-age.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.query(
    ""MATCH (u:User) WHERE u.age > $age return u"",
    ""users-age.json"",
    {params:{age:15}}
)
Table 7. Results
file source format nodes relationships properties time rows batchSize batches done data
""users-age.json""
""statement: cols(1)""
""json""
2
0
8
3
2
-1
0
TRUE
NULL
The contents of users-age.json are shown below:
Json
users-age.json
Copy to Clipboard
{""u"":{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}}
{""u"":{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
{""u"":{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}}
Cypher
The following query returns a stream of User nodes with an age property greater than 10 to the data column
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.query(
    ""MATCH (u:User) WHERE u.age > $age return u"",
    null,
    {params:{age:15}, stream: true}
)
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 8. Results
file nodes relationships properties data
NULL
2
0
8
""{\""u\"":{\""type\"":\""node\"",\""id\"":\""0\"",\""labels\"":[\""User\""],\""properties\"":{\""born\"":\""2015-07-04T19:32:24\"",\""name\"":\""Adam\"",\""place\"":{\""crs\"":\""wgs-84\"",\""latitude\"":13.1,\""longitude\"":33.46789,\""height\"":null},\""age\"":42,\""male\"":true,\""kids\"":[\""Sam\"",\""Anna\"",\""Grace\""]}}} {\""u\"":{\""type\"":\""node\"",\""id\"":\""1\"",\""labels\"":[\""User\""],\""properties\"":{\""name\"":\""Jim\"",\""age\"":42}}}""
Cypher
The following query exports a complex Cypher map structure to the file complex-cypher-structure.json
Copy to Clipboard
Run in Neo4j Browser
WITH ""RETURN {
 value:1,
    data:[
     10, 'car', null,
        point({ longitude: 56.7, latitude: 12.78 }),
        point({ longitude: 56.7, latitude: 12.78, height: 8 }),
        point({ x: 2.3, y: 4.5 }),
        point({ x: 2.3, y: 4.5, z: 2 }),
        date('2018-10-10'),
        datetime('2018-10-18T14:21:40.004Z'),
        localdatetime({ year:1984, week:10, dayOfWeek:3, hour:12, minute:31, second:14, millisecond: 645 }),
        {x:1, y:[1,2,3,{age:10}]}
    ]
} as key"" AS query
CALL apoc.export.json.query(query, ""complex-cypher-structure.json"")
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 9. Results
file source format nodes relationships properties time rows batchSize batches done data
""complex-cypher-structure.json""
""statement: cols(1)""
""json""
0
0
16
2
1
-1
0
TRUE
NULL
The contents of complex-cypher-structure.json are shown below:
Json
complex-cypher-structure.json
Copy to Clipboard
{""key"":{""data"":[10,""car"",null,{""crs"":""wgs-84"",""latitude"":12.78,""longitude"":56.7,""height"":null},{""crs"":""wgs-84-3d"",""latitude"":12.78,""longitude"":56.7,""height"":8.0},{""crs"":""cartesian"",""x"":2.3,""y"":4.5,""z"":null},{""crs"":""cartesian-3d"",""x"":2.3,""y"":4.5,""z"":2.0},""2018-10-10"",""2018-10-18T14:21:40.004Z"",""1984-03-07T12:31:14.645"",{""x"":1,""y"":[1,2,3,{""age"":10}]}],""value"":1}}
Cypher
The following query exports a list of User nodes with an age property is greater than 10 to the file users-list.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.query(
    ""MATCH (u:User) RETURN COLLECT(u) as list"",
    ""users-list.json"",
    {params:{age:10}}
)
Table 10. Results
file source format nodes relationships properties time rows batchSize batches done data
""users-list.json""
""statement: cols(1)""
""json""
3
0
9
1
1
-1
0
TRUE
NULL
The contents of users-list.json are shown below:
Json
users-list.json
Copy to Clipboard
{""list"":[{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}},{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}]}
Cypher
The following query exports the map representation of User nodes connected by a KNOWS relationship to the file users-map.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.query(
    ""MATCH (u:User)-[r:KNOWS]->(d:User) RETURN u {.*}, d {.*}, r {.*}"",
    ""users-map.json"",
    {params:{age:10}}
)
Table 11. Results
file source format nodes relationships properties time rows batchSize batches done data
""users-map.json""
""statement: cols(3)""
""json""
0
0
11
8
1
-1
0
TRUE
NULL
The contents of users-map.json are shown below:
Json
users-map.json
Copy to Clipboard
{""u"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]},""d"":{""name"":""Jim"",""age"":42},""r"":{""bffSince"":""P5M1DT12H"",""since"":1993}}
In this example we use the {.*} syntax when returning graph entities in the Cypher statement. This syntax returns a map representation of graph entities, meaning that only properties will be exported; labels and relationship types are excluded.
Cypher
The following query exports all KNOWS relationship, including start and end nodes and their properties, to the file knows-with-node-properties.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.query(
    ""MATCH p = (u:User)-[rel:KNOWS]->(u2:User) RETURN rel"",
    ""knows-with-node-properties.json"",
    {writeNodeProperties:true}
)
Table 12. Results
file source format nodes relationships properties time rows batchSize batches done data
""knows-with-node-properties.json""
""statement: cols(1)""
""json""
0
1
1
20
2
-1
0
TRUE
NULL
The contents of knows-with-node-properties.json are shown below:
Json
knows-with-node-properties.json
Copy to Clipboard
{""rel"":{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}}
You can also compress the files to export. See here for more information
Export to CSV
Export to Cypher Script
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.json.data;"apoc.export.json.data
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Procedure
apoc.export.json.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided JSON file.
Signature
None
Copy to Clipboard
apoc.export.json.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
file
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
true
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
More documentation of apoc.export.json.data
apoc.export.json.all
apoc.export.json.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.json.graph;"apoc.export.json.graph
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Procedure
apoc.export.json.graph(graph Map<String, Any>, file String , config Map<String, Any>) - exports the given graph to the provided JSON file.
Signature
None
Copy to Clipboard
apoc.export.json.graph(graph :: MAP?, file :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
graph
MAP?
null
file
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
true
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
More documentation of apoc.export.json.graph
apoc.export.json.data
apoc.export.json.query
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.json.all;"apoc.export.json.all
Contents
Signature
Input parameters
Config parameters
Output parameters
Exporting to a file
Exporting a stream
Usage Examples
Procedure
apoc.export.json.all(file String, config Map<String, Any>) - exports the full database to the provided JSON file.
Signature
None
Copy to Clipboard
apoc.export.json.all(file :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
writeNodeProperties
boolean
true
if true export properties too.
stream
boolean
false
stream the json directly to the client into the data field
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:User {
    name:'Adam', age:42, male:true, kids:['Sam','Anna','Grace'],
    born:localdatetime('2015185T19:32:24'),
    place:point({latitude: 13.1, longitude: 33.46789})
})
CREATE (b:User {name:'Jim', age:42})
CREATE (c:User {age:12})

CREATE (a)-[:KNOWS {since: 1993}]->(b);
The following query exports the whole database to the file all.json
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.all(""all.json"",{useTypes:true});
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""all.json""
""database: nodes(3), rels(1)""
""json""
3
1
10
7
0
-1
0
TRUE
NULL
The contents of all.json are shown below:
Json
all.json
Copy to Clipboard
{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}
{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}
{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}
{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
The following query returns a stream of the whole database in the data column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.json.all(null,{useTypes:true, stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 3. Results
file nodes relationships properties data
NULL
3
1
10
""{\""type\"":\""node\"",\""id\"":\""0\"",\""labels\"":[\""User\""],\""properties\"":{\""born\"":\""2015-07-04T19:32:24\"",\""name\"":\""Adam\"",\""place\"":{\""crs\"":\""wgs-84\"",\""latitude\"":33.46789,\""longitude\"":13.1,\""height\"":null},\""age\"":42,\""male\"":true,\""kids\"":[\""Sam\"",\""Anna\"",\""Grace\""]}} {\""type\"":\""node\"",\""id\"":\""1\"",\""labels\"":[\""User\""],\""properties\"":{\""name\"":\""Jim\"",\""age\"":42}} {\""type\"":\""node\"",\""id\"":\""2\"",\""labels\"":[\""User\""],\""properties\"":{\""age\"":12}} {\""id\"":\""50000\"",\""type\"":\""relationship\"",\""label\"":\""KNOWS\"",\""properties\"":{\""since\"":1993},\""start\"":{\""id\"":\""0\"",\""labels\"":[\""User\""]},\""end\"":{\""id\"":\""1\"",\""labels\"":[\""User\""]}}""
More documentation of apoc.export.json.all
apoc.export.graphml.query
apoc.export.json.data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.graphml.query;"apoc.export.graphml.query
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.graphml.query(statement String, file String, config Map<String, Any>) - exports the given nodes and relationships from the Cypher statement to the provided GraphML file.
Signature
None
Copy to Clipboard
apoc.export.graphml.query(query :: STRING?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
query
STRING?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The apoc.export.graphml.query procedure exports the results of a Cypher query to a CSV file or as a stream.
The following query exports all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-directed.graphml:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[directed:DIRECTED]->(movie)
      RETURN person, directed, movie"" AS query
CALL apoc.export.graphml.query(query, ""movies-directed.graphml"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-directed.graphml""
""statement: nodes(3), rels(2)""
""graphml""
3
2
7
2
5
-1
0
TRUE
NULL
The contents of movies-directed.csv are shown below:
Xml
movies-directed.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n193"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Lilly Wachowski</data></node>
<node id=""n194"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1965</data><data key=""name"">Lana Wachowski</data></node>
<edge id=""e271"" source=""n193"" target=""n188"" label=""DIRECTED""><data key=""label"">DIRECTED</data></edge>
<edge id=""e272"" source=""n194"" target=""n188"" label=""DIRECTED""><data key=""label"">DIRECTED</data></edge>
</graph>
</graphml>
The following query returns a stream of all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[directed:DIRECTED]->(movie)
      RETURN person, directed, movie"" AS query
CALL apoc.export.graphml.query(query, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 2. Results
file nodes relationships properties data
NULL
3
2
7
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/\""""
          =/// /////\"""">
   
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       DIRECTED
     
     
       DIRECTED
     
   
 
  ""
View all (187 more lines)
More documentation of apoc.export.graphml.query
apoc.export.graphml.graph
apoc.export.json.all
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.graphml.graph;"apoc.export.graphml.graph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.graphml.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided GraphML file.
Signature
None
Copy to Clipboard
apoc.export.graphml.graph(graph :: MAP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
graph
MAP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
See here for more documentation of apoc.export.graphml.graph.
apoc.export.graphml.data
apoc.export.graphml.query
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.graphml.data;"apoc.export.graphml.data
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.graphml.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided GraphML file.
Signature
None
Copy to Clipboard
apoc.export.graphml.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The apoc.export.graphml.data procedure exports the specified nodes and relationships to a CSV file or as a stream.
The following query exports all nodes with the :Person label with a name property that starts with L to the file movies-l.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.name STARTS WITH ""L""
WITH collect(person) AS people
CALL apoc.export.graphml.data(people, [], ""movies-l.graphml"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-l.csv""
""data: nodes(3), rels(0)""
""csv""
3
0
6
2
3
20000
1
TRUE
NULL
Xml
movies-l.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
<node id=""n193"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Lilly Wachowski</data></node>
<node id=""n194"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1965</data><data key=""name"">Lana Wachowski</data></node>
</graph>
</graphml>
The following query returns a stream of all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship in the data column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.graphml.data(people + movies, actedInRels, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 2. Results
file nodes relationships properties data
NULL
5
4
15
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/\""""
 =/// /////\"""">
   
   
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1964
       Keanu Reeves
     
     
       :Person
       1967
       Carrie-Anne Moss
     
     
       :Person
       1961
       Laurence Fishburne
     
     
       :Person
       1960
       Hugo Weaving
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       :Person
       1952
       Joel Silver
     
     
       ACTED_IN
       [\""Neo\""]
     
     
       ACTED_IN
       [\""Trinity\""]
     
     
       ACTED_IN
       [\""Morpheus\""]
     
     
       ACTED_IN
       [\""Agent Smith\""]
     
     
       DIRECTED
     
     
       DIRECTED
     
     
       PRODUCED
     
   
 ""
View all (416 more lines)
More documentation of apoc.export.graphml.data
apoc.export.graphml.all
apoc.export.graphml.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.graphml.all;"apoc.export.graphml.all
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.graphml.all(file String, config Map<String, Any>) - exports the full database to the provided GraphML file.
Signature
None
Copy to Clipboard
apoc.export.graphml.all(file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The apoc.export.graphml.all procedure exports the whole database to a GraphML file or as a stream.
The following query exports the whole database to the file movies.graphml:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.graphml.all(""movies.graphml"", {})
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""database: nodes(8), rels(7)""
""graphml""
8
7
21
4
15
-1
0
TRUE
NULL
Xml
movies.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""roles"" for=""edge"" attr.name=""roles""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n189"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1964</data><data key=""name"">Keanu Reeves</data></node>
<node id=""n190"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Carrie-Anne Moss</data></node>
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
:Person1960</data><data key=""name"">Hugo Weaving</data></node>
:Person1967</data><data key=""name"">Lilly Wachowski</data></node>
:Person1965</data><data key=""name"">Lana Wachowski</data></node>
:Person1952</data><data key=""name"">Joel Silver</data></node>
ACTED_IN</data><data key=""roles"">[""Neo""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Trinity""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Morpheus""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Agent Smith""]</data></edge>
DIRECTED</data></edge>
DIRECTED</data></edge>
PRODUCED</data></edge>
View all (14 more lines)
The following query returns a stream of the whole database in the data column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.graphml.all(null, {stream:true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 2. Results
file nodes relationships properties data
NULL
8
7
21
Xml
Copy to Clipboard
""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>
 <graphml xmlns=""\""http://graphml.graphdrawing.org/xmlns\""""
          xmlns:xsi=""\""http://www.w3.org/2001/\""""
          =/// /////\"""">
   
   
   
   
   
   
   
   
   
     
       :Movie
       The Matrix
       Welcome to the Real World
       1999
     
     
       :Person
       1964
       Keanu Reeves
     
     
       :Person
       1967
       Carrie-Anne Moss
     
     
       :Person
       1961
       Laurence Fishburne
     
     
       :Person
       1960
       Hugo Weaving
     
     
       :Person
       1967
       Lilly Wachowski
     
     
       :Person
       1965
       Lana Wachowski
     
     
       :Person
       1952
       Joel Silver
     
     
       ACTED_IN
       [\""Neo\""]
     
     
       ACTED_IN
       [\""Trinity\""]
     
     
       ACTED_IN
       [\""Morpheus\""]
     
     
       ACTED_IN
       [\""Agent Smith\""]
     
     
       DIRECTED
     
     
       DIRECTED
     
     
       PRODUCED
     
   
 
  ""
View all (416 more lines)
More documentation of apoc.export.graphml.all
apoc.export.cypher.schema
apoc.export.graphml.data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.cypher.schema;"apoc.export.cypher.schema
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.cypher.schema(file String, config Map<String, Any>) - exports all schema indexes and constraints to Cypher statements.
Signature
None
Copy to Clipboard
apoc.export.cypher.schema(file =  :: STRING?, config = {} :: MAP?) :: (file :: STRING?, batches :: INTEGER?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, cypherStatements :: STRING?, nodeStatements :: STRING?, relationshipStatements :: STRING?, schemaStatements :: STRING?, cleanupStatements :: STRING?)
Input parameters
Name Type Default
file
STRING?
config
MAP?
{}
Output parameters
Name Type
file
STRING?
batches
INTEGER?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
cypherStatements
STRING?
nodeStatements
STRING?
relationshipStatements
STRING?
schemaStatements
STRING?
cleanupStatements
STRING?
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT personName FOR (person:Person)
REQUIRE person.name IS UNIQUE;

CREATE CONSTRAINT userId FOR (user:User)
REQUIRE user.id IS UNIQUE;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.cypher.schema()
YIELD format, time, cypherStatements
RETURN format, time, cypherStatements;
Table 1. Results
format time cypherStatements
""cypher""
1
"":begin CREATE CONSTRAINT FOR (node:Person) REQUIRE (node.name) IS UNIQUE; CREATE CONSTRAINT FOR (node:User) REQUIRE (node.id) IS UNIQUE; :commit CALL db.awaitIndexes(300); ""
More documentation of apoc.export.cypher.schema
apoc.export.cypher.query
apoc.export.graphml.all
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/compression;"To compress a file through an export procedure, you can pass in config parameter the value compression: COMPRESSION_TYPE, where COMPRESSION_TYPE can be BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4 or FRAMED_SNAPPY. By default is NONE, that is without compression.
Note that to compress a file, you have to specify both the base file extension and the compression extension, for example to export a test.csv you can write test.csv.gz, or test.csv.bz2 or whatever. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""test.csv.gz"", {compression: ""GZIP""})
This works also with a multi-file export, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""testBulk.csv.zz"",{compression: ""DEFLATE"", bulkImport: true, separateHeader: true, delim: ';'})
with a series of testBulk.<nodes/relationships>.<label/rel>.csv.zz files.
Moreover, you can use it with a file split into batches:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(null, {compression: 'DEFLATE',stream:true,batchSize:2,useOptimizations:{unwindBatchSize:2}})
YIELD data RETURN data
Table 1. Results
data
compressed byte array
compressed byte array
compressed byte array
Was this page helpful?"
https://neo4j.com/docs/apoc/5/export/csv;"Export to CSV
Contents
Available Procedures
Exporting to a file
Exporting to S3
Using S3 protocol
Memory Requirements
Exporting a stream
Examples
Export whole database to CSV
Export specified nodes and relationships to CSV
Export results of Cypher query to CSV
Configuration parameters
The export CSV procedures export data into a format more supported by Data Science libraries in the Python and R ecosystems. We may also want to export data into JSON format for importing into other tools or for general sharing of query results. The procedures described in this section support exporting to a file or as a stream.
For apoc.export.csv.all, apoc.export.csv.data and apoc.export.csv.graph, nodes and relationships properties are ordered alphabetically, using the following structure:
_id,_labels,<list_nodes_properties_naturally_sorted>,_start,_end,_type,<list_rel_properties_naturally_sorted>.
For a graph containing node properties age, city, kids, male, name, and street and containing relationship propeties bar and foo, we’d have the following:
_id,_labels,age,city,kids,male,name,street,_start,_end,_type,bar,foo
Labels exported are ordered alphabetically. The output of labels() function is not sorted, use it in combination with apoc.coll.sort().
Note that, to perform a correct Point serialization, it is not recommended to export a point with coordinates x,y and crs: 'wgs-84', for example point({x: 56.7, y: 12.78, crs: 'wgs-84'}). Otherwise, the point will be exported with longitude and latitude (and height) instead of x and y (and z)
Available Procedures
The table below describes the available procedures:
Qualified Name Type
apoc.export.csv.all
apoc.export.csv.all(file,config) - exports whole database as csv to the provided file
Procedure
apoc.export.csv.data
apoc.export.csv.data(nodes,rels,file,config) - exports given nodes and relationships as csv to the provided file
Procedure
apoc.export.csv.graph
apoc.export.csv.graph(graph,file,config) - exports given graph object as csv to the provided file
Procedure
apoc.export.csv.query
apoc.export.csv.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as csv to the provided file
Procedure
Exporting to a file
By default exporting to the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Export files are written to the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to write to an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.io.FileNotFoundException: /path/to/neo4j/import/tmp/fileName (No such file or directory)
We can enable writing to anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to write anywhere on the file system, so be sure that this is your intention before setting this property.
Exporting to S3
By default exporting to S3 is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we try to use any of the export procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Export to files not enabled, please set apoc.export.file.enabled=true in your apoc.conf. Otherwise, if you are running in a cloud environment without filesystem access, you can use the {stream:true} config and null as a 'file' parameter to stream the export back to your client.
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Memory Requirements
To support large uploads, the S3 uploading utility may use up to 2.25 GB of memory at a time. The actual usage will depend on the size of the upload, but will use a maximum of 2.25 GB.
Exporting a stream
If we don’t want to export to a file, we can stream results back in the data column instead by passing a file name of null and providing the stream:true config.
Examples
This section includes examples showing how to use the export to CSV procedures. These examples are based on a movies dataset, which can be imported by running the following Cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Export whole database to CSV
The apoc.export.csv.all procedure exports the whole database to a CSV file or as a stream.
Cypher
The following query exports the whole database to the file movies.csv
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""movies.csv"", {})
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.csv""
""database: nodes(8), rels(7)""
""csv""
8
7
21
39
15
20000
1
TRUE
NULL
The contents of movies.csv are shown below:
Csv
movies.csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""released"",""tagline"",""title"",""_start"",""_end"",""_type"",""roles""
""188"","":Movie"","""","""",""1999"",""Welcome to the Real World"",""The Matrix"",,,,
""189"","":Person"",""1964"",""Keanu Reeves"","""","""","""",,,,
""190"","":Person"",""1967"",""Carrie-Anne Moss"","""","""","""",,,,
""191"","":Person"",""1961"",""Laurence Fishburne"","""","""","""",,,,
""192"","":Person"",""1960"",""Hugo Weaving"","""","""","""",,,,
""193"","":Person"",""1967"",""Lilly Wachowski"","""","""","""",,,,
""194"","":Person"",""1965"",""Lana Wachowski"","""","""","""",,,,
""195"","":Person"",""1952"",""Joel Silver"","""","""","""",,,,
,,,,,,,""189"",""188"",""ACTED_IN"",""[""""Neo""""]""
,,,,,,,""190"",""188"",""ACTED_IN"",""[""""Trinity""""]""
,,,,,,,""191"",""188"",""ACTED_IN"",""[""""Morpheus""""]""
,,,,,,,""192"",""188"",""ACTED_IN"",""[""""Agent Smith""""]""
,,,,,,,""193"",""188"",""DIRECTED"",""""
,,,,,,,""194"",""188"",""DIRECTED"",""""
,,,,,,,""195"",""188"",""PRODUCED"",""""
Cypher
The following query returns a stream of the whole database in the data column
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(null, {stream:true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 2. Results
file nodes relationships properties data
NULL
8
7
21
""\""_id\"",\""_labels\"",\""born\"",\""name\"",\""released\"",\""tagline\"",\""title\"",\""_start\"",\""_end\"",\""_type\"",\""roles\"" \""188\"",\"":Movie\"",\""\"",\""\"",\""1999\"",\""Welcome to the Real World\"",\""The Matrix\"",,,, \""189\"",\"":Person\"",\""1964\"",\""Keanu Reeves\"",\""\"",\""\"",\""\"",,,, \""190\"",\"":Person\"",\""1967\"",\""Carrie-Anne Moss\"",\""\"",\""\"",\""\"",,,, \""191\"",\"":Person\"",\""1961\"",\""Laurence Fishburne\"",\""\"",\""\"",\""\"",,,, \""192\"",\"":Person\"",\""1960\"",\""Hugo Weaving\"",\""\"",\""\"",\""\"",,,, \""193\"",\"":Person\"",\""1967\"",\""Lilly Wachowski\"",\""\"",\""\"",\""\"",,,, \""194\"",\"":Person\"",\""1965\"",\""Lana Wachowski\"",\""\"",\""\"",\""\"",,,, \""195\"",\"":Person\"",\""1952\"",\""Joel Silver\"",\""\"",\""\"",\""\"",,,, ,,,,,,,\""189\"",\""188\"",\""ACTED_IN\"",\""[\""\""Neo\""\""]\"" ,,,,,,,\""190\"",\""188\"",\""ACTED_IN\"",\""[\""\""Trinity\""\""]\"" ,,,,,,,\""191\"",\""188\"",\""ACTED_IN\"",\""[\""\""Morpheus\""\""]\"" ,,,,,,,\""192\"",\""188\"",\""ACTED_IN\"",\""[\""\""Agent Smith\""\""]\"" ,,,,,,,\""193\"",\""188\"",\""DIRECTED\"",\""\"" ,,,,,,,\""194\"",\""188\"",\""DIRECTED\"",\""\"" ,,,,,,,\""195\"",\""188\"",\""PRODUCED\"",\""\"" ""
Export specified nodes and relationships to CSV
The apoc.export.csv.data procedure exports the specified nodes and relationships to a CSV file or as a stream.
Cypher
The following query exports all nodes with the :Person label with a name property that starts with L to the file movies-l.csv
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.name STARTS WITH ""L""
WITH collect(person) AS people
CALL apoc.export.csv.data(people, [], ""movies-l.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 3. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-l.csv""
""data: nodes(3), rels(0)""
""csv""
3
0
6
2
3
20000
1
TRUE
NULL
The contents of movies-l.csv are shown below:
Csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""_start"",""_end"",""_type""
""191"","":Person"",""1961"",""Laurence Fishburne"",,,
""193"","":Person"",""1967"",""Lilly Wachowski"",,,
""194"","":Person"",""1965"",""Lana Wachowski"",,,
Cypher
The following query exports all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-actedIn.csv
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.csv.data(people + movies, actedInRels, ""movies-actedIn.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 4. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-actedIn.csv""
""data: nodes(5), rels(4)""
""csv""
5
4
15
2
9
20000
1
TRUE
NULL
The contents of movies-actedIn.csv are shown below:
Csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""released"",""tagline"",""title"",""_start"",""_end"",""_type"",""roles""
""189"","":Person"",""1964"",""Keanu Reeves"","""","""","""",,,,
""190"","":Person"",""1967"",""Carrie-Anne Moss"","""","""","""",,,,
""191"","":Person"",""1961"",""Laurence Fishburne"","""","""","""",,,,
""192"","":Person"",""1960"",""Hugo Weaving"","""","""","""",,,,
""188"","":Movie"","""","""",""1999"",""Welcome to the Real World"",""The Matrix"",,,,
,,,,,,,""189"",""188"",""ACTED_IN"",""[""""Neo""""]""
,,,,,,,""190"",""188"",""ACTED_IN"",""[""""Trinity""""]""
,,,,,,,""191"",""188"",""ACTED_IN"",""[""""Morpheus""""]""
,,,,,,,""192"",""188"",""ACTED_IN"",""[""""Agent Smith""""]""
Cypher
The following query returns a stream of all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship in the data column
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.csv.data(people + movies, actedInRels, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 5. Results
file nodes relationships properties data
NULL
5
4
15
""\""_id\"",\""_labels\"",\""born\"",\""name\"",\""released\"",\""tagline\"",\""title\"",\""_start\"",\""_end\"",\""_type\"",\""roles\"" \""190\"",\"":Person\"",\""1967\"",\""Carrie-Anne Moss\"",\""\"",\""\"",\""\"",,,, \""189\"",\"":Person\"",\""1964\"",\""Keanu Reeves\"",\""\"",\""\"",\""\"",,,, \""191\"",\"":Person\"",\""1961\"",\""Laurence Fishburne\"",\""\"",\""\"",\""\"",,,, \""192\"",\"":Person\"",\""1960\"",\""Hugo Weaving\"",\""\"",\""\"",\""\"",,,, \""188\"",\"":Movie\"",\""\"",\""\"",\""1999\"",\""Welcome to the Real World\"",\""The Matrix\"",,,, ,,,,,,,\""189\"",\""188\"",\""ACTED_IN\"",\""[\""\""Neo\""\""]\"" ,,,,,,,\""190\"",\""188\"",\""ACTED_IN\"",\""[\""\""Trinity\""\""]\"" ,,,,,,,\""191\"",\""188\"",\""ACTED_IN\"",\""[\""\""Morpheus\""\""]\"" ,,,,,,,\""192\"",\""188\"",\""ACTED_IN\"",\""[\""\""Agent Smith\""\""]\"" ""
Export results of Cypher query to CSV
The apoc.export.csv.query procedure exports the results of a Cypher query to a CSV file or as a stream.
Cypher
The following query exports all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-directed.csv
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[:DIRECTED]->(movie)
      RETURN person.name AS name, person.born AS born,
             movie.title AS title, movie.tagline AS tagline, movie.released AS released"" AS query
CALL apoc.export.csv.query(query, ""movies-directed.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 6. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-directed.csv""
""statement: cols(5)""
""csv""
0
0
10
3
2
20000
1
TRUE
NULL
The contents of movies-directed.csv are shown below:
Csv
Copy to Clipboard
""name"",""born"",""role"",""title"",""tagline"",""released""
""Lilly Wachowski"",""1967"","""",""The Matrix"",""Welcome to the Real World"",""1999""
""Lana Wachowski"",""1965"","""",""The Matrix"",""Welcome to the Real World"",""1999""
Cypher
The following query returns a stream of all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[:DIRECTED]->(movie)
      RETURN person.name AS name, person.born AS born,
             movie.title AS title, movie.tagline AS tagline, movie.released AS released"" AS query
CALL apoc.export.csv.query(query, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 7. Results
file nodes relationships properties data
NULL
0
0
10
""\""name\"",\""born\"",\""title\"",\""tagline\"",\""released\"" \""Lilly Wachowski\"",\""1967\"",\""The Matrix\"",\""Welcome to the Real World\"",\""1999\"" \""Lana Wachowski\"",\""1965\"",\""The Matrix\"",\""Welcome to the Real World\"",\""1999\"" ""
You can also compress the files to export. See here for more information
When the config bulkImport is enable it create a list of file that can be used for Neo4j Bulk Import.
This config can be used only with apoc.export.csv.all and apoc.export.csv.graph
All file create are named as follow:
Nodes file are construct with the name of the input file append with .nodes.[LABEL_NAME].csv
Rel file are construct with the name of the input file append with .relationships.[TYPE_NAME].csv
If Node or Relationship have more than one Label/Type it will create one file for Label/Type.
Configuration parameters
The procedures support the following config parameters:
Table 8. configuration options
param default description
batchSize
20000
The batch size.
delim
"",""
The delimiter character of the CSV file.
arrayDelim
"";""
The delimiter character used for arrays (used in the bulk import).
quotes
'always'
Quote-characters used for CSV, possible values are:
* none: No quotes are added. * always: Quotes are added around all values. * ifNeeded: Applies quotes to strings only when necessary.
useTypes
false
Add the types on to the file header.
bulkImport
true
Create files for Neo4j Admin import.
timeoutSeconds
100
The maximum time in seconds the query should run before timing out.
separateHeader
false
Create two files: one for the header and one for the data.
streamStatements
false
Batch the results across multiple rows by configuring the batchSize config.
stream
false
Equivalent to the streamStatements config.
Quotes config example
It is possible to export the graph to a csv file using different quoting strategies.
The following queries are executed on a graph containing one node:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Quote {name: 'foo,bar,baz', array:[""a"",""b"",""c""], other: 123})
Exporting without quotes
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""fileNoQuote.csv"", {quotes: 'none'})
The following CSV file is returned:
Csv
fileNoQuote.csv
Copy to Clipboard
_id,_labels,array,name,other,_start,_end,_type
5,:Quote,[""a"",""b"",""c""],foo,bar,baz,123,,,
Exporting with quotes
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""fileAlwaysQuote.csv"", {quotes: 'always'})
The following CSV file is returned:
Csv
fileAlwaysQuote.csv
Copy to Clipboard
""_id"",""_labels"",""array"",""name"",""other"",""_start"",""_end"",""_type""
""5"","":Quote"",""[""""a"""",""""b"""",""""c""""]"",""foo,bar,baz"",""123"",,,
Exporting with quotes when needed
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""fileIfNeededQuote.csv"", {quotes: 'ifNeeded'})
The following CSV file is returned:
Csv
fileIfNeededQuote.csv
Copy to Clipboard
_id,_labels,array,name,other,_start,_end,_type
5,:Quote,""[""a"",""b"",""c""]"",""foo,bar,baz"",123,,,
Export
Export to JSON
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.csv.all;"apoc.export.csv.all
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.csv.all(file String, config Map<String, Any>) - exports the full database to the provided CSV file.
Signature
None
Copy to Clipboard
apoc.export.csv.all(file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.csv.all procedure exports the whole database to a CSV file or as a stream.
The following query exports the whole database to the file movies.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(""movies.csv"", {})
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.csv""
""database: nodes(8), rels(7)""
""csv""
8
7
21
39
15
20000
1
TRUE
NULL
The contents of movies.csv are shown below:
Csv
movies.csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""released"",""tagline"",""title"",""_start"",""_end"",""_type"",""roles""
""188"","":Movie"","""","""",""1999"",""Welcome to the Real World"",""The Matrix"",,,,
""189"","":Person"",""1964"",""Keanu Reeves"","""","""","""",,,,
""190"","":Person"",""1967"",""Carrie-Anne Moss"","""","""","""",,,,
""191"","":Person"",""1961"",""Laurence Fishburne"","""","""","""",,,,
""192"","":Person"",""1960"",""Hugo Weaving"","""","""","""",,,,
""193"","":Person"",""1967"",""Lilly Wachowski"","""","""","""",,,,
""194"","":Person"",""1965"",""Lana Wachowski"","""","""","""",,,,
""195"","":Person"",""1952"",""Joel Silver"","""","""","""",,,,
,,,,,,,""189"",""188"",""ACTED_IN"",""[""""Neo""""]""
,,,,,,,""190"",""188"",""ACTED_IN"",""[""""Trinity""""]""
,,,,,,,""191"",""188"",""ACTED_IN"",""[""""Morpheus""""]""
,,,,,,,""192"",""188"",""ACTED_IN"",""[""""Agent Smith""""]""
,,,,,,,""193"",""188"",""DIRECTED"",""""
,,,,,,,""194"",""188"",""DIRECTED"",""""
,,,,,,,""195"",""188"",""PRODUCED"",""""
The following query returns a stream of the whole database in the data column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all(null, {stream:true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 2. Results
file nodes relationships properties data
NULL
8
7
21
""\""_id\"",\""_labels\"",\""born\"",\""name\"",\""released\"",\""tagline\"",\""title\"",\""_start\"",\""_end\"",\""_type\"",\""roles\"" \""188\"",\"":Movie\"",\""\"",\""\"",\""1999\"",\""Welcome to the Real World\"",\""The Matrix\"",,,, \""189\"",\"":Person\"",\""1964\"",\""Keanu Reeves\"",\""\"",\""\"",\""\"",,,, \""190\"",\"":Person\"",\""1967\"",\""Carrie-Anne Moss\"",\""\"",\""\"",\""\"",,,, \""191\"",\"":Person\"",\""1961\"",\""Laurence Fishburne\"",\""\"",\""\"",\""\"",,,, \""192\"",\"":Person\"",\""1960\"",\""Hugo Weaving\"",\""\"",\""\"",\""\"",,,, \""193\"",\"":Person\"",\""1967\"",\""Lilly Wachowski\"",\""\"",\""\"",\""\"",,,, \""194\"",\"":Person\"",\""1965\"",\""Lana Wachowski\"",\""\"",\""\"",\""\"",,,, \""195\"",\"":Person\"",\""1952\"",\""Joel Silver\"",\""\"",\""\"",\""\"",,,, ,,,,,,,\""189\"",\""188\"",\""ACTED_IN\"",\""[\""\""Neo\""\""]\"" ,,,,,,,\""190\"",\""188\"",\""ACTED_IN\"",\""[\""\""Trinity\""\""]\"" ,,,,,,,\""191\"",\""188\"",\""ACTED_IN\"",\""[\""\""Morpheus\""\""]\"" ,,,,,,,\""192\"",\""188\"",\""ACTED_IN\"",\""[\""\""Agent Smith\""\""]\"" ,,,,,,,\""193\"",\""188\"",\""DIRECTED\"",\""\"" ,,,,,,,\""194\"",\""188\"",\""DIRECTED\"",\""\"" ,,,,,,,\""195\"",\""188\"",\""PRODUCED\"",\""\"" ""
You can use the configuration sampling (default: false). With this config, the apoc.export.csv.all procedure uses the apoc.meta.nodeTypeProperties and the apoc.meta.relTypeProperties procedures under the hood to get the property types. You can customize the configuration of these 2 apoc.meta.* procedure, using the samplingConfig: MAP configuration, to limit the number of nodes/rels to analyze.
So you can execute with the following data set:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:User:Sample {`last:Name`:'Galilei'}), (:User:Sample {address:'Universe'}),
    (:User:Sample {foo:'bar'})-[:KNOWS {one: 'two', three: 'four'}]->(:User:Sample {baz:'baa', foo: true})
Combined with the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.csv.all('movies.csv', {sampling: true, samplingConfig: {sample: 1}})
Table 3. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.csv""
""database: nodes(4), rels(1)""
""csv""
4
1
3
4
5
20000
1
TRUE
NULL
Execution of the above query would output content similar to that below (result could change depending on the sample):
Csv
movies.csv
Copy to Clipboard
""_id"",""_labels"",""baz"",""foo"",""_start"",""_end"",""_type""
""0"","":Sample:User"","""","""",,,
""1"","":Sample:User"","""","""",,,
""2"","":Sample:User"","""",""bar"",,,
""3"","":Sample:User"",""baa"",""true"",,,
,,,,""2"",""3"",""KNOWS""
More documentation of apoc.export.csv.all
apoc.export
apoc.export.csv.data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export;"apoc.export
Qualified Name Type
apoc.export.arrow.all
apoc.export.arrow.all(file String, config Map<String, Any>) - exports the full database database as an arrow file.
Procedure
apoc.export.arrow.graph
apoc.export.arrow.graph(file String, graph Any, config Map<String, Any>) - exports the given graph as an arrow file.
Procedure
apoc.export.arrow.query
apoc.export.arrow.query(file String, query String, config Map<String, Any>) - exports the results from the given Cypher query as an arrow file.
Procedure
apoc.export.arrow.stream.all
apoc.export.arrow.stream.all(config Map<String, Any>) - exports the full database as an arrow byte array.
Procedure
apoc.export.arrow.stream.graph
apoc.export.arrow.stream.graph(graph Any, config Map<String, Any>) - exports the given graph as an arrow byte array.
Procedure
apoc.export.arrow.stream.query
apoc.export.arrow.stream.query(query String, config Map<String, Any>) - exports the given Cypher query as an arrow byte array.
Procedure
apoc.export.csv.all
apoc.export.csv.all(file String, config Map<String, Any>) - exports the full database to the provided CSV file.
Procedure
apoc.export.csv.data
apoc.export.csv.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided CSV file.
Procedure
apoc.export.csv.graph
apoc.export.csv.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided CSV file.
Procedure
apoc.export.csv.query
apoc.export.csv.query(query String, file String, config Map<String, Any>) - exports the results from running the given Cypher query to the provided CSV file.
Procedure
apoc.export.cypher.all
apoc.export.cypher.all(file String, config Map<String, Any>) - exports the full database (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.data
apoc.export.cypher.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.graph
apoc.export.cypher.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.query
apoc.export.cypher.query(statement String, file String, config Map<String, Any>) - exports the nodes and relationships from the given Cypher query (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.schema
apoc.export.cypher.schema(file String, config Map<String, Any>) - exports all schema indexes and constraints to Cypher statements.
Procedure
apoc.export.graphml.all
apoc.export.graphml.all(file String, config Map<String, Any>) - exports the full database to the provided GraphML file.
Procedure
apoc.export.graphml.data
apoc.export.graphml.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided GraphML file.
Procedure
apoc.export.graphml.graph
apoc.export.graphml.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided GraphML file.
Procedure
apoc.export.graphml.query
apoc.export.graphml.query(statement String, file String, config Map<String, Any>) - exports the given nodes and relationships from the Cypher statement to the provided GraphML file.
Procedure
apoc.export.json.all
apoc.export.json.all(file String, config Map<String, Any>) - exports the full database to the provided JSON file.
Procedure
apoc.export.json.data
apoc.export.json.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided JSON file.
Procedure
apoc.export.json.graph
apoc.export.json.graph(graph Map<String, Any>, file String , config Map<String, Any>) - exports the given graph to the provided JSON file.
Procedure
apoc.export.json.query
apoc.export.json.query(statement String, file String, config Map<String, Any>) - exports the results from the Cypher statement to the provided JSON file.
Procedure
apoc.example.movies
apoc.export.csv.all
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.example/apoc.example.movies;"apoc.example.movies
Contents
Signature
Output parameters
Usage Examples
Procedure
apoc.example.movies()- seeds the database with the Neo4j movie dataset.
Signature
None
Copy to Clipboard
apoc.example.movies() :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.example.movies();
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.cypher""
""example movie database from themoviedb.org""
""cypher""
169
250
558
955
0
-1
0
TRUE
NULL
apoc.example
apoc.export
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.example;"apoc.example
Qualified Name Type
apoc.example.movies
apoc.example.movies()- seeds the database with the Neo4j movie dataset.
Procedure
apoc.do.when
apoc.example.movies
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.do/apoc.do.when;"apoc.do.when
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.do.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - runs the given read/write ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Signature
None
Copy to Clipboard
apoc.do.when(condition :: BOOLEAN?, ifQuery :: STRING?, elseQuery =  :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
condition
BOOLEAN?
null
ifQuery
STRING?
null
elseQuery
STRING?
params
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
The following will create a node with a name property of A, as per the ifQuery, because the predicate is true:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.when(true,
  'CREATE (a:Node{name:""A""}) RETURN a AS node',
  'CREATE (b:Node{name:""B""}) RETURN b AS node',
  {}
)
YIELD value
RETURN value.node AS node;
Table 1. Results
node
(:Node {name: ""A""})
The following will create a node with a name property of B, as per the elseQuery, because the predicate is false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.when(false,
  'CREATE (a:Node{name:""A""}) RETURN a AS node',
  'CREATE (b:Node{name:""B""}) RETURN b AS node',
  {}
)
YIELD value
RETURN value.node AS node;
Table 2. Results
node
(:Node {name: ""B""})
More documentation of apoc.do.when
apoc.do.case
apoc.example
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.do/apoc.do.case;"apoc.do.case
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.do.case(conditionals [Any], elseQuery String, params Map<String, Any>) - for each pair of conditional queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Signature
None
Copy to Clipboard
apoc.do.case(conditionals :: LIST? OF ANY?, elseQuery =  :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
conditionals
LIST? OF ANY?
null
elseQuery
STRING?
params
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
The following will create a node with a name property of B, because that’s the first of the conditionals to evaluate to true:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.case([
  false,
  'CREATE (a:Node{name:""A""}) RETURN a AS node',
  true,
  'CREATE (b:Node{name:""B""}) RETURN b AS node'
  ],
  'CREATE (c:Node{name:""C""}) RETURN c AS node',{})
YIELD value
RETURN value.node AS node;
Table 1. Results
node
(:Node {name: ""B""})
The following will create a node with a name property of C, as per the elseQuery, because all conditionals evaluate to false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.case([
  false,
  'CREATE (a:Node{name:""A""}) RETURN a AS node',
  false,
  'CREATE (b:Node{name:""B""}) RETURN b AS node'
  ],
  'CREATE (c:Node{name:""C""}) RETURN c AS node',{})
YIELD value
RETURN value.node AS node;
Table 2. Results
node
(:Node {name: ""C""})
More documentation of apoc.do.case
apoc.do
apoc.do.when
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.do;"apoc.do
Qualified Name Type
apoc.do.case
apoc.do.case(conditionals [Any], elseQuery String, params Map<String, Any>) - for each pair of conditional queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Procedure
apoc.do.when
apoc.do.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - runs the given read/write ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Procedure
apoc.diff.nodes
apoc.do.case
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.diff/apoc.diff.nodes;"apoc.diff.nodes
Contents
Signature
Input parameters
Usage Examples
Function
Signature
None
Copy to Clipboard
`apoc.diff.nodes (leftNode Node, rightNode Node)` - returns a list detailing the differences between the two given nodes.
Input parameters
Name Type Default
leftNode
NODE?
null
rightNode
NODE?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (joe:Person {name: ""Joe"", dateOfBirth: datetime(""1981-09-02"")})
MERGE (ryan:Person {name: ""Ryan"", twitter: ""@ryguyrg""});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (joe:Person {name: ""Joe""})
MATCH (ryan:Person {name: ""Ryan""})
RETURN apoc.diff.nodes(joe, ryan) AS output;
Table 1. Results
output
{leftOnly: {dateOfBirth: 1981-09-02T00:00Z}, inCommon: {}, different: {name: {left: ""Joe"", right: ""Ryan""}}, rightOnly: {twitter: ""@ryguyrg""}}
apoc.diff
apoc.do
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.diff;"apoc.diff
Qualified Name Type
apoc.diff.nodes
apoc.diff.nodes (leftNode Node, rightNode Node) - returns a list detailing the differences between the two given nodes.
Function
apoc.date.toYears
apoc.diff.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.toYears;"apoc.date.toYears
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.toYears(value Any, format String) - converts the given timestamp or the given date into a floating point representing years.
Signature
None
Copy to Clipboard
apoc.date.toYears(value :: ANY?, format = yyyy-MM-dd HH:mm:ss :: STRING?) :: (FLOAT?)
Input parameters
Name Type Default
value
ANY?
null
format
STRING?
yyyy-MM-dd HH:mm:ss
Usage Examples
The following converts a datetime in milliseconds to floating point years:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH datetime(""2020-11-05"").epochMillis AS datetime
RETURN apoc.date.toYears(datetime) AS years;
Table 1. Results
years
50.87945205479452
The following converts a date to floating point years:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.toYears(""2020-11-02"", ""YYYY-MM-dd"") AS years;
Table 2. Results
years
2020.027397260274
apoc.date.toISO8601
apoc.diff
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.toISO8601;"apoc.date.toISO8601
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.toISO8601(time Long, unit String) - returns a string representation of a specified time value in the ISO8601 format.
Signature
None
Copy to Clipboard
apoc.date.toISO8601(time :: INTEGER?, unit = ms :: STRING?) :: (STRING?)
Input parameters
Name Type Default
time
INTEGER?
null
unit
STRING?
ms
Usage Examples
The unit parameter supports the following values:
ms, milli, millis, milliseconds
s, second, seconds
m, minute, minutes
h, hour, hours
d, day, days
The following converts the current datetime in milliseconds to a date string in ISO8601 standard format:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.toISO8601(datetime().epochMillis, ""ms"") AS iso8601;
Table 1. Results
iso8601
""2020-11-05T14:21:58.179Z""
apoc.date.systemTimezone
apoc.date.toYears
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.systemTimezone;"apoc.date.systemTimezone
Contents
Signature
Usage Examples
Function
apoc.date.systemTimezone() - returns the display name of the system time zone (e.g. Europe/London).
Signature
None
Copy to Clipboard
apoc.date.systemTimezone() :: (STRING?)
Usage Examples
The following returns the system timezone where Neo4j is running:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.systemTimezone() AS timezone;
Table 1. Results
timezone
""Europe/London""
apoc.date.parse
apoc.date.toISO8601
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.parse;"apoc.date.parse
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.parse(time String, unit String, format String, timezone String) - parses the given date string from a specified format into the specified time unit.
Signature
None
Copy to Clipboard
apoc.date.parse(time :: STRING?, unit = ms :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone =  :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
time
STRING?
null
unit
STRING?
ms
format
STRING?
yyyy-MM-dd HH:mm:ss
timezone
STRING?
Usage Examples
The following converts a date string into epoch milliseconds:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.parse(""2020-11-04"", ""ms"", ""yyyy-MM-dd"") AS outputInMs;
Table 1. Results
outputInMs
1604448000000
apoc.date.fromISO8601
apoc.date.systemTimezone
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.fromISO8601;"apoc.date.fromISO8601
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.format(time Long, unit String, format String, timezone String) - returns a string representation of the time value. The time unit (default: ms), date format (default: ISO), and time zone (default: current time zone) can all be changed.
Signature
None
Copy to Clipboard
apoc.date.fromISO8601(time :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
time
STRING?
null
Usage Examples
The time parameter is a date string in the ISO8601 standard format
The following converts a date string in ISO 8601 format to epoch millis:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.fromISO8601('2020-11-04T12:21:33.000Z') AS outputInMs;
Table 1. Results
outputInMs
1604492493000
apoc.date.format
apoc.date.parse
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.format;"apoc.date.format
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.format(time Long, unit String, format String, timezone String) - returns a string representation of the time value. The time unit (default: ms), date format (default: ISO), and time zone (default: current time zone) can all be changed.
Signature
None
Copy to Clipboard
apoc.date.format(time :: INTEGER?, unit = ms :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone =  :: STRING?) :: (STRING?)
Input parameters
Name Type Default
time
INTEGER?
null
unit
STRING?
ms
format
STRING?
yyyy-MM-dd HH:mm:ss
timezone
STRING?
Usage Examples
The unit parameter supports the following values:
ms, milli, millis, milliseconds
s, second, seconds
m, minute, minutes
h, hour, hours
d, day, days
The format parameter supports values defined under Patterns for Formatting and Parsing of the Java DateTime formats.
The timezone parameter can be specified with GMT or database (text) name, as listed for timezones
The following converts a datetime in epoch millis to yyyy-MM-dd format:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH datetime(""2020-11-04T11:23:22"").epochMillis AS datetime
RETURN apoc.date.format(datetime, ""ms"", ""yyyy-MM-dd"") AS output;
Table 1. Results
output
""2020-11-04""
The following converts a GMT datetime in epoch millis to yyyy-MM-dd’T’HH:mm:ssz format, using the Australian/Sydney timezone:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH datetime(""2020-11-04T11:23:22+00:00"").epochMillis AS datetime
RETURN apoc.date.format(datetime, ""ms"", ""yyyy-MM-dd'T'HH:mm:ssz"", ""Australia/Sydney"") AS output;
Table 2. Results
output
""2020-11-04T22:23:22AEDT""
apoc.date.fields
apoc.date.fromISO8601
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.fields;"apoc.date.fields
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.fields(date String, pattern String) - splits the given date into fields returning a map containing the values of each field.
Signature
None
Copy to Clipboard
apoc.date.fields(date :: STRING?, pattern = yyyy-MM-dd HH:mm:ss :: STRING?) :: (MAP?)
Input parameters
Name Type Default
date
STRING?
null
pattern
STRING?
yyyy-MM-dd HH:mm:ss
Usage Examples
The date parameter is a date string in an ISO8601 standard format
The pattern parameter supports values defined under Patterns for Formatting and Parsing of the Java DateTime formats
The following returns the fields of a date:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.fields(""2020-11-04"", ""YYYY-MM-dd"") AS fields;
Table 1. Results
fields
{days: 4, zoneid: ""UTC"", months: 11}
The following returns the fields of a datetime:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.fields(""2020-11-04T10:30:21"", ""YYYY-MM-dd'T'HH:mm:ss"") AS fields;
Table 2. Results
fields
{hours: 10, seconds: 21, months: 11, minutes: 30, days: 4, zoneid: ""UTC""}
The following returns the fields of a datetime that contains a timezone:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.fields(""2020-11-04T10:30:21+01:00"", ""YYYY-MM-dd'T'HH:mm:ssz"") AS fields;
Table 3. Results
fields
{hours: 10, seconds: 21, months: 11, minutes: 30, days: 4, zoneid: ""+01:00""}
In version 3.4 Neo4j introduced temporal data types, which are the recommended way of representing dates in Neo4j. Fields of a temporal type can be retrieved using Cypher’s instance.field function. (e.g. datetime({epochMillis: dateInteger}).year) See the Cypher documentation for more details on the syntax.
If, however, you still need to convert timestamp formats, this procedure provides that functionality.
apoc.date.field
apoc.date.format
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.field;"apoc.date.field
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.field(time Long, unit String, timezone String) - returns the value of one field from the given date time.
Signature
None
Copy to Clipboard
apoc.date.field(time :: INTEGER?, unit = d :: STRING?, timezone = UTC :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
time
INTEGER?
null
unit
STRING?
d
timezone
STRING?
UTC
Usage Examples
The unit parameter supports the following values:
ms, milli, millis, milliseconds
s, second, seconds
m, minute, minutes
h, hour, hours
d, day, days
w, weekday, weekdays
month, months
year, years
The computed value will be in the unit specified by the unit parameter.
The following returns the hours of a datetime:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH datetime(""2020-11-04T10:30:00"").epochMillis AS datetime
RETURN apoc.date.field(datetime, ""hours"") AS hour;
Table 1. Results
hour
10
The following returns the weekday of a datetime:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH datetime(""2020-11-04T10:30:00"").epochMillis AS datetime
RETURN apoc.date.field(datetime, ""weekday"") AS weekday;
Table 2. Results
weekday
3
In version 3.4 Neo4j introduced temporal data types, which are the recommended way of representing dates in Neo4j. Fields of a temporal type can be retrieved using Cypher’s instance.field function. (e.g. datetime({epochMillis: dateInteger}).year) See the Cypher documentation for more details on the syntax.
If, however, you still need to convert timestamp formats, this procedure provides that functionality.
apoc.date.currentTimestamp
apoc.date.fields
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.currentTimestamp;"apoc.date.currentTimestamp
Contents
Signature
Usage Examples
Function
apoc.date.currentTimestamp() - returns the current Unix epoch timestamp in milliseconds.
Signature
None
Copy to Clipboard
apoc.date.currentTimestamp() :: (INTEGER?)
Usage Examples
The following returns the current timestamp in ms:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.currentTimestamp() AS outputInMs
RETURN outputinMs, datetime({epochMillis: output}) AS datetime;
Table 1. Results
outputinMs datetime
1604571467744
2020-11-05T10:17:47.744Z
The following returns the current timestamp before and after sleeping for 1000 ms:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.currentTimestamp() AS outputStart
CALL apoc.util.sleep(1000)
WITH outputStart, apoc.date.currentTimestamp() AS outputEnd
RETURN outputStart,
       datetime({epochMillis: outputStart}) AS datetimeStart,
       outputEnd,
       datetime({epochMillis: outputEnd}) AS datetimeEnd;
Table 2. Results
outputStart datetimeStart outputEnd datetimeEnd
1604571641430
2020-11-05T10:20:41.430Z
1604571642434
2020-11-05T10:20:42.434Z
apoc.date.convertFormat
apoc.date.field
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.convertFormat;"apoc.date.convertFormat
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.convertFormat(temporal String, currentFormat String, convertTo String) - converts a string of one type of date format into a string of another type of date format.
Signature
None
Copy to Clipboard
apoc.date.convertFormat(temporal :: STRING?, currentFormat :: STRING?, convertTo = yyyy-MM-dd :: STRING?) :: (STRING?)
Input parameters
Name Type Default
temporal
STRING?
null
currentFormat
STRING?
null
convertTo
STRING?
yyyy-MM-dd
Usage Examples
The currentFormat parameter supports the values specified under Patterns for Formatting and Parsing for the DateTimeFormatter.
The convertTo parameter supports Java formats or built-in formats.
The following converts a date in YYYY-MM-dd format to basic_date (yyyyMMdd) format:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.convertFormat(""2020-11-04"", ""date"", ""basic_date"") AS output;
Table 1. Results
output
""20201104""
The following converts a date in date_hour (yyyy-MM-dd’T’HH) format to date_hour_minute (yyyy-MM-dd’T’HH:mm) format:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.convertFormat(""2020-11-04T22"", ""date_hour"", ""date_hour_minute"") AS output;
Table 2. Results
output
""2020-11-04T22:00""
apoc.date.convert
apoc.date.currentTimestamp
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.convert;"apoc.date.convert
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.convert(time Long, unit String, toUnit String) - converts the given timestamp from one time unit into a timestamp of a different time unit.
Signature
None
Copy to Clipboard
apoc.date.convert(time :: INTEGER?, unit :: STRING?, toUnit :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
time
INTEGER?
null
unit
STRING?
null
toUnit
STRING?
null
Usage Examples
The unit and toUnit parameters support the following values:
ms, milli, millis, milliseconds
s, second, seconds
m, minute, minutes
h, hour, hours
d, day, days
The computed value will be in the unit specified by the unit parameter.
The following converts 30 minutes into seconds:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.convert(30, ""minutes"", ""seconds"") as outputInSeconds;
Table 1. Results
outputInSeconds
1800
The following converts the current datetime in epoch seconds into the number of days since 1st January 1970:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.convert(datetime().epochSeconds, ""seconds"", ""days"") as outputInDays;
Table 2. Results
outputInDays
18571
apoc.date.add
apoc.date.convertFormat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date/apoc.date.add;"apoc.date.add
Contents
Signature
Input parameters
Usage Examples
Function
apoc.date.add(time Long, unit String, addValue Integer, addUnit String) - adds a unit of specified time to the given timestamp.
Signature
None
Copy to Clipboard
apoc.date.add(time :: INTEGER?, unit :: STRING?, addValue :: INTEGER?, addUnit :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
time
INTEGER?
null
unit
STRING?
null
addValue
INTEGER?
null
addUnit
STRING?
null
Usage Examples
The unit and addUnit parameters support the following values:
ms, milli, millis, milliseconds
s, second, seconds
m, minute, minutes
h, hour, hours
d, day, days
The computed value will be in the unit specified by the unit parameter.
The following adds 10,000 milliseconds to the current datetime:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.add(datetime().epochMillis, ""ms"", 10000, ""ms"") AS output
RETURN outputinMs, datetime({epochMillis: output}) AS datetime;
Table 1. Results
outputinMs datetime
1604509597386
2020-11-04T17:06:37.386Z
The following adds 1 day to the current datetime:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.add(datetime().epochMillis, ""ms"", 1, ""day"") AS output
RETURN outputinMs, datetime({epochMillis: output}) AS datetime;
Table 2. Results
outputinMs datetime
1604596506209
2020-11-05T17:15:06.209Z
The following adds 1 hour to 12 hours:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.add(12, ""hour"", 1, ""hour"") AS outputinHours
Table 3. Results
outputinHours
13
The following adds 1 hour to 34 minutes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.date.add(34, ""minutes"", 1, ""hour"") AS outputInMinutes;
Table 4. Results
outputInMinutes
94
apoc.date
apoc.date.convert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.date;"apoc.date
Qualified Name Type
apoc.date.add
apoc.date.add(time Long, unit String, addValue Integer, addUnit String) - adds a unit of specified time to the given timestamp.
Function
apoc.date.convert
apoc.date.convert(time Long, unit String, toUnit String) - converts the given timestamp from one time unit into a timestamp of a different time unit.
Function
apoc.date.convertFormat
apoc.date.convertFormat(temporal String, currentFormat String, convertTo String) - converts a string of one type of date format into a string of another type of date format.
Function
apoc.date.currentTimestamp
apoc.date.currentTimestamp() - returns the current Unix epoch timestamp in milliseconds.
Function
apoc.date.field
apoc.date.field(time Long, unit String, timezone String) - returns the value of one field from the given date time.
Function
apoc.date.fields
apoc.date.fields(date String, pattern String) - splits the given date into fields returning a map containing the values of each field.
Function
apoc.date.format
apoc.date.format(time Long, unit String, format String, timezone String) - returns a string representation of the time value. The time unit (default: ms), date format (default: ISO), and time zone (default: current time zone) can all be changed.
Function
apoc.date.fromISO8601
apoc.date.fromISO8601(time String) - converts the given date string (ISO8601) to an integer representing the time value in milliseconds.
Function
apoc.date.parse
apoc.date.parse(time String, unit String, format String, timezone String) - parses the given date string from a specified format into the specified time unit.
Function
apoc.date.systemTimezone
apoc.date.systemTimezone() - returns the display name of the system time zone (e.g. Europe/London).
Function
apoc.date.toISO8601
apoc.date.toISO8601(time Long, unit String) - returns a string representation of a specified time value in the ISO8601 format.
Function
apoc.date.toYears
apoc.date.toYears(value Any, format String) - converts the given timestamp or the given date into a floating point representing years.
Function
apoc.data.url
apoc.date.add
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.data/apoc.data.url;"apoc.data.url
Contents
Signature
Input parameters
Usage Examples
Function
apoc.data.url(url String) - turns a URL into a map.
Signature
None
Copy to Clipboard
apoc.data.url(url :: STRING?) :: (MAP?)
Input parameters
Name Type Default
url
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.data.url(""https://www.neo4j.com/developer/graph-data-science?q=neo4j#heading-1"") AS output
UNWIND keys(output) AS key
RETURN key, output[key] AS value;
Table 1. Results
key value
""path""
""/developer/graph-data-science""
""protocol""
""https""
""file""
""/developer/graph-data-science?q=neo4j""
""port""
NULL
""query""
""q=neo4j""
""anchor""
""heading-1""
""host""
""www.neo4j.com""
""user""
NULL
apoc.data
apoc.date
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.data;"apoc.data
Qualified Name Type
apoc.data.url
apoc.data.url(url String) - turns a URL into a map.
Function
apoc.cypher.runFirstColumnSingle
apoc.data.url
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runFirstColumnSingle;"apoc.cypher.runFirstColumnSingle
Contents
Signature
Input parameters
Usage Examples
Function
apoc.cypher.runFirstColumnSingle(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first element of the first column.
Signature
None
Copy to Clipboard
apoc.cypher.runFirstColumnSingle(cypher :: STRING?, params :: MAP?) :: (ANY?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (TomT:Person {name:'Tom Tykwer', born:1965})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)
 (TomT)-[:]->(CloudAtlas);
View all (11 more lines)
This function is useful for executing Cypher statements that have a dynamic node label or relationship type and return one row of one column. For example, we can return a stream of all the labels and their counts by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label
RETURN label,
       apoc.cypher.runFirstColumnSingle(""MATCH (:"" + label + "") RETURN count(*)"", {}) AS count;
Table 1. Results
label count
""Person""
3
""Movie""
9
And we can return a stream of all relationship types and their counts, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.relationshipTypes()
YIELD relationshipType
RETURN relationshipType,
       apoc.cypher.runFirstColumnSingle(""MATCH ()-[:"" + relationshipType + ""]->() RETURN count(*)"", {}) AS count;
Table 2. Results
relationshipType count
""ACTED_IN""
9
""DIRECTED""
1
More documentation of apoc.cypher.runFirstColumnSingle
apoc.cypher.runFirstColumnMany
apoc.data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/cypher-execution;"Cypher Execution
This section includes:
Running Cypher fragments
Conditional Cypher Execution
Timeboxed Cypher statements
Run multiple Statements
Fingerprinting
Running Cypher fragments
Was this page helpful?"
https://neo4j.com/docs/apoc/5/cypher-execution/cypher-multiple-statements;"Run multiple Statements
This procedure runs each semicolon separated statement and returns summary. There are currently no schema operations.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runMany('cypher;\nstatements;',{params},[{statistics:true,timeout:10}])
Timeboxed Cypher statements
Virtual Nodes & Relationships (Graph Projections)
Was this page helpful?"
https://neo4j.com/docs/apoc/5/virtual;"Virtual Nodes & Relationships (Graph Projections)
Virtual Nodes and Relationships don’t exist in the graph, they are only returned by a query, and can be used to represent a graph projection.
They can be used to visually project data, for example aggregating relationships into one, or collapsing intermediate nodes into virtual relationships. We could project a citation graph into a virtual author-author or paper-paper graph with aggregated relationships between them, or even turn Twitter data into a user-user mention graph.
We can combine real and virtual entities, for example by creating a virtual relationship between two real nodes or creating a virtual relationship from a virtual node to a real node.
Below are some other uses of virtual entities:
return only a few properties of nodes/rels to the visualization, e.g. if you have huge text properties
visualize clusters found by graph algorithms
aggregate information to a higher level of abstraction
skip intermediate nodes in a longer path
hide away properties or intermediate nodes/relationships for security reasons
graph grouping
visualization of data from other sources (computation, RDBMS, document-dbs, CSV, XML, JSON) as graph without even storing it
projecting partial data
There are a few things to keep in mind when using virtual nodes:
They have negative ids.
As virtual nodes cannot be queried from the graph, they must be kept in our own lookup structure. The apoc.map.groupBy function works well for this.
For more information on how to use these procedures, see:
Virtual Nodes/Rels
Collapse Nodes
Virtual Graph
Graph Grouping
Run multiple Statements
Virtual Nodes/Rels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/virtual/virtual-nodes-rels;"Virtual Nodes/Rels
Contents
Function Overview
Virtual Nodes/Rels Example
Virtual Nodes and Relationships don’t exist in the graph, they are only returned to the UI/user for representing a graph projection. They can be visualized or processed otherwise. Please note that they have negative id’s.
Function Overview
Qualified Name Type
apoc.create.vNode
CALL apoc.create.vNode(['Label'], {key:value,…}) YIELD node - returns a virtual node
Procedure
apoc.create.vNode
apoc.create.vNode(['Label'], {key:value,…}) - function returns a virtual node
Function
apoc.create.vNodes
apoc.create.vNodes(['Label'], [{key:value,…}]) returns virtual nodes
Procedure
apoc.create.virtual.fromNode
apoc.create.virtual.fromNode(node, [propertyNames]) - function returns a virtual node built from an existing node with only the requested properties
Function
apoc.create.vRelationship
CALL apoc.create.vRelationship(nodeFrom,'KNOWS',{key:value,…}, nodeTo) YIELD rel - returns a virtual relationship
Procedure
apoc.create.vRelationship
apoc.create.vRelationship(nodeFrom,'KNOWS',{key:value,…}, nodeTo) YIELD rel - returns a virtual relationship
Function
apoc.create.virtualPath
apoc.create.virtualPath(['LabelA'],{key:value},'KNOWS',{key:value,…},['LabelB'],{key:value}) returns a virtual path of nodes joined by a relationship and the associated properties
Procedure
apoc.create.clonePathToVirtual
Procedure
apoc.create.clonePathsToVirtual
Procedure
Virtual Nodes/Rels Example
Virtual node and virtual relationship vNode, vRelationship
From this simple data set:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (from:Account), (to:Account)
WITH from, to
CREATE (from)-[:SENT]->(:Payment {amount: 250})-[:RECEIVED]->(to)
CREATE (from)-[:SENT]->(:Payment {amount: 750})-[:RECEIVED]->(to)
we can do:
Cypher
Simple example aggregate Relationships
Copy to Clipboard
Run in Neo4j Browser
MATCH (from:Account)-[:SENT]->(p:Payment)-[:RECEIVED]->(to:Account)
RETURN from, to, apoc.create.vRelationship(from,'PAID',{amount:sum(p.amount)},to) as rel;
From this simple data set:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {country: ""Test1""})-[:KNOWS]->(:Person {country: ""Test2""}),
(:Person {country: ""Foo""})-[:KNOWS]->(:Person {country: ""Bar""})
we can execute:
Cypher
Example with virtual node lookups, people grouped by their countries
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person) WITH collect(distinct p.country) as countries
WITH [cName IN countries | apoc.create.vNode(['Country'],{name:cName})] as countryNodes
WITH apoc.map.groupBy(countryNodes,'name') as countries
MATCH (p1:Person)-[:KNOWS]->(p2:Person)
WITH p1.country as cFrom, p2.country as cTo, count(*) as count, countries
RETURN countries[cFrom] as from, countries[cTo] as to, apoc.create.vRelationship(countries[cFrom],'KNOWS',{count:count},countries[cTo]) as rel;
That’s of course easier with apoc.nodes.group.
From a simple data set
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE(a:Person)-[r:ACTED_IN]->(b:Movie)
We can create a virtual copy, adding as attribute name the labels value
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a)-[r]->(b)
WITH head(labels(a)) AS l, head(labels(b)) AS l2, type(r) AS rel_type, count(*) as count
CALL apoc.create.vNode([l],{name:l}) yield node as a
CALL apoc.create.vNode([l2],{name:l2}) yield node as b
CALL apoc.create.vRelationship(a,rel_type,{count:count},b) yield rel
RETURN *;
Virtual nodes and virtual relationships have always a negative id
Virtual nodes can also be built from existing nodes, filtering the properties in order to get a subset of them. In this case, the Virtual node keeps the id of the original node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (node:Person {name:'neo', age:'42'})
return apoc.create.virtual.fromNode(node, ['name']) as person
Cypher
Virtual path virtualPath
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.virtualPath(['British','Person'],{name:'James', age:28},'KNOWS',{since:2009},['Swedish','Person'],{name:'Daniel', age:30})
We can create a virtual pattern from an existing one
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE(a:Person {name:'Daniel'})-[r:KNOWS]->(b:Person {name:'John'})
From this dataset we can create a virtual pattern
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a)-[r]->(b)
WITH head(labels(a)) AS labelA, head(labels(b)) AS labelB, type(r) AS rel_type, a.name AS aName, b.name AS bName
CALL apoc.create.virtualPath([labelA],{name: aName},rel_type,{since:2009},[labelB],{name: bName}) yield from, rel, to
RETURN *;
To update a virtual node you can use the apoc.create.setProperty or apoc.create.setProperties, otherwise for a virtual relationships the apoc.create.setRelProperty or apoc.create.setRelProperties
Virtual Nodes & Relationships (Graph Projections)
Collapse Nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.vNodes;"apoc.create.vNodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.vNodes(labels [String], props [Map<String, Any>]) - returns virtual nodes.
Signature
None
Copy to Clipboard
apoc.create.vNodes(labels :: LIST? OF STRING?, props :: LIST? OF MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
props
LIST? OF MAP?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Xavier', score: 82});
CREATE (s:Student {name: 'Jackson', score: 81});
CREATE (s:Student {name: 'Sophia', score: 74});
CREATE (s:Student {name: 'Ariana', score: 70});
CREATE (s:Student {name: 'Elena', score: 92});
CREATE (s:Student {name: 'Luca', score: 85});
The apoc.create.vNodes is a procedure that takes a list or group of data and calls the procedure once for the entire batch.
We can use the same example from the apoc.create.vNode, but collect the scores into a single list for the procedure to create a node for each in a single call:
Cypher
apoc.create.vNode Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
WITH collect(s {.score}) as scores
CALL apoc.create.vNodes(['Score'],scores) YIELD node
RETURN node;
Table 1. Results
node
{""score"":82}
{""score"":81}
{""score"":74}
{""score"":70}
{""score"":92}
{""score"":85}
More documentation of apoc.create.vNodes
apoc.create.vNode
apoc.create.vRelationship
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.vRelationship;"apoc.create.vRelationship
Contents
Signature
Input parameters
Usage Examples
Function
apoc.create.vRelationship(from Node, relType String, props Map<String, Any>, to Node) - returns a virtual relationship.
Signature
None
Copy to Clipboard
apoc.create.vRelationship(from :: NODE?, relType :: STRING?, props :: MAP?, to :: NODE?) :: (RELATIONSHIP?)
Input parameters
Name Type Default
from
NODE?
null
relType
STRING?
null
props
MAP?
null
to
NODE?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'})
CREATE (s2:Student {name: 'Joachim'})
CREATE (s3:Student {name: 'Dominic'})
CREATE (s4:Student {name: 'Amir'})
CREATE (s5:Student {name: 'Natasha'})
CREATE (s6:Student {name: 'Elena'})

CREATE (t1:TestScore {score: 87})
CREATE (t2:TestScore {score: 90})
CREATE (t3:TestScore {score: 78})
CREATE (t4:TestScore {score: 84})
CREATE (t5:TestScore {score: 76})
CREATE (t6:TestScore {score: 92})

CREATE (a:Level {level: 'beginner'})
 (b: {level: })
 (c: {level: })

 (s1)-[:]->(t1)-[:]->(b)
 (s2)-[:]->(t2)-[:]->(c)
 (s3)-[:]->(t3)-[:]->(a)
 (s4)-[:]->(t4)-[:]->(b)
 (s5)-[:]->(t5)-[:]->(a)
 (s6)-[:]->(t6)-[:]->(c);
View all (9 more lines)
The apoc.create.vRelationship offers both a procedure and function version, so we can create the virtual relationships independently or return them based on results of a query.
For instance, we might want to create virtual relationships between students to see which students have the same understanding level of class material:
Cypher
apoc.create.vRelationship Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)<-[:ASSIGNED_TO]-(:TestScore)<-[:HAS]-(s2:Student)
CALL apoc.create.vRelationship(s1,'SIMILAR_LEVEL',{level: l.level},s2) YIELD rel
RETURN s1, rel, s2;
Figure 1. Results
We could also create a virtual relationship straight to their level and use the function version of the apoc.create.vRelationship.
Cypher
apoc.create.vRelationship Function
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)
RETURN s1, apoc.create.vRelationship(s1,'HAS_UNDERSTANDING',{},l) as rel, l
Figure 2. Results
More documentation of apoc.create.vRelationship
apoc.create.vNodes
apoc.create.virtualPath
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.virtualPath;"apoc.create.virtualPath
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.create.virtualPath(labelsN [String],n Map<String, Any>, relType String, props Map<String, Any>, labelsM [String], m Map<String, Any>) - returns a virtual path.
Signature
None
Copy to Clipboard
apoc.create.virtualPath(labelsN :: LIST? OF STRING?, n :: MAP?, relType :: STRING?, props :: MAP?, labelsM :: LIST? OF STRING?, m :: MAP?) :: (from :: NODE?, rel :: RELATIONSHIP?, to :: NODE?)
Input parameters
Name Type Default
labelsN
LIST? OF STRING?
null
n
MAP?
null
relType
STRING?
null
props
MAP?
null
labelsM
LIST? OF STRING?
null
m
MAP?
null
Output parameters
Name Type
from
NODE?
rel
RELATIONSHIP?
to
NODE?
More documentation of apoc.create.virtualPath
apoc.create.vRelationship
apoc.create.uuid
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.uuid;"apoc.create.uuid
Contents
Signature
Usage Examples
Function Deprecated
apoc.create.uuids(count Integer) - returns a stream of UUIDs.
Signature
None
Copy to Clipboard
apoc.create.uuid() :: (STRING?)
Usage Examples
The following generates a new UUID:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.create.uuid() as output;
Table 1. Results
Output
""3bfef4ba-564e-4ce1-b3af-616651f90aff""
apoc.create.virtualPath
apoc.create.vNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.vNode;"apoc.create.vNode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.create.vNode(labels [String], props Map<String, Any>) - returns a virtual node.
Signature
None
Copy to Clipboard
apoc.create.vNode(labels :: LIST? OF STRING?, props = {} :: MAP?) :: (NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
props
MAP?
{}
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Alice', score: 71});
CREATE (s:Student {name: 'Mark', score: 95});
CREATE (s:Student {name: 'Andrea', score: 86});
CREATE (s:Student {name: 'Rajesh', score: 89});
CREATE (s:Student {name: 'Jennifer', score: 96});
CREATE (s:Student {name: 'Katarina', score: 80});
The apoc.create.vNode offers both a procedure and function version, so that we can create the virtual nodes independently or return them based on results of a query.
For instance, we might want to create virtual nodes for just the scores, so that researchers could retrieve the score, but not student data:
Cypher
apoc.create.vNode Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.create.vNode(['Score'],{value: s.score}) YIELD node
RETURN node;
Table 1. Results
node
{""value"":71}
{""value"":95}
{""value"":86}
{""value"":89}
{""value"":96}
{""value"":80}
We could also create a virtual graph adhoc that separates students from their scores. This allows testing or querying the data in an alternate data model than what physically exists in the database.
Cypher
apoc.create.vNode Function
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
RETURN apoc.create.vNode(['Student'],{name: s.name}) as student,
       apoc.create.vNode(['Score'],{value: s.score}) as score;
Table 2. Results
student score
{""name"":""Alice""}
{""value"":71}
{""name"":""Mark""}
{""value"":95}
{""name"":""Andrea""}
{""value"":86}
{""name"":""Rajesh""}
{""value"":89}
{""name"":""Jennifer""}
{""value"":96}
{""name"":""Katarina""}
{""value"":80}
More documentation of apoc.create.vNode
apoc.create.uuids
apoc.create.vNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.uuids;"apoc.create.uuids
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Deprecated
apoc.create.uuids(count Integer) - returns a stream of UUIDs.
Signature
None
Copy to Clipboard
apoc.create.uuids(count :: INTEGER?) :: (row :: INTEGER?, uuid :: STRING?)
Input parameters
Name Type Default
count
INTEGER?
null
Output parameters
Name Type
row
INTEGER?
uuid
STRING?
Usage Examples
The following generates a stream of UUID:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.uuids(10);
Table 1. Results
row uuid
0
""e2c84705-5667-4550-b468-9e1faf08c0d7""
1
""7112c6ac-13bc-4c0c-afd8-2c1bc47b9942""
2
""bb4f5089-6907-4550-9b38-919c2400e82c""
3
""40cf6b89-5b42-4792-802c-bc55d03e12e4""
4
""486b2b05-7d73-4f14-ba14-dc4ea72f5335""
5
""3b0e6253-73e1-4b19-a6af-e57164bd34cd""
6
""7f01f2b4-f8bf-4975-9a1f-a4567e70d0f9""
7
""1c2ad4cb-0ba1-412c-baeb-0349126c4938""
8
""52ce2443-8ce5-42c1-8553-349d8dfbefb4""
9
""02111796-7531-41b9-99dc-22c8625009c4""
apoc.create.setRelProperty
apoc.create.vNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.setRelProperty;"apoc.create.setRelProperty
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.setRelProperties(rels Any, keys [String], values [Any]) - sets the given properties on the relationship(s).
Signature
None
Copy to Clipboard
apoc.create.setRelProperty(relationships :: ANY?, key :: STRING?, value :: ANY?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
relationships
ANY?
null
key
STRING?
null
value
ANY?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (station1:Station {name: ""Station 1""})
CREATE (station2:Station {name: ""Station 3""})
CREATE (station1)-[:JOURNEY {arrival: ""0802"", departure: ""0803""}]->(station2);
We want to convert the arrival and departure properties into Time types and store them as new properties, whose names are based on the original property keys.
We can generate the new property keys and Time values, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Station)-[journey:JOURNEY]->(:Station)
UNWIND [""arrival"", ""departure""] AS key
RETURN key + ""Time"" AS newKey, time(journey[key]) AS time;
Table 1. Results
newKey
time
""arrivalTime""
08:02Z
""departureTime""
08:03Z
But if we try to save these properties back to the database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Station)-[journey:JOURNEY]->(:Station)
UNWIND [""arrival"", ""departure""] AS key
WITH stop, key + ""Time"" AS newKey, time(journey[key]) AS time
SET journey[newKey] = time;
We’ll receive the following error:
Text
Results
Copy to Clipboard
Invalid input '[': expected "":"" (line 5, column 12 (offset: 160))
""SET journey[newKey] = time;""
            ^
We can use apoc.create.setRelProperty to work around this problem, as shown in the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Station)-[journey:JOURNEY]->(:Station)
UNWIND [""arrival"", ""departure""] AS key
WITH journey, key + ""Time"" AS newKey, time(journey[key]) AS time
CALL apoc.create.setRelProperty(journey, newKey, time)
YIELD rel
RETURN rel;
Table 2. Results
rel
[:JOURNEY {departure: ""0803"", arrival: ""0802"", arrivalTime: 08:02Z}]
[:JOURNEY {departureTime: 08:03Z, departure: ""0803"", arrival: ""0802"", arrivalTime: 08:02Z}]
More documentation of apoc.create.setRelProperty
apoc.create.setRelProperties
apoc.create.uuids
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates/data-creation;"Creating data
Contents
Functions for creating data dynamically
Examples
Remove Node Labels
Set Node and Relationship Properties
Remove Node and Relationship Properties
Linked Lists
The APOC library contains procedures which enhance Neo4j’s write functionality. Many of these procedures enable dynamic data creation, such as dynamically adding node labels.
For an explanation of how to create nodes and relationships dynamically using the APOC library by Michael Hunger, Senior Director of User Innovation at Neo4j, watch this video:
Functions for creating data dynamically
Qualified Name Type
apoc.create.node
apoc.create.node(label [String], props Map<String, Any>) - creates a node with the given dynamic labels.
Procedure
apoc.create.nodes
apoc.create.nodes(label [String], props [Map<String, Any>]) - creates nodes with the given dynamic labels.
Procedure
apoc.create.relationship
apoc.create.relationship(from Node, relType String, props Map<String, Any>, to Node) - creates a relationship with the given dynamic relationship type.
Procedure
apoc.create.removeLabels
apoc.create.removeLabels(nodes Any, label [String]) - removes the given labels from the given node(s).
Procedure
apoc.create.removeProperties
apoc.create.removeProperties(nodes Any, keys [String]) - removes the given properties from the given node(s).
Procedure
apoc.create.removeRelProperties
apoc.create.removeRelProperties(rels Any, keys [String]) - removes the given properties from the given relationship(s).
Procedure
apoc.create.setProperties
apoc.create.setProperties(nodes Any, keys [String], values [Any]) - sets the given properties to the given node(s).
Procedure
apoc.create.setProperty
apoc.create.setProperty(nodes Any, key [String], value [Any]) - sets the given property to the given node(s).
Procedure
apoc.create.setRelProperties
apoc.create.setRelProperties(rels Any, keys [String], values [Any]) - sets the given properties on the relationship(s).
Procedure
apoc.create.setRelProperty
apoc.create.setRelProperty(rels Any, key String, value Any) - sets the given property on the relationship(s).
Procedure
apoc.nodes.link
apoc.nodes.link(nodes [Node], type String, config Map<String, Any>) - creates a linked list of the given nodes connected by the given relationship type.
Procedure
apoc.merge.relationship
apoc.merge.relationship(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties.
Procedure
apoc.merge.nodeWithStats
apoc.merge.nodeWithStats(label [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels. Provides queryStatistics in the result.
Procedure
apoc.merge.nodeWithStats.eager
apoc.merge.nodeWithStats.eager(label [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly. Provides queryStatistics in the result.
Procedure
apoc.merge.relationshipWithStats
apoc.merge.relationshipWithStats(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties. Provides queryStatistics in the result.
Procedure
apoc.merge.relationshipWithStats.eager
apoc.merge.relationshipWithStats.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly. Provides queryStatistics in the result.
Procedure
Examples
The below examples will further explain these procedures.
Remove Node Labels
Cypher supports deleting labels as long as the labels are hard coded. If the labels are dynamically specified, the apoc.create.removeLabels procedure can be used.
Cypher
The following creates a sample graph of people:
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person:US {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person:US {name: ""Karin"", community: 4, partition: 2})
CREATE (mark:Person:UK {name: ""Mark"", community: 3, partition: 3})
Cypher
The following removes all labels except Person from all nodes:
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label WHERE label <> ""Person""
WITH collect(label) AS labels
MATCH (p:Person)
WITH collect(p) AS people, labels
CALL apoc.create.removeLabels(people, labels)
YIELD node
RETURN node, labels(node) AS labels
Table 1. Results
node labels
(:Person {name: ""Jennifer"", partition: 4, community: 1})
[""Person""]
(:Person {name: ""Karin"", partition: 2, community: 4})
[""Person""]
(:Person {name: ""Mark"", partition: 3, community: 3})
[""Person""]
Set Node and Relationship Properties
Cypher supports setting properties as long as the property names are hard coded. If the property names are dynamically specified, use the apoc.create.setProperties and apoc.create.setRelProperties procedures.
Cypher
The following creates a sample graph of people:
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine)
Cypher
The following duplicates all node properties on Person nodes:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p, keys(p) AS keys
CALL apoc.create.setProperties(p,[k in keys | k + ""Copy""], [k in keys | p[k]])
YIELD node
RETURN node
Table 2. Results
node
{""name"":""Jennifer"",""partition"":4,""community"":1,""nameCopy"":""Jennifer"",""partitionCopy"":4,""communityCopy"":1}
{""name"":""Karin"",""partition"":2,""community"":4,""nameCopy"":""Karin"",""partitionCopy"":2,""communityCopy"":4}
{""name"":""Mark"",""partition"":3,""community"":3,""nameCopy"":""Mark"",""partitionCopy"":3,""communityCopy"":3}
Cypher
The following duplicates all relationship properties:
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)-[friends:FRIENDS]->(:Person)
WITH friends, keys(friends) AS keys
CALL apoc.create.setRelProperties(friends,[k in keys | k + ""Copy""], [k in keys | friends[k]])
YIELD rel
RETURN startNode(rel) AS start, rel, endNode(rel) AS end
Table 3. Results
start rel end
{ ""name"": ""Jennifer"", ""partition"": 4, ""community"": 1, ""nameCopy"": ""Jennifer"", ""partitionCopy"": 4, ""communityCopy"": 1 }
{ ""sinceCopy"": ""2019-05-04T00:00:00Z"", ""since"": ""2019-05-04T00:00:00Z"" }
{ ""name"": ""Elaine"", ""partition"": 3, ""community"": 3, ""nameCopy"": ""Elaine"", ""partitionCopy"": 3, ""communityCopy"": 3 }
{ ""name"": ""Jennifer"", ""partition"": 4, ""community"": 1, ""nameCopy"": ""Jennifer"", ""partitionCopy"": 4, ""communityCopy"": 1 }
{ ""sinceCopy"": ""2019-06-01T00:00:00Z"", ""since"": ""2019-06-01T00:00:00Z"" }
{ ""name"": ""Karin"", ""partition"": 2, ""community"": 4, ""nameCopy"": ""Karin"", ""partitionCopy"": 2, ""communityCopy"": 4 }
Remove Node and Relationship Properties
Cypher supports deleting properties as long as the property names are hard coded. If the property names are dynamically specified, use the apoc.create.removeProperties and apoc.create.removeRelProperties procedures.
Cypher
The following creates a sample graph of people:
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine)
Cypher
The following deletes all properties except for name from Person nodes:
Copy to Clipboard
Run in Neo4j Browser
CALL db.propertyKeys()
YIELD propertyKey WHERE propertyKey <> ""name""
WITH collect(propertyKey) AS propertyKeys
MATCH (p:Person)
WITH collect(p) AS nodes, propertyKeys
CALL apoc.create.removeProperties(nodes, propertyKeys)
YIELD node
RETURN node
Table 4. Results
node
{""name"":""Jennifer""}
{""name"":""Karin""}
{""name"":""Elaine""}
Cypher
The following deletes properties from all relationships:
Copy to Clipboard
Run in Neo4j Browser
CALL db.propertyKeys()
YIELD propertyKey
WITH collect(propertyKey) AS propertyKeys
MATCH (:Person)-[friends:FRIENDS]->(:Person)
WITH collect(friends) AS friendsRels, propertyKeys
CALL apoc.create.removeRelProperties(friendsRels, propertyKeys)
YIELD rel
RETURN startNode(rel) AS start, rel, endNode(rel) AS end
Table 5. Results
start rel end
{""name"":""Jennifer""}
{}
{""name"":""Elaine""}
{""name"":""Jennifer""}
{}
{""name"":""Karin""}
Linked Lists
apoc.nodes.link can be used to create a linked list of nodes.
Cypher
The following creates a linked list of nodes:
Copy to Clipboard
Run in Neo4j Browser
MATCH (e:Event)
WITH e ORDER BY e.date
WITH collect(e) AS events
CALL apoc.nodes.link(events, ""NEXT"")
RETURN count(*);
Linked lists can also be created using Cypher.
Cypher
The following creates a linked list of nodes:
Copy to Clipboard
Run in Neo4j Browser
MATCH (e:Event)
WITH e ORDER BY e.date
WITH collect(e) AS events, count(e) as size
CALL {
    WITH events, size
    UNWIND range(0, size - 2) as i
    WITH events[i] as a, events[i+1] as b
    MERGE (a)-[:NEXT]->(b)
}
RETURN events
Graph updates
Periodic execution
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.setProperty;"apoc.create.setProperty
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.setProperty(nodes Any, key String, value [Any]) - sets the given property to the given node(s).
Signature
None
Copy to Clipboard
apoc.create.setProperty(nodes :: ANY?, key :: STRING?, value :: ANY?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
key
STRING?
null
value
ANY?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (stop:Stop {arrival: ""0802"", departure: ""0803""});
We want to convert the arrival and departure properties into Time types and store them as new properties, whose names are based on the original property keys.
We can generate the new property keys and Time values, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (stop:Stop)
UNWIND [""arrival"", ""departure""] AS key
RETURN key + ""Time"" AS newKey, time(stop[key]) AS time;
Table 1. Results
newKey
time
""arrivalTime""
08:02Z
""departureTime""
08:03Z
But if we try to save these properties back to the database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (stop:Stop)
UNWIND [""arrival"", ""departure""] AS key
WITH stop, key + ""Time"" AS newKey, time(stop[key]) AS time
SET stop[newKey] = time;
We’ll receive the following error:
Table 2. Results
Invalid input '[': expected an identifier character, whitespace, '{', node labels, a property map, a relationship pattern, '.', '(', '=' or ""+="" (line 5, column 9 (offset: 119)) ""SET stop[newKey] = time;""
We can use apoc.create.setProperty to work around this problem, as shown in the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (stop:Stop)
UNWIND [""arrival"", ""departure""] AS key
WITH stop, key + ""Time"" AS newKey, time(stop[key]) AS time
CALL apoc.create.setProperty(stop, newKey, time)
YIELD node
RETURN node;
Table 3. Results
node
(:Stop {departure: ""0803"", arrival: ""0802"", arrivalTime: 08:02Z})
(:Stop {departureTime: 08:03Z, departure: ""0803"", arrival: ""0802"", arrivalTime: 08:02Z})
More documentation of apoc.create.setProperty
apoc.create.setProperties
apoc.create.setRelProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.setRelProperties;"apoc.create.setRelProperties
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.setRelProperties(rels Any, keys [String], values [Any]) - sets the given properties on the relationship(s).
Signature
None
Copy to Clipboard
apoc.create.setRelProperties(rels :: ANY?, keys :: LIST? OF STRING?, values :: LIST? OF ANY?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
rels
ANY?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine);
We can duplicate all relationship properties, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)-[friends:FRIENDS]->(:Person)
WITH friends, keys(friends) AS keys
CALL apoc.create.setRelProperties(friends,[k in keys | k + ""Copy""], [k in keys | friends[k]])
YIELD rel
RETURN startNode(rel).name AS start, rel, endNode(rel).name AS end;
Table 1. Results
start rel end
""Jennifer""
[:FRIENDS {sinceCopy: 2019-05-04T00:00Z, since: 2019-05-04T00:00Z}]
""Elaine""
""Jennifer""
[:FRIENDS {sinceCopy: 2019-06-01T00:00Z, since: 2019-06-01T00:00Z}]
""Karin""
More documentation of apoc.create.setRelProperties
apoc.create.setProperty
apoc.create.setRelProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.setProperties;"apoc.create.setProperties
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.setProperties(nodes Any, keys [String], values [Any]) - sets the given properties to the given node(s).
Signature
None
Copy to Clipboard
apoc.create.setProperties(nodes :: ANY?, keys :: LIST? OF STRING?, values :: LIST? OF ANY?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
keys
LIST? OF STRING?
null
values
LIST? OF ANY?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine);
We can duplicate all node properties on Person nodes, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p, keys(p) AS keys
CALL apoc.create.setProperties(p,[k in keys | k + ""Copy""], [k in keys | p[k]])
YIELD node
RETURN node;
Table 1. Results
node
{""name"":""Jennifer"",""partition"":4,""community"":1,""nameCopy"":""Jennifer"",""partitionCopy"":4,""communityCopy"":1}
{""name"":""Karin"",""partition"":2,""community"":4,""nameCopy"":""Karin"",""partitionCopy"":2,""communityCopy"":4}
{""name"":""Mark"",""partition"":3,""community"":3,""nameCopy"":""Mark"",""partitionCopy"":3,""communityCopy"":3}
More documentation of apoc.create.setProperties
apoc.create.setLabels
apoc.create.setProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.setLabels;"apoc.create.setLabels
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.setLabels(nodes Any, labels [String]) - sets the given labels to the given node(s). Non-matching labels are removed from the nodes.
Signature
None
Copy to Clipboard
apoc.create.setLabels(nodes :: ANY?, labels :: LIST? OF STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
labels
LIST? OF STRING?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Movie {title: 'A Few Good Men', genre: 'Drama'});
We can move the 'genre' property to a label and remove it as a property, as well as removing any other labels, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
CALL apoc.create.setLabels( n, [ n.genre ] )
YIELD node
REMOVE node.genre
RETURN node;
Table 1. Results
node
(:Drama {title: ""A Few Good Men""})
If we want to only add new labels and not remove existing ones, see apoc.create.addLabels
apoc.create.removeRelProperties
apoc.create.setProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.addLabels;"apoc.create.addLabels
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.addLabels(nodes Any, labels [String]) - adds the given labels to the given nodes.
Signature
None
Copy to Clipboard
apoc.create.addLabels(nodes :: ANY?, labels :: LIST? OF STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
labels
LIST? OF STRING?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Movie {title: 'A Few Good Men', genre: 'Drama'});
We can move the 'genre' property to a label and remove it as a property by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
CALL apoc.create.addLabels( n, [ n.genre ] )
YIELD node
REMOVE node.genre
RETURN node;
Table 1. Results
node
(:Movie:Drama {title: ""A Few Good Men""})
apoc.create
apoc.create.node
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create;"apoc.create
Qualified Name Type
apoc.create.addLabels
apoc.create.addLabels(nodes Any, labels [String]) - adds the given labels to the given nodes.
Procedure
apoc.create.clonePathToVirtual
apoc.create.clonePathToVirtual(path Path) - takes the given path and returns a virtual representation of it.
Procedure
apoc.create.clonePathsToVirtual
apoc.create.clonePathsToVirtual(paths [Path]) - takes the given paths and returns a virtual representation of them.
Procedure
apoc.create.node
apoc.create.node(labels [String], props Map<String, Any>) - creates a node with the given dynamic labels.
Procedure
apoc.create.nodes
apoc.create.nodes(labels [String], props [Map<String, Any>]) - creates nodes with the given dynamic labels.
Procedure
apoc.create.relationship
apoc.create.relationship(from Node, relType String, props Map<String, Any>, to Node) - creates a relationship with the given dynamic relationship type.
Procedure
apoc.create.removeLabels
apoc.create.removeLabels(nodes Any, labels [String]) - removes the given labels from the given node(s).
Procedure
apoc.create.removeProperties
apoc.create.removeProperties(nodes Any, keys [String]) - removes the given properties from the given node(s).
Procedure
apoc.create.removeRelProperties
apoc.create.removeRelProperties(rels Any, keys [String]) - removes the given properties from the given relationship(s).
Procedure
apoc.create.setLabels
apoc.create.setLabels(nodes Any, labels [String]) - sets the given labels to the given node(s). Non-matching labels are removed from the nodes.
Procedure
apoc.create.setProperties
apoc.create.setProperties(nodes Any, keys [String], values [Any]) - sets the given properties to the given node(s).
Procedure
apoc.create.setProperty
apoc.create.setProperty(nodes Any, key String, value [Any]) - sets the given property to the given node(s).
Procedure
apoc.create.setRelProperties
apoc.create.setRelProperties(rels Any, keys [String], values [Any]) - sets the given properties on the relationship(s).
Procedure
apoc.create.setRelProperty
apoc.create.setRelProperty(rels Any, key String, value Any) - sets the given property on the relationship(s).
Procedure
apoc.create.uuids
apoc.create.uuids(count Integer) - returns a stream of UUIDs.
Procedure
apoc.create.vNode
apoc.create.vNode(labels [String], props Map<String, Any>) - returns a virtual node.
Procedure
apoc.create.vNodes
apoc.create.vNodes(labels [String], props [Map<String, Any>]) - returns virtual nodes.
Procedure
apoc.create.vRelationship
apoc.create.vRelationship(from Node, relType String, props Map<String, Any>, to Node) - returns a virtual relationship.
Procedure
apoc.create.virtualPath
apoc.create.virtualPath(labelsN [String],n Map<String, Any>, relType String, props Map<String, Any>, labelsM [String], m Map<String, Any>) - returns a virtual path.
Procedure
apoc.create.uuid
apoc.create.uuid() - creates a UUID
Function
apoc.create.uuidBase64
apoc.create.uuidBase64() - returns a UUID encoded with base64.
Function
apoc.create.uuidBase64ToHex
apoc.create.uuidBase64ToHex(base64Uuid String) - takes the given base64 encoded UUID and returns it as a hexadecimal string.
Function
apoc.create.uuidHexToBase64
apoc.create.uuidHexToBase64(uuid String) - takes the given UUID represented as a hexadecimal string and returns it encoded with base64.
Function
apoc.create.virtual.fromNode
apoc.create.virtual.fromNode(node Node, propertyNames [String]) - returns a virtual node from the given existing node.
Function
apoc.create.vNode
apoc.create.vNode(labels [String], props Map<String, Any>) - returns a virtual node.
Function
apoc.create.vRelationship
apoc.create.vRelationship(from Node, relType String, props Map<String, Any>, to Node) - returns a virtual relationship.
Function
apoc.convert.toSortedJsonMap
apoc.create.addLabels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.uuidBase64ToHex;"apoc.create.uuidBase64ToHex
Contents
Signature
Input parameters
Usage Examples
Function
apoc.create.uuidBase64ToHex(base64Uuid String) - takes the given base64 encoded UUID and returns it as a hexadecimal string.
Signature
None
Copy to Clipboard
apoc.create.uuidBase64ToHex(base64Uuid :: STRING?) :: (STRING?)
Input parameters
Name Type Default
base64Uuid
STRING?
null
Usage Examples
The following converts a UUID encoded with Base64 to HEX representation:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.create.uuidBase64ToHex(""vX8dM5XoSe2ldoc/QzMEyw"") as output;
Table 1. Results
Output
""bd7f1d33-95e8-49ed-a576-873f433304cb""
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.node;"apoc.create.node
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.node(labels [String], props Map<String, Any>) - creates a node with the given dynamic labels.
Signature
None
Copy to Clipboard
apoc.create.node(labels :: LIST? OF STRING?, props :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
props
MAP?
null
Output parameters
Name Type
node
NODE?
Usage Examples
This procedure provides a more flexible way of creating nodes than Cypher’s CREATE clause.
The example below shows equivalent ways of creating a node with the Person and Actor labels, with a name property of ""Tom Hanks"":
apoc.create.node
CREATE clause
Cypher
apoc.create.node
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.node([""Person"", ""Actor""], {name: ""Tom Hanks""});
Table 1. Results
node
(:Person:Actor {name: ""Tom Hanks""})
But this procedure is mostly useful for creating nodes that have dynamic labels or properties. For example, we might want to create a node with labels or properties passed in as parameters.
The following creates labels and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param labels =>  ([""Human"", ""MovieStar""]);
:param properties => ({name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""});
The following creates a node with labels and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.node($labels, $properties);
Table 2. Results
node
(:Human:MovieStar {name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""})
More documentation of apoc.create.node
apoc.create.addLabels
apoc.create.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.nodes;"apoc.create.nodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.nodes(labels [String], props [Map<String, Any>]) - creates nodes with the given dynamic labels.
Signature
None
Copy to Clipboard
apoc.create.nodes(labels :: LIST? OF STRING?, props :: LIST? OF MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
props
LIST? OF MAP?
null
Output parameters
Name Type
node
NODE?
Usage Examples
This procedure provides a more flexible way of creating nodes than Cypher’s CREATE clause.
The example below shows equivalent ways of creating a node with the Person and Actor labels, with a name property of ""Tom Hanks"":
apoc.create.node
CREATE clause
Cypher
apoc.create.node
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.nodes([""Person"", ""Actor""], [{name: ""Tom Hanks""}]);
Table 1. Results
node
(:Person:Actor {name: ""Tom Hanks""})
But this procedure is mostly useful for creating nodes that have dynamic labels or properties. For example, we might want to create a node with labels or properties passed in as parameters.
The following creates labels and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param labels =>  ([""Human"", ""MovieStar""]);
:param properties => ([{name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""}, {name: ""Reese Witherspoon"", placeOfBirth: ""New Orleans, Louisiana, United States""}]);
The following creates nodes with labels and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.create.nodes($labels, $properties);
Table 2. Results
node
(:Human:MovieStar {name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""})
(:Human:MovieStar {name: ""Reese Witherspoon"", placeOfBirth: ""New Orleans, Louisiana, United States""})
More documentation of apoc.create.nodes
apoc.create.node
apoc.create.relationship
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.relationship;"apoc.create.relationship
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.relationship(from Node, relType String, props Map<String, Any>, to Node) - creates a relationship with the given dynamic relationship type.
Signature
None
Copy to Clipboard
apoc.create.relationship(from :: NODE?, relType :: STRING?, props :: MAP?, to :: NODE?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
from
NODE?
null
relType
STRING?
null
props
MAP?
null
to
NODE?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Person {name: ""Tom Hanks""})
CREATE (m:Movie {title:""You've Got Mail""});
This procedure provides a more flexible way of creating relationships than Cypher’s CREATE clause.
The example below shows equivalent ways of creating a node with the Person and Actor labels, with a name property of ""Tom Hanks"":
apoc.create.relationship
CREATE clause
Cypher
apoc.create.relationship
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
MATCH (m:Movie {title:""You've Got Mail""})
CALL apoc.create.relationship(p, ""ACTED_IN"", {roles:['Joe Fox']}, m)
YIELD rel
RETURN rel;
Table 1. Results
rel
[:ACTED_IN {roles: [""Joe Fox""]}]
But this procedure is mostly useful for creating relationships that have a dynamic relationship type or dynamic properties. For example, we might want to create a relationship with a relationship type or properties passed in as parameters.
The following creates relationshipType and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param relType =>  (""ACTED_IN"");
:param properties => ({roles: [""Joe Fox""]});
The following creates a relationship with a relationship type and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
MATCH (m:Movie {title:""You've Got Mail""})
CALL apoc.create.relationship(p, $relType, $properties, m)
YIELD rel
RETURN rel;
Table 2. Results
rel
[:ACTED_IN {roles: [""Joe Fox""]}]
More documentation of apoc.create.relationship
apoc.create.nodes
apoc.create.removeLabels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.removeLabels;"apoc.create.removeLabels
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.removeLabels(nodes Any, labels [String]) - removes the given labels from the given node(s).
Signature
None
Copy to Clipboard
apoc.create.removeLabels(nodes :: ANY?, labels :: LIST? OF STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
labels
LIST? OF STRING?
null
Output parameters
Name Type
node
NODE?
Usage Examples
Cypher supports deleting of labels as long as the labels are hard coded. If the labels are dynamically specified, we can use this procedure.
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person:US {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person:US {name: ""Karin"", community: 4, partition: 2})
CREATE (mark:Person:UK {name: ""Mark"", community: 3, partition: 3});
The following removes all labels except Person from all nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label WHERE label <> ""Person""
WITH collect(label) AS labels
MATCH (p:Person)
WITH collect(p) AS people, labels
CALL apoc.create.removeLabels(people, labels)
YIELD node
RETURN node, labels(node) AS labels;
Table 1. Results
node labels
(:Person {name: ""Jennifer"", partition: 4, community: 1})
[""Person""]
(:Person {name: ""Karin"", partition: 2, community: 4})
[""Person""]
(:Person {name: ""Mark"", partition: 3, community: 3})
[""Person""]
More documentation of apoc.create.removeLabels
apoc.create.relationship
apoc.create.removeProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.removeProperties;"apoc.create.removeProperties
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.removeProperties(nodes Any, labels[String]) - removes the given properties from the given node(s).
Signature
None
Copy to Clipboard
apoc.create.removeProperties(nodes :: ANY?, keys :: LIST? OF STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
keys
LIST? OF STRING?
null
Output parameters
Name Type
node
NODE?
Usage Examples
Cypher supports deleting of node properties as long as the property names are hard coded. If the property names are dynamically specified we can use this procedure instead.
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine);
We can delete all properties from relationships, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.propertyKeys()
YIELD propertyKey WHERE propertyKey <> ""name""
WITH collect(propertyKey) AS propertyKeys
MATCH (p:Person)
WITH collect(p) AS nodes, propertyKeys
CALL apoc.create.removeProperties(nodes, propertyKeys)
YIELD node
RETURN node;
Table 1. Results
node
(:Person {name: ""Jennifer""})
(:Person {name: ""Karin""})
(:Person {name: ""Elaine""})
More documentation of apoc.create.removeProperties
apoc.create.removeLabels
apoc.create.removeRelProperties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.removeRelProperties;"apoc.create.removeRelProperties
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.create.removeRelProperties(rels Any, keys [String]) - removes the given properties from the given relationship(s).
Signature
None
Copy to Clipboard
apoc.create.removeRelProperties(rels :: ANY?, keys :: LIST? OF STRING?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
rels
ANY?
null
keys
LIST? OF STRING?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
Cypher supports deleting of relationship properties as long as the property names are hard coded. If the property names are dynamically specified we can use this procedure instead.
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (jennifer:Person {name: ""Jennifer"", community: 1, partition: 4})
CREATE (karin:Person {name: ""Karin"", community: 4, partition: 2})
CREATE (elaine:Person {name: ""Elaine"", community: 3, partition: 3})
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-06-01"")}]-(karin)
MERGE (jennifer)-[:FRIENDS {since: datetime(""2019-05-04"")}]-(elaine);
We can delete all properties except for name from Person nodes, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.propertyKeys()
YIELD propertyKey
WITH collect(propertyKey) AS propertyKeys
MATCH (:Person)-[friends:FRIENDS]->(:Person)
WITH collect(friends) AS friendsRels, propertyKeys
CALL apoc.create.removeRelProperties(friendsRels, propertyKeys)
YIELD rel
RETURN startNode(rel).name AS start, rel, endNode(rel).name AS end;
Table 1. Results
start rel end
""Jennifer""
[:FRIENDS]
""Elaine""
""Jennifer""
[:FRIENDS]
""Karin""
More documentation of apoc.create.removeRelProperties
apoc.create.removeProperties
apoc.create.setLabels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toSortedJsonMap;"apoc.convert.toSortedJsonMap
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.toSortedJsonMap(value Any, ignoreCase Boolean) - converts a serialized JSON object from the property of a given node into a Cypher map.
Signature
None
Copy to Clipboard
apoc.convert.toSortedJsonMap(value :: ANY?, ignoreCase = true :: BOOLEAN?) :: (STRING?)
Input parameters
Name Type Default
value
ANY?
null
ignoreCase
BOOLEAN?
true
Usage examples
The following converts a map to a JSON map with keys sorted alphabetically, ignoring case sensitivity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {b:8, d:3, a:2, E: 12, C:9} as map
RETURN apoc.convert.toSortedJsonMap(map) as output;
Table 1. Results
Output
""{\""a\"":2,\""b\"":8,\""C\"":9,\""d\"":3,\""E\"":12}""
The following converts a map to a JSON map with keys sorted alphabetically, with case sensitivity:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {b:8, d:3, a:2, E: 12, C:9} as map
RETURN apoc.convert.toSortedJsonMap(map, false) as output;
Table 2. Results
Output
""{\""C\"":9,\""E\"":12,\""a\"":2,\""b\"":8,\""d\"":3}""
apoc.convert.toSet
apoc.create
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toSet;"apoc.convert.toSet
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.toSet(list [Any]) - converts the given value into a set.
Signature
None
Copy to Clipboard
apoc.convert.toSet(list :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
ANY?
null
Usage examples
Cypher
Convert list to set
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.toSet([1,2,3,2]) AS output;
Table 1. Results
Output
[1, 2, 3]
apoc.convert.toRelationshipList
apoc.convert.toSortedJsonMap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toRelationshipList;"apoc.convert.toRelationshipList
Contents
Signature
Input parameters
Function
apoc.convert.toRelationshipList(relList [Any]) - converts the given value into a list of relationships.
Signature
None
Copy to Clipboard
apoc.convert.toRelationshipList(list :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
ANY?
null
apoc.convert.toRelationship
apoc.convert.toSet
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toRelationship;"apoc.convert.toRelationship
Contents
Signature
Input parameters
Function
apoc.convert.toRelationship(rel Any) - converts the given value into a relationship.
Signature
None
Copy to Clipboard
apoc.convert.toRelationship(relationship :: ANY?) :: (RELATIONSHIP?)
Input parameters
Name Type Default
relationship
ANY?
null
apoc.convert.toNodeList
apoc.convert.toRelationshipList
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toNodeList;"apoc.convert.toNodeList
Contents
Signature
Input parameters
Function
apoc.convert.toNodeList(list [Any]) - converts the given value into a list of nodes.
Signature
None
Copy to Clipboard
apoc.convert.toNodeList(list :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
ANY?
null
apoc.convert.toNode
apoc.convert.toRelationship
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toNode;"apoc.convert.toNode
Contents
Signature
Input parameters
Function
apoc.convert.toNode(node Any) - converts the given value into a node.
Signature
None
Copy to Clipboard
apoc.convert.toNode(node :: ANY?) :: (NODE?)
Input parameters
Name Type Default
node
ANY?
null
apoc.convert.toMap
apoc.convert.toNodeList
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toMap;"apoc.convert.toMap
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.toMap(map Any) - converts the given value into a map.
Signature
None
Copy to Clipboard
apoc.convert.toMap(map :: ANY?) :: (MAP?)
Input parameters
Name Type Default
map
ANY?
null
Usage examples
Cypher
Convert node to map
Copy to Clipboard
Run in Neo4j Browser
CREATE (node:Node {id: 4})
RETURN apoc.convert.toMap(node) AS output;
Table 1. Results
output
{id: 4}
apoc.convert.toList
apoc.convert.toNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toList;"apoc.convert.toList
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.toList(value Any) - converts the given value into a list.
Signature
None
Copy to Clipboard
apoc.convert.toList(list :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)

CREATE (TomH)-[:ACTED_IN {roles:['Joe Fox']}]->(YouveGotMail);
We can find all the ACTED_IN paths by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[:ACTED_IN]->()
RETURN path;
Table 1. Results
path
(:Person {name: ""Keanu Reeves"", born: 1964})-[:ACTED_IN {roles: [""Neo""]}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999})
(:Person {name: ""Keanu Reeves"", born: 1964})-[:ACTED_IN {roles: [""Neo""]}]→(:Movie {tagline: ""Free your mind"", title: ""The Matrix Reloaded"", released: 2003})
(:Person {name: ""Tom Hanks"", born: 1956})-[:ACTED_IN {roles: [""Joe Fox""]}]→(:Movie {tagline: ""At odds in life… in love on-line."", title: ""You’ve Got Mail"", released: 1998})
What if we want to take the first element from each path? We could try to do it like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[:ACTED_IN]->()
RETURN path[0];
Text
Results
Copy to Clipboard
Type mismatch: expected List<T> but was Path (line 3, column 8 (offset: 40))
""RETURN path[0];""
        ^
We can use apoc.convert.toList to convert the path to a list and then take the first item from that list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[:ACTED_IN]->()
RETURN apoc.convert.toList(path)[0];
Table 2. Results
apoc.convert.toList(path)[0]
(:Person {name: ""Keanu Reeves"", born: 1964})
(:Person {name: ""Keanu Reeves"", born: 1964})
(:Person {name: ""Tom Hanks"", born: 1956})
apoc.convert.toJson
apoc.convert.toMap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toJson;"apoc.convert.toJson
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.toJson(value Any) - serializes the given JSON value.
Signature
None
Copy to Clipboard
apoc.convert.toJson(value :: ANY?) :: (STRING?)
Input parameters
Name Type Default
value
ANY?
null
Usage examples
Cypher
Convert map to JSON
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.toJson({
  name: ""Michael"",
  time: datetime()
}) AS output;
Table 1. Results
Output
""{\""name\"":\""Michael\"",\""time\"":\""2020-11-03T12:05:50.963Z\""}""
Cypher
Convert node properties to JSON
Copy to Clipboard
Run in Neo4j Browser
CREATE (node:Node {id: 4, name: ""Foo""})
RETURN apoc.convert.toJson(properties(node)) AS output;
Table 2. Results
Output
""{\""name\"":\""Foo\"",\""id\"":4}""
Convert node to JSON
In case of node, will be returned a map with the id of the node, the array of labels and (if any) the properties.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:Foo:Foo2 {bar: 'baz', name: 'Sherlock'})
RETURN apoc.convert.toJson(a) AS output;
Table 3. Results
Output
""{""id"":""3"",""type"":""node"",""labels"":[""Foo"",""Foo2""],""properties"":{""bar"":""baz"",""name"":""Sherlock""}}""
Convert relationship to JSON
In case of node, will be returned a map with the id of the relationship, the relationship-type and (if any) the properties.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Foo)-[r:MY_REL {name: ""Sherlock"", surname: ""Holmes""}]->(:Bar)
RETURN apoc.convert.toJson(r) AS output;
Table 4. Results
Output
""{""id"":""0"",""type"":""relationship"",""label"":""MY_REL"",""start"":{""id"":""4"",""labels"":[""Foo""]},""end"":{""id"":""5"",""labels"":[""Bar""]},""properties"":{""surname"":""Holmes"",""name"":""Sherlock""}}""
Cypher
Convert path to JSON
Copy to Clipboard
Run in Neo4j Browser
CREATE p=(a:Test {foo: 7})-[:TEST]->(b:Baz {a:'b'})<-[:TEST_2 {aa:'bb'}]-(:Bar {one:'www', two:2, three: localdatetime('2020-01-01')})
RETURN apoc.convert.toJson(p) AS output;
Table 5. Results
Output
""[{""id"":""6"",""type"":""node"",""properties"":{""foo"":7},""labels"":[""Test""]},{""start"":{""id"":""6"",""properties"":{""foo"":7},""labels"":[""Test""]},""end"":{""id"":""7"",""properties"":{""a"":""b""},""labels"":[""Baz""]},""id"":""1"",""label"":""TEST"",""type"":""relationship""},{""id"":""7"",""type"":""node"",""properties"":{""a"":""b""},""labels"":[""Baz""]},{""start"":{""id"":""8"",""properties"":{""one"":""www"",""two"":2,""three"":""2020-01-01T00:00""},""labels"":[""Bar""]},""end"":{""id"":""7"",""properties"":{""a"":""b""},""labels"":[""Baz""]},""id"":""2"",""label"":""TEST_2"",""type"":""relationship"",""properties"":{""aa"":""bb""}},{""id"":""8"",""type"":""node"",""properties"":{""one"":""www"",""two"":2,""three"":""2020-01-01T00:00""},""labels"":[""Bar""]}]""
Cypher
Convert list of nodes to JSON
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:User {name:'Adam',age:42,male:true,kids:['Sam','Anna','Grace'], born:localdatetime('2015185T19:32:24'), place:point({latitude: 13.1, longitude: 33.46789})}),(b:User {name:'Jim',age:42}),(c:User {age:12}),(d:User),(e {pippo:'pluto'})
RETURN apoc.convert.toJson(collect(a)+b+c+d+e)
Table 6. Results
Output
""[{""id"":""23"",""type"":""node"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},{""id"":""24"",""type"":""node"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}},{""id"":""25"",""type"":""node"",""labels"":[""User""],""properties"":{""age"":12}},{""id"":""26"",""type"":""node"",""labels"":[""User""]},{""id"":""27"",""type"":""node"",""properties"":{""pippo"":""pluto""}}]""
apoc.convert.getJsonPropertyMap
apoc.convert.toList
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.getJsonPropertyMap;"apoc.convert.getJsonPropertyMap
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.getJsonPropertyMap(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into a Cypher map.
Signature
None
Copy to Clipboard
apoc.convert.getJsonPropertyMap(node :: NODE?, key :: STRING?, path =  :: STRING?, pathOptions = null :: LIST? OF STRING?) :: (MAP?)
Input parameters
Name Type Default
node
NODE?
null
key
STRING?
null
path
STRING?
pathOptions
LIST? OF STRING?
[]
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {json:'{a:[1,2,3]}'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN apoc.convert.getJsonPropertyMap(p, ""json"") AS output;
Table 1. Results
Output
{a: [1, 2, 3]}
Moreover, we can customize the Json path options, adding as third parameter (pathOptions) a list of strings, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So, with a (n:JsonPathNode {prop: '{""columns"":{""col2"":{""_id"":""772col2""}}}'}) we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:JsonPathNode) RETURN apoc.convert.getJsonPropertyMap(n, 'prop', '$.columns.col2') AS output;
Table 2. Results
output
{ ""_id"": ""772col2"" }
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:JsonPathNode) RETURN apoc.convert.getJsonPropertyMap(n, 'prop', '$.columns.col2', ['ALWAYS_RETURN_LIST']) AS path
Table 3. Results
Failed to invoke function apoc.convert.getJsonPropertyMap: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of java.util.LinkedHashMap<java.lang.Object,java.lang.Object> out of START_ARRAY token at [Source: UNKNOWN; line: -1, column: -1]
apoc.convert.getJsonProperty
apoc.convert.toJson
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.getJsonProperty;"apoc.convert.getJsonProperty
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.getJsonProperty(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into the equivalent Cypher structure (e.g. map, list).
Signature
None
Copy to Clipboard
apoc.convert.getJsonProperty(node :: NODE?, key :: STRING?, path =  :: STRING?, pathOptions = null :: LIST? OF STRING?) :: (ANY?)
Input parameters
Name Type Default
node
NODE?
null
key
STRING?
null
path
STRING?
pathOptions
LIST? OF STRING?
[]
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {json:'{a:[1,2,3]}'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN apoc.convert.getJsonProperty(p, ""json"") AS output;
Table 1. Results
Output
{a: [1, 2, 3]}
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN apoc.convert.getJsonProperty(p, ""json"", ""$.a"") AS output;
Table 2. Results
Output
[1, 2, 3]
Moreover, we can customize the Json path options, adding as third parameter (pathOptions) a list of strings, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So, with a (n:JsonPathNode {prop: '{""columns"":{""col2"":{""_id"":""772col2""}}}'}) we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:JsonPathNode) RETURN apoc.convert.getJsonProperty(n, 'prop', '$..columns') AS output;
Table 3. Results
output
[ {""col2"": { ""_id"": ""772col2"" }}, null, null ]
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:JsonPathNode) RETURN apoc.convert.getJsonProperty(n, 'prop', '$..columns',  ['ALWAYS_RETURN_LIST']) AS output;
Table 4. Results
Output
[ {""col2"": { ""_id"": ""772col2"" }} ]
apoc.convert.fromJsonMap
apoc.convert.getJsonPropertyMap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.fromJsonMap;"apoc.convert.fromJsonMap
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.fromJsonMap(map String, path String, pathOptions [String]) - converts the given JSON map into a Cypher map.
Signature
None
Copy to Clipboard
apoc.convert.fromJsonMap(map :: STRING?, path =  :: STRING?, pathOptions = null :: LIST? OF STRING?) :: (MAP?)
Input parameters
Name Type Default
map
STRING?
null
path
STRING?
pathOptions
LIST? OF STRING?
[]
Usage examples
The following converts a JSON map into a Cypher map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonMap('{""name"": ""Graph Data Science Library""}') AS output;
Table 1. Results
Output
{name: ""Graph Data Science Library""}
We can also use JSON path expressions to extract part of a JSON map. For example, the following extracts the product property from a JSON map and returns a map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonMap('{""product"": {""name"": ""Bloom""}}', '$.product') AS output;
Table 2. Results
Output
{name: ""Bloom""}
If we try to convert a non-map structure, we’ll get an exception. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonMap('[{""name"": ""Neo4j""}]') AS output;
Table 3. Results
Failed to invoke function apoc.convert.fromJsonMap: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of java.util.LinkedHashMap<java.lang.Object,java.lang.Object> out of START_ARRAY token at [Source: (String)""[{""name"": ""Neo4j""}]""; line: 1, column: 1]
In this case we should instead use apoc.convert.fromJsonList.
Moreover, we can customize the Json path options, adding as third parameter (pathOptions) a list of strings, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonMap('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$.columns.col2') AS output;
Table 4. Results
output
{ ""_id"": ""772col2"" }
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonMap('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$.columns.col2', ['ALWAYS_RETURN_LIST']) AS output;
Table 5. Results
Failed to invoke function apoc.convert.getJsonPropertyMap: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of java.util.LinkedHashMap<java.lang.Object,java.lang.Object> out of START_ARRAY token at [Source: UNKNOWN; line: -1, column: -1]
apoc.convert.fromJsonList
apoc.convert.getJsonProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.fromJsonList;"apoc.convert.fromJsonList
Contents
Signature
Input parameters
Usage examples
Function
apoc.convert.fromJsonList(list [String], path String, pathOptions [String]) - converts the given JSON list into a Cypher list.
Signature
None
Copy to Clipboard
apoc.convert.fromJsonList(list :: STRING?, path =  :: STRING?, pathOptions = null :: LIST? OF STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
STRING?
null
path
STRING?
pathOptions
LIST? OF STRING?
[]
Usage examples
The following converts a JSON list into a Cypher list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonList('[1,2,3]') AS output;
Table 1. Results
Output
[1, 2, 3]
We can also use JSON path expressions to extract part of a JSON list. For example, the following extracts the name property from a JSON list of objects and returns a list of Cypher strings:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonList('[
  {""name"": ""Neo4j""},
  {""name"": ""Graph Data Science Library""},
  {""name"": ""Bloom""}
]', '.name') AS output;
Table 2. Results
Output
[""Neo4j"", ""Graph Data Science Library"", ""Bloom""]
Moreover, we can customize the Json path options, adding as third parameter (pathOptions) a list of strings, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonList('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$..columns') AS output;
Table 3. Results
output
[ {""col2"": { ""_id"": ""772col2"" }}, null, null ]
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonList('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$..columns', ['ALWAYS_RETURN_LIST']) AS output;
Table 4. Results
output
[ {""col2"": { ""_id"": ""772col2"" }} ]
If we try to convert a non-list structure, we’ll get an exception. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.convert.fromJsonList('{""name"": ""Neo4j""}') AS output;
Table 5. Results
Failed to invoke function apoc.convert.fromJsonList: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of java.util.ArrayList<java.lang.Object> out of START_OBJECT token at [Source: (String)""{""name"": ""Neo4j""}""; line: 1, column: 1]
In this case we should instead use apoc.convert.fromJsonMap.
apoc.convert.toTree
apoc.convert.fromJsonMap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.toTree;"apoc.convert.toTree
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage examples
Procedure
apoc.convert.toTree(paths [Path], lowerCaseRels Boolean, config Map<String, Any>) - returns a stream of maps, representing the given paths as a tree with at least one root.
Signature
None
Copy to Clipboard
apoc.convert.toTree(paths :: LIST? OF PATH?, lowerCaseRels = true :: BOOLEAN?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
paths
LIST? OF PATH?
null
lowerCaseRels
BOOLEAN?
true
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
nodes
Map<String, List<String>>
{}
properties to include for each node label e.g. {Movie: ['title']} or to exclude (e.g. {Movie: ['-title']}).
rels
Map<String, List<String>>
{}
properties to include for each relationship type e.g. {`ACTED_IN: [""roles""]}` or to exclude (e.g. {`ACTED_IN: [""-roles""]}`).
sortPaths
boolean
true
to sort the result by path length
Output parameters
Name Type
value
MAP?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (TomT:Person {name:'Tom Tykwer', born:1965})
CREATE (JamesThompson:Person {name:'James Thompson'})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)
 (TomT)-[:]->(CloudAtlas)

 (JamesThompson)-[: {summary:, rating:}]->(TheMatrix)
 (JamesThompson)-[: {summary:, rating:}]->(TheMatrixReloaded)
 (JamesThompson)-[: {summary:, rating:}]->(TheMatrixRevolutions);
View all (16 more lines)
The following converts a list of paths of Keanu Reeves movies into a nested map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p:Person {name: ""Keanu Reeves""})-[:ACTED_IN]->(movie)
WITH collect(path) AS paths
CALL apoc.convert.toTree(paths)
YIELD value
RETURN value;
Table 2. Results
value
Json
Copy to Clipboard
{
   ""_type"":""Person"",
   ""name"":""Keanu Reeves"",
   ""acted_in"":[
      {
         ""acted_in.roles"":[
            ""Kevin Lomax""
         ],
         ""_type"":""Movie"",
         ""tagline"":""Evil has its winning ways"",
         ""_id"":34,
         ""title"":""The Devil's Advocate"",
         ""released"":1997
      },
      {
         :,
         :,
         :,
         :[
            
         ],
         :
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      }
   ],
   :,
   :
}
View all (42 more lines)
By default, relationship types are converted to lower case. We can keep their normal casing by passing in false for the 2nd parameter (lowerCaseRels):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p:Person {name: ""Keanu Reeves""})-[:ACTED_IN]->(movie)
WITH collect(path) AS paths
CALL apoc.convert.toTree(paths, false)
YIELD value
RETURN value;
Table 3. Results
value
Json
Copy to Clipboard
{
   ""_type"":""Person"",
   ""name"":""Keanu Reeves"",
   ""ACTED_IN"":[
      {
         ""ACTED_IN.roles"":[
            ""Kevin Lomax""
         ],
         ""_type"":""Movie"",
         ""tagline"":""Evil has its winning ways"",
         ""_id"":34,
         ""title"":""The Devil's Advocate"",
         ""released"":1997
      },
      {
         :,
         :,
         :,
         :,
         :[
            
         ]
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      },
      {
         :[
            
         ],
         :,
         :,
         :,
         :,
         :
      }
   ],
   :,
   :
}
View all (42 more lines)
By default, all properties are included for node labels and relationship types. We can limit the properties for nodes using the nodes config key and for relationship types using the rels config key.
If we want to return only the title of each of Keanu Reeves' movies, we can do this using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p:Person {name: ""Keanu Reeves""})-[:ACTED_IN]->(movie)
WITH collect(path) AS paths
CALL apoc.convert.toTree(paths, true, {
  nodes: {Movie: ['title']}
})
YIELD value
RETURN value;
Table 4. Results
value
Json
Copy to Clipboard
{
   ""_type"":""Person"",
   ""name"":""Keanu Reeves"",
   ""acted_in"":[
      {
         ""_type"":""Movie"",
         ""_id"":34,
         ""title"":""The Devil's Advocate"",
         ""acted_in.roles"":[
            ""Kevin Lomax""
         ]
      },
      {
         ""_type"":""Movie"",
         ""_id"":33,
         :,
         :[
            
         ]
      },
      {
         :,
         :,
         :,
         :[
            
         ]
      },
      {
         :,
         :,
         :,
         :[
            
         ]
      },
      {
         :,
         :,
         :,
         :[
            
         ]
      }
   ],
   :,
   :
}
View all (33 more lines)
And if we want to return only the rating of movies reviewed by James Thompson, we can do this using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p:Person {name:'James Thompson'})-[:REVIEWED]->(movie)
WITH collect(path) AS paths
CALL apoc.convert.toTree(paths, true, {
  nodes: {Movie: ['title']},
  rels:  {reviewed: ['rating']}
})
YIELD value
RETURN value;
Table 5. Results
value
Json
Copy to Clipboard
{
   ""_type"":""Person"",
   ""name"":""James Thompson"",
   ""reviewed"":[
      {
         ""_type"":""Movie"",
         ""_id"":43,
         ""reviewed.rating"":95,
         ""title"":""The Matrix""
      },
      {
         ""_type"":""Movie"",
         ""_id"":45,
         ""reviewed.rating"":100,
         ""title"":""The Matrix Revolutions""
      },
      {
         :,
         :,
         :,
         :
      }
   ],
   :
}
View all (10 more lines)
On the other hand, we can also include everything and specify certain nodes/relationships to exclude. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p:Person {name:'James Thompson'})-[:REVIEWED]->(movie)
WITH collect(path) AS paths
CALL apoc.convert.toTree(paths, true, {
  nodes: {Movie: ['-title']},
  rels:  {reviewed: ['-rating']}
})
YIELD value
RETURN value;
Table 6. Results
value
Json
Copy to Clipboard
{
  ""_type"": ""Person"",
  ""name"": ""James Thompson"",
  ""reviewed"": [
    {
      ""_type"": ""Movie"",
      ""tagline"": ""Everything that has a beginning has an end"",
      ""reviewed.summary"": ""The best of the three"",
      ""_id"": 6,
      ""released"": 2003
    },
    {
      ""_type"": ""Movie"",
      ""tagline"": ""Free your mind"",
      ""reviewed.summary"": ""It was alright."",
      : ,
      : 
    },
    {
      : ,
      : ,
      : ,
      : ,
      : 
    }
  ],
  : 
}
View all (14 more lines)
apoc.convert.setJsonProperty
apoc.convert.fromJsonList
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert/apoc.convert.setJsonProperty;"apoc.convert.setJsonProperty
Contents
Signature
Input parameters
Usage examples
Procedure
apoc.convert.setJsonProperty(node Node, key String, value Any) - serializes the given JSON object and sets it as a property on the given node.
Signature
None
Copy to Clipboard
apoc.convert.setJsonProperty(node :: NODE?, key :: STRING?, value :: ANY?) :: VOID
Input parameters
Name Type Default
node
NODE?
null
key
STRING?
null
value
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {json:'{a:[1,2,3]}'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
CALL apoc.convert.setJsonProperty(p, 'json', {a: [4,5,6]})
RETURN p
Table 1. Results
p
(:Person {json: ""{\""a\"":[4,5,6]}""})
We can extract the JSON value from the node using apoc.convert.getJsonPropertyMap:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN apoc.convert.getJsonPropertyMap(p, ""json"") AS map;
Table 2. Results
map
{a: [4, 5, 6]}
apoc.convert
apoc.convert.toTree
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.convert;"apoc.convert
Contents
Signature
Qualified Name Type
apoc.convert.setJsonProperty
apoc.convert.setJsonProperty(node Node, key String, value Any) - serializes the given JSON object and sets it as a property on the given node.
Procedure
apoc.convert.toTree
apoc.convert.toTree(paths [Path], lowerCaseRels Boolean, config Map<String, Any>) - returns a stream of maps, representing the given paths as a tree with at least one root.
Procedure
apoc.convert.fromJsonList
apoc.convert.fromJsonList(list [String], path String, pathOptions [String]) - converts the given JSON list into a Cypher list.
Function
apoc.convert.fromJsonMap
apoc.convert.fromJsonMap(map String, path String, pathOptions [String]) - converts the given JSON map into a Cypher map.
Function
apoc.convert.getJsonProperty
apoc.convert.getJsonProperty(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into the equivalent Cypher structure (e.g. map, list).
Function
apoc.convert.getJsonPropertyMap
apoc.convert.getJsonPropertyMap(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into a Cypher map.
Function
apoc.convert.toJson
apoc.convert.toJson(value Any) - serializes the given JSON value.
Function
apoc.convert.toList
apoc.convert.toList(value Any) - converts the given value into a list.
Function
apoc.convert.toMap
apoc.convert.toMap(map Any) - converts the given value into a map.
Function
apoc.convert.toNode
apoc.convert.toNode(node Any) - converts the given value into a node.
Function
apoc.convert.toNodeList
apoc.convert.toNodeList(list [Any]) - converts the given value into a list of nodes.
Function
apoc.convert.toRelationship
apoc.convert.toRelationship(rel Any) - converts the given value into a relationship.
Function
apoc.convert.toRelationshipList
apoc.convert.toRelationshipList(relList [Any]) - converts the given value into a list of relationships.
Function
apoc.convert.toSet
apoc.convert.toSet(list [Any]) - converts the given value into a set.
Function
apoc.convert.toSortedJsonMap
apoc.convert.toSortedJsonMap(value Any, ignoreCase Boolean) - converts a serialized JSON object from the property of a given node into a Cypher map.
Signature
Function
apoc.coll.zip
apoc.convert.setJsonProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.zip;"apoc.coll.zip
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.zip(list1 [Any], list2 [Any]) - returns the two given lists zipped together as a list of lists.
Signature
None
Copy to Clipboard
apoc.coll.zip(list1 :: LIST? OF ANY?, list2 :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list1
LIST? OF ANY?
null
list2
LIST? OF ANY?
null
Usage examples
The following combines two lists, element for element, into a list of lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.zip([1,2,3], [""a"", ""b"", ""c""]) as output;
Table 1. Results
Output
[[1, ""a""], [2, ""b""], [3, ""c""]]
apoc.coll.unionAll
apoc.convert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.unionAll;"apoc.coll.unionAll
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.unionAll(list1 [Any], list2 [Any]) - returns the full union of the two given lists (duplicates included).
Signature
None
Copy to Clipboard
apoc.coll.unionAll(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following creates the full union of two lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.unionAll([1,2,3,4,5], [3,4,5,6,7]) AS output;
Table 1. Results
Output
[1, 2, 3, 4, 5, 3, 4, 5, 6, 7]
apoc.coll.union
apoc.coll.zip
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.union;"apoc.coll.union
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.union(list1 [Any], list2 [Any]) - returns the distinct union of the two given lists.
Signature
None
Copy to Clipboard
apoc.coll.union(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following creates a distinct union of two lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.union([1,2,3,4,5], [3,4,5,6,7]) AS output;
Table 1. Results
Output
[1, 2, 3, 4, 5, 6, 7]
apoc.coll.toSet
apoc.coll.unionAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.toSet;"apoc.coll.toSet
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.toSet(coll [Any]) - returns a unique list from the given list.
Signature
None
Copy to Clipboard
apoc.coll.toSet(values :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage examples
The following converts a list to a set:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.toSet([1,1,2,1,3,4,1]) AS output;
Table 1. Results
Output
[1, 2, 3, 4]
apoc.coll.sumLongs
apoc.coll.union
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sumLongs;"apoc.coll.sumLongs
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sumLongs(coll [Number]) - returns the sum of all the numbers in the list.
Signature
None
Copy to Clipboard
apoc.coll.sumLongs(numbers :: LIST? OF NUMBER?) :: (INTEGER?)
Input parameters
Name Type Default
numbers
LIST? OF NUMBER?
null
Usage examples
The following computes the sum of numeric values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sumLongs([1,2,3,4,5]) AS output;
Table 1. Results
Output
15
apoc.coll.sum
apoc.coll.toSet
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sum;"apoc.coll.sum
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sum(coll [Number]) - returns the sum of all the numbers in the list.
Signature
None
Copy to Clipboard
apoc.coll.sum(numbers :: LIST? OF NUMBER?) :: (FLOAT?)
Input parameters
Name Type Default
numbers
LIST? OF NUMBER?
null
Usage examples
The following computes the sum of values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sum([1,2,3,4,5]) AS output;
Table 1. Results
Output
15.0
apoc.coll.subtract
apoc.coll.sumLongs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.subtract;"apoc.coll.subtract
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.subtract(list1 [Any], list2 [Any]) - returns the first list as a set with all the elements of the second list removed.
Signature
None
Copy to Clipboard
apoc.coll.subtract(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following returns unique set of first list with all elements of second list removed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.subtract([1,2,3,4,5,6,6], [3,4,5]) AS output;
Table 1. Results
Output
[1, 2, 6]
apoc.coll.stdev
apoc.coll.sum
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.stdev;"apoc.coll.stdev
Contents
Signature
Input parameters
Function
apoc.coll.stdev(list [Number], isBiasCorrected Boolean) - returns sample or population standard deviation with isBiasCorrected true or false respectively.
Signature
None
Copy to Clipboard
apoc.coll.stdev(list :: LIST? OF NUMBER?, isBiasCorrected = true :: BOOLEAN?) :: (NUMBER?)
Input parameters
Name Type Default
list
LIST? OF NUMBER?
null
isBiasCorrected
BOOLEAN?
true
apoc.coll.sortText
apoc.coll.subtract
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sortText;"apoc.coll.sortText
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sortText(coll [String], conf Map<String, Any>) - sorts the given list of strings into ascending order.
Signature
None
Copy to Clipboard
apoc.coll.sortText(coll :: LIST? OF STRING?, conf = {} :: MAP?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF STRING?
null
conf
MAP?
{}
Usage examples
The following sort a list of strings:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// n.b. if no locale is provided it takes the default of the machine where neo4j is running on
RETURN apoc.coll.sortText(['Єльська', 'Гусак'], {locale: 'ru'}) as output;
Table 1. Results
Output
Гусак
Єльська
apoc.coll.sortNodes
apoc.coll.stdev
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sortNodes;"apoc.coll.sortNodes
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sortNodes(coll [Node], prop String) - sorts the given list of nodes by their property into ascending order.
Signature
None
Copy to Clipboard
apoc.coll.sortNodes(coll :: LIST? OF NODE?, prop :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF NODE?
null
prop
STRING?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (TomT:Person {name:'Tom Tykwer', born:1965});
The following sorts a collection of nodes by the name property in descending order:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WITH collect(person) AS people
RETURN apoc.coll.sortNodes(people, 'name') AS output;
Table 1. Results
Output
[(:Person {name: ""Tom Tykwer"", born: 1965}), (:Person {name: ""Tom Hanks"", born: 1956}), (:Person {name: ""Keanu Reeves"", born: 1964})]
The following sorts a collection of nodes by the name property in ascending order:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WITH collect(person) AS people
RETURN apoc.coll.sortNodes(people, '^name') AS output;
Table 2. Results
Output
[(:Person {name: ""Keanu Reeves"", born: 1964}), (:Person {name: ""Tom Hanks"", born: 1956}), (:Person {name: ""Tom Tykwer"", born: 1965})]
apoc.coll.sortMulti
apoc.coll.sortText
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sortMulti;"apoc.coll.sortMulti
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sortMulti(coll [Map<String, Any>], orderFields [String], limit Integer, skip Integer) - sorts the given list of maps by the given fields. To indicate that a field should be sorted according to ascending values, prefix it with a caret (^). It is also possible to add limits to the list and to skip values.
Signature
None
Copy to Clipboard
apoc.coll.sortMulti(coll :: LIST? OF MAP?, orderFields = [] :: LIST? OF STRING?, limit = -1 :: INTEGER?, skip = 0 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF MAP?
null
orderFields
LIST? OF STRING?
[]
limit
INTEGER?
-1
skip
INTEGER?
0
Usage examples
The following sorts a list of maps by the name property in ascending order:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMulti([
  {name:'graphs'},
  {name:'are',age:32},
  {name:'everywhere',age:42}
], ['^name']) as output;
Table 1. Results
Output
[{name: ""are"", age: 32}, {name: ""everywhere"", age: 42}, {name: ""graphs""}]
The following sorts a list of maps by the name property in ascending order and then the age property in descending order:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMulti([
  {name:'graphs'},
  {name:'are',age:32},
  {name:'are',age:21},
  {name:'everywhere'}
], ['^name', 'age']) as output;
Table 2. Results
Output
[{name: ""are"", age: 32}, {name: ""are"", age: 21}, {name: ""everywhere""}, {name: ""graphs""}]
The following sorts a list of maps by the name property in ascending order and returns only one value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMulti([
  {name:'graphs'},
  {name:'are'},
  {name:'everywhere'}
], ['^name'], 1) as output;
Table 3. Results
Output
[{name: ""are""}]
The following sorts a list of maps by the name property in ascending order and skips the first value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMulti([
  {name:'graphs'},
  {name:'are'},
  {name:'everywhere'}
], ['^name'], -1, 1) as output;
Table 4. Results
Output
[{name: ""everywhere""}, {name: ""graphs""}]
The following sorts a list of maps by the name property in ascending order, skips the first value, and returns only one value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMulti([
  {name:'graphs'},
  {name:'are'},
  {name:'everywhere'}
], ['^name'], 1, 1) as output;
Table 5. Results
Output
[{name: ""everywhere""}]
apoc.coll.sortMaps
apoc.coll.sortNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sortMaps;"apoc.coll.sortMaps
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sortMaps(list [Map<String, Any>], prop String) - sorts the given list into ascending order, based on the map property indicated by prop.
Signature
None
Copy to Clipboard
apoc.coll.sortMaps(coll :: LIST? OF MAP?, prop :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF MAP?
null
prop
STRING?
null
Usage examples
The following sorts a list of maps in reverse alphabetical order by the key name:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMaps([
    {name: ""Lionel Messi""},
    {name: ""Cristiano Ronaldo""},
    {name: ""Wayne Rooney""}
], ""name"") AS output;
Table 1. Results
Output
Json
Copy to Clipboard
[
    {
      ""name"": ""Wayne Rooney""
    }
    ,
    {
      ""name"": ""Lionel Messi""
    }
    ,
    {
      ""name"": ""Cristiano Ronaldo""
    }
]
The following sorts a list of maps in alphabetical order by the key name:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sortMaps([
    {name: ""Lionel Messi""},
    {name: ""Cristiano Ronaldo""},
    {name: ""Wayne Rooney""}
], ""^name"") AS output;
Table 2. Results
Output
Json
Copy to Clipboard
[
    {
      ""name"": ""Cristiano Ronaldo""
    }
    ,
    {
      ""name"": ""Lionel Messi""
    }
    ,
    {
      ""name"": ""Wayne Rooney""
    }
]
apoc.coll.sort
apoc.coll.sortMulti
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.sort;"apoc.coll.sort
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.sort(coll [Any]) - sorts the given list into ascending order.
Signature
None
Copy to Clipboard
apoc.coll.sort(coll :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following sorts a collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.sort([5,4,2,3,1]) AS output;
Table 1. Results
Output
[1, 2, 3, 4, 5]
apoc.coll.shuffle
apoc.coll.sortMaps
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.shuffle;"apoc.coll.shuffle
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.shuffle(coll [Any]) - returns the list shuffled.
Signature
None
Copy to Clipboard
apoc.coll.shuffle(coll :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following shuffles a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.shuffle([1,3,5,7,9]) AS output;
Table 1. Results
Output
[7, 5, 9, 3, 1]
apoc.coll.set
apoc.coll.sort
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.set;"apoc.coll.set
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.set(coll [Any], index Integer, value Any) - sets the element at the given index to the new value.
Signature
None
Copy to Clipboard
apoc.coll.set(coll :: LIST? OF ANY?, index :: INTEGER?, value :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
index
INTEGER?
null
value
ANY?
null
Usage examples
The following replaces the item at index 4 with the value 11:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.set([1,3,5,7,9], 4, 11) AS output;
Table 1. Results
Output
[1, 3, 5, 7, 11]
apoc.coll.runningTotal
apoc.coll.shuffle
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.runningTotal;"apoc.coll.runningTotal
Contents
Signature
Input parameters
Function
apoc.coll.runningTotal(list [Number]) - returns an accumulative array.
Signature
None
Copy to Clipboard
apoc.coll.runningTotal(list :: LIST? OF NUMBER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
LIST? OF NUMBER?
null
apoc.coll.removeAll
apoc.coll.set
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.removeAll;"apoc.coll.removeAll
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.removeAll(list1 [Any], list2 [Any]) - returns the first list with all elements of the second list removed.
Signature
None
Copy to Clipboard
apoc.coll.removeAll(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following returns first list with all elements of second list removed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.removeAll([1,2,3,4,5,6,6], [3,4,5]) AS output;
Table 1. Results
Output
[1, 2, 6, 6]
apoc.coll.remove
apoc.coll.runningTotal
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.remove;"apoc.coll.remove
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.remove(coll [Any], index Integer, length Integer) - removes a range of values from the list, beginning at position index for the given length of values.
Signature
None
Copy to Clipboard
apoc.coll.remove(coll :: LIST? OF ANY?, index :: INTEGER?, length = 1 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
index
INTEGER?
null
length
INTEGER?
1
Usage examples
The following removes 2 values, starting from index 1:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.remove([1,3,5,7,9], 1, 2) AS output;
Table 1. Results
Output
[1, 7, 9]
apoc.coll.randomItems
apoc.coll.removeAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.randomItems;"apoc.coll.randomItems
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.randomItems(coll [Any], itemCount Integer, allowRepick Boolean) - returns a list of itemCount random items from the original list (optionally allowing elements in the original list to be selected more than once).
Signature
None
Copy to Clipboard
apoc.coll.randomItems(coll :: LIST? OF ANY?, itemCount :: INTEGER?, allowRepick = false :: BOOLEAN?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
itemCount
INTEGER?
null
allowRepick
BOOLEAN?
false
Usage examples
The following returns 2 random values from a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.randomItems([1,3,5,7,9], 2) AS output;
Table 1. Results
Output
[5, 3]
apoc.coll.randomItem
apoc.coll.remove
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.randomItem;"apoc.coll.randomItem
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.randomItem(coll [Any])- returns a random item from the list, or null on an empty or null list.
Signature
None
Copy to Clipboard
apoc.coll.randomItem(coll :: LIST? OF ANY?) :: (ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following returns a random value from a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.randomItem([1,3,5,7,9]) AS output;
Table 1. Results
Output
7
apoc.coll.partition
apoc.coll.randomItems
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.partition;"apoc.coll.partition
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.partition(coll [Any], batchSize Integer) - partitions the original list into sub-lists of the given batch size. The final list may be smaller than the given batch size.
Signature
None
Copy to Clipboard
apoc.coll.partition(values :: LIST? OF ANY?, batchSize :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
batchSize
INTEGER?
null
Usage examples
The following partitions a list into sublists of size 2:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.coll.partition([1,2,3,4,5], 2);
Table 1. Results
Value
[1, 2]
[3, 4]
[5]
apoc.coll.elements
apoc.coll.split
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.elements;"apoc.coll.elements
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.coll.elements(coll [Any], limit Integer, offset Integer) - deconstructs a list of mixed types into identifiers indicating their specific type.
Signature
None
Copy to Clipboard
apoc.coll.elements(values :: LIST? OF ANY?, limit = -1 :: INTEGER?, offset = 0 :: INTEGER?) :: (_1 :: ANY?, _2 :: ANY?, _3 :: ANY?, _4 :: ANY?, _5 :: ANY?, _6 :: ANY?, _7 :: ANY?, _8 :: ANY?, _9 :: ANY?, _10 :: ANY?, _1s :: STRING?, _2s :: STRING?, _3s :: STRING?, _4s :: STRING?, _5s :: STRING?, _6s :: STRING?, _7s :: STRING?, _8s :: STRING?, _9s :: STRING?, _10s :: STRING?, _1i :: INTEGER?, _2i :: INTEGER?, _3i :: INTEGER?, _4i :: INTEGER?, _5i :: INTEGER?, _6i :: INTEGER?, _7i :: INTEGER?, _8i :: INTEGER?, _9i :: INTEGER?, _10i :: INTEGER?, _1f :: FLOAT?, _2f :: FLOAT?, _3f :: FLOAT?, _4f :: FLOAT?, _5f :: FLOAT?, _6f :: FLOAT?, _7f :: FLOAT?, _8f :: FLOAT?, _9f :: FLOAT?, _10f :: FLOAT?, _1b :: BOOLEAN?, _2b :: BOOLEAN?, _3b :: BOOLEAN?, _4b :: BOOLEAN?, _5b :: BOOLEAN?, _6b :: BOOLEAN?, _7b :: BOOLEAN?, _8b :: BOOLEAN?, _9b :: BOOLEAN?, _10b :: BOOLEAN?, _1l :: LIST? OF ANY?, _2l :: LIST? OF ANY?, _3l :: LIST? OF ANY?, _4l :: LIST? OF ANY?, _5l :: LIST? OF ANY?, _6l :: LIST? OF ANY?, _7l :: LIST? OF ANY?, _8l :: LIST? OF ANY?, _9l :: LIST? OF ANY?, _10l :: LIST? OF ANY?, _1m :: MAP?, _2m :: MAP?, _3m :: MAP?, _4m :: MAP?, _5m :: MAP?, _6m :: MAP?, _7m :: MAP?, _8m :: MAP?, _9m :: MAP?, _10m :: MAP?, _1n :: NODE?, _2n :: NODE?, _3n :: NODE?, _4n :: NODE?, _5n :: NODE?, _6n :: NODE?, _7n :: NODE?, _8n :: NODE?, _9n :: NODE?, _10n :: NODE?, _1r :: RELATIONSHIP?, _2r :: RELATIONSHIP?, _3r :: RELATIONSHIP?, _4r :: RELATIONSHIP?, _5r :: RELATIONSHIP?, _6r :: RELATIONSHIP?, _7r :: RELATIONSHIP?, _8r :: RELATIONSHIP?, _9r :: RELATIONSHIP?, _10r :: RELATIONSHIP?, _1p :: PATH?, _2p :: PATH?, _3p :: PATH?, _4p :: PATH?, _5p :: PATH?, _6p :: PATH?, _7p :: PATH?, _8p :: PATH?, _9p :: PATH?, _10p :: PATH?, elements :: INTEGER?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
limit
INTEGER?
-1
offset
INTEGER?
0
Output parameters
Name Type
_1
ANY?
_2
ANY?
_3
ANY?
_4
ANY?
_5
ANY?
_6
ANY?
_7
ANY?
_8
ANY?
_9
ANY?
_10
ANY?
_1s
STRING?
_2s
STRING?
_3s
STRING?
_4s
STRING?
_5s
STRING?
_6s
STRING?
_7s
STRING?
_8s
STRING?
_9s
STRING?
_10s
STRING?
_1i
INTEGER?
_2i
INTEGER?
_3i
INTEGER?
_4i
INTEGER?
_5i
INTEGER?
_6i
INTEGER?
_7i
INTEGER?
_8i
INTEGER?
_9i
INTEGER?
_10i
INTEGER?
_1f
FLOAT?
_2f
FLOAT?
_3f
FLOAT?
_4f
FLOAT?
_5f
FLOAT?
_6f
FLOAT?
_7f
FLOAT?
_8f
FLOAT?
_9f
FLOAT?
_10f
FLOAT?
_1b
BOOLEAN?
_2b
BOOLEAN?
_3b
BOOLEAN?
_4b
BOOLEAN?
_5b
BOOLEAN?
_6b
BOOLEAN?
_7b
BOOLEAN?
_8b
BOOLEAN?
_9b
BOOLEAN?
_10b
BOOLEAN?
_1l
LIST? OF ANY?
_2l
LIST? OF ANY?
_3l
LIST? OF ANY?
_4l
LIST? OF ANY?
_5l
LIST? OF ANY?
_6l
LIST? OF ANY?
_7l
LIST? OF ANY?
_8l
LIST? OF ANY?
_9l
LIST? OF ANY?
_10l
LIST? OF ANY?
_1m
MAP?
_2m
MAP?
_3m
MAP?
_4m
MAP?
_5m
MAP?
_6m
MAP?
_7m
MAP?
_8m
MAP?
_9m
MAP?
_10m
MAP?
_1n
NODE?
_2n
NODE?
_3n
NODE?
_4n
NODE?
_5n
NODE?
_6n
NODE?
_7n
NODE?
_8n
NODE?
_9n
NODE?
_10n
NODE?
_1r
RELATIONSHIP?
_2r
RELATIONSHIP?
_3r
RELATIONSHIP?
_4r
RELATIONSHIP?
_5r
RELATIONSHIP?
_6r
RELATIONSHIP?
_7r
RELATIONSHIP?
_8r
RELATIONSHIP?
_9r
RELATIONSHIP?
_10r
RELATIONSHIP?
_1p
PATH?
_2p
PATH?
_3p
PATH?
_4p
PATH?
_5p
PATH?
_6p
PATH?
_7p
PATH?
_8p
PATH?
_9p
PATH?
_10p
PATH?
elements
INTEGER?
Usage Examples
The following deconstructs a list of 3 values into identifiers of the correct type:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.coll.elements([9, true, ""Neo4j""])
YIELD _1, _1s, _1i, _1b, _1l, _1m, _1n, _1r, _1p,
      _2, _2s, _2i, _2b, _2l, _2m, _2n, _2r, _2p,
      _3, _3s, _3i, _3b, _3l, _3m, _3n, _3r, _3p
RETURN _1, _1s, _1i, _1b, _1l, _1m, _1n, _1r, _1p,
       _2, _2s, _2i, _2b, _2l, _2m, _2n, _2r, _2p,
       _3, _3s, _3i, _3b, _3l, _3m, _3n, _3r, _3p;
The output below would usually be in one table, but for readability we format it into multiple tables
Table 1. Results
_1 _1s _1i _1b _1l _1m _1n _1r _1p
9
NULL
9
NULL
NULL
NULL
NULL
NULL
NULL
Table 2. Results
_2 _2s _2i _2b _2l _2m _2n _2r _2p
TRUE
NULL
NULL
TRUE
NULL
NULL
NULL
NULL
NULL
Table 3. Results
_3 _3s _3i _3b _3l _3m _3n _3r _3p
""Neo4j""
""Neo4j""
NULL
NULL
NULL
NULL
NULL
NULL
NULL
apoc.coll
apoc.coll.partition
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll;"apoc.coll
Qualified Name Type
apoc.coll.elements
apoc.coll.elements(coll [Any], limit Integer, offset Integer) - deconstructs a list of mixed types into identifiers indicating their specific type.
Procedure
apoc.coll.split
apoc.coll.split(coll [Any], value Any) - splits a collection by the given value. The value itself will not be part of the resulting lists.
Procedure
apoc.coll.zipToRows
apoc.coll.zipToRows(list1 [Any], list2 [Any]) - returns the two lists zipped together, with one row per zipped pair.
Procedure
apoc.coll.avg
apoc.coll.avg(coll [Number]) - returns the average of the numbers in the list.
Function
apoc.coll.combinations
apoc.coll.combinations(coll [Any], minSelect Integer, maxSelect Integer) - returns a collection of all combinations of list elements between the selection size minSelect and maxSelect (default: minSelect).
Function
apoc.coll.contains
apoc.coll.contains(coll [Any], value Any) - returns whether or not the given value exists in the given collection (using a HashSet).
Function
apoc.coll.containsAll
apoc.coll.containsAll(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values exist in the given collection (using a HashSet).
Function
apoc.coll.containsAllSorted
apoc.coll.containsAllSorted(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values in the second list exist in an already sorted collection (using a binary search).
Function
apoc.coll.containsDuplicates
apoc.coll.containsDuplicates(coll [Any]) - returns true if a collection contains duplicate elements.
Function
apoc.coll.containsSorted
apoc.coll.containsSorted(coll [Any], value Any) - returns whether or not the given value exists in an already sorted collection (using a binary search).
Function
apoc.coll.different
apoc.coll.different(coll [Any]) - returns true if any of the values in the given list are different.
Function
apoc.coll.disjunction
apoc.coll.disjunction(list1 [Any], list2[Any]) - returns the disjunct set of two lists.
Function
apoc.coll.dropDuplicateNeighbors
apoc.coll.dropDuplicateNeighbors(list [Any]) - removes duplicate consecutive objects in the list.
Function
apoc.coll.duplicates
apoc.coll.duplicates(coll [Any]) - returns a list of duplicate items in the collection.
Function
apoc.coll.duplicatesWithCount
apoc.coll.duplicatesWithCount(coll [Any]) - returns a list of duplicate items in the collection and their count, keyed by item and count.
Function
apoc.coll.fill
apoc.coll.fill(items String, count Integer) - returns a list with the given count of items.
Function
apoc.coll.flatten
apoc.coll.flatten(coll [Any], recursive Boolean) - flattens the given list (to flatten nested lists, set recursive to true).
Function
apoc.coll.frequencies
apoc.coll.frequencies(coll [Any]) - returns a list of frequencies of the items in the collection, keyed by item and count.
Function
apoc.coll.frequenciesAsMap
apoc.coll.frequenciesAsMap(coll [Any]) - returns a map of frequencies of the items in the collection, keyed by item and count.
Function
apoc.coll.indexOf
apoc.coll.indexOf(coll [Any], value Any) - returns the index for the first occurrence of the specified value in the list.
Function
apoc.coll.insert
apoc.coll.insert(coll [Any], index Integer, value Any) - inserts a value into the specified index in the list.
Function
apoc.coll.insertAll
apoc.coll.insertAll(coll [Any], index Integer, values [Any]) - inserts all of the values into the list, starting at the specified index.
Function
apoc.coll.intersection
apoc.coll.intersection(list1 [Any], list2[Any]) - returns the distinct intersection of two lists.
Function
apoc.coll.isEqualCollection
apoc.coll.isEqualCollection(coll [Any], values [Any]) - returns true if the two collections contain the same elements with the same cardinality in any order (using a HashMap).
Function
apoc.coll.max
apoc.coll.max(values [Any]) - returns the maximum of all values in the given list.
Function
apoc.coll.min
apoc.coll.min(values [Any]) - returns the minimum of all values in the given list.
Function
apoc.coll.occurrences
apoc.coll.occurrences(coll [Any], item Any) - returns the count of the given item in the collection.
Function
apoc.coll.pairs
apoc.coll.pairs(list [Any]) - returns a list of adjacent elements in the list ([1,2],[2,3],[3,null]).
Function
apoc.coll.pairsMin
apoc.coll.pairsMin(list [Any]) - returns lists of adjacent elements in the list ([1,2],[2,3]), skipping the final element.
Function
apoc.coll.pairWithOffset
apoc.coll.pairWithOffset(coll [Any], offset Integer) - returns a list of pairs defined by the offset.
Function
apoc.coll.partition
apoc.coll.partition(coll [Any], batchSize Integer) - partitions the original list into sub-lists of the given batch size. The final list may be smaller than the given batch size.
Function
apoc.coll.randomItem
apoc.coll.randomItem(coll [Any])- returns a random item from the list, or null on an empty or null list.
Function
apoc.coll.randomItems
apoc.coll.randomItems(coll [Any], itemCount Integer, allowRepick Boolean) - returns a list of itemCount random items from the original list (optionally allowing elements in the original list to be selected more than once).
Function
apoc.coll.remove
apoc.coll.remove(coll [Any], index Integer, length Integer) - removes a range of values from the list, beginning at position index for the given length of values.
Function
apoc.coll.removeAll
apoc.coll.removeAll(list1 [Any], list2 [Any]) - returns the first list with all elements of the second list removed.
Function
apoc.coll.runningTotal
apoc.coll.runningTotal(list [Number]) - returns an accumulative array.
Function
apoc.coll.set
apoc.coll.set(coll [Any], index Integer, value Any) - sets the element at the given index to the new value.
Function
apoc.coll.shuffle
apoc.coll.shuffle(coll [Any]) - returns the list shuffled.
Function
apoc.coll.sort
apoc.coll.sort(coll [Any]) - sorts the given list into ascending order.
Function
apoc.coll.sortMaps
apoc.coll.sortMaps(list [Map<String, Any>], prop String) - sorts the given list into ascending order, based on the map property indicated by prop.
Function
apoc.coll.sortMulti
apoc.coll.sortMulti(coll [Map<String, Any>], orderFields [String], limit Integer, skip Integer) - sorts the given list of maps by the given fields. To indicate that a field should be sorted according to ascending values, prefix it with a caret (^). It is also possible to add limits to the list and to skip values.
Function
apoc.coll.sortNodes
apoc.coll.sortNodes(coll [Node], prop String) - sorts the given list of nodes by their property into ascending order.
Function
apoc.coll.sortText
apoc.coll.sortText(coll [String], conf Map<String, Any>) - sorts the given list of strings into ascending order.
Function
apoc.coll.stdev
apoc.coll.stdev(list [Number], isBiasCorrected Boolean) - returns sample or population standard deviation with isBiasCorrected true or false respectively.
Function
apoc.coll.subtract
apoc.coll.subtract(list1 [Any], list2 [Any]) - returns the first list as a set with all the elements of the second list removed.
Function
apoc.coll.sum
apoc.coll.sum(coll [Number]) - returns the sum of all the numbers in the list.
Function
apoc.coll.sumLongs
apoc.coll.sumLongs(coll [Number]) - returns the sum of all the numbers in the list.
Function
apoc.coll.toSet
apoc.coll.toSet(coll [Any]) - returns a unique list from the given list.
Function
apoc.coll.union
apoc.coll.union(list1 [Any], list2 [Any]) - returns the distinct union of the two given lists.
Function
apoc.coll.unionAll
apoc.coll.unionAll(list1 [Any], list2 [Any]) - returns the full union of the two given lists (duplicates included).
Function
apoc.coll.zip
apoc.coll.zip(list1 [Any], list2 [Any]) - returns the two given lists zipped together as a list of lists.
Function
apoc.bitwise.op
apoc.coll.elements
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.different;"apoc.coll.different
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.different(coll [Any]) - returns true if any of the values in the given list are different.
Signature
None
Copy to Clipboard
apoc.coll.different(values :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage examples
The following indicates whether all values in a collection are different:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.different([1,3,5,7,9]) AS output;
Table 1. Results
Output
true
apoc.coll.containsSorted
apoc.coll.disjunction
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.containsSorted;"apoc.coll.containsSorted
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.containsSorted(coll [Any], value Any) - returns whether or not the given value exists in an already sorted collection (using a binary search).
Signature
None
Copy to Clipboard
apoc.coll.containsSorted(coll :: LIST? OF ANY?, value :: ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
value
ANY?
null
Usage examples
The following checks if a sorted collection contains a value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsSorted([1,4,5], 4) AS output;
Table 1. Results
Output
TRUE
This function will not work on unsorted collections, as shown in the example below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsSorted([1,5,4], 4) AS output;
Table 2. Results
Output
FALSE
If we want to find a value in an unsorted collection, see apoc.coll.contains.
apoc.coll.containsDuplicates
apoc.coll.different
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.contains;"apoc.coll.contains
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.contains(coll [Any], value Any) - returns whether or not the given value exists in the given collection (using a HashSet).
Signature
None
Copy to Clipboard
apoc.coll.contains(coll :: LIST? OF ANY?, value :: ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
value
ANY?
null
Usage examples
The following checks if a collection contains a value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.contains([1,2,3,4,5], 4) AS output;
Table 1. Results
Output
true
The following checks if a collection contains all the values from another collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.contains([1,2,3,4,5], [3,7]) AS output;
Table 2. Results
Output
false
apoc.coll.combinations
apoc.coll.containsAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.combinations;"apoc.coll.combinations
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.combinations(coll [Any], minSelect Integer, maxSelect Integer) - returns a collection of all combinations of list elements between the selection size minSelect and maxSelect (default: minSelect).
Signature
None
Copy to Clipboard
apoc.coll.combinations(coll :: LIST? OF ANY?, minSelect :: INTEGER?, maxSelect = -1 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
minSelect
INTEGER?
null
maxSelect
INTEGER?
-1
Usage examples
The following returns a collection of all combinations of list elements of selection size between 3 and 4 elements:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.combinations([1,3,5,7,9], 3, 4) AS output;
Table 1. Results
Output
[[1, 3, 5], [1, 3, 7], [1, 5, 7], [3, 5, 7], [1, 3, 9], [1, 5, 9], [3, 5, 9], [1, 7, 9], [3, 7, 9], [5, 7, 9], [1, 3, 5, 7], [1, 3, 5, 9], [1, 3, 7, 9], [1, 5, 7, 9], [3, 5, 7, 9]]
apoc.coll.avg
apoc.coll.contains
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.avg;"apoc.coll.avg
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.avg(coll [Number]) - returns the average of the numbers in the list.
Signature
None
Copy to Clipboard
apoc.coll.avg(numbers :: LIST? OF NUMBER?) :: (FLOAT?)
Input parameters
Name Type Default
numbers
LIST? OF NUMBER?
null
Usage examples
The following computes the average of values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.avg([1,2,3,4,5]) AS output;
Table 1. Results
Output
3.0
apoc.coll.zipToRows
apoc.coll.combinations
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.zipToRows;"apoc.coll.zipToRows
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.coll.zipToRows(list1 [Any], list2 [Any]) - returns the two lists zipped together, with one row per zipped pair.
Signature
None
Copy to Clipboard
apoc.coll.zipToRows(list1 :: LIST? OF ANY?, list2 :: LIST? OF ANY?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
list1
LIST? OF ANY?
null
list2
LIST? OF ANY?
null
Output parameters
Name Type
value
LIST? OF ANY?
Usage examples
The following indicates whether all values in a collection are different:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.coll.zipToRows([1,2,3], [""a"", ""b"", ""c""]);
Table 1. Results
value
[1, ""a""]
[2, ""b""]
[3, ""c""]
apoc.coll.split
apoc.coll.avg
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.split;"apoc.coll.split
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.coll.split(coll [Any], value Any) - splits a collection by the given value. The value itself will not be part of the resulting lists.
Signature
None
Copy to Clipboard
apoc.coll.split(values :: LIST? OF ANY?, value :: ANY?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
value
ANY?
null
Output parameters
Name Type
value
LIST? OF ANY?
Usage examples
The following splits a collection on the value .:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.coll.split([""Hello"", ""World"", ""."", ""How"", ""are"", ""you"", ""?""], ""."");
Table 1. Results
Value
[""Hello"", ""World""]
[""How"", ""are"", ""you"", ""?""]
apoc.coll.partition
apoc.coll.zipToRows
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.containsAll;"apoc.coll.containsAll
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.containsAll(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values exist in the given collection (using a HashSet).
Signature
None
Copy to Clipboard
apoc.coll.containsAll(coll :: LIST? OF ANY?, values :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
values
LIST? OF ANY?
null
Usage examples
The following checks if a collection contains all the values from another collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsAll([1,2,3,4,5], [3,7]) AS output;
Table 1. Results
Output
FALSE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsAll([1,2,3,4,5], [1,3]) AS output;
Table 2. Results
Output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsAll([1,2,3,4,5], [4,1]) AS output;
Table 3. Results
Output
TRUE
apoc.coll.contains
apoc.coll.containsAllSorted
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.containsAllSorted;"apoc.coll.containsAllSorted
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.containsAllSorted(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values in the second list exist in an already sorted collection (using a binary search).
Signature
None
Copy to Clipboard
apoc.coll.containsAllSorted(coll :: LIST? OF ANY?, values :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
values
LIST? OF ANY?
null
Usage examples
The following checks if a sorted collection contains all the values from another collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsAllSorted([1,4,5], [1,4]) AS output;
Table 1. Results
Output
TRUE
This function will not work on unsorted collections, as shown in the example below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsAllSorted([1,5,4], [1,4]) AS output;
Table 2. Results
Output
FALSE
If we want to find values in an unsorted collection, see apoc.coll.containsAll.
apoc.coll.containsAll
apoc.coll.containsDuplicates
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.containsDuplicates;"apoc.coll.containsDuplicates
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.containsDuplicates(coll [Any]) - returns true if a collection contains duplicate elements.
Signature
None
Copy to Clipboard
apoc.coll.containsDuplicates(coll :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following indicates whether a list contains duplicate values:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.containsDuplicates([1,3,5,7,9,9]) AS output;
Table 1. Results
Output
true
apoc.coll.containsAllSorted
apoc.coll.containsSorted
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.disjunction;"apoc.coll.disjunction
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.disjunction(list1 [Any], list2[Any]) - returns the disjunct set of two lists.
Signature
None
Copy to Clipboard
apoc.coll.disjunction(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following returns the unique disjunction of two lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.disjunction([1,2,3,4,5], [3,4,5]) AS output;
Table 1. Results
Output
[1, 2]
apoc.coll.different
apoc.coll.dropDuplicateNeighbors
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.dropDuplicateNeighbors;"apoc.coll.dropDuplicateNeighbors
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.dropDuplicateNeighbors(list [Any]) - removes duplicate consecutive objects in the list.
Signature
None
Copy to Clipboard
apoc.coll.dropDuplicateNeighbors(list :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
LIST? OF ANY?
null
Usage examples
The following removes duplicate neighbors
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.dropDuplicateNeighbors([1,1,1,4,5,4,6,6,7]) as output;
Table 1. Results
Output
[1, 4, 5, 4, 6, 7]
apoc.coll.disjunction
apoc.coll.duplicates
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.duplicates;"apoc.coll.duplicates
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.duplicates(coll [Any]) - returns a list of duplicate items in the collection.
Signature
None
Copy to Clipboard
apoc.coll.duplicates(coll :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following returns a list of duplicates in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.duplicates([1,3,5,7,9,9]) AS output;
Table 1. Results
Output
[9]
apoc.coll.dropDuplicateNeighbors
apoc.coll.duplicatesWithCount
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.duplicatesWithCount;"apoc.coll.duplicatesWithCount
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.duplicatesWithCount(coll [Any]) - returns a list of duplicate items in the collection and their count, keyed by item and count.
Signature
None
Copy to Clipboard
apoc.coll.duplicatesWithCount(coll :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following returns duplicates in a list of maps containing an item and its count:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.duplicatesWithCount([1,3,5,7,9,9]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
[
    {
      ""count"": 2,
      ""item"": 9
    }
]
apoc.coll.duplicates
apoc.coll.fill
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.fill;"apoc.coll.fill
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.fill(items String, count Integer) - returns a list with the given count of items.
Signature
None
Copy to Clipboard
apoc.coll.fill(item :: STRING?, count :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
item
STRING?
null
count
INTEGER?
null
Usage examples
The following returns a list containing 2 lists with the contents abc:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.fill('abc', 2) as output;
Table 1. Results
Output
[""abc"", ""abc""]
apoc.coll.duplicatesWithCount
apoc.coll.flatten
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.flatten;"apoc.coll.flatten
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.flatten(coll [Any], recursive Boolean) - flattens the given list (to flatten nested lists, set recursive to true).
Signature
None
Copy to Clipboard
apoc.coll.flatten(coll :: LIST? OF ANY?, recursive = false :: BOOLEAN?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
recursive
BOOLEAN?
false
Usage examples
The following flattens a collection of collections:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.flatten([1,2,3,[4,5,6]]) AS output;
Table 1. Results
Output
[1, 2, 3, 4, 5, 6]
apoc.coll.fill
apoc.coll.frequencies
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.frequencies;"apoc.coll.frequencies
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.frequencies(coll [Any]) - returns a list of frequencies of the items in the collection, keyed by item and count.
Signature
None
Copy to Clipboard
apoc.coll.frequencies(coll :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following returns a list of maps containing each item and their frequency in a collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.frequencies([1,3,5,7,9,9]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
[
    {
      ""count"": 1,
      ""item"": 1
    }
    ,
    {
      ""count"": 1,
      ""item"": 3
    }
    ,
    {
      ""count"": 1,
      ""item"": 5
    }
    ,
    {
      : ,
      : 
    }
    ,
    {
      : ,
      : 
    }
]
View all (11 more lines)
apoc.coll.flatten
apoc.coll.frequenciesAsMap
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.frequenciesAsMap;"apoc.coll.frequenciesAsMap
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.frequenciesAsMap(coll [Any]) - returns a map of frequencies of the items in the collection, keyed by item and count.
Signature
None
Copy to Clipboard
apoc.coll.frequenciesAsMap(coll :: LIST? OF ANY?) :: (MAP?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
Usage examples
The following returns a map containing each item and their frequency in a collection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.frequenciesAsMap([1,3,5,7,9,9]) AS output;
Table 1. Results
Output
Json
Copy to Clipboard
{
  ""1"": 1,
  ""3"": 1,
  ""5"": 1,
  ""7"": 1,
  ""9"": 2
}
apoc.coll.frequencies
apoc.coll.indexOf
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.indexOf;"apoc.coll.indexOf
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.indexOf(coll [Any], value Any) - returns the index for the first occurrence of the specified value in the list.
Signature
None
Copy to Clipboard
apoc.coll.indexOf(coll :: LIST? OF ANY?, value :: ANY?) :: (INTEGER?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
value
ANY?
null
Usage examples
The following returns the index of the value 3 in the list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.indexOf([1,3,5,7,9], 3) AS output;
Table 1. Results
Output
1
apoc.coll.frequenciesAsMap
apoc.coll.insert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.insert;"apoc.coll.insert
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.insert(coll [Any], index Integer, value Any) - inserts a value into the specified index in the list.
Signature
None
Copy to Clipboard
apoc.coll.insert(coll :: LIST? OF ANY?, index :: INTEGER?, value :: ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
index
INTEGER?
null
value
ANY?
null
Usage examples
The following inserts the value 11 at index 3 in the list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.insert([1,3,5,7,9], 3, 11) AS output;
Table 1. Results
Output
[1, 3, 5, 11, 7, 9]
apoc.coll.indexOf
apoc.coll.insertAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.insertAll;"apoc.coll.insertAll
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.insertAll(coll [Any], index Integer, values [Any]) - inserts all of the values into the list, starting at the specified index.
Signature
None
Copy to Clipboard
apoc.coll.insertAll(coll :: LIST? OF ANY?, index :: INTEGER?, values :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
index
INTEGER?
null
values
LIST? OF ANY?
null
Usage examples
The following inserts the values 11, 12, and 13 at index 3 in the list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.insertAll([1,3,5,7,9], 3, [11,12,13]) AS output;
Table 1. Results
Output
[1, 3, 5, 11, 12, 13, 7, 9]
apoc.coll.insert
apoc.coll.intersection
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.intersection;"apoc.coll.intersection
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.intersection(list1 [Any], list2[Any]) - returns the distinct intersection of two lists.
Signature
None
Copy to Clipboard
apoc.coll.intersection(first :: LIST? OF ANY?, second :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
first
LIST? OF ANY?
null
second
LIST? OF ANY?
null
Usage examples
The following returns the unique intersection of the two lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.intersection([1,2,3,4,5], [3,4,5]) AS output;
Table 1. Results
Output
[3, 4, 5]
apoc.coll.insertAll
apoc.coll.isEqualCollection
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.isEqualCollection;"apoc.coll.isEqualCollection
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.isEqualCollection(coll [Any], values [Any]) - returns true if the two collections contain the same elements with the same cardinality in any order (using a HashMap).
Signature
None
Copy to Clipboard
apoc.coll.isEqualCollection(coll :: LIST? OF ANY?, values :: LIST? OF ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
values
LIST? OF ANY?
null
Usage examples
The following checks if two collections contain exactly the same values in any order:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.isEqualCollection([1,4,5], [1,5,4]) AS output;
Table 1. Results
Output
TRUE
If the collections contain the same unique values but have a different cardinality, they aren’t considered equal:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.isEqualCollection([1,4,4,5], [1,5,4]) AS output;
Table 2. Results
Output
FALSE
apoc.coll.intersection
apoc.coll.max
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.max;"apoc.coll.max
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.max(values [Any]) - returns the maximum of all values in the given list.
Signature
None
Copy to Clipboard
apoc.coll.max(values :: LIST? OF ANY?) :: (ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage examples
The following computes the maximum of values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.max([1,2,3,4,5]) AS output;
Table 1. Results
Output
5
apoc.coll.isEqualCollection
apoc.coll.min
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.min;"apoc.coll.min
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.min(values [Any]) - returns the minimum of all values in the given list.
Signature
None
Copy to Clipboard
apoc.coll.min(values :: LIST? OF ANY?) :: (ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage examples
The following computes the minimum of values in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.min([1,2,3,4,5]) AS output;
Table 1. Results
Output
1
apoc.coll.max
apoc.coll.occurrences
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.occurrences;"apoc.coll.occurrences
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.occurrences(coll [Any], item Any) - returns the count of the given item in the collection.
Signature
None
Copy to Clipboard
apoc.coll.occurrences(coll :: LIST? OF ANY?, item :: ANY?) :: (INTEGER?)
Input parameters
Name Type Default
coll
LIST? OF ANY?
null
item
ANY?
null
Usage examples
The following returns the number of occurrences of the value 9 in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.occurrences([1,3,5,7,9,9], 9) AS output;
Table 1. Results
Output
2
apoc.coll.min
apoc.coll.pairs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.pairs;"apoc.coll.pairs
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.pairs(list [Any]) - returns a list of adjacent elements in the list ([1,2],[2,3],[3,null]).
Signature
None
Copy to Clipboard
apoc.coll.pairs(list :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
LIST? OF ANY?
null
Usage examples
The following creates a list of lists of adjacent elements in a list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.pairs([1,2,3,4,5]) AS output;
Table 1. Results
Output
[[1, 2], [2, 3], [3, 4], [4, 5], [5, null]]
apoc.coll.occurrences
apoc.coll.pairsMin
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.pairsMin;"apoc.coll.pairsMin
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.pairsMin(list [Any]) - returns lists of adjacent elements in the list ([1,2],[2,3]), skipping the final element.
Signature
None
Copy to Clipboard
apoc.coll.pairsMin(list :: LIST? OF ANY?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
list
LIST? OF ANY?
null
Usage examples
The following creates a list of lists of adjacent elements in a list, skipping the last item:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.pairsMin([1,2,3,4,5]) AS output;
Table 1. Results
Output
[[1, 2], [2, 3], [3, 4], [4, 5]]
apoc.coll.pairs
apoc.coll.partition
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.bitwise/apoc.bitwise.op;"apoc.bitwise.op
Contents
Signature
Input parameters
Usage examples
Function
apoc.bitwise.op(a Integer, operator String, b Integer) - returns the result of the bitwise operation.
Signature
None
Copy to Clipboard
apoc.bitwise.op(a :: INTEGER?, operator :: STRING?, b :: INTEGER?) :: (INTEGER?)
Input parameters
Name Type Default
a
INTEGER?
null
operator
STRING?
null
b
INTEGER?
null
Usage examples
Cypher
AND (a & b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,""&"",13) AS output;
Table 1. Results
output
12
Cypher
OR (a | b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,""|"",13) AS output;
Table 2. Results
output
61
Cypher
XOR (a ^ b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,""&"",13) AS output;
Table 3. Results
output
49
Cypher
NOT (~a)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,""~"",0) AS output;
Table 4. Results
output
-61
Cypher
LEFT SHIFT (a << b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,""<<"",2) AS output;
Table 5. Results
output
240
Cypher
RIGHT SHIFT (a >> b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,"">>"",2) AS output;
Table 6. Results
output
15
Cypher
UNSIGNED RIGHT SHIFT (a >> b)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.bitwise.op(60,"">>>"",2) AS output;
Table 7. Results
output
15
apoc.bitwise
apoc.coll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.bitwise;"apoc.bitwise
Qualified Name Type
apoc.bitwise.op
apoc.bitwise.op(a Integer, operator String, b Integer) - returns the result of the bitwise operation.
Function
apoc.atomic.update
apoc.bitwise.op
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.update;"apoc.atomic.update
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.update(container Any, propertyName String, operation String, times Integer) - updates the value of a property with a Cypher operation.
Signature
None
Copy to Clipboard
apoc.atomic.update(container :: ANY?, propertyName :: STRING?, operation :: STRING?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
operation
STRING?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
The following updates salary1 with the result of an expression:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'Ryan'})
CALL apoc.atomic.update(p,'salary1','n.salary1*3 + n.salary2',5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
In the operation expression (3rd parameter) the entity passed in as container (1st parameter) is referred to using the variable n. If we rename our node/rel (as in the example above) we still have to refer to it in the expression as n.
Table 1. Results
oldValue newValue
1800
6900
More documentation of apoc.atomic.update
apoc.atomic.subtract
apoc.bitwise
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates/atomic-updates;"Atomic property updates
Contents
Procedures for thread-safe updating of properties on nodes and relationships
Examples
The APOC library contains procedures that can be used for thread-safe updating of properties on nodes and relationships.
Procedures for thread-safe updating of properties on nodes and relationships
Qualified Name Type
apoc.atomic.add
apoc.atomic.add(container Any, propertyName String, value Number, times Integer) - sets the given property to the sum of itself and the number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.concat
apoc.atomic.concat(container Any, propertyName String, string String, times Integer) - sets the given property to the concatenation of itself and the string value. The procedure then sets the property to the returned string.
Procedure
apoc.atomic.insert
apoc.atomic.insert(container Any, propertyName String, position Integer, value Any, times Integer) - inserts a value at position into the array value of a property. The procedure then sets the result back on the property.
Procedure
apoc.atomic.remove
apoc.atomic.remove(container Any, propertyName String, position Integer, times Integer) - removes the element at position from the array value of a property. The procedure then sets the property to the resulting array value.
Procedure
apoc.atomic.subtract
apoc.atomic.subtract(container Any, propertyName String, number Number, times Integer) - sets the property of a value to itself minus the given number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.update
apoc.atomic.update(container Any, propertyName String, operation String, times Integer) - updates the value of a property with a Cypher operation.
Procedure
Examples
The below examples will further explain these procedures.
Cypher
The following creates sample nodes:
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Person {name:'Tom',age: 40})
CREATE (p:Person {name:'Will',age: 35})
CREATE (p:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (p:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (p:Person {name:'Ryan', salary1:1800, salary2:1500})
Cypher
The following adds 10 to the property age for Tom:
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name:'Tom'})
CALL apoc.atomic.add(n,'age',10,5)
YIELD oldValue, newValue
RETURN n
Table 1. Results
n
{""name"":""Tom"",""age"":50}
Cypher
The following subtracts 10 from the property age for Tom:
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name:'Tom'})
CALL apoc.atomic.subtract(n,'age',10,5)
YIELD oldValue, newValue
RETURN n
Table 2. Results
n
{""name"":""Tom"",""age"":40}
Cypher
The following concatenates iam to the name property for Will:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'Will',age: 35})
CALL apoc.atomic.concat(p,""name"",'iam',5)
YIELD newValue
RETURN p
Table 3. Results
p
{""name"":""William"",""age"":35}
Cypher
The following adds Mary in position 2 of children list:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'David'})
CALL apoc.atomic.insert(p,'children',2,'Mary',5)
YIELD newValue
RETURN p
Table 4. Results
p
{""name"":""David"",""children"":[""Anne"",""Sam"",""Mary"",""Paul""]}
Cypher
The following removes the element X3, which is at position 1, from the array cars
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'John'})
CALL apoc.atomic.remove(p,'cars',1,5)
YIELD newValue
RETURN p
Table 5. Results
p
{""name"":""John"",""cars"":[""Class A"",""Focus""]}
Cypher
The following updates salary1 with the result of an expression:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'Ryan'})
CALL apoc.atomic.update(p,'salary1','n.salary1*3 + n.salary2',5)
YIELD newValue
RETURN p
In the operation expression (3rd parameter) the entity passed in as container` (1st parameter) is referred to using the variable n. If the node or relationship is renamed (as in the example above), it is still necessary to refer to it in the expression as n.
Table 6. Results
p
{""name"":""Ryan"",""salary1"":6900,""salary2"":1500}
Periodic execution
Locks
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.subtract;"apoc.atomic.subtract
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.subtract(container Any, propertyName String, number Number, times Integer) - sets the property of a value to itself minus the given number value. The procedure then sets the property to the returned sum.
Signature
None
Copy to Clipboard
apoc.atomic.subtract(container :: ANY?, propertyName :: STRING?, number :: NUMBER?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
number
NUMBER?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
The following subtracts 10 from the property age for Tom:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name:'Tom'})
CALL apoc.atomic.subtract(n,'age',10,5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
Table 1. Results
oldValue newValue
40
30
More documentation of apoc.atomic.subtract
apoc.atomic.remove
apoc.atomic.update
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.remove;"apoc.atomic.remove
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.remove(container Any, propertyName String, position Integer, times Integer) - removes the element at position from the array value of a property. The procedure then sets the property to the resulting array value.
Signature
None
Copy to Clipboard
apoc.atomic.remove(container :: ANY?, propertyName :: STRING?, position :: INTEGER?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
position
INTEGER?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
The following removes the element X3, which is at position 1, from the array cars
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'John'})
CALL apoc.atomic.remove(p,'cars',1,5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
Table 1. Results
oldValue newValue
[""Class A"", ""X3"", ""Focus""]
[""Class A"", ""Focus""]
More documentation of apoc.atomic.remove
apoc.atomic.insert
apoc.atomic.subtract
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.insert;"apoc.atomic.insert
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.insert(container Any, propertyName String, position Integer, value Any, times Integer) - inserts a value at position into the array value of a property. The procedure then sets the result back on the property.
Signature
None
Copy to Clipboard
apoc.atomic.insert(container :: ANY?, propertyName :: STRING?, position :: INTEGER?, value :: ANY?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
position
INTEGER?
null
value
ANY?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
The following adds Mary in position 2 of children list:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'David'})
CALL apoc.atomic.insert(p,'children',2,'Mary',5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
Table 1. Results
oldValue newValue
[""Anne"", ""Sam"", ""Paul""]
[""Anne"", ""Sam"", ""Mary"", ""Paul""]
More documentation of apoc.atomic.insert
apoc.atomic.concat
apoc.atomic.remove
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.concat;"apoc.atomic.concat
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.concat(container Any, propertyName String, string String, times Integer) - sets the given property to the concatenation of itself and the string value. The procedure then sets the property to the returned string.
Signature
None
Copy to Clipboard
apoc.atomic.concat(container :: ANY?, propertyName :: STRING?, string :: STRING?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
string
STRING?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
Cypher
The following concatenates iam to the name property for Will:
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'Will',age: 35})
CALL apoc.atomic.concat(p,""name"",'iam',5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
Table 1. Results
oldValue newValue
""Will""
""William""
More documentation of apoc.atomic.concat
apoc.atomic.add
apoc.atomic.insert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic/apoc.atomic.add;"apoc.atomic.add
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.atomic.add(container Any, propertyName String, number Number, times Integer) - sets the given property to the sum of itself and the number value. The procedure then sets the property to the returned sum.
Signature
None
Copy to Clipboard
apoc.atomic.add(container :: ANY?, propertyName :: STRING?, number :: NUMBER?, times = 5 :: INTEGER?) :: (container :: ANY?, property :: STRING?, oldValue :: ANY?, newValue :: ANY?)
Input parameters
Name Type Default
container
ANY?
null
propertyName
STRING?
null
number
NUMBER?
null
times
INTEGER?
5
Output parameters
Name Type
container
ANY?
property
STRING?
oldValue
ANY?
newValue
ANY?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name:'Tom',age: 40})
CREATE (:Person {name:'Will',age: 35})
CREATE (:Person {name:'David', children: ['Anne','Sam','Paul']})
CREATE (:Person {name:'John', cars: ['Class A','X3','Focus']})
CREATE (:Person {name:'Ryan', salary1:1800, salary2:1500});
The following adds 10 to the property age for Tom:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person {name:'Tom'})
CALL apoc.atomic.add(n,'age',10,5)
YIELD oldValue, newValue
RETURN oldValue, newValue;
Table 1. Results
oldValue newValue
40
50
More documentation of apoc.atomic.add
apoc.atomic
apoc.atomic.concat
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.atomic;"apoc.atomic
Qualified Name Type
apoc.atomic.add
apoc.atomic.add(container Any, propertyName String, number Number, times Integer) - sets the given property to the sum of itself and the number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.concat
apoc.atomic.concat(container Any, propertyName String, string String, times Integer) - sets the given property to the concatenation of itself and the string value. The procedure then sets the property to the returned string.
Procedure
apoc.atomic.insert
apoc.atomic.insert(container Any, propertyName String, position Integer, value Any, times Integer) - inserts a value at position into the array value of a property. The procedure then sets the result back on the property.
Procedure
apoc.atomic.remove
apoc.atomic.remove(container Any, propertyName String, position Integer, times Integer) - removes the element at position from the array value of a property. The procedure then sets the property to the resulting array value.
Procedure
apoc.atomic.subtract
apoc.atomic.subtract(container Any, propertyName String, number Number, times Integer) - sets the property of a value to itself minus the given number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.update
apoc.atomic.update(container Any, propertyName String, operation String, times Integer) - updates the value of a property with a Cypher operation.
Procedure
apoc.any.property
apoc.atomic.add
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.any/apoc.any.property;"apoc.any.property
Contents
Signature
Input parameters
Usage examples
Function
apoc.any.property(object Any, key String) - returns the property for the given key from an object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Signature
None
Copy to Clipboard
apoc.any.property(thing :: ANY?, key :: STRING?) :: (ANY?)
Input parameters
Name Type Default
thing
ANY?
null
key
STRING?
null
Usage examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Alice', score: 71});
CREATE (s:Student {name: 'Mark', score: 95});
CREATE (s:Student {name: 'Andrea', score: 86});
CREATE (s:Student {name: 'Rajesh', score: 89});
CREATE (s:Student {name: 'Jennifer', score: 96});
CREATE (s:Student {name: 'Katarina', score: 80});
If we create virtual nodes containing students scores, we can use apoc.any.property to extract a property from these virtual nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.create.vNode(['Score'],{value: s.score})
YIELD node
RETURN apoc.any.property(node, ""value"") AS score;
Table 1. Results
score
71
95
86
89
96
80
More documentation of apoc.any.property
apoc.any.properties
apoc.atomic
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.any/apoc.any.properties;"apoc.any.properties
Contents
Signature
Input parameters
Usage examples
Function
apoc.any.properties(object Any, keys [String]) - returns all properties of the given object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Signature
None
Copy to Clipboard
apoc.any.properties(thing :: ANY?, keys = null :: LIST? OF STRING?) :: (MAP?)
Input parameters
Name Type Default
thing
ANY?
null
keys
LIST? OF STRING?
null
Usage examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Alice', score: 71});
CREATE (s:Student {name: 'Mark', score: 95});
CREATE (s:Student {name: 'Andrea', score: 86});
CREATE (s:Student {name: 'Rajesh', score: 89});
CREATE (s:Student {name: 'Jennifer', score: 96});
CREATE (s:Student {name: 'Katarina', score: 80});
If we create virtual nodes containing students scores, we can use apoc.any.properties to return the properties of those virtual nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.create.vNode(['Score'],{value: s.score})
YIELD node
RETURN apoc.any.properties(node) AS properties;
Table 1. Results
properties
{value: 71}
{value: 95}
{value: 86}
{value: 89}
{value: 96}
{value: 80}
More documentation of apoc.any.properties
apoc.any
apoc.any.property
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.any;"apoc.any
Qualified Name Type
apoc.any.isDeleted
apoc.any.isDeleted(object Any) - returns true if the given node or relationship no longer exists.
Function
apoc.any.properties
apoc.any.properties(object Any, keys [String]) - returns all properties of the given object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Function
apoc.any.property
apoc.any.property(object Any, key String) - returns the property for the given key from an object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Function
apoc.algo.dijkstra
apoc.any.properties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.any/apoc.any.isDeleted;"apoc.any.isDeleted
Contents
Signature
Input parameters
Function
apoc.any.isDeleted(object Any) - returns true if the given node or relationship no longer exists.
Signature
None
Copy to Clipboard
apoc.any.isDeleted (object :: ANY?) :: (BOOLEAN?)
Input parameters
Name Type Default
object
ANY?
null
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo/apoc.algo.dijkstra;"apoc.algo.dijkstra
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.algo.dijkstra(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, defaultWeight Float, numberOfWantedPaths Integer) - runs Dijkstra’s algorithm using the given relationship property as the cost function.
Signature
None
Copy to Clipboard
apoc.algo.dijkstra(startNode :: NODE?, endNode :: NODE?, relationshipTypesAndDirections :: STRING?, weightPropertyName :: STRING?, defaultWeight = NaN :: FLOAT?, numberOfWantedPaths = 1 :: INTEGER?) :: (path :: PATH?, weight :: FLOAT?)
Input parameters
Name Type Default
startNode
NODE?
null
endNode
NODE?
null
relationshipTypesAndDirections
STRING?
null
weightPropertyName
STRING?
null
defaultWeight
FLOAT?
NaN
numberOfWantedPaths
INTEGER?
1
Output parameters
Name Type
path
PATH?
weight
FLOAT?
More documentation of apoc.algo.dijkstra
apoc.algo.cover
apoc.any
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo/apoc.algo.cover;"apoc.algo.cover
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.algo.cover(nodes Any) - returns all relationships between a given set of nodes.
Signature
None
Copy to Clipboard
apoc.algo.cover(nodes :: ANY?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
nodes
ANY?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (Keanu)-[:KNOWS]->(Carrie);
CREATE (Tom)-[:KNOWS]->(Carrie);
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (p:Person)
WHERE p.name IN [""Keanu Reeves"", ""Carrie-Anne Moss""]
with collect(id(p)) as nodes
CALL apoc.algo.cover(nodes)
YIELD rel
RETURN  startNode(rel), rel, endNode(rel);
Table 1. Results
startNode(rel) rel endNode(rel)
(:Person {name: ""Keanu Reeves"", born: 1964})
[:KNOWS]
(:Person {name: ""Carrie-Anne Moss"", born: 1967})
More documentation of apoc.algo.cover
apoc.algo.allSimplePaths
apoc.algo.dijkstra
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo/apoc.algo.allSimplePaths;"apoc.algo.allSimplePaths
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.algo.allSimplePaths(startNode Node, endNode Node, relTypesAndDirections String, maxNodes Integer) - runs a search algorithm to find all of the simple paths between the given relationships, up to a max depth described by maxNodes. The returned paths will not contain loops.
Signature
None
Copy to Clipboard
apoc.algo.allSimplePaths(startNode :: NODE?, endNode :: NODE?, relationshipTypesAndDirections :: STRING?, maxNodes :: INTEGER?) :: (path :: PATH?)
Input parameters
Name Type Default
startNode
NODE?
null
endNode
NODE?
null
relationshipTypesAndDirections
STRING?
null
maxNodes
INTEGER?
null
Output parameters
Name Type
path
PATH?
More documentation of apoc.algo.allSimplePaths
apoc.algo.aStarConfig
apoc.algo.cover
Was this page helpful?"
https://neo4j.com/docs/apoc/5/algorithms/path-finding-procedures;"Path Finding Procedures
Contents
apoc.algo.aStarConfig
APOC exposes some built in path-finding functions that are included in Neo4j.
apoc.algo.dijkstra(startNode, endNode, 'KNOWS|<WORKS_WITH|IS_MANAGER_OF>', 'distance') YIELD path, weight
run dijkstra with relationship property name as cost function
apoc.algo.aStar(startNode, endNode, 'KNOWS|<WORKS_WITH|IS_MANAGER_OF>', 'distance','lat','lon') YIELD path, weight
run A* with relationship property name as cost function
apoc.algo.aStarConfig(startNode, endNode, 'KNOWS
<WORKS_WITH
IS_MANAGER_OF>', {weight:'dist',default:10, x:'lon',y:'lat',pointPropName:'point'}) YIELD path, weight - run A* with relationship property name as cost function
apoc.algo.allSimplePaths(startNode, endNode, 'KNOWS|<WORKS_WITH|IS_MANAGER_OF>', 5) YIELD path, weight
run allSimplePaths with relationships given and maxNodes
apoc.stats.degrees(relTypesDirections) yield type, direction, total, min, max, mean, p50, p75, p90, p95, p99, p999
Example To find the weighted shortest path based on relationship property d from A to B following only :ROAD relationships, run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (from:Loc{name:'A'}), (to:Loc{name:'D'})
CALL apoc.algo.dijkstra(from, to, 'ROAD', 'd') yield path as path, weight as weight
RETURN path, weight
apoc.algo.aStarConfig
Given this dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (b:City {name:'Berlin', coords: point({latitude:52.52464,longitude:13.40514}), lat:52.52464,lon:13.40514})
CREATE (m:City {name:'München', coords: point({latitude:48.1374,longitude:11.5755}), lat:48.1374,lon:11.5755})
CREATE (f:City {name:'Frankfurt',coords: point({latitude:50.1167,longitude:8.68333}), lat:50.1167,lon:8.68333})
CREATE (h:City {name:'Hamburg', coords: point({latitude:53.554423,longitude:9.994583}), lat:53.554423,lon:9.994583})
CREATE (b)-[:DIRECT {dist:255.64*1000}]->(h)
CREATE (b)-[:DIRECT {dist:504.47*1000}]->(m)
CREATE (b)-[:DIRECT {dist:424.12*1000}]->(f)
CREATE (f)-[:DIRECT {dist:304.28*1000}]->(m)
CREATE (f)-[:DIRECT {dist:393.15*1000}]->(h)
It is possible to execute the following query (leveraging on lat and lon node properties, which are numbers, on dist relationship property and with default cost 100):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (from:City {name:'München'}), (to:City {name:'Hamburg'})
CALL apoc.algo.aStarConfig(from, to, 'DIRECT', {weight:'dist',y:'lat', x:'lon',default:100})
YIELD weight, path
RETURN weight, path
Table 1. Results
weight path
697430.0
[source,json] ---- { ""start"": { ""identity"": 1520006, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""München"", ""lon"": 11.5755, ""lat"": 48.1374, ""coords"": point({srid:4326, x:11.5755, y:48.1374}) } }, ""end"": { ""identity"": 1520008, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""Hamburg"", ""lon"": 9.994583, ""lat"": 53.554423, ""coords"": point({srid:4326, x:9.994583, y:53.554423}) } }, ""segments"": [ { ""start"": { ""identity"": 1520006, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""München"", ""lon"": 11.5755, ""lat"": 48.1374, ""coords"": point({srid:4326, x:11.5755, y:48.1374}) } }, ""relationship"": { ""identity"": 3, ""start"": 1520007, ""end"": 1520006, ""type"": ""DIRECT"", ""properties"": { ""dist"": 304280.0 } }, ""end"": { ""identity"": 1520007, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""Frankfurt"", ""lon"": 8.68333, ""lat"": 50.1167, ""coords"": point({srid:4326, x:8.68333, y:50.1167}) } } }, { ""start"": { ""identity"": 1520007, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""Frankfurt"", ""lon"": 8.68333, ""lat"": 50.1167, ""coords"": point({srid:4326, x:8.68333, y:50.1167}) } }, ""relationship"": { ""identity"": 4, ""start"": 1520007, ""end"": 1520008, ""type"": ""DIRECT"", ""properties"": { ""dist"": 393150.0 } }, ""end"": { ""identity"": 1520008, ""labels"": [ ""City"" ], ""properties"": { ""name"": ""Hamburg"", ""lon"": 9.994583, ""lat"": 53.554423, ""coords"": point({srid:4326, x:9.994583, y:53.554423}) } } } ], ""length"": 2.0 } ----
Or equivalently, with the same result, leveraging on coords node property, which is a Point, with the same configurations. Note that in case of a 3d-coordinate, the procedure will pick only the x and y or the longitude and latitude values.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (from:City {name:'München'}), (to:City {name:'Hamburg'})
CALL apoc.algo.aStarConfig(from, to, 'DIRECT', {pointPropName:'coords', weight:'dist', default:100})
YIELD weight, path
RETURN weight, path
Graph Algorithms
List of procedures with its own transaction
Was this page helpful?"
https://neo4j.com/docs/apoc/5/transaction;"List of procedures with its own transaction
The list of procedures that start their own transaction:
apoc.cypher.runMany
apoc.cypher.runTimeboxed
apoc.export.csv.*
apoc.export.cypher.**
apoc.export.graphml* .*
apoc.export.json.*
apoc.import.graphml
apoc.nodes.delete
apoc.nodes.group
apoc.periodic.iterate
apoc.refactor.categorize
apoc.schema.properties.distinctCount
apoc.stats.degrees
apoc.trigger.add
apoc.trigger.pause
apoc.trigger.remove
apoc.trigger.removeAll
apoc.trigger.resume
Path Finding Procedures
Deprecations and additions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/deprecations-and-additions;"Deprecations and additions
Contents
Version 5.1
Removed procedures and functions
Version 5.0
Deprecated procedures and functions
Removed procedures and functions
Removed Config Settings
This chapter lists all the features that have been removed, deprecated, added or extended in the recent versions of APOC.
Version 5.1
Removed procedures and functions
Feature Details
Function Removed
apoc.convert.toBoolean(value)
Use the following instead:
toBoolean(value)
or
toBooleanOrNull(value)
Function Removed
apoc.convert.toBooleanList(value)
Use the following instead:
toBooleanList(value)
Function Removed
apoc.convert.toFloat(value)
Use the following instead:
toFloat(value)
or
toFloatOrNull(value)
Function Removed
apoc.convert.toIntList(value)
Use the following instead:
toIntegerList(value)
Function Removed
apoc.convert.toInteger(value)
Use the following instead:
toInteger(value)
or
toIntegerOrNull(value)
Function Removed
apoc.convert.toString(value)
Use the following instead:
toString(value)
or
toStringOrNull(value)
Function Removed
apoc.convert.toStringList(value)
Use the following instead:
toStringList(value)
Version 5.0
Deprecated procedures and functions
Feature Details
Function Deprecated
RETURN apoc.create.uuid()
Replaced by Neo4j Function randomUUID():
RETURN randomUUID()
Procedure Deprecated
CALL apoc.create.uuids($count)
Replaced by Neo4j Function randomUUID():
UNWIND range(0,$count) AS row RETURN row, randomUUID() AS uuid
Procedure Deprecated
apoc.warmup.run(loadProperties=false,loadDynamicProperties=false,loadIndexes=false)
This procedure duplicated functionality of page cache warm up which is a part of the DBMS.
Removed procedures and functions
Feature Details
Procedure Removed
apoc.algo.dijkstraWithDefaultWeight(startNode, endNode, 'KNOWS', 'distance', 10) YIELD path, weight
Use the following instead:
apoc.algo.dijkstra(startNode, endNode, 'KNOWS', 'distance', defaultValue, numberOfWantedResults) YIELD path, weight
Function Removed
apoc.date.parseAsZonedDateTime('2012-12-23 23:59:59','yyyy-MM-dd HH:mm:ss', 'UTC-hour-offset')
Replaced by:
apoc.temporal.toZonedTemporal('2012-12-23 23:59:59','yyyy-MM-dd HH:mm:ss', 'UTC-hour-offset')
Function Removed
apoc.coll.reverse(coll)
Replaced in Cypher with:
WITH [4923,'abc',521, null, 487] AS ids
RETURN reverse(ids)
Procedure Removed
apoc.export.cypherAll(file,config)
Replaced by:
apoc.export.cypher.all(file,config)
Procedure Removed
apoc.export.cypherData(nodes,rels,file,config)
Replaced by:
apoc.export.cypher.data(nodes,rels,file,config)
Procedure Removed
apoc.export.cypherGraph(graph,file,config)
Replaced by:
apoc.export.cypher.graph(graph,file,config)
Procedure Removed
apoc.export.cypherQuery(query,file,config)
Replaced by:
apoc.export.cypher.query(query,file,config)
Function Removed
apoc.meta.type(value)
Replaced by:
apoc.meta.cypher.type(value)
Function Removed
apoc.meta.types(node-relationship-map)
Replaced by:
apoc.meta.cypher.types(node-relationship-map)
Function Removed
apoc.meta.isType(value,type)
Replaced by:
apoc.meta.cypher.isType(value,type)
Function Removed
apoc.meta.typeName(value)
Replaced by:
apoc.meta.cypher.type(value)
Procedure Removed
apoc.periodic.rock_n_roll_while('some cypher for knowing when to stop', 'some cypher for iteration', 'some cypher as action on each iteration', 10000) YIELD batches, total
Partially replaced in Cypher with:
CALL {} IN TRANSACTIONS OF n ROWS
Procedure Removed
apoc.periodic.rock_n_roll('some cypher for iteration', 'some cypher as action on each iteration', 10000) YIELD batches, total
Replaced in Cypher with:
CALL {} IN TRANSACTIONS OF n ROWS
Procedure Removed
apoc.create.vPattern({_labels:['LabelA'],key:value},'KNOWS',{key:value,...}, {_labels:['LabelB'],key:value}) returns a virtual pattern
Replaced by:
apoc.create.virtualPath(['LabelA'],{key:value},'KNOWS',{key:value,...},['LabelB'],{key:value})
Procedure Removed
apoc.create.vPatternFull(['LabelA'],{key:value},'KNOWS',{key:value,...},['LabelB'],{key:value}) returns a virtual pattern
Replaced by:
apoc.create.virtualPath(['LabelA'],{key:value},'KNOWS',{key:value,...},['LabelB'],{key:value})
Procedure Removed
apoc.xml.import(url, config)
Replaced by:
apoc.import.xml(file,config)
Procedure Removed
apoc.refactor.cloneNodesWithRelationships([node1,node2,...])
Use the following instead, and set withRelationships = true:
apoc.refactor.cloneNodes(nodes, withRelationships, skipProperties)
Procedure Removed
CALL apoc.text.phonetic(value) yield value
Replaced by the function:
RETURN apoc.text.phonetic(text) yield value
Procedure Removed
CALL apoc.text.doubleMetaphone(value) yield value
Replaced by the function:
RETURN apoc.text.doubleMetaphone(text) yield value
Function Removed
apoc.math.round(value,[prec],mode=[CEILING,FLOOR,UP,DOWN,HALF_EVEN,HALF_DOWN,HALF_UP,DOWN,UNNECESSARY])
Replaced by the Neo4j round() function:
RETURN round(3.141592, 3)
Function Removed
apoc.cypher.runFirstColumn(statement, params, expectMultipleValues)
Replaced by:
apoc.cypher.runFirstColumnMany(statement, params)
apoc.cypher.runFirstColumnSingle(statement, params)
Removed Config Settings
Setting Details
Setting Removed apoc.initializer.cypher - a cypher statement to be executed once the database is started
This has been replaced by database-specific initializers. Use apoc.initializer.<database name> instead.
List of procedures with its own transaction
Was this page helpful?"
https://neo4j.com/docs/apoc/5/algorithms;"Graph Algorithms
Path Finding Procedures
Schema Information
Path Finding Procedures
Was this page helpful?"
https://neo4j.com/docs/apoc/5/indexes/schema-index-operations;"Schema Information
Contents
Examples
List Schema assert
List indexes and constraints for nodes
List constraints for relationships
Check if an index or a constraint exists for a Label and property
To drop or create index or constraint, you can use the following procedure:
Qualified Name Type
apoc.schema.assert
apoc.schema.assert({indexLabel:, …}, {constraintLabel:[constraintKeys], …}, dropExisting : true) yield label, key, keys, unique, action - drops all other existing indexes and constraints when dropExisting is true (default is true), and asserts that at the end of the operation the given indexes and unique constraints are there, each label:key pair is considered one constraint/label. Non-constraint indexes can define compound indexes with label:[key1,key2…] pairings.
Procedure
apoc.schema.nodes
CALL apoc.schema.nodes([config]) yield name, label, properties, status, type
Procedure
apoc.schema.relationships
CALL apoc.schema.relationships([config]) yield name, startLabel, type, endLabel, properties, status
Procedure
apoc.schema.node.constraintExists
RETURN apoc.schema.node.constraintExists(labelName, propertyNames)
Function
apoc.schema.relationship.constraintExists
RETURN apoc.schema.relationship.constraintExists(type, propertyNames)
Function
apoc.schema.node.indexExists
RETURN apoc.schema.node.indexExists(labelName, propertyNames)
Function
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert({indexLabel:[[indexKeys]], ...}, {constraintLabel:[constraintKeys], ...}, dropExisting : true)
YIELD label, key, keys, unique, action
Where the outputs are:
label
key
keys, list of the key
unique, if the index or constraint are unique
action, can be the following values: DROPPED, CREATED
To retrieve indexes and constraints information for all the node labels in your database, you can use the following procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.nodes()
YIELD name, label, properties, status, type
Where the outputs are:
name of the index/constraint,
label
properties, (for Neo4j 3.1 and lower versions is a single element array) that are affected by the constraint
status, for index can be one of the following values: ONLINE, POPULATING and FAILED
type, always ""INDEX"" for indexes, constraint type for constraints
failure, the failure description of a failed index
populationProgress, the population progress of the index in percentage
size, the size of the index
valuesSelectivity, computes the selectivity of the unique values
userDescription, a user friendly description of what this index indexes
To retrieve the constraint information for all the relationship types in your database, you can use the following procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.relationships()
YIELD name, type, properties, status
Where the outputs are:
name of the constraint
type of the relationship
properties, (for Neo4j 3.1 and lower versions is a single element array) that are affected by the constraint
status
Config optional param is a map and its possible values are:
labels : list of labels to retrieve index/constraint information
excludeLabels: list of labels to exclude from retrieve index/constraint information
relationships: list of relationships type to retrieve constraint information
excludeRelationships: list of relationships' type to exclude from retrieve constraint information
Exclude has more power than include, so if excludeLabels and labels are both valued, procedure considers excludeLabels only, the same for relationships.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.nodes({labels:['Book']})
YIELD name, label, properties, status, type
N.B. Constraints for property existence on nodes and relationships are available only for the Enterprise Edition.
To retrieve the index existence on node, you can use the following user function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.indexExists(labelName, propertyNames)
The output return the index existence on node is present or not
To retrieve if the constraint exists on node, you can use the following user function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.constraintExists(labelName, propertyNames)
The output return the constraint existence on node.
To retrieve if the constraint exists on relationship, you can use the following user function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.relationship.constraintExists(type, propertyNames)
The output return the constraint on the relationship is present or not
Examples
List Schema assert
When you:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert({Foo:['bar']},null)
you will receive this result:
When you:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert(null,{Foo:['bar']})
you will receive this result:
When you:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert(null,null)
you will receive this result:
List indexes and constraints for nodes
Given the following cypher statements:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT FOR (bar:Bar) REQUIRE bar.foobar IS NOT NULL
CREATE CONSTRAINT FOR (bar:Bar) REQUIRE bar.foo IS UNIQUE
CREATE INDEX FOR (n:Person) ON (n.name)
CREATE INDEX FOR (n:Publication) ON (n.name)
CREATE INDEX FOR (n:Source) ON (n.(name)
When you
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.nodes()
you will receive this result:
List constraints for relationships
Given the following cypher statements:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT FOR ()-[like:LIKED]-() REQUIRE like.day IS NOT NULL
CREATE CONSTRAINT FOR ()-[starred:STARRED]-() REQUIRE starred.month IS NOT NULL
When you
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.relationships()
you will receive this result:
Check if an index or a constraint exists for a Label and property
Given the previous index definitions, running this statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.indexExists(""Publication"", [""name""])
produces the following output:
Given the previous constraint definitions, running this statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.constraintExists(""Bar"", [""foobar""])
produces the following output:
If you want to check if a constraint exists for a relationship you can run this statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.relationship.constraintExists('LIKED', ['day'])
and you get the following result:
Text and Lookup Indexes
Graph Algorithms
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.relationship.constraintExists;"apoc.schema.relationship.constraintExists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.schema.relationship.constraintExists(type String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given relationship type with the given property names.
Signature
None
Copy to Clipboard
apoc.schema.relationship.constraintExists(type :: STRING?, propertyName :: LIST? OF STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
type
STRING?
null
propertyName
LIST? OF STRING?
null
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT likesDay
FOR ()-[like:LIKED]-()
REQUIRE (like.day) IS NOT NULL;
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.relationship.constraintExists(""LIKED"", [""day""]) AS output;
Table 1. Results
output
TRUE
More documentation of apoc.schema.relationship.constraintExists
apoc.schema.node.indexExists
apoc.schema.relationship.indexExists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.node.indexExists;"apoc.schema.node.indexExists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.schema.node.indexExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not an index exists for the given node label with the given property names.
Signature
None
Copy to Clipboard
apoc.schema.node.indexExists(labelName :: STRING?, propertyName :: LIST? OF STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
labelName
STRING?
null
propertyName
LIST? OF STRING?
null
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT personName FOR (person:Person)
REQUIRE person.name IS UNIQUE;

CREATE CONSTRAINT userId FOR (user:User)
REQUIRE user.id IS UNIQUE;

CREATE INDEX personCity FOR (person:Person)
ON (person.city);
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.indexExists(""Person"", [""name""]) AS output;
Table 1. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.indexExists(""Person"", [""city""]) AS output;
Table 2. Results
output
TRUE
More documentation of apoc.schema.node.indexExists
apoc.schema.node.constraintExists
apoc.schema.relationship.constraintExists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.node.constraintExists;"apoc.schema.node.constraintExists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.schema.node.constraintExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given node label with the given property names.
Signature
None
Copy to Clipboard
apoc.schema.node.constraintExists(labelName :: STRING?, propertyName :: LIST? OF STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
labelName
STRING?
null
propertyName
LIST? OF STRING?
null
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT personName FOR (person:Person)
REQUIRE person.name IS UNIQUE;

CREATE CONSTRAINT userId FOR (user:User)
REQUIRE user.id IS UNIQUE;
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.constraintExists(""Person"", [""name""]) AS output;
Table 1. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.schema.node.constraintExists(""Person"", [""name"", ""id""]) AS output;
Table 2. Results
output
FALSE
More documentation of apoc.schema.node.constraintExists
apoc.schema.relationships
apoc.schema.node.indexExists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.relationships;"apoc.schema.relationships
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.schema.relationships(config Map<String, Any>) - returns the indexes and constraints information for all the relationship types in the database. It is possible to define a set of relationship types to include or exclude in the config parameters.
Signature
None
Copy to Clipboard
apoc.schema.relationships(config = {} :: MAP?) :: (name :: STRING?, type :: STRING?, properties :: LIST? OF STRING?, status :: STRING?)
Input parameters
Name Type Default
config
MAP?
{}
Output parameters
Name Type
name
STRING?
type
STRING?
properties
LIST? OF STRING?
status
STRING?
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT likesDay
FOR ()-[like:LIKED]-()
REQUIRE (like.day) IS NOT NULL;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.relationships();
Table 1. Results
name type properties status
""CONSTRAINT ON ()-[liked:LIKED]-() ASSERT liked.day IS NOT NULL""
""RELATIONSHIP_PROPERTY_EXISTENCE""
[""day""]
""""
More documentation of apoc.schema.relationships
apoc.schema.properties.distinctCount
apoc.schema.node.constraintExists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.properties.distinctCount;"apoc.schema.properties.distinctCount
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.schema.properties.distinctCount(label String, key String) - returns all distinct property values and counts for the given key.
Signature
None
Copy to Clipboard
apoc.schema.properties.distinctCount(label =  :: STRING?, key =  :: STRING?) :: (label :: STRING?, key :: STRING?, value :: ANY?, count :: INTEGER?)
Input parameters
Name Type Default
label
STRING?
key
STRING?
Output parameters
Name Type
label
STRING?
key
STRING?
value
ANY?
count
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Michael""});
CREATE (:Person {name: ""Ryan""});
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.properties.distinctCount(""Person"", ""name"");
Table 1. Results
label key value count
""Person""
""name""
""Michael""
1
""Person""
""name""
""Ryan""
1
More documentation of apoc.schema.properties.distinctCount
apoc.schema.properties.distinct
apoc.schema.relationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.properties.distinct;"apoc.schema.properties.distinct
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.schema.properties.distinct(label String, key String) - returns all distinct node property values for the given key.
Signature
None
Copy to Clipboard
apoc.schema.properties.distinct(label :: STRING?, key :: STRING?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
label
STRING?
null
key
STRING?
null
Output parameters
Name Type
value
LIST? OF ANY?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Michael""});
CREATE (:Person {name: ""Ryan""});
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.properties.distinct(""Person"", ""name"");
Table 1. Results
value
[""Michael"", ""Ryan""]
More documentation of apoc.schema.properties.distinct
apoc.schema.nodes
apoc.schema.properties.distinctCount
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.nodes;"apoc.schema.nodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.schema.nodes(config Map<String, Any>) - returns all indexes and constraints information for all node labels in the database. It is possible to define a set of labels to include or exclude in the config parameters.
Signature
None
Copy to Clipboard
apoc.schema.nodes(config = {} :: MAP?) :: (name :: STRING?, label :: ANY?, properties :: LIST? OF STRING?, status :: STRING?, type :: STRING?, failure :: STRING?, populationProgress :: FLOAT?, size :: INTEGER?, valuesSelectivity :: FLOAT?, userDescription :: STRING?)
Input parameters
Name Type Default
config
MAP?
{}
Output parameters
Name Type
name
STRING?
label
ANY?
properties
LIST? OF STRING?
status
STRING?
type
STRING?
failure
STRING?
populationProgress
FLOAT?
size
INTEGER?
valuesSelectivity
FLOAT?
userDescription
STRING?
Usage Examples
The examples in this section are based on a database that has applied the following constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT personName FOR (person:Person)
REQUIRE person.name IS UNIQUE;

CREATE CONSTRAINT userId FOR (user:User)
REQUIRE user.id IS UNIQUE;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.nodes();
Table 1. Results
name label properties status type failure populationProgress size valuesSelectivity userDescription
"":Person(name)""
""Person""
[""name""]
""ONLINE""
""UNIQUENESS""
""NO FAILURE""
100.0
7
1.0
""Index( id=1, name='personName', type='UNIQUE RANGE', schema=(:Person {name}), indexProvider='native-btree-1.0' )""
"":User(id)""
""User""
[""id""]
""ONLINE""
""UNIQUENESS""
""NO FAILURE""
100.0
0
1.0
""Index( id=3, name='userId', type='UNIQUE RANGE', schema=(:User {id}), indexProvider='native-btree-1.0' )""
More documentation of apoc.schema.nodes
apoc.schema.assert
apoc.schema.properties.distinct
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.assert;"apoc.schema.assert
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.schema.assert(indexes Map<String, [Any]>, constraints Map<String, [Any]>, dropExisting Boolean) - drops all other existing indexes and constraints when dropExisting is true (default is true). Asserts at the end of the operation that the given indexes and unique constraints are there.
Signature
None
Copy to Clipboard
apoc.schema.assert(indexes :: MAP?, constraints :: MAP?, dropExisting = true :: BOOLEAN?) :: (label :: ANY?, key :: STRING?, keys :: LIST? OF STRING?, unique :: BOOLEAN?, action :: STRING?)
Input parameters
Name Type Default
indexes
MAP?
null
constraints
MAP?
null
dropExisting
BOOLEAN?
true
Output parameters
Name Type
label
ANY?
key
STRING?
keys
LIST? OF STRING?
unique
BOOLEAN?
action
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert({
  Person: [""id""]
}, {
  Person: [""name""]
});
We can create a uniqueness constraint on :Person(name) and an index on :Person(id) by running the following query:
Table 1. Results
label key keys unique action
""Person""
""id""
[""id""]
FALSE
""CREATED""
""Person""
""name""
[""name""]
TRUE
""CREATED""
We can drop all constraints and indexes, by running the following query. Note that the cancellation mechanism doesn’t consider indexes of type LOOKUP and multi-token indexes, that is indexes applicable to multiple rel-types or multiple labels, for example CREATE FULLTEXT INDEX titlesAndDescriptions FOR (n:Movie|Book) ON EACH [n.title, n.description] or CREATE FULLTEXT INDEX fullIdxRel FOR ()-[r:TYPE_1|TYPE_2]-() ON EACH [r.alpha, r.beta]. This because they cannot be re-created by the apoc.schema.assert procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert({}, {});
Table 2. Results
label key keys unique action
""Person""
""id""
[""id""]
FALSE
""DROPPED""
""Person""
""name""
[""name""]
TRUE
""DROPPED""
More documentation of apoc.schema.assert
apoc.schema
apoc.schema.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema;"apoc.schema
Qualified Name Type
apoc.schema.assert
apoc.schema.assert(indexes Map<String, [Any]>, constraints Map<String, [Any]>, dropExisting Boolean) - drops all other existing indexes and constraints when dropExisting is true (default is true). Asserts at the end of the operation that the given indexes and unique constraints are there.
Procedure
apoc.schema.nodes
apoc.schema.nodes(config Map<String, Any>) - returns all indexes and constraints information for all node labels in the database. It is possible to define a set of labels to include or exclude in the config parameters.
Procedure
apoc.schema.properties.distinct
apoc.schema.properties.distinct(label String, key String) - returns all distinct node property values for the given key.
Procedure
apoc.schema.properties.distinctCount
apoc.schema.properties.distinctCount(label String, key String) - returns all distinct property values and counts for the given key.
Procedure
apoc.schema.relationships
apoc.schema.relationships(config Map<String, Any>) - returns the indexes and constraints information for all the relationship types in the database. It is possible to define a set of relationship types to include or exclude in the config parameters.
Procedure
apoc.schema.node.constraintExists
apoc.schema.node.constraintExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given node label with the given property names.
Function
apoc.schema.node.indexExists
apoc.schema.node.indexExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not an index exists for the given node label with the given property names.
Function
apoc.schema.relationship.constraintExists
apoc.schema.relationship.constraintExists(type String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given relationship type with the given property names.
Function
apoc.schema.relationship.indexExists
apoc.schema.relationship.indexExists(type String, propertyName [String])- returns a boolean depending on whether or not an index exists for the given relationship type with the given property names.
Function
apoc.rel.type
apoc.schema.assert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.schema/apoc.schema.relationship.indexExists;"apoc.schema.relationship.indexExists
Contents
Signature
Input parameters
Function
apoc.schema.relationship.indexExists(type String, propertyName [String])- returns a boolean depending on whether or not an index exists for the given relationship type with the given property names.
Signature
None
Copy to Clipboard
apoc.schema.relationship.indexExists(type :: STRING?, propertyName :: LIST? OF STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
labelName
STRING?
null
propertyName
LIST? OF STRING?
null
More documentation of apoc.schema.relationship.indexExists
apoc.schema.relationship.constraintExists
apoc.scoring
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.scoring;"apoc.scoring
Qualified Name Type
apoc.scoring.existence
apoc.scoring.existence(score Integer, exists Boolean) - returns the given score if true, 0 if false.
Function
apoc.scoring.pareto
apoc.scoring.pareto(minimumThreshold Integer, eightyPercentValue Integer, maximumValue Integer, score Integer) - applies a Pareto scoring function over the given integers.
Function
apoc.schema.relationship.indexExists
apoc.scoring.existence
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.scoring/apoc.scoring.pareto;"apoc.scoring.pareto
Contents
Signature
Input parameters
Usage Examples
Function
apoc.scoring.pareto(minimumThreshold Integer, eightyPercentValue Integer, maximumValue Integer, score Integer) - applies a Pareto scoring function over the given integers.
Signature
None
Copy to Clipboard
apoc.scoring.pareto(minimumThreshold :: INTEGER?, eightyPercentValue :: INTEGER?, maximumValue :: INTEGER?, score :: INTEGER?) :: (FLOAT?)
Input parameters
Name Type Default
minimumThreshold
INTEGER?
null
eightyPercentValue
INTEGER?
null
maximumValue
INTEGER?
null
score
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND [0,1,2,8,10,100] as value
RETURN value, apoc.scoring.pareto(2,8,10,value) as output;
Table 1. Results
value output
0
0.0
1
0.0
2
3.31259695023578
8
8.0
10
8.662519390047157
100
9.999999981682132
apoc.scoring.existence
apoc.search
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.scoring/apoc.scoring.existence;"apoc.scoring.existence
Contents
Signature
Input parameters
Usage Examples
Function
apoc.scoring.existence(score Integer, exists Boolean) - returns the given score if true, 0 if false.
Signature
None
Copy to Clipboard
apoc.scoring.existence(score :: INTEGER?, exists :: BOOLEAN?) :: (FLOAT?)
Input parameters
Name Type Default
score
INTEGER?
null
exists
BOOLEAN?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.scoring.existence(10,true) AS output;
Table 1. Results
output
10.0
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.scoring.existence(10,false) AS output;
Table 2. Results
output
0.0
apoc.scoring
apoc.scoring.pareto
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search;"apoc.search
Qualified Name Type
apoc.search.multiSearchReduced
apoc.search.multiSearchReduced(labelPropertyMap Any, operator String, value String) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Procedure
apoc.search.node
apoc.search.node(labelPropertyMap Any, operator String, value String) - returns all the distinct nodes found after a parallel search over multiple indexes.
Procedure
apoc.search.nodeAll
apoc.search.nodeAll(labelPropertyMap Any, operator String, value String) - returns all the nodes found after a parallel search over multiple indexes.
Procedure
apoc.search.nodeAllReduced
apoc.search.nodeAllReduced(labelPropertyMap Any, operator String, value Any) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Procedure
apoc.scoring.pareto
apoc.search.multiSearchReduced
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search/apoc.search.nodeAll;"apoc.search.nodeAll
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.search.nodeAll(labelPropertyMap Any, operator String, value String) - returns all the nodes found after a parallel search over multiple indexes.
Signature
None
Copy to Clipboard
apoc.search.nodeAll(LabelPropertyMap :: ANY?, operator :: STRING?, value :: STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
LabelPropertyMap
ANY?
null
operator
STRING?
null
value
STRING?
null
Output parameters
Name Type
node
NODE?
More documentation of apoc.search.nodeAll
apoc.search.node
apoc.search.nodeAllReduced
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/parallel-node-search;"Parallel Node Search
Utility to find nodes in parallel (if possible). These procedures return a single list of nodes or a list of 'reduced' records with node id, labels, and the properties where the search was executed upon.
Qualified Name Type
apoc.search.node
Do a parallel search over multiple indexes returning nodes. usage apoc.search.node( map of label and properties which will be searched upon, operator: EXACT | CONTAINS | STARTS WITH | ENDS WITH, searchValue ) returns all the DISTINCT Nodes found in the different searches.
Procedure
apoc.search.nodeAll
Do a parallel search over multiple indexes returning nodes. usage apoc.search.nodeAll( map of label and properties which will be searched upon, operator: EXACT | CONTAINS | STARTS WITH | ENDS WITH, searchValue ) returns all the Nodes found in the different searches.
Procedure
apoc.search.nodeReduced
Do a parallel search over multiple indexes returning a reduced representation of the nodes found: node id, labels and the searched properties. apoc.search.nodeReduced( map of label and properties which will be searched upon, operator: EXACT | CONTAINS | STARTS WITH | ENDS WITH, searchValue ). Multiple search results for the same node are merged into one record.
Procedure
apoc.search.nodeAllReduced
Do a parallel search over multiple indexes returning a reduced representation of the nodes found: node id, labels and the searched property. apoc.search.nodeShortAll( map of label and properties which will be searched upon, operator: EXACT / CONTAINS / STARTS WITH | ENDS WITH / = / <> / < / > …, value ). All 'hits' are returned.
Procedure
These procedures are passed the following parameters:
labelPropertyMap
'{ label1 : ""propertyOne"", label2 :[""propOne"",""propTwo""] }'
(JSON or Map) For every Label-Property combination a search will be executed in parallel (if possible): Label1.propertyOne, label2.propOne and label2.propTwo.
searchType
'exact' or 'contains' or 'starts with' or 'ends with'
Case insensitive string search operators
searchType
""<"", "">"", ""="", ""<>"", ""⇐"", "">="", ""=~""
Operators
search
'Keanu'
The actual search term (string, number, etc).
Cypher
example
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.search.nodeAll('{Person: ""name"",Movie: [""title"",""tagline""]}','contains','her') YIELD node AS n RETURN n
call apoc.search.nodeReduced({Person: 'born', Movie: ['released']},'>',2000) yield id, labels, properties RETURN *
Node Querying
Comparing Graphs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search/apoc.search.nodeReduced;"apoc.search.nodeReduced
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.search.nodeReduced(labelPropertyMap Any, operator String, value String) - returns a reduced representation of the distinct nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Signature
None
Copy to Clipboard
apoc.search.nodeReduced(LabelPropertyMap :: ANY?, operator :: STRING?, value :: STRING?) :: (id :: INTEGER?, labels :: LIST? OF STRING?, values :: MAP?)
Input parameters
Name Type Default
LabelPropertyMap
ANY?
null
operator
STRING?
null
value
STRING?
null
Output parameters
Name Type
id
INTEGER?
labels
LIST? OF STRING?
values
MAP?
More documentation of apoc.search.nodeReduced
apoc.search.nodeAllReduced
apoc.spatial
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search/apoc.search.nodeAllReduced;"apoc.search.nodeAllReduced
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.search.nodeAllReduced(labelPropertyMap Any, operator String, value Any) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Signature
None
Copy to Clipboard
apoc.search.nodeAllReduced(LabelPropertyMap :: ANY?, operator :: STRING?, value :: ANY?) :: (id :: INTEGER?, labels :: LIST? OF STRING?, values :: MAP?)
Input parameters
Name Type Default
LabelPropertyMap
ANY?
null
operator
STRING?
null
value
ANY?
null
Output parameters
Name Type
id
INTEGER?
labels
LIST? OF STRING?
values
MAP?
More documentation of apoc.search.nodeAllReduced
apoc.search.nodeAll
apoc.search.nodeReduced
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.spatial;"apoc.spatial
Qualified Name Type
apoc.spatial.geocode
apoc.spatial.geocode(location String, maxResults Integer, quotaException Boolean, config Map<String, Any>) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap).
Procedure
apoc.spatial.geocodeOnce
apoc.spatial.geocodeOnce(location String, config Map<String, Any>) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Procedure
apoc.spatial.reverseGeocode
apoc.spatial.reverseGeocode(latitude Float, longitude Float, quotaException Boolean, config Map<String, Any>) - returns a textual address from the given geographic location (latitude, longitude) using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Procedure
apoc.spatial.sortByDistance
apoc.spatial.sortByDistance(paths [Path]) - sorts the given collection of paths by the sum of their distance based on the latitude/longitude values on the nodes.
Procedure
apoc.search.nodeReduced
apoc.spatial.geocode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.spatial/apoc.spatial.reverseGeocode;"apoc.spatial.reverseGeocode
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.spatial.reverseGeocode(latitude Float, longitude Float, quotaException Boolean, config Map<String, Any>) - returns a textual address from the given geographic location (latitude, longitude) using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Signature
None
Copy to Clipboard
apoc.spatial.reverseGeocode(latitude :: FLOAT?, longitude :: FLOAT?, quotaException = false :: BOOLEAN?, config :: MAP?) :: (location :: MAP?, data :: MAP?, latitude :: FLOAT?, longitude :: FLOAT?, description :: STRING?)
Input parameters
Name Type Default
latitude
FLOAT?
null
longitude
FLOAT?
null
quotaException
BOOLEAN?
false
config
MAP?
null
Output parameters
Name Type
location
MAP?
data
MAP?
latitude
FLOAT?
longitude
FLOAT?
description
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.reverseGeocode(51.5074, 0.1277);
Table 1. Results
location data latitude longitude description
{description: ""Crossway, London Borough of Bexley, London, Greater London, England, SE28 8NH, United Kingdom"", latitude: 51.50743369498096, longitud e: 0.1274535888695359}
{country: ""United Kingdom"", country_code: ""gb"", road: ""Crossway"", city: ""London"", state_district: ""Greater London"", postcode: ""SE28 8NH"", state: ""England"", city_district: ""London Borough of Bexley""}
51.50743369498096
0.1274535888695359
""Crossway, London Borough of Bexl ey, London, Greater London, England, SE28 8NH, United Kingdom""
More documentation of apoc.spatial.reverseGeocode
apoc.spatial.geocodeOnce
apoc.spatial.sortByDistance
Was this page helpful?"
https://neo4j.com/docs/apoc/5/misc/spatial;"Spatial
Contents
Geocode
Configuring Geocode
Configuring Custom Geocode Provider
Configure via config parameter map
Using Geocode within a bigger Cypher query
Calculating distance between locations
sortByDistance
Graph Refactoring
Combined Space and Time search
The spatial procedures enable geographic capabilities on your data, and complement the spatial functions that come with Neo4j. More extensive Spatial functionality can be found in the Neo4j Spatial Library.
Qualified Name Type
apoc.spatial.geocode
apoc.spatial.geocode('address', maxResults, quotaException, $config) YIELD location, latitude, longitude, description, osmData - look up geographic location of address from a geocoding service (the default one is OpenStreetMap)
Procedure
apoc.spatial.reverseGeocode
apoc.spatial.reverseGeocode(latitude,longitude, quotaException, $config) YIELD location, latitude, longitude, description - look up address from latitude and longitude from a geocoding service (the default one is OpenStreetMap)
Procedure
apoc.spatial.sortByDistance
apoc.spatial.sortByDistance(List<Path>) sort the given paths based on the geo informations (lat/long) in ascending order
Procedure
Geocode
The geocode procedure converts a textual address into a location containing latitude, longitude and description. Despite being only a single function, together with the built-in functions point and distance we can achieve quite powerful results.
First, how can we use the procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.geocodeOnce('21 rue Paul Bellamy 44000 NANTES FRANCE')
YIELD location
RETURN location.latitude, location.longitude
Table 1. Results
location.latitude location.longitude
47.2221667
-1.5566625
There are three forms of the procedure:
geocodeOnce(address) returns zero or one result.
geocode(address,maxResults) returns zero, one or more up to maxResults.
reverseGeocode(latitude,longitude) returns zero or one result.
This is because the backing geocoding service (OSM, Google, OpenCage or other) might return multiple results for the same query. GeocodeOnce() is designed to return the first, or highest ranking result.
The third procedure reverseGeocode will convert a location containing latitude and longitude into a textual address.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.reverseGeocode(47.2221667,-1.5566625) YIELD location
RETURN location.description;
Table 2. Results
location.description
""21, Rue Paul Bellamy, Talensac - Pont Morand, Hauts-Pavés - Saint-Félix, Nantes, Loire-Atlantique, Pays de la Loire, France métropolitaine, 44000, France""
Configuring Geocode
There are a few options that can be set in the apoc.conf file or via $config parameter (see below the Configure via config parameter map section) to control the service.
In the apoc.conf we can pass:
apoc.spatial.geocode.provider=osm (osm, google, opencage, etc.)
apoc.spatial.geocode.osm.throttle=5000 (ms to delay between queries to not overload OSM servers)
apoc.spatial.geocode.google.throttle=1 (ms to delay between queries to not overload Google servers)
apoc.spatial.geocode.google.key=xxxx (API key for google geocode access)
apoc.spatial.geocode.google.client=xxxx (client code for google geocode access)
apoc.spatial.geocode.google.signature=xxxx (client signature for google geocode access)
For google, you should use either a key or a combination of client and signature. Read more about this on the google page for geocode access at https://developers.google.com/maps/documentation/geocoding/get-api-key#key
Configuring Custom Geocode Provider
Geocode
For any provider that is not 'osm' or 'google' you get a configurable supplier that requires two additional settings, 'url' and 'key'. The 'url' must contain the two words 'PLACE' and 'KEY'. The 'KEY' will be replaced with the key you get from the provider when you register for the service. The 'PLACE' will be replaced with the address to geocode when the procedure is called.
Reverse Geocode
The 'url' must contain the three words 'LAT', 'LNG' and 'KEY'. The 'LAT' will be replaced with the latitude and 'LNG' will be replaced with the the longitude to reverse geocode when the procedure is called.
For example, to get the service working with OpenCage, perform the following steps:
Register your own application key at https://geocoder.opencagedata.com/
Once you have a key, add the following three lines to apoc.conf
apoc.spatial.geocode.provider=opencage
apoc.spatial.geocode.opencage.key=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
apoc.spatial.geocode.opencage.url=http://api.opencagedata.com/geocode/v1/json?q=PLACE&key=KEY
apoc.spatial.geocode.opencage.reverse.url=http://api.opencagedata.com/geocode/v1/json?q=LAT+LNG&key=KEY
make sure that the 'XXXXXXX' part above is replaced with your actual key
Restart the Neo4j server and then test the geocode procedures to see that they work
If you are unsure if the provider is correctly configured try verify with:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.showConfig()
Configure via config parameter map
Alternatively, we can pass a config map.
Note that these configs take precedence over the apoc.conf settings.
We can pass a provider key, which will be equivalent to apoc.spatial.geocode.provider setting key, and the other keys will be equivalent to apoc.spatial.geocode.<PROVIDER>.<KEY> settings.
For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.geocodeOnce('<MY_PLACE>', {
  provider: 'opencage',
  url: 'http://api.opencagedata.com/geocode/v1/json?q=PLACE&key=KEY',
  reverseUrl: 'http://api.opencagedata.com/geocode/v1/json?q=LAT+LNG&key=KEY',
  key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'
})
is equivalent to these (note that we transform UpperCamelCase keys in dot.case, e.g from reverseUrl to reverse.url):
apoc.spatial.geocode.provider=opencage
apoc.spatial.geocode.opencage.key=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
apoc.spatial.geocode.opencage.url=http://api.opencagedata.com/geocode/v1/json?q=PLACE&key=KEY
apoc.spatial.geocode.opencage.reverse.url=http://api.opencagedata.com/geocode/v1/json?q=LAT+LNG&key=KEY
If we don’t pass the provider via config map, the setting apoc.spatial.geocode.provider will be choose, otherwise the default 'osm'. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
/* apoc.conf
  ...
  apoc.spatial.geocode.provider=google
  ...
*/
CALL apoc.spatial.geocodeOnce('<MY_PLACE>', {key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'})
will pass a config like apoc.spatial.geocode.google.key=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.
Using Geocode within a bigger Cypher query
A more complex, or useful, example which geocodes addresses found in properties of nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Place)
WHERE a.address IS NOT NULL
CALL apoc.spatial.geocodeOnce(a.address) YIELD location
RETURN location.latitude AS latitude, location.longitude AS longitude, location.description AS description
Calculating distance between locations
If we wish to calculate the distance between addresses, we need to use the point() function to convert latitude and longitude to Cyper Point types, and then use the point.distance() function to calculate the distance:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH point({latitude: 48.8582532, longitude: 2.294287}) AS eiffel
MATCH (a:Place)
WHERE a.address IS NOT NULL
CALL apoc.spatial.geocodeOnce(a.address) YIELD location
WITH location, point.distance(point(location), eiffel) AS distance
WHERE distance < 5000
RETURN location.description AS description, distance
ORDER BY distance
LIMIT 100
sortByDistance
The second procedure enables you to sort a given collection of paths by the sum of their distance based on lat/long properties on the nodes.
Sample data :
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (bruges:City {name:""bruges"", latitude: 51.2605829, longitude: 3.0817189})
CREATE (brussels:City {name:""brussels"", latitude: 50.854954, longitude: 4.3051786})
CREATE (paris:City {name:""paris"", latitude: 48.8588376, longitude: 2.2773455})
CREATE (dresden:City {name:""dresden"", latitude: 51.0767496, longitude: 13.6321595})
MERGE (bruges)-[:NEXT]->(brussels)
MERGE (brussels)-[:NEXT]->(dresden)
MERGE (brussels)-[:NEXT]->(paris)
MERGE (bruges)-[:NEXT]->(paris)
MERGE (paris)-[:NEXT]->(dresden)
Finding paths and sort them by distance
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:City {name:'bruges'}), (b:City {name:'dresden'})
MATCH p=(a)-[*]->(b)
WITH collect(p) as paths
CALL apoc.spatial.sortByDistance(paths) YIELD path, distance
RETURN path, distance
Graph Refactoring
In order not to have to repeatedly geocode the same thing in multiple queries, especially if the database will be used by many people, it might be a good idea to persist the results in the database so that subsequent calls can use the saved results.
Geocode and persist the result
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Place)
WHERE a.address IS NOT NULL AND a.latitude IS NULL
WITH a LIMIT 1000
CALL apoc.spatial.geocodeOnce(a.address) YIELD location
SET a.latitude = location.latitude
SET a.longitude = location.longitude
Note that the above command only geocodes the first 1000 ‘Place’ nodes that have not already been geocoded. This query can be run multiple times until all places are geocoded. Why would we want to do this? Two good reasons:
The geocoding service is a public service that can throttle or blacklist sites that hit the service too heavily, so controlling how much we do is useful.
The transaction is updating the database, and it is wise not to update the database with too many things in the same transaction, to avoid using up too much memory. This trick will keep the memory usage very low.
Now make use of the results in distance queries
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH point({latitude: 48.8582532, longitude: 2.294287}) AS eiffel
MATCH (a:Place)
WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL
WITH a, point.distance(point(a), eiffel) AS distance
WHERE distance < 5000
RETURN a.name, distance
ORDER BY distance
LIMIT 100
Combined Space and Time search
Combining spatial and date-time functions can allow for more complex queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH point({latitude: 48.8582532, longitude: 2.294287}) AS eiffel
MATCH (e:Event)
WHERE e.address IS NOT NULL AND e.datetime IS NOT NULL
CALL apoc.spatial.geocodeOnce(e.address) YIELD location
WITH e, location,
distance(point(location), eiffel) AS distance,
            (apoc.date.parse('2016-06-01 00:00:00','h') - apoc.date.parse(e.datetime,'h'))/24.0 AS days_before_due
WHERE distance < 5000 AND days_before_due < 14 AND apoc.date.parse(e.datetime,'h') < apoc.date.parse('2016-06-01 00:00:00','h')
RETURN e.name AS event, e.datetime AS date,
location.description AS description, distance
ORDER BY distance
Text Functions
Utilities
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.spatial/apoc.spatial.sortByDistance;"apoc.spatial.sortByDistance
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.spatial.sortByDistance(paths [Path]) - sorts the given collection of paths by the sum of their distance based on the latitude/longitude values on the nodes.
Signature
None
Copy to Clipboard
apoc.spatial.sortByDistance(paths :: LIST? OF PATH?) :: (path :: PATH?, distance :: FLOAT?)
Input parameters
Name Type Default
paths
LIST? OF PATH?
null
Output parameters
Name Type
path
PATH?
distance
FLOAT?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (bruges:City {name:""bruges"", latitude: 51.2605829, longitude: 3.0817189})
CREATE (brussels:City {name:""brussels"", latitude: 50.854954, longitude: 4.3051786})
CREATE (paris:City {name:""paris"", latitude: 48.8588376, longitude: 2.2773455})
CREATE (dresden:City {name:""dresden"", latitude: 51.0767496, longitude: 13.6321595})
MERGE (bruges)-[:NEXT]->(brussels)
MERGE (brussels)-[:NEXT]->(dresden)
MERGE (brussels)-[:NEXT]->(paris)
MERGE (bruges)-[:NEXT]->(paris)
MERGE (paris)-[:NEXT]->(dresden);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:City {name:'bruges'}), (b:City {name:'dresden'})
MATCH p=(a)-[*]->(b)
WITH collect(p) as paths
CALL apoc.spatial.sortByDistance(paths)
YIELD path, distance
RETURN path, distance;
Table 1. Results
path distance
(:City {name: ""bruges"", latitude: 51.2605829, longitude: 3.0817189})-[:NEXT]→(:City {name: ""brussels"", latitude: 50.854954, longitude: 4.3051786})- [:NEXT]→(:City {name: ""dresden"", latitude: 51.0767496, longitude: 13.6321595})
749.8210570020021
(:City {name: ""bruges"", latitude: 51.2605829, longitude: 3.0817189})-[:NEXT]→(:City {name: ""paris"", latitude: 48.8588376, longitude: 2.2773455})-[: NEXT]→(:City {name: ""dresden"", latitude: 51.0767496, longitude: 13.6321595})
1120.8512195180913
(:City {name: ""bruges"", latitude: 51.2605829, longitude: 3.0817189})-[:NEXT]→(:City {name: ""brussels"", latitude: 50.854954, longitude: 4.3051786})- [:NEXT]→(:City {name: ""paris"", latitude: 48.8588376, longitude: 2.2773455})-[:NEXT]→(:City {name: ""dresden"", latitude: 51.0767496, longitude: 13.632 1595})
1209.661314133324
More documentation of apoc.spatial.sortByDistance
apoc.spatial.reverseGeocode
apoc.stats
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.stats;"apoc.stats
Qualified Name Type
apoc.stats.degrees
apoc.stats.degrees(relTypes String) - returns the percentile groupings of the degrees on the nodes connected by the given relationship types.
Procedure
apoc.spatial.sortByDistance
apoc.stats.degrees
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.stats/apoc.stats.degrees;"apoc.stats.degrees
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.stats.degrees(relTypes String) - returns the percentile groupings of the degrees on the nodes connected by the given relationship types.
Signature
None
Copy to Clipboard
apoc.stats.degrees(types =  :: STRING?) :: (type :: STRING?, direction :: STRING?, total :: INTEGER?, p50 :: INTEGER?, p75 :: INTEGER?, p90 :: INTEGER?, p95 :: INTEGER?, p99 :: INTEGER?, p999 :: INTEGER?, max :: INTEGER?, min :: INTEGER?, mean :: FLOAT?)
Input parameters
Name Type Default
types
STRING?
Output parameters
Name Type
type
STRING?
direction
STRING?
total
INTEGER?
p50
INTEGER?
p75
INTEGER?
p90
INTEGER?
p95
INTEGER?
p99
INTEGER?
p999
INTEGER?
max
INTEGER?
min
INTEGER?
mean
FLOAT?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.stats.degrees();
Table 1. Results
type direction total p50 p75 p90 p95 p99 p999 max min mean
NULL
""BOTH""
7
1
1
1
7
7
7
7
1
1.75
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.stats.degrees(""ACTED_IN"");
Table 2. Results
type direction total p50 p75 p90 p95 p99 p999 max min mean
""ACTED_IN""
""BOTH""
4
1
1
1
4
4
4
4
0
1.0
apoc.stats
apoc.temporal
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.temporal;"apoc.temporal
Qualified Name Type
apoc.temporal.format
apoc.temporal.format(temporal Any, format String) - formats the given temporal value into the given time format.
Function
apoc.temporal.formatDuration
apoc.temporal.formatDuration(input Any, format String) - formats the given duration into the given time format.
Function
apoc.temporal.toZonedTemporal
apoc.temporal.toZonedTemporal(time String, format String, timezone String) - parses the given date string using the specified format into the given time zone.
Function
apoc.stats.degrees
apoc.temporal.format
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.temporal/apoc.temporal.toZonedTemporal;"apoc.temporal.toZonedTemporal
Contents
Signature
Input parameters
Usage Examples
Function
apoc.temporal.toZonedTemporal(time String, format String, timezone String) - parses the given date string using the specified format into the given time zone.
Signature
None
Copy to Clipboard
apoc.temporal.toZonedTemporal(time :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone = UTC :: STRING?) :: (DATETIME?)
Input parameters
Name Type Default
time
STRING?
null
format
STRING?
yyyy-MM-dd HH:mm:ss
timezone
STRING?
UTC
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.toZonedTemporal('2012-12-23 23:59:59',""yyyy-MM-dd HH:mm:ss"") AS output;
Table 1. Results
output
2012-12-23T23:59:59Z[UTC]
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.toZonedTemporal('2012-12-23 23:59:59',""yyyy-MM-dd HH:mm:ss"", ""+04:30"") AS output;
Table 2. Results
output
2012-12-24T04:29:59+04:30
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.toZonedTemporal('2012-12-23 23:59:59',""yyyy-MM-dd HH:mm:ss"", ""Pacific/Auckland"") AS output;
Table 3. Results
output
2012-12-23T23:59:59+13:00[Pacific/Auckland]
More documentation of apoc.temporal.toZonedTemporal
apoc.temporal.formatDuration
apoc.text
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.temporal/apoc.temporal.formatDuration;"apoc.temporal.formatDuration
Contents
Signature
Input parameters
Usage Examples
Function
apoc.temporal.formatDuration(input Any, format String) - formats the given duration into the given time format.
Signature
None
Copy to Clipboard
apoc.temporal.formatDuration(input :: ANY?, format :: STRING?) :: (STRING?)
Input parameters
Name Type Default
input
ANY?
null
format
STRING?
null
Usage Examples
This function handles a pattern string similar to the one used in DateTimeFormatter.ofPattern(<pattern>), but with some differences. Below is the conversion table between letters and Duration Fields:
letter field
y or Y or u
year
d or D
days
M or L
months of year
q or Q
quarters of year
w or W
weeks
h or H or k`or `K
hours
m
minutes of hour
s
seconds of minutes
n or S
nanoseconds of seconds
A
milliseconds
N
nanoseconds
I
ISO nanoseconds, i.e. with trimmed right zero. e.g. ""12300"" becomes ""123""
It is also possible to use one of a Predefined Java formats or as elastic formats, except ones which require timezone or weekyear, such as basic_date_time or week_date_time.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.formatDuration(duration({seconds: 6000}), ""hour"") AS output;
Table 1. Results
output
""01""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.formatDuration( duration({seconds: 10000}), ""hour_minute"") AS output;
Table 2. Results
output
""02:46""
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH duration.between(datetime('2017-06-02T18:40:32.1234560'), datetime('2019-07-13T19:41:33')) AS duration
RETURN apoc.temporal.formatDuration(duration, ""yy 'years' MM 'months' www 'weeks' dd 'days' - HH:mm:ss SSSS"") AS output
Table 3. Results
output
""02 years 01 months 001 weeks 11 days - 01:01:00 8765""
More documentation of apoc.temporal.formatDuration
apoc.temporal.format
apoc.temporal.toZonedTemporal
Was this page helpful?"
https://neo4j.com/docs/apoc/5/temporal/temporal-conversions;"Temporal Functions
Contents
Formatting Temporal Types
Formatting Durations
To ZonedDateTime
These functions can be used to format temporal values using a valid DateTimeFormatter pattern.
Formatting Temporal Types
You can pass through any temporal type (Date, Time, DateTime, LocalTime, LocalDateTime, Duration) along with a pattern. Please note that if the pattern is invalid for the value that you pass in (for example HH for hours on a Date value or DD for day on a Time value), an Exception will be thrown.
Cypher
Format as date
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( date(), 'YYYY-MM-dd') AS output;
Table 1. Results
Output
""2019-06-24""
Cypher
Format as date and time
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( datetime(), 'YYYY-MM-dd HH:mm:ss.SSSSZ') AS output;
Table 2. Results
Output
""2019-06-24 13:56:56.8550+0000""
Cypher
Format as time
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( localtime(), 'HH:mm:ss.SSSS') AS output;
Table 3. Results
Output
""13:57:31.9250""
View full pattern listing
You can also pass a ISO DATE TIME pattern, the list is available here ISO_DATE
For example:
Cypher
Format as date
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( date( { year: 2018, month: 12, day: 10 } ), 'date' ) as output;
Table 4. Results
Output
""2018-12-10""
Cypher
Format as date and time
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( localdatetime( { year: 2018, month: 12, day: 10, hour: 12, minute: 34, second: 56, nanosecond: 123456789 } ), 'ISO_LOCAL_DATE_TIME' ) as output;
Table 5. Results
Output
""2018-12-10T12:34:56.123456789""
Cypher
Format as date
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( date( { year: 2018, month: 12, day: 10 } ), 'ISO_DATE' ) as output;
Table 6. Results
Output
""2018-12-10""
Formatting Durations
When attempting to format a duration, the procedure will attempt to create a date (01/01/0000) and add the duration. This allows you to provide a consistent format as above.
Cypher
Format as duration
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( duration.between( datetime.transaction(), datetime.realtime() ) , 'HH:mm:ss.SSSS') AS output;
Table 7. Results
Output
""00:00:00.0110""
To ZonedDateTime
You can pass a string to be converted as a 1st parameter, a pattern to convert the string into a ZonedDateTime as a 2nd parameter (default: 'yyyy-MM-dd HH:mm:ss'), and the timezone as a 3rd parameter (default: 'UTC').
For example, using the default pattern and timezone:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.toZonedTemporal('2015-12-23 23:59:59') AS output;
Table 8. Results
Output
""2015-12-23T23:59:59[UTC]""
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.toZonedTemporal('2012-12-23T23:59:59', ""yyyy-MM-dd'T'HH:mm:ss"", ""Asia/Tokyo"") AS output;
Table 9. Results
Output
""2012-12-23T23:59:59[Asia/Tokyo]""
Temporal (Date Time)
Date and Time Conversions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/temporal;"Temporal (Date Time)
The APOC library adds support for formatting temporal types, timestamps, and date string values. For more information on how to use these procedures, see:
Temporal Functions
Date and Time Conversions
Collection Functions
Temporal Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/temporal/datetime-conversions;"Date and Time Conversions
Contents
Notes on formats for dates and times:
Procedure Overview
apoc.date.add
apoc.date.convert
apoc.date.convertFormat
apoc.date.currentTimestamp
apoc.date.field
apoc.date.fields
apoc.date.format
apoc.date.fromISO8601
apoc.date.parse
apoc.date.systemTimezone
apoc.date.toISO8601
apoc.date.toYears
Dates and times can show up in a variety of formats and configurations, often requiring translations or conversions for data storage systems, reports, web pages, and more. The APOC date functions allow users to take these Long or String values and manipulate them for different types of format requirements.
If you need to manipulate Date object types into other formats, see Temporal Functions.
Notes on formats for dates and times:
the default format is yyyy-MM-dd HH:mm:ss
if the format pattern doesn’t specify timezone, formatter considers dates to belong to the UTC timezone
if the timezone pattern is specified, the timezone is extracted from the date string, otherwise an error will be reported
the to/fromSeconds timestamp values are in POSIX (Unix time) system, i.e. timestamps represent the number of seconds elapsed since 00:00:00 UTC, Thursday, 1 January 1970
the full list of supported formats is described in SimpleDateFormat JavaDoc
Procedure Overview
The table below describes the available procedures:
Qualified Name Type
apoc.date.add
apoc.date.add(12345, 'ms', -365, 'd') - given a timestamp in one time unit, adds a value of the specified time unit
Function
apoc.date.convert
apoc.date.convert(12345, 'ms', 'd') - convert a timestamp in one time unit into one of a different time unit
Function
apoc.date.convertFormat
apoc.date.convertFormat('Tue, 14 May 2019 14:52:06 -0400', 'rfc_1123_date_time', 'iso_date_time') - convert a String of one date format into a String of another date format.
Function
apoc.date.currentTimestamp
apoc.date.currentTimestamp() - returns System.currentTimeMillis() at the time it was called. The value is current throughout transaction execution, and is different from Cypher’s timestamp() function, which does not update within a transaction.
Function
apoc.date.field
apoc.date.field(12345,('ms|s|m|h|d|month|year'),('TZ')
Function
apoc.date.fields
apoc.date.fields('2012-12-23',('yyyy-MM-dd')) - return columns and a map representation of date parsed with the given format with entries for years,months,weekdays,days,hours,minutes,seconds,zoneid
Function
apoc.date.format
apoc.date.format(12345,('ms|s|m|h|d'),('yyyy-MM-dd HH:mm:ss zzz'),('TZ')) - get string representation of time value optionally using the specified unit (default ms) using specified format (default ISO) and specified time zone (default current TZ)
Function
apoc.date.fromISO8601
apoc.date.fromISO8601('yyyy-MM-ddTHH:mm:ss.SSSZ') - return number representation of time in EPOCH format
Function
apoc.date.parse
apoc.date.parse('2012-12-23','ms|s|m|h|d','yyyy-MM-dd') - parse date string using the specified format into the specified time unit
Function
apoc.date.systemTimezone
apoc.date.systemTimezone() - returns the system timezone display name
Function
apoc.date.toISO8601
apoc.date.toISO8601(12345,('ms|s|m|h|d') - return string representation of time in ISO8601 format
Function
apoc.date.toYears
toYears(timestamp) or toYears(date[,format]) - converts timestamp into floating point years
Function
apoc.date.add
This function can add or subtract time unit values to or from dates in the epoch format.
signature
apoc.date.add(time :: INTEGER?, unit :: STRING?, addValue :: INTEGER?, addUnit :: STRING?) :: (INTEGER?)
It accepts the following parameters:
Table 1. Config
name type description potential values
time
Integer
the date value (in epoch integer format) to operate upon
unit
String
the specificity of the input value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
addValue
Integer
the number to add or subtract from the time
addUnit
String
the unit type to add or subtract
ms,s,m,h,d or long forms
View usage examples
apoc.date.convert
This function converts date values of one time unit to date values of a different time unit.
signature
apoc.date.convert(time :: INTEGER?, unit :: STRING?, toUnit :: STRING?) :: (INTEGER?)
It accepts the following parameters:
Table 2. Config
name type description potential values
time
Integer
the date value (in epoch integer format) to operate upon
unit
String
the specificity of the input value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
toUnit
String
the unit type for the output value
ms,s,m,h,d or long forms
View usage examples
apoc.date.convertFormat
This function converts date strings of one format to date strings of a different format.
signature
apoc.date.convertFormat(temporal :: STRING?, currentFormat :: STRING?, convertTo = yyyy-MM-dd :: STRING?) :: (STRING?)
It accepts the following parameters:
Table 3. Config
name type description potential values
temporal
String
the date string that needs converted
currentFormat
String
the format of the input date string
see the Java documentation for full list (under Patterns for Formatting and Parsing)
convertTo
String
the format for the output temporal type
can be specified manually with Java formats or as built-in formats
View usage examples
apoc.date.currentTimestamp
This function returns the current timestamp from the system at the time it is called. It provides the System.currentTimeMillis(), which is current throughout transaction execution, and is different from Cypher’s timestamp() function, which does not update within a transaction.
signature
apoc.date.currentTimestamp() :: (INTEGER?)
It accepts no parameters.
View usage examples
apoc.date.field
This function extracts the value of one field from a date in epoch format.
signature
apoc.date.field(time :: INTEGER?, unit = d :: STRING?, timezone = UTC :: STRING?) :: (INTEGER?)
In version 3.4 Neo4j introduced temporal data types, which are the recommended way of representing dates in Neo4j. Fields of a temporal type can be retrieved using Cypher’s instance.field function. (e.g. datetime({epochMillis: dateInteger}).year) See the Cypher documentation for more details on the syntax.
If, however, you still need to convert timestamp formats, this procedure provides that functionality.
It accepts the following parameters:
Table 4. Config
name type description potential values
time
Integer
the date value (in epoch integer format) to operate upon
unit
String
the specificity of the input value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
timezone
String
the timezone of the resulting date string
can be specified with GMT or database (text) name, as listed for timezones
View usage examples
apoc.date.fields
This function extracts values of all fields from a date in epoch format and returns the columns and a map representation.
signature
apoc.date.fields(date :: STRING?, pattern = yyyy-MM-dd HH:mm:ss :: STRING?) :: (MAP?)
In version 3.4 Neo4j introduced temporal data types, which are the recommended way of representing dates in Neo4j. Fields of a temporal type can be retrieved using Cypher’s instance.field function. (e.g. datetime({epochMillis: dateInteger}).year) See the Cypher documentation for more details on the syntax.
If, however, you still need to convert timestamp formats, this procedure provides that functionality.
It accepts the following parameters:
Table 5. Config
name type description potential values
date
String
the date string that needs formatted
date string in an ISO8601 standard format
pattern
String
the format of the input date string
see the Java documentation for full list (under Patterns for Formatting and Parsing)
View usage examples
apoc.date.format
This function converts dates in epoch format to date strings with a specified format.
signature
apoc.date.format(time :: INTEGER?, unit = ms :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone = :: STRING?) :: (STRING?)
It accepts the following parameters:
Table 6. Config
name type description potential values
time
Integer
the date value (in epoch integer format) to operate upon
unit
String
the specificity of the input value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
format
String
the format for the output date string
can be specified manually with Java formats or as built-in formats
timezone
String
the timezone of the resulting date string
can be specified with GMT or database (text) name, as listed for timezones
View usage examples
apoc.date.fromISO8601
This function converts date strings in an ISO8601 standard format to dates in epoch format.
signature
apoc.date.format(time :: INTEGER?, unit = ms :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone = :: STRING?) :: (STRING?)
It accepts the following parameters:
Table 7. Config
name type description potential values
time
String
the date string that needs formatted
date string in an ISO8601 standard format
The date string timezone expects only a GMT+00:00 format of Z as the timezone specifier. Other timezone specifications are not supported by this procedure.
View usage examples
apoc.date.parse
This function parses a date string in one format and converts it to a date of the specified time unit in Epoch format.
signature
apoc.date.parse(time :: STRING?, unit = ms :: STRING?, format = yyyy-MM-dd HH:mm:ss :: STRING?, timezone = :: STRING?) :: (INTEGER?)
It accepts the following parameters:
Table 8. Config
name type description potential values
time
String
the date string that needs formatted
date string in an ISO8601 standard format
unit
String
the specificity desired for the output date value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
format
String
the format of the date string to convert
see the Java documentation for full list (under Patterns for Formatting and Parsing)
timezone
String
the timezone of the resulting date string
can be specified with GMT or database (text) name, as listed for timezones
View usage examples
apoc.date.systemTimezone
This function returns the timezone display name of the system.
signature
apoc.date.systemTimezone() :: (STRING?)
It accepts no parameters.
View usage examples
apoc.date.toISO8601
This function converts dates in epoch format to date strings in ISO8601 standard format.
signature
apoc.date.toISO8601(time :: INTEGER?, unit = ms :: STRING?) :: (STRING?)
It accepts the following parameters:
Table 9. Config
name type description potential values
time
Integer
the date value (in epoch integer format) to operate upon
unit
String
the specificity of the input value
ms,s,m,h,d or long forms (millis,seconds,minutes,hours,days)
View usage examples
apoc.date.toYears
This function can make a couple of different conversions.
Convert dates in epoch millisecond format to the number of years that have passed since the Unix epoch time of January 1, 1970.
Convert date strings in specified formats to the number of years that have passed since the year 0.
signature
apoc.date.toISO8601(time :: INTEGER?, unit = ms :: STRING?) :: (STRING?)
It accepts the following parameters for each conversion:
Table 10. Config - epoch to years
name type description potential values
value
Integer
the date value (in epoch millisecond integer format) to operate upon
NOTE: the timestamp must be in ms format!
Table 11. Config - string date to years
name type description potential values
value
String
the date string that needs formatted
date string in an ISO8601 standard format
format
String
the format of the date string to convert
see the Java documentation for full list (under Patterns for Formatting and Parsing)
View usage examples
Temporal Functions
Mathematical Operations
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical;"Mathematical Operations
For more information on how to use the mathematical procedures and functions in the APOC library, see:
Bitwise Operations
Exact Math
Mathematical Functions
Number Format Conversions
Sigmoid & Hyperbolic Operations
Date and Time Conversions
Bitwise Operations
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical/math-functions;"Mathematical Functions
Contents
Functions for common mathematical operations
Examples
Functions for common mathematical operations
Qualified Name Type
apoc.math.maxByte
apoc.math.maxByte() - returns the maximum value of a byte.
Function
apoc.math.maxDouble
apoc.math.maxDouble() - returns the largest positive finite value of type double.
Function
apoc.math.maxInt
apoc.math.maxInt() - returns the maximum value of an integer.
Function
apoc.math.maxLong
apoc.math.maxLong() - returns the maximum value of a long.
Function
apoc.math.minByte
apoc.math.minByte() - returns the minimum value of a byte.
Function
apoc.math.minDouble
apoc.math.minDouble() - returns the smallest positive non-zero value of type double.
Function
apoc.math.minInt
apoc.math.minInt() - returns the minimum value of an integer.
Function
apoc.math.minLong
apoc.math.minLong() - returns the minimum value of a long.
Function
apoc.number.arabicToRoman
apoc.number.arabicToRoman(number Any) - converts the given Arabic numbers to Roman numbers.
Function
apoc.number.romanToArabic
apoc.number.romanToArabic(romanNumber String) - converts the given Roman numbers to Arabic numbers.
Function
Examples
Cypher
The following returns the maximum long value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxLong() AS output;
Table 1. Results
Output
9223372036854775807
Cypher
The following returns the minimum long value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minLong() AS output;
Table 2. Results
Output
-9223372036854775808
Cypher
The following returns the maximum double value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxDouble() AS output;
Table 3. Results
Output
1.7976931348623157e+308.0
Cypher
The following returns the minimum double value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minDouble() AS output;
Table 4. Results
Output
5e-324
Cypher
The following returns the maximum int value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxInt() AS output;
Table 5. Results
Output
2147483647
Cypher
The following returns the minimum int value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minInt() AS output;
Table 6. Results
Output
-2147483648
Cypher
The following returns the maximum byte value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxByte() AS output;
Table 7. Results
Output
127
Cypher
The following returns the minimum byte value:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minByte() AS output;
Table 8. Results
Output
-128
Exact Math
Number Format Conversions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.maxDouble;"apoc.math.maxDouble
Contents
Signature
Usage Examples
Function
apoc.math.maxDouble() - returns the largest positive finite value of type double.
Signature
None
Copy to Clipboard
apoc.math.maxDouble() :: (FLOAT?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxDouble() AS output;
Table 1. Results
output
1.7976931348623157E308
More documentation of apoc.math.maxDouble
apoc.math.maxByte
apoc.math.maxInt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.maxInt;"apoc.math.maxInt
Contents
Signature
Usage Examples
Function
apoc.math.maxInt() - returns the maximum value of an integer.
Signature
None
Copy to Clipboard
apoc.math.maxInt() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxInt() AS output;
Table 1. Results
output
2147483647
More documentation of apoc.math.maxInt
apoc.math.maxDouble
apoc.math.maxLong
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.maxLong;"apoc.math.maxLong
Contents
Signature
Usage Examples
Function
apoc.math.maxLong() - returns the maximum value of a long.
Signature
None
Copy to Clipboard
apoc.math.maxLong() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxLong() AS output;
Table 1. Results
output
9223372036854775807
More documentation of apoc.math.maxLong
apoc.math.maxInt
apoc.math.minByte
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.minByte;"apoc.math.minByte
Contents
Signature
Usage Examples
Function
apoc.math.minByte() - returns the minimum value of a byte.
Signature
None
Copy to Clipboard
apoc.math.minByte() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minByte() AS output;
Table 1. Results
output
-128
More documentation of apoc.math.minByte
apoc.math.maxLong
apoc.math.minDouble
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.minDouble;"apoc.math.minDouble
Contents
Signature
Usage Examples
Function
apoc.math.minDouble() - returns the smallest positive non-zero value of type double.
Signature
None
Copy to Clipboard
apoc.math.minDouble() :: (FLOAT?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minDouble() AS output;
Table 1. Results
output
4.9E-324
More documentation of apoc.math.minDouble
apoc.math.minByte
apoc.math.minInt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.minInt;"apoc.math.minInt
Contents
Signature
Usage Examples
Function
apoc.math.minInt() - returns the minimum value of an integer.
Signature
None
Copy to Clipboard
apoc.math.minInt() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minInt() AS output;
Table 1. Results
output
-2147483648
More documentation of apoc.math.minInt
apoc.math.minDouble
apoc.math.minLong
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.minLong;"apoc.math.minLong
Contents
Signature
Usage Examples
Function
apoc.math.minLong() - returns the minimum value of a long.
Signature
None
Copy to Clipboard
apoc.math.minLong() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.minLong() AS output;
Table 1. Results
output
-9223372036854775808
More documentation of apoc.math.minLong
apoc.math.minInt
apoc.math.sech
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.sech;"apoc.math.sech
Contents
Signature
Input parameters
Function
apoc.math.sech(value Float) - returns the hyperbolic secant of the given value.
Signature
None
Copy to Clipboard
apoc.math.sech(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.minLong
apoc.math.sigmoid
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.sigmoid;"apoc.math.sigmoid
Contents
Signature
Input parameters
Function
apoc.math.sigmoid(value Float) - returns the sigmoid of the given value.
Signature
None
Copy to Clipboard
apoc.math.sigmoid(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.sech
apoc.math.sigmoidPrime
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.sigmoidPrime;"apoc.math.sigmoidPrime
Contents
Signature
Input parameters
Function
apoc.math.sigmoidPrime(value Float) - returns the sigmoid prime [ sigmoid(val) * (1 - sigmoid(val)) ] of the given value.
Signature
None
Copy to Clipboard
apoc.math.sigmoidPrime(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.sigmoid
apoc.math.sinh
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.maxByte;"apoc.math.maxByte
Contents
Signature
Usage Examples
Function
apoc.math.maxByte() - returns the maximum value of a byte.
Signature
None
Copy to Clipboard
apoc.math.maxByte() :: (INTEGER?)
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.math.maxByte() AS output;
Table 1. Results
output
127
More documentation of apoc.math.maxByte
apoc.math.csch
apoc.math.maxDouble
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.csch;"apoc.math.csch
Contents
Signature
Input parameters
Function
apoc.math.csch(value Float) - returns the hyperbolic cosecant.
Signature
None
Copy to Clipboard
apoc.math.csch(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.coth
apoc.math.maxByte
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.coth;"apoc.math.coth
Contents
Signature
Input parameters
Function
apoc.math.coth(value Float) - returns the hyperbolic cotangent.
Signature
None
Copy to Clipboard
apoc.math.coth(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.cosh
apoc.math.csch
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.cosh;"apoc.math.cosh
Contents
Signature
Input parameters
Function
apoc.math.cosh(value Float) - returns the hyperbolic cosine.
Signature
None
Copy to Clipboard
apoc.math.cosh(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.regr
apoc.math.coth
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.regr;"apoc.math.regr
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.math.regr(label String, propertyY String, propertyX String) - returns the coefficient of determination (R-squared) for the values of propertyY and propertyX in the given label.
Signature
None
Copy to Clipboard
apoc.math.regr(label :: STRING?, propertyY :: STRING?, propertyX :: STRING?) :: (r2 :: FLOAT?, avgX :: FLOAT?, avgY :: FLOAT?, slope :: FLOAT?)
Input parameters
Name Type Default
label
STRING?
null
propertyY
STRING?
null
propertyX
STRING?
null
Output parameters
Name Type
r2
FLOAT?
avgX
FLOAT?
avgY
FLOAT?
slope
FLOAT?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:REGR_TEST {x_property: 1 , y_property: 2 })
CREATE (:REGR_TEST {x_property: 2 , y_property: 3 })
CREATE (:REGR_TEST {y_property: 10000 })
CREATE (:REGR_TEST {x_property: 3 , y_property: 6 });
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.math.regr('REGR_TEST', 'y_property', 'x_property');
Table 1. Results
r2 avgX avgY slope
0.9854227405247813
2.0
3.6666666666666665
1.8571428571428572
More documentation of apoc.math.regr
apoc.math
apoc.math.cosh
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical/exact-math-functions;"Exact Math
Contents
Functions for high precision arithmetic
Examples
Functions for high precision arithmetic
Qualified Name Type
apoc.number.exact.add
apoc.number.exact.add(stringA String, stringB String) - returns the result of adding the two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.div
apoc.number.exact.div(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of dividing a given large number with another given large number (using Java BigDecimal).
Function
apoc.number.exact.mul
apoc.number.exact.mul(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of multiplying two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.sub
apoc.number.exact.sub(stringA String, stringB String) - returns the result of subtracting a given large number from another given large number (using Java BigDecimal).
Function
apoc.number.exact.toExact
apoc.number.exact.toExact(number Integer) - returns the exact value of the given number (using Java BigDecimal).
Function
apoc.number.exact.toFloat
apoc.number.exact.toFloat(string String, precision Integer, roundingMode String) - returns the float value of the given large number (using Java BigDecimal).
Function
apoc.number.exact.toInteger
apoc.number.exact.toInteger(string String, precision Integer, roundingMode String) - returns the integer value of the given large number (using Java BigDecimal).
Function
Possible roundingMode options are UP, DOWN, CEILING, FLOOR, HALF_UP, HALF_DOWN, HALF_EVEN, UNNECESSARY.
The precision parameter allows users to set the precision of the operation result. The default value of the precision parameter is 0 (unlimited precision arithmetic), while for roundingMode the default value is HALF_UP. For more information abouth the precision and roundingMode parameters, see Java’s MathContext page.
Examples
In the below example, the precision parameter is set to 2. Consequently, only the first two digits of the returned result are precise.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.div('5555.5555','5', 2, 'HALF_DOWN') as value;
Table 1. Results
Value
1100
In the below example, the precision parameter is set to 8. The first eight digits of the returned result are therefore precise.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.div('5555.5555','5', 8, 'HALF_DOWN') as value;
Table 2. Results
Value
1111.1111
These functions accept scientific notation as input. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.number.exact.add('1E6','1E6') as value;
Table 3. Results
Value
2000000
For more information, see Java’s BigDecimal page and Java’s BigInteger page.
Bitwise Operations
Mathematical Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/mathematical/bitwise-operations;"Bitwise Operations
Contents
Functions for bitwise operations
Examples
Functions for bitwise operations
Qualified Name Type
apoc.bitwise.op
apoc.bitwise.op(a Integer, operator String, b Integer) - returns the result of the bitwise operation.
Function
Examples
operator name example result
a & b
AND
apoc.bitwise.op(60,""&"",13)
12
a | b
OR
apoc.bitwise.op(60,""|"",13)
61
a ^ b
XOR
apoc.bitwise.op(60,""&"",13)
49
~a
NOT
apoc.bitwise.op(60,""&"",0)
-61
a << b
LEFT SHIFT
apoc.bitwise.op(60,""<<"",2)
240
a >> b
RIGHT SHIFT
apoc.bitwise.op(60,"">>"",2)
15
a >>> b
UNSIGNED RIGHT SHIFT
apoc.bitwise.op(60,"">>>"",2)
15
Mathematical Operations
Exact Math
Was this page helpful?"
https://neo4j.com/docs/apoc/5/data-structures/collection-list-functions;"Collection Functions
APOC has a wide variety of Collection and List functions.
Qualified Name Type
apoc.coll.sum
apoc.coll.sum([0.5,1,2.3])
Function
apoc.coll.avg
apoc.coll.avg([0.5,1,2.3])
Function
apoc.coll.min
apoc.coll.min([0.5,1,2.3])
Function
apoc.coll.max
apoc.coll.max([0.5,1,2.3])
Function
apoc.coll.sumLongs
apoc.coll.sumLongs([1,3,3])
Function
apoc.coll.partition
apoc.coll.partition(list,batchSize)
Function
apoc.coll.zip
apoc.coll.zip([list1],[list2])
Function
apoc.coll.pairs
`apoc.coll.pairs([1,2,3]) returns [1,2],[2,3],[3,null] `
Function
apoc.coll.pairsMin
apoc.coll.pairsMin([1,2,3]) returns [1,2],[2,3]
Function
apoc.coll.toSet
apoc.coll.toSet([list]) returns a unique list backed by a set
Function
apoc.coll.sort
apoc.coll.sort(coll) sort on Collections
Function
apoc.coll.sortNodes
apoc.coll.sortNodes([nodes], 'name') sort nodes by property
Function
apoc.coll.sortMaps
apoc.coll.sortMaps([maps], 'name') - sort maps by property
Function
apoc.coll.contains
apoc.coll.contains(coll, value) optimized contains operation (using a HashSet) (returns single row or not)
Function
apoc.coll.containsAll
apoc.coll.containsAll(coll, values) optimized contains-all operation (using a HashSet) (returns single row or not)
Function
apoc.coll.containsSorted
apoc.coll.containsSorted(coll, value) optimized contains on a sorted list operation (Collections.binarySearch) (returns single row or not)
Function
apoc.coll.containsAllSorted
apoc.coll.containsAllSorted(coll, value) optimized contains-all on a sorted list operation (Collections.binarySearch) (returns single row or not)
Function
apoc.coll.isEqualCollection
apoc.coll.isEqualCollection(coll, values) return true if two collections contain the same elements with the same cardinality in any order (using a HashMap)
Function
apoc.coll.union
apoc.coll.union(first, second) - creates the distinct union of the 2 lists
Function
apoc.coll.unionAll
apoc.coll.unionAll(first, second) - creates the full union with duplicates of the two lists
Function
apoc.coll.subtract
apoc.coll.subtract(first, second) - returns unique set of first list with all elements of second list removed
Function
apoc.coll.removeAll
apoc.coll.removeAll(first, second) - returns first list with all elements of second list removed
Function
apoc.coll.intersection
apoc.coll.intersection(first, second) - returns the unique intersection of the two lists
Function
apoc.coll.disjunction
apoc.coll.disjunction(first, second) - returns the disjunct set of the two lists
Function
apoc.coll.split
apoc.coll.split(list,value) | splits collection on given values rows of lists, value itself will not be part of resulting lists
Procedure
apoc.coll.indexOf
apoc.coll.indexOf(coll, value) | position of value in the list
Function
apoc.coll.shuffle
apoc.coll.shuffle(coll) - returns the shuffled list
Function
apoc.coll.randomItem
apoc.coll.randomItem(coll)- returns a random item from the list, or null on an empty or null list
Function
apoc.coll.randomItems
apoc.coll.randomItems(coll, itemCount, allowRepick: false) - returns a list of itemCount random items from the original list, optionally allowing picked elements to be picked again
Function
apoc.coll.containsDuplicates
apoc.coll.containsDuplicates(coll) - returns true if a collection contains duplicate elements
Function
apoc.coll.duplicates
apoc.coll.duplicates(coll) - returns a list of duplicate items in the collection
Function
apoc.coll.duplicatesWithCount
apoc.coll.duplicatesWithCount(coll) - returns a list of duplicate items in the collection and their count, keyed by item and count (e.g., [{item: xyz, count:2}, {item:zyx, count:5}])
Function
apoc.coll.occurrences
apoc.coll.occurrences(coll, item) - returns the count of the given item in the collection
Function
apoc.coll.frequencies
apoc.coll.frequencies(coll) - returns a list of frequencies of the items in the collection, keyed by item and count (e.g., [{item: xyz, count:2}, {item:zyx, count:5}, {item:abc, count:1}])
Function
apoc.coll.frequenciesAsMap
apoc.coll.frequenciesAsMap(coll) - return a map of frequencies of the items in the collection, key item, value count (e.g., {1:2, 2:1})
Function
apoc.coll.sortMulti
apoc.coll.sortMulti(coll, ['^name','age'],[limit],[skip]) - sort list of maps by several sort fields (ascending with ^ prefix) and optionally applies limit and skip
Function
apoc.coll.flatten
apoc.coll.flatten(coll, [recursive]) - flattens list (nested if recursive is true)
Function
apoc.coll.combinations
apoc.coll.combinations(coll, minSelect, maxSelect:minSelect) - Returns collection of all combinations of list elements of selection size between minSelect and maxSelect (default:minSelect), inclusive
Function
apoc.coll.elements
apoc.coll.elements(list,limit,offset) yield _1,_2,..,_10,_1s,_2i,_3f,_4m,_5l,_6n,_7r,_8p - deconstruct subset of mixed list into identifiers of the correct type
Procedure
apoc.coll.set
apoc.coll.set(coll, index, value) | set index to value
Function
apoc.coll.insert
apoc.coll.insert(coll, index, value) | insert value at index
Function
apoc.coll.insertAll
apoc.coll.insertAll(coll, index, values) | insert values at index
Function
apoc.coll.remove
apoc.coll.remove(coll, index, [length=1]) | remove range of values from index to length
Function
apoc.coll.different
apoc.coll.different(values) - returns true if values are different
Function
apoc.coll.fill
apoc.coll.fill(item, count) - returns a list with the given count of items
Function
apoc.coll.sortText
apoc.coll.sortText(coll) sort on string based collections
Function
apoc.coll.pairWithOffset
apoc.coll.pairWithOffset(values, offset) - returns a list of pairs defined by the offset
Function
Map Functions
Temporal (Date Time)
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.coll/apoc.coll.pairWithOffset;"apoc.coll.pairWithOffset
Contents
Signature
Input parameters
Usage examples
Function
apoc.coll.pairWithOffset(coll [Any], offset Integer) - returns a list of pairs defined by the offset.
Signature
None
Copy to Clipboard
apoc.coll.pairWithOffset(values :: LIST? OF ANY?, offset :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
offset
INTEGER?
null
Usage examples
The following returns a list of pairs defined by the offset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.coll.pairWithOffset([1,2,3,4], 2) AS value
Table 1. Results
value
[[1,3],[2,4],[3,null],[4,null]]
It works also as procedure:
CALL apoc.coll.pairWithOffset([1,2,3,4], 2)
Table 2. Results
value
[1,3]
[2,4]
[3,null]
[4,null]
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.temporal/apoc.temporal.format;"apoc.temporal.format
Contents
Signature
Input parameters
Usage Examples
Function
apoc.temporal.format(temporal Any, format String) - formats the given temporal value into the given time format.
Signature
None
Copy to Clipboard
apoc.temporal.format(temporal :: ANY?, format = yyyy-MM-dd :: STRING?) :: (STRING?)
Input parameters
Name Type Default
temporal
ANY?
null
format
STRING?
yyyy-MM-dd
Usage Examples
Cypher
The following formats the current date:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( date(), 'YYYY-MM-dd') AS output;
Table 1. Results
output
""2021-01-19""
Cypher
The following formats the current datetime:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( datetime(), 'YYYY-MM-dd HH:mm:ss.SSSSZ') AS output;
Table 2. Results
output
""2021-01-19 10:57:25.2140+0000""
Cypher
The following formats the current time:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( localtime(), 'HH:mm:ss.SSSS') AS output;
Table 3. Results
output
""10:57:57.8140""
Cypher
The following formats a date:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( date( { year: 2018, month: 12, day: 10 } ), 'ISO_DATE' ) as output;
Table 4. Results
Output
""2018-12-10""
Cypher
The following formats a duration:
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.temporal.format( duration.between( datetime.transaction(), datetime.realtime() ) , 'HH:mm:ss.SSSS') AS output;
Table 5. Results
Output
""00:00:00.0131""
More documentation of apoc.temporal.format
apoc.temporal
apoc.temporal.formatDuration
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.spatial/apoc.spatial.geocode;"apoc.spatial.geocode
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.spatial.geocode(location String, maxResults Integer, quotaException Boolean, config Map<String, Any>) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap).
Signature
None
Copy to Clipboard
apoc.spatial.geocode(location :: STRING?, maxResults = 100 :: INTEGER?, quotaException = false :: BOOLEAN?, config :: MAP?) :: (location :: MAP?, data :: MAP?, latitude :: FLOAT?, longitude :: FLOAT?, description :: STRING?)
Input parameters
Name Type Default
location
STRING?
null
maxResults
INTEGER?
100
quotaException
BOOLEAN?
false
config
MAP?
null
Output parameters
Name Type
location
MAP?
data
MAP?
latitude
FLOAT?
longitude
FLOAT?
description
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.geocode('Union House, London');
Table 1. Results
location data latitude longitude description
{description: ""Union House, 182-194, Union Street, Bankside, Southwark, London Borough of Southwark, London, Greater London, England, SE1 0LR, Unite d Kingdom"", latitude: 51.503819199999995, longitude: -0.10101882640252435}
{osm_type: ""way"", osm_id: 77765231, licence: ""Data © OpenStreetMap contri butors, ODbL 1.0. https://osm.org/copyright"", boundingbox: [""51.5037439"", ""51.5038945"", ""-0.1013092"", ""-0.1007285""], importance: 0.31100000000000005, lon: ""-0.10101882640252435"", display_name: ""Union House, 182-194, Union Street, Bankside, Southwark, London Borough of Southwark, London, Greater Lond on, England, SE1 0LR, United Kingdom"", type: ""yes"", class: ""building"", place_id: 104116750, lat: ""51.503819199999995""}
51.503819199999995
-0.10101 882640252435
""Union House, 182-194, Union Street, Bankside, Southwark, London Borough of Southwark, London, Greater London, England, SE1 0LR, United Kingdom""
{description: ""Union House, Shepherds Bush Green, Brook Green, London Borough of Hammersmith and Fulham, London, Greater London, England, W12 7DP, U nited Kingdom"", latitude: 51.504723, longitude: -0.2249915937565324}
{osm_type: ""way"", osm_id: 159245997, licence: ""Data © OpenStreetMap contr ibutors, ODbL 1.0. https://osm.org/copyright"", boundingbox: [""51.5045808"", ""51.5048507"", ""-0.2251614"", ""-0.2248218""], importance: 0.31100000000000005, lon: ""-0.2249915937565324"", display_name: ""Union House, Shepherds Bush Green, Brook Green, London Borough of Hammersmith and Fulham, London, Greater London, England, W12 7DP, United Kingdom"", type: ""yes"", class: ""building"", place_id: 123432321, lat: ""51.504723""}
51.504723
-0.22499 15937565324
""Union House, Shepherds Bush Green, Brook Green, London Borough of Hammersmith and Fulham, London, Greater London, England, W12 7DP, Un ited Kingdom""
{description: ""Union House, 6, Martin Lane, Bishopsgate, City of London, Greater London, England, EC4R 0DP, United Kingdom"", latitude: 51.510519, lo ngitude: -0.08806049069724674}
{osm_type: ""way"", osm_id: 809354346, licence: ""Data © OpenStreetMap contr ibutors, ODbL 1.0. https://osm.org/copyright"", boundingbox: [""51.5104519"", ""51.5106113"", ""-0.0882068"", ""-0.0878968""], importance: 0.30100000000000005, lon: ""-0.08806049069724674"", display_name: ""Union House, 6, Martin Lane, Bishopsgate, City of London, Greater London, England, EC4R 0DP, United Kingd om"", type: ""commercial"", class: ""building"", place_id: 289689410, lat: ""51.510519""}
51.510519
-0.08806 049069724674
""Union House, 6, Martin Lane, Bishopsgate, City of London, Greater London, England, EC4R 0DP, United Kingdom""
More documentation of apoc.spatial.geocode
apoc.spatial
apoc.spatial.geocodeOnce
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.spatial/apoc.spatial.geocodeOnce;"apoc.spatial.geocodeOnce
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.spatial.geocodeOnce(location String, config Map<String, Any>) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Signature
None
Copy to Clipboard
apoc.spatial.geocodeOnce(location :: STRING?, config :: MAP?) :: (location :: MAP?, data :: MAP?, latitude :: FLOAT?, longitude :: FLOAT?, description :: STRING?)
Input parameters
Name Type Default
location
STRING?
null
config
MAP?
null
Output parameters
Name Type
location
MAP?
data
MAP?
latitude
FLOAT?
longitude
FLOAT?
description
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.spatial.geocodeOnce('21 rue Paul Bellamy 44000 NANTES FRANCE')
Table 1. Results
location data latitude longitude description
{description: ""21, Rue Paul Bellamy, Talensac - Pont Morand, Hauts-Pavés - Saint-Félix, Nantes, Loire-Atlantique, Pays de la Loire, France métropolitaine, 44000, France"", latitude: 47.2221667, longitude: -1.5566625}
{osm_type: ""node"", osm_id: 1730317979, licence: ""Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright"", boundingbox: [""47.2221167"", ""47.2222167"", ""-1.5567125"", ""-1.5566125""], importance: 0.721, lon: ""-1.5566625"", display_name: ""21, Rue Paul Bellamy, Talensac - Pont Morand, Hauts-Pavés - Saint-Félix, Nantes, Loire-Atlantique, Pays de la Loire, France métropolitaine, 44000, France"", type: ""house"", class: ""place"", place_id: 17843897, lat: ""47.2221667""}
47.2221667
-1.5566625
""21, Rue Paul Bellamy, Talensac - Pont Morand, Hauts-Pavés - Saint-Félix, Nantes, Loire-Atlantique, Pays de la Loire, France métropolitaine, 44000, France""
More documentation of apoc.spatial.geocodeOnce
apoc.spatial.geocode
apoc.spatial.reverseGeocode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/misc/text-functions;"Text Functions
Contents
Overview Text Functions
Data Extraction
Text Similarity Functions
Compare the strings with the Levenshtein distance
Compare the given strings with the Sørensen–Dice coefficient formula.
Check if 2 words can be matched in a fuzzy way with fuzzyMatch
Phonetic Comparison Functions
Formatting Text
String Search
Regular Expressions
Split and Join
Data Cleaning
Case Change Functions
Base64 De- and Encoding
Random String
Hashing Functions
Cypher has some basic functions to work with text like
split(string, delim)
toLower and toUpper
concatenation with +
predicates like CONTAINS, STARTS WITH, ENDS WITH and regular expression matches via =~.
But a lot of useful functions for string manipulation, comparison, and filtering are missing. APOC adds these functions.
Overview Text Functions
apoc.text.indexOf(text, lookup, offset=0, to=-1==len)
find the first occurence of the lookup string in the text, from inclusive, to exclusive,, -1 if not found, null if text is null.
apoc.text.indexesOf(text, lookup, from=0, to=-1==len)
finds all occurences of the lookup string in the text, return list, from inclusive, to exclusive, empty list if not found, null if text is null.
apoc.text.replace(text, regex, replacement)
replace each substring of the given string that matches the given regular expression with the given replacement.
apoc.text.regexGroups(text, regex)
returns an array containing a nested array for each match. The inner array contains all match groups.
apoc.text.join(['text1','text2',...], delimiter)
join the given strings with the given delimiter.
apoc.text.repeat('item',count)
multiply the given string with the given count
apoc.text.format(text,[params],language)
sprintf format the string with the params given, and optional param language (default value is 'en').
apoc.text.lpad(text,count,delim)
left pad the string to the given width
apoc.text.rpad(text,count,delim)
right pad the string to the given width
apoc.text.random(length, [valid])
returns a random string to the specified length
apoc.text.capitalize(text)
capitalise the first letter of the word
apoc.text.capitalizeAll(text)
capitalise the first letter of every word in the text
apoc.text.decapitalize(text)
decapitalize the first letter of the word
apoc.text.decapitalizeAll(text)
decapitalize the first letter of all words
apoc.text.swapCase(text)
Swap the case of a string
apoc.text.camelCase(text)
Convert a string to camelCase
apoc.text.upperCamelCase(text)
Convert a string to UpperCamelCase
apoc.text.snakeCase(text)
Convert a string to snake-case
apoc.text.toUpperCase(text)
Convert a string to UPPER_CASE
apoc.text.charAt(text, index)
Returns the decimal value of the character at the given index
apoc.text.code(codepoint)
Returns the unicode character of the given codepoint
apoc.text.hexCharAt(text, index)
Returns the hex value string of the character at the given index
apoc.text.hexValue(value)
Returns the hex value string of the given value
apoc.text.byteCount(text,[charset])
return size of text in bytes
apoc.text.bytes(text,[charset])
return bytes of the text
apoc.text.toCypher(value, {skipKeys,keepKeys,skipValues,keepValues,skipNull,node,relationship,start,end})
tries its best to convert the value to a cypher-property-string
apoc.text.base64Encode(text)
Encode a string with Base64
apoc.text.base64Decode(text)
Decode Base64 encoded string
apoc.text.base64UrlEncode(url)
Encode a url with Base64
apoc.text.base64UrlDecode(url)
Decode Base64 encoded url
The replace, split and regexGroups functions work with regular expressions.
Data Extraction
apoc.data.url('url') as {protocol,user,host,port,path,query,file,anchor}
turn URL into map structure
Text Similarity Functions
apoc.text.distance(text1, text2)
compare the given strings with the Levenshtein distance algorithm
apoc.text.levenshteinDistance(text1, text2)
compare the given strings with the Levenshtein distance algorithm
apoc.text.levenshteinSimilarity(text1, text2)
calculate the similarity (a value within 0 and 1) between two texts based on Levenshtein distance.
apoc.text.hammingDistance(text1, text2)
compare the given strings with the Hamming distance algorithm
apoc.text.jaroWinklerDistance(text1, text2)
compare the given strings with the Jaro-Winkler distance algorithm
apoc.text.sorensenDiceSimilarity(text1, text2)
compare the given strings with the Sørensen–Dice coefficient formula, assuming an English locale
apoc.text.sorensenDiceSimilarityWithLanguage(text1, text2, languageTag)
compare the given strings with the Sørensen–Dice coefficient formula, with the provided IETF language tag
apoc.text.fuzzyMatch(text1, text2)
check if 2 words can be matched in a fuzzy way (LevenShtein). Depending on the length of the String it will allow more characters that needs to be edited to match the second String (distance: length < 3 then 0, length < 5 then 1, else 2).
Compare the strings with the Levenshtein distance
Compare the given strings with the StringUtils.distance(text1, text2) method (Levenshtein).
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.distance(""Levenshtein"", ""Levenstein"") // 1
Compare the given strings with the Sørensen–Dice coefficient formula.
Cypher
computes the similarity assuming Locale.ENGLISH
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.sorensenDiceSimilarity(""belly"", ""jolly"") // 0.5
Cypher
computes the similarity with an explicit locale
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.sorensenDiceSimilarityWithLanguage(""halım"", ""halim"", ""tr-TR"") // 0.5
Check if 2 words can be matched in a fuzzy way with fuzzyMatch
Depending on the length of the String (distance: length < 3 then 0, length < 5 then 1, else 2) it will allow more characters that needs to be edited to match the second String (LevenShtein distance).
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.fuzzyMatch(""The"", ""the"") // true
Phonetic Comparison Functions
The phonetic text (soundex) functions allow you to compute the soundex encoding of a given string. There is also a procedure to compare how similar two strings sound under the soundex algorithm. All soundex procedures by default assume the used language is US English.
apoc.text.phonetic(value)
Compute the US_ENGLISH phonetic soundex encoding of all words of the text value which can be a single string or a list of strings
apoc.text.doubleMetaphone(value)
Compute the Double Metaphone phonetic encoding of all words of the text value which can be a single string or a list of strings
apoc.text.clean(text)
strip the given string of everything except alpha numeric characters and convert it to lower case.
apoc.text.compareCleaned(text1, text2)
compare the given strings stripped of everything except alpha numeric characters converted to lower case.
Table 1. Procedure
apoc.text.phoneticDelta(text1, text2) yield phonetic1, phonetic2, delta
Compute the US_ENGLISH soundex character difference between two given strings
Cypher
Copy to Clipboard
Run in Neo4j Browser
// will return 'H436'
RETURN apoc.text.phonetic('Hello, dear User!')
Cypher
Copy to Clipboard
Run in Neo4j Browser
// will return '4'  (very similar)
RETURN apoc.text.phoneticDelta('Hello Mr Rabbit', 'Hello Mr Ribbit')
Formatting Text
Format the string with the params given, and optional param language.
Cypher
without language param ('en' default)
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.format('ab%s %d %.1f %s%n',['cd',42,3.14,true]) AS value // abcd 42 3.1 true
Cypher
with language param
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.format('ab%s %d %.1f %s%n',['cd',42,3.14,true],'it') AS value // abcd 42 3,1 true
String Search
The indexOf function, provides the fist occurrence of the given lookup string within the text, or -1 if not found. It can optionally take from (inclusive) and to (exclusive) parameters.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexOf('Hello World!', 'World') // 6
The indexesOf function, provides all occurrences of the given lookup string within the text, or empty list if not found. It can optionally take from (inclusive) and to (exclusive) parameters.
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.indexesOf('Hello World!', 'o',2,9) // [4,7]
If you want to get a substring starting from your index match, you can use this
Cypher
returns World!
Copy to Clipboard
Run in Neo4j Browser
WITH 'Hello World!' as text, length(text) as len
WITH text, len, apoc.text.indexOf(text, 'World',3) as index
RETURN substring(text, case index when -1 then len-1 else index end, len);
Regular Expressions
Cypher
will return 'HelloWorld'
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.replace('Hello World!', '[^a-zA-Z]', '')
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.regexGroups('abc <link xxx1>yyy1</link> def <link xxx2>yyy2</link>','<link (\\w+)>(\\w+)</link>') AS result

// [[""<link xxx1>yyy1</link>"", ""xxx1"", ""yyy1""], [""<link xxx2>yyy2</link>"", ""xxx2"", ""yyy2""]]
Split and Join
Cypher
will split with the given regular expression return ['Hello', 'World']
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.split('Hello   World', ' +')
Cypher
will return 'Hello World'
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.join(['Hello', 'World'], ' ')
Data Cleaning
Cypher
will return 'helloworld'
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.clean('Hello World!')
Cypher
will return true
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.compareCleaned('Hello World!', '_hello-world_')
Cypher
will return only 'Hello World!'
Copy to Clipboard
Run in Neo4j Browser
UNWIND ['Hello World!', 'hello worlds'] as text
RETURN apoc.text.filterCleanMatches(text, 'hello_world') as text
The clean functionality can be useful for cleaning up slightly dirty text data with inconsistent formatting for non-exact comparisons.
Cleaning will strip the string of all non-alphanumeric characters (including spaces) and convert it to lower case.
Case Change Functions
Cypher
Capitalise the first letter of the word with capitalize
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.capitalize(""neo4j"") // ""Neo4j""
Cypher
Capitalise the first letter of every word in the text with capitalizeAll
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.capitalizeAll(""graph database"") // ""Graph Database""
Cypher
Decapitalize the first letter of the string with decapitalize
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.decapitalize(""Graph Database"") // ""graph Database""
Cypher
Decapitalize the first letter of all words with decapitalizeAll
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.decapitalizeAll(""Graph Databases"") // ""graph databases""
Cypher
Swap the case of a string with swapCase
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.swapCase(""Neo4j"") // nEO4J
Cypher
Convert a string to lower camelCase with camelCase
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""FOO_BAR"");    // ""fooBar""
RETURN apoc.text.camelCase(""Foo bar"");    // ""fooBar""
RETURN apoc.text.camelCase(""Foo22 bar"");  // ""foo22Bar""
RETURN apoc.text.camelCase(""foo-bar"");    // ""fooBar""
RETURN apoc.text.camelCase(""Foobar"");     // ""foobar""
RETURN apoc.text.camelCase(""Foo$$Bar"");   // ""fooBar""
Cypher
Convert a string to UpperCamelCase with upperCamelCase
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.upperCamelCase(""FOO_BAR"");   // ""FooBar""
RETURN apoc.text.upperCamelCase(""Foo bar"");   // ""FooBar""
RETURN apoc.text.upperCamelCase(""Foo22 bar""); // ""Foo22Bar""
RETURN apoc.text.upperCamelCase(""foo-bar"");   // ""FooBar""
RETURN apoc.text.upperCamelCase(""Foobar"");    // ""Foobar""
RETURN apoc.text.upperCamelCase(""Foo$$Bar"");  // ""FooBar""
Cypher
Convert a string to snake-case with snakeCase
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.snakeCase(""test Snake Case""); // ""test-snake-case""
RETURN apoc.text.snakeCase(""FOO_BAR"");         // ""foo-bar""
RETURN apoc.text.snakeCase(""Foo bar"");         // ""foo-bar""
RETURN apoc.text.snakeCase(""fooBar"");          // ""foo-bar""
RETURN apoc.text.snakeCase(""foo-bar"");         // ""foo-bar""
RETURN apoc.text.snakeCase(""Foo bar"");         // ""foo-bar""
RETURN apoc.text.snakeCase(""Foo  bar"");        // ""foo-bar""
Cypher
Convert a string to UPPER_CASE with toUpperCase
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.toUpperCase(""test upper case""); // ""TEST_UPPER_CASE""
RETURN apoc.text.toUpperCase(""FooBar"");          // ""FOO_BAR""
RETURN apoc.text.toUpperCase(""fooBar"");          // ""FOO_BAR""
RETURN apoc.text.toUpperCase(""foo-bar"");         // ""FOO_BAR""
RETURN apoc.text.toUpperCase(""foo--bar"");        // ""FOO_BAR""
RETURN apoc.text.toUpperCase(""foo$$bar"");        // ""FOO_BAR""
RETURN apoc.text.toUpperCase(""foo 22 bar"");      // ""FOO_22_BAR""
Base64 De- and Encoding
Encode or decode a string in base64 or base64Url
Cypher
Encode base 64
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64Encode(""neo4j"") // bmVvNGo=
Cypher
Decode base 64
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64Decode(""bmVvNGo="") // neo4j
Cypher
Encode base 64 URL
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64UrlEncode(""http://neo4j.com/?test=test"") // aHR0cDovL25lbzRqLmNvbS8_dGVzdD10ZXN0
Cypher
Decode base 64 URL
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64UrlDecode(""aHR0cDovL25lbzRqLmNvbS8_dGVzdD10ZXN0"") // http://neo4j.com/?test=test
Random String
You can generate a random string to a specified length by calling apoc.text.random with a length parameter and optional string of valid characters.
The valid parameter will accept the following regex patterns, alternatively you can provide a string of letters and/or characters.
Pattern
Description
A-Z
A-Z in uppercase
a-z
A-Z in lowercase
0-9
Numbers 0-9 inclusive
Cypher
The following call will return a random string including uppercase letters, numbers and . and $ characters.
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.random(10, ""A-Z0-9.$"")
Hashing Functions
apoc.util.sha1([values])
computes the sha1 of the concatenation of all string values of the list
apoc.util.md5([values])
computes the md5 of the concatenation of all string values of the list
Miscellaneous
Spatial
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.base64UrlEncode;"apoc.text.base64UrlEncode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.base64UrlEncode(url String) - encodes the given URL with Base64.
Signature
None
Copy to Clipboard
apoc.text.base64UrlEncode(url :: STRING?) :: (STRING?)
Input parameters
Name Type Default
url
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.base64UrlEncode(""http://neo4j.com/?test=test"") AS output;
Table 1. Results
output
""aHR0cDovL25lbzRqLmNvbS8_dGVzdD10ZXN0""
apoc.text.base64UrlDecode
apoc.text.byteCount
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.byteCount;"apoc.text.byteCount
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.byteCount(text String, charset String) - returns the size of the given string in bytes.
Signature
None
Copy to Clipboard
apoc.text.byteCount(text :: STRING?, charset = UTF-8 :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
text
STRING?
null
charset
STRING?
UTF-8
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.byteCount(""Neo4j"") AS output;
Table 1. Results
output
5
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.byteCount(""Jesús"") AS output;
Table 2. Results
output
6
apoc.text.base64UrlEncode
apoc.text.bytes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.bytes;"apoc.text.bytes
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.bytes(text String, charset String) - returns the given string as bytes.
Signature
None
Copy to Clipboard
apoc.text.bytes(text :: STRING?, charset = UTF-8 :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
text
STRING?
null
charset
STRING?
UTF-8
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.bytes(""Neo4j"") AS output;
Table 1. Results
output
[78, 101, 111, 52, 106]
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.bytes(""Jesús"") AS output;
Table 2. Results
output
[74, 101, 115, 195, 186, 115]
apoc.text.byteCount
apoc.text.camelCase
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.camelCase;"apoc.text.camelCase
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.camelCase(text String) - converts the given string to camel case.
Signature
None
Copy to Clipboard
apoc.text.camelCase(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""FOO_BAR"") AS output;
Table 1. Results
output
""fooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""Foo bar"") AS output;
Table 2. Results
output
""fooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""Foo22 bar"") AS output;
Table 3. Results
output
""foo22Bar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""foo-bar"") AS output;
Table 4. Results
output
""fooBar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""Foobar"") AS output;
Table 5. Results
output
""foobar""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.camelCase(""Foo$$Bar"") AS output;
Table 6. Results
output
""fooBar""
apoc.text.bytes
apoc.text.capitalize
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.capitalize;"apoc.text.capitalize
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.capitalize(text String) - capitalizes the first letter of the given string.
Signature
None
Copy to Clipboard
apoc.text.capitalize(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Capitalise the first letter of the word
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.capitalize(""neo4j"") AS output;
Table 1. Results
output
""Neo4j""
apoc.text.camelCase
apoc.text.capitalizeAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.capitalizeAll;"apoc.text.capitalizeAll
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.capitalizeAll(text String) - capitalizes the first letter of every word in the given string.
Signature
None
Copy to Clipboard
apoc.text.capitalizeAll(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Capitalise the first letter of every word in the text
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.capitalizeAll(""graph database"") AS output;
Table 1. Results
output
""Graph Database""
apoc.text.capitalize
apoc.text.charAt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.charAt;"apoc.text.charAt
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.charAt(text String, index Integer) - returns the long value of the character at the given index.
Signature
None
Copy to Clipboard
apoc.text.charAt(text :: STRING?, index :: INTEGER?) :: (INTEGER?)
Input parameters
Name Type Default
text
STRING?
null
index
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.charAt(""Neo4j"", 4) AS output;
Table 1. Results
output
106
apoc.text.capitalizeAll
apoc.text.clean
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.clean;"apoc.text.clean
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.clean(text String) - strips the given string of everything except alpha numeric characters and converts it to lower case.
Signature
None
Copy to Clipboard
apoc.text.clean(text :: STRING?) :: (STRING?)
Input parameters
Name Type Default
text
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.clean('Hello World!') AS output;
Table 1. Results
output
""helloworld""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.clean('Hello___World!') AS output;
Table 2. Results
output
""helloworld""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.clean('$-Hello___World!$') AS output;
Table 3. Results
output
""helloworld""
apoc.text.charAt
apoc.text.code
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.code;"apoc.text.code
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.code(codepoint Long) - converts the long value into a string.
Signature
None
Copy to Clipboard
apoc.text.code(codepoint :: INTEGER?) :: (STRING?)
Input parameters
Name Type Default
codepoint
INTEGER?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.code(102) AS output;
Table 1. Results
output
""f""
apoc.text.clean
apoc.text.compareCleaned
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.text/apoc.text.compareCleaned;"apoc.text.compareCleaned
Contents
Signature
Input parameters
Usage Examples
Function
apoc.text.compareCleaned(text1 String, text2 String) - compares two given strings stripped of everything except alpha numeric characters converted to lower case.
Signature
None
Copy to Clipboard
apoc.text.compareCleaned(text1 :: STRING?, text2 :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
text1
STRING?
null
text2
STRING?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.compareCleaned('Hello World!', '_hello-world_') AS output;
Table 1. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.text.compareCleaned('Hello World!', '_hello-world_$') AS output;
Table 2. Results
output
TRUE
apoc.text.code
apoc.text.decapitalize
Was this page helpful?"
https://neo4j.com/docs/apoc/5/misc/utility-functions;"Utilities
Qualified Name Type
apoc.util.sleep
apoc.util.sleep(<duration>) | sleeps for <duration> millis, transaction termination is honored
Procedure
apoc.util.validate
apoc.util.validate(predicate, message, params) | if the predicate yields to true raise an exception
Procedure
apoc.util.validatePredicate
apoc.util.validatePredicate(predicate, message, params) | if the predicate yields to true raise an exception else returns true, for use inside WHERE subclauses
Function
Spatial
Text and Lookup Indexes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/indexes;"Text and Lookup Indexes
These procedures complement the indexing functionality that comes out of the box.
Schema Information
Utilities
Schema Information
Was this page helpful?"
https://neo4j.com/docs/apoc/5/comparing-graphs;"Comparing Graphs
For more information on how to use these procedures, see:
Diff
Fingerprinting
Parallel Node Search
Diff
Was this page helpful?"
https://neo4j.com/docs/apoc/5/comparing-graphs/node-difference;"Diff
Diff is a user function to return a detailed difference between two nodes.
apoc.diff.nodes([leftNode],[rightNode])
Cypher
Example
Copy to Clipboard
Run in Neo4j Browser
CREATE
    (n:Person{name:'Steve',age:34, eyes:'blue'}),
    (m:Person{name:'Jake',hair:'brown',age:34})
WITH n,m
return apoc.diff.nodes(n,m)
Json
Resulting JSON body:
Copy to Clipboard
{
  ""leftOnly"": {
    ""eyes"": ""blue""
  },
  ""inCommon"": {
    ""age"": 34
  },
  ""different"": {
    ""name"": {
      ""left"": ""Steve"",
      ""right"": ""Jake""
    }
  },
  ""rightOnly"": {
    ""hair"": ""brown""
  }
}
Comparing Graphs
Fingerprinting
Was this page helpful?"
https://neo4j.com/docs/apoc/5/comparing-graphs/fingerprinting;"Fingerprinting
Contents
Configuration parameters
Fingerprinting strategy
The following functions calculate hashsums over nodes, relationship or the entire graph. It takes into account all properties, node labels and relationship types.
The algorithm used for hashing may change between APOC versions. It is therefore only possible to compare the hashing results of two entities/graphs from the same graph, or from different graphs using the same apoc version.
The hashsum of a graph first calculates the hashsums for each node. The resulting hashsum list is ordered, and for each node the hashsum for all relationships and their end nodes are added. This approach provides independence of internal ids.
It is also possible to supply a list of propertyKeys which should be ignored on all nodes. This can be useful when storing properties, such as created=timestamp() that should be ignored.
Function name Description
apoc.hashing.fingerprint(object, <list_of_props_to_ignore>)
calculates a md5 hashsum over the object. It deals with ordering (in case of maps), scalars and arrays. Unsuitable for cryptographic use-cases.
apoc.hashing.fingerprinting(object, {conf})
calculates a md5 hashsum over the object. It deals with ordering (in case of maps), scalars and arrays (see the Fingerprinting configuration params table for more details). Unsuitable for cryptographic use-cases.
apoc.hashing.graph(<list_of_props_to_ignore>)
calculates a md5 hashsum over the full graph. Unsuitable for cryptographic use-cases.
Configuration parameters
Table 1. Fingerprinting configuration params
Property name Type Default Description
digestAlgorithm
ENUM
MD5
the digest algorithm used to create the fingerprint. Currently there is only support for MD5.
nodeAllowMap
Map<K,V>
empty
a map where the key is the node Label and the value is a lists properties allowed.
relAllowMap
Map<K,V>
empty
a map where the key is the rel-type and the value is a lists properties allowed.
nodeDisallowMap
Map<K,V>
empty
a DisallowMap map where the key is the node Label and the value is a lists properties disallowed.
relDisallowMap
Map<K,V>
empty
a DisallowMap map where the key is the rel-type and the value is a lists properties disallowed.
mapAllowList
List
empty
a List used in case the input to the procedure is a map allowed.
mapDisallowList
List
empty
a List used in case the input to the procedure is a map disallowed.
allNodesAllowList
List
empty
a List used for properties common to all Nodes must be included in the fingerprint.
allRelsAllowList
List
empty
a List used for properties common to all Relationships that must be included in the fingerprint.
allNodesDisallowList
List
empty
a List used for properties common to all Nodes that must be excluded from the fingerprint.
allRelsDisallowList
List
empty
a List used for properties common to all Relationships that must be excluded from the fingerprint.
strategy
Enum[EAGER, LAZY]
LAZY
defines the behaviour in case the properties are not present for the specific node/relationship (see the Fingerprinting strategy paragraph for more details).
It is not possible to allow and disallow lists for the same entity type. Lists must consequently be either allowed or disallowed when setting the fingerprinting parameters for nodes, relationships, and maps.
Fingerprinting strategy
In case the properties defined in the configuration are not present in the node and/or relationship, it is possible to define how the fingerprinting procedure must proceed with the process:
EAGER: it evaluates the whole node properties in order to create the fingerprint of the node/relationship
LAZY: it evaluates only the nodes/relationships provided in the configuration
Diff
Cypher Execution
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search/apoc.search.node;"apoc.search.node
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.search.node(labelPropertyMap Any, operator String, value String) - returns all the distinct nodes found after a parallel search over multiple indexes.
Signature
None
Copy to Clipboard
apoc.search.node(LabelPropertyMap :: ANY?, operator :: STRING?, value :: STRING?) :: (node :: NODE?)
Input parameters
Name Type Default
LabelPropertyMap
ANY?
null
operator
STRING?
null
value
STRING?
null
Output parameters
Name Type
node
NODE?
More documentation of apoc.search.node
apoc.search.multiSearchReduced
apoc.search.nodeAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.search/apoc.search.multiSearchReduced;"apoc.search.multiSearchReduced
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.search.multiSearchReduced(labelPropertyMap Any, operator String, value String) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Signature
None
Copy to Clipboard
apoc.search.multiSearchReduced(LabelPropertyMap :: ANY?, operator :: STRING?, value :: STRING?) :: (id :: INTEGER?, labels :: LIST? OF STRING?, values :: MAP?)
Input parameters
Name Type Default
LabelPropertyMap
ANY?
null
operator
STRING?
null
value
STRING?
null
Output parameters
Name Type
id
INTEGER?
labels
LIST? OF STRING?
values
MAP?
apoc.search
apoc.search.node
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.rel/apoc.rel.type;"apoc.rel.type
Contents
Signature
Input parameters
Usage Examples
Function
apoc.rel.type(rel Rel) - returns the type for the given virtual relationship.
Signature
None
Copy to Clipboard
apoc.rel.type(rel :: RELATIONSHIP?) :: (STRING?)
Input parameters
Name Type Default
rel
RELATIONSHIP?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'})
CREATE (s2:Student {name: 'Joachim'})
CREATE (s3:Student {name: 'Dominic'})
CREATE (s4:Student {name: 'Amir'})
CREATE (s5:Student {name: 'Natasha'})
CREATE (s6:Student {name: 'Elena'})

CREATE (t1:TestScore {score: 87})
CREATE (t2:TestScore {score: 90})
CREATE (t3:TestScore {score: 78})
CREATE (t4:TestScore {score: 84})
CREATE (t5:TestScore {score: 76})
CREATE (t6:TestScore {score: 92})

CREATE (a:Level {level: 'beginner'})
 (b: {level: })
 (c: {level: })

 (s1)-[:]->(t1)-[:]->(b)
 (s2)-[:]->(t2)-[:]->(c)
 (s3)-[:]->(t3)-[:]->(a)
 (s4)-[:]->(t4)-[:]->(b)
 (s5)-[:]->(t5)-[:]->(a)
 (s6)-[:]->(t6)-[:]->(c);
View all (9 more lines)
If we create virtual relationships between students to see which students have the same understanding level of class material, we can use apoc.rel.type to return the relationship type of those virtual relationships:
Cypher
apoc.create.vRelationship Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)<-[:ASSIGNED_TO]-(:TestScore)<-[:HAS]-(s2:Student)
CALL apoc.create.vRelationship(s1,'SIMILAR_LEVEL',{level: l.level},s2)
YIELD rel
RETURN rel, apoc.rel.type(rel) AS relType;
Table 1. Results
rel relType
[:SIMILAR_LEVEL {level: ""intermediate""}]
""SIMILAR_LEVEL""
[:SIMILAR_LEVEL {level: ""advanced""}]
""SIMILAR_LEVEL""
[:SIMILAR_LEVEL {level: ""beginner""}]
""SIMILAR_LEVEL""
[:SIMILAR_LEVEL {level: ""intermediate""}]
""SIMILAR_LEVEL""
[:SIMILAR_LEVEL {level: ""beginner""}]
""SIMILAR_LEVEL""
[:SIMILAR_LEVEL {level: ""advanced""}]
""SIMILAR_LEVEL""
apoc.rel.startNode
apoc.schema
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.rel/apoc.rel.startNode;"apoc.rel.startNode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.rel.startNode(rel Rel) - returns the start node for the given virtual relationship.
Signature
None
Copy to Clipboard
apoc.rel.startNode(rel :: RELATIONSHIP?) :: (NODE?)
Input parameters
Name Type Default
rel
RELATIONSHIP?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'})
CREATE (s2:Student {name: 'Joachim'})
CREATE (s3:Student {name: 'Dominic'})
CREATE (s4:Student {name: 'Amir'})
CREATE (s5:Student {name: 'Natasha'})
CREATE (s6:Student {name: 'Elena'})

CREATE (t1:TestScore {score: 87})
CREATE (t2:TestScore {score: 90})
CREATE (t3:TestScore {score: 78})
CREATE (t4:TestScore {score: 84})
CREATE (t5:TestScore {score: 76})
CREATE (t6:TestScore {score: 92})

CREATE (a:Level {level: 'beginner'})
 (b: {level: })
 (c: {level: })

 (s1)-[:]->(t1)-[:]->(b)
 (s2)-[:]->(t2)-[:]->(c)
 (s3)-[:]->(t3)-[:]->(a)
 (s4)-[:]->(t4)-[:]->(b)
 (s5)-[:]->(t5)-[:]->(a)
 (s6)-[:]->(t6)-[:]->(c);
View all (9 more lines)
If we create virtual relationships between students to see which students have the same understanding level of class material, we can use apoc.rel.startNode to return the relationship id of those virtual relationships:
Cypher
apoc.create.vRelationship Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)<-[:ASSIGNED_TO]-(:TestScore)<-[:HAS]-(s2:Student)
CALL apoc.create.vRelationship(s1,'SIMILAR_LEVEL',{level: l.level},s2)
YIELD rel
RETURN apoc.rel.startNode(rel) AS startNode;
Table 1. Results
startNode
(:Student {name: ""Priya""})
(:Student {name: ""Joachim""})
(:Student {name: ""Dominic""})
(:Student {name: ""Amir""})
(:Student {name: ""Natasha""})
(:Student {name: ""Elena""})
apoc.rel.id
apoc.rel.type
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.rel/apoc.rel.id;"apoc.rel.id
Contents
Signature
Input parameters
Usage Examples
Function
apoc.rel.id(rel Rel) - returns the id for the given virtual relationship.
Signature
None
Copy to Clipboard
apoc.rel.id(rel :: RELATIONSHIP?) :: (INTEGER?)
Input parameters
Name Type Default
rel
RELATIONSHIP?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'})
CREATE (s2:Student {name: 'Joachim'})
CREATE (s3:Student {name: 'Dominic'})
CREATE (s4:Student {name: 'Amir'})
CREATE (s5:Student {name: 'Natasha'})
CREATE (s6:Student {name: 'Elena'})

CREATE (t1:TestScore {score: 87})
CREATE (t2:TestScore {score: 90})
CREATE (t3:TestScore {score: 78})
CREATE (t4:TestScore {score: 84})
CREATE (t5:TestScore {score: 76})
CREATE (t6:TestScore {score: 92})

CREATE (a:Level {level: 'beginner'})
 (b: {level: })
 (c: {level: })

 (s1)-[:]->(t1)-[:]->(b)
 (s2)-[:]->(t2)-[:]->(c)
 (s3)-[:]->(t3)-[:]->(a)
 (s4)-[:]->(t4)-[:]->(b)
 (s5)-[:]->(t5)-[:]->(a)
 (s6)-[:]->(t6)-[:]->(c);
View all (9 more lines)
If we create virtual relationships between students to see which students have the same understanding level of class material, we can use apoc.rel.id to return the relationship id of those virtual relationships:
Cypher
apoc.create.vRelationship Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)<-[:ASSIGNED_TO]-(:TestScore)<-[:HAS]-(s2:Student)
CALL apoc.create.vRelationship(s1,'SIMILAR_LEVEL',{level: l.level},s2)
YIELD rel
RETURN rel, apoc.rel.id(rel) AS relId;
Table 1. Results
rel relId
[:SIMILAR_LEVEL {level: ""intermediate""}]
-1
[:SIMILAR_LEVEL {level: ""advanced""}]
-2
[:SIMILAR_LEVEL {level: ""beginner""}]
-3
[:SIMILAR_LEVEL {level: ""intermediate""}]
-4
[:SIMILAR_LEVEL {level: ""beginner""}]
-5
[:SIMILAR_LEVEL {level: ""advanced""}]
-6
apoc.rel.endNode
apoc.rel.startNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.rel/apoc.rel.endNode;"apoc.rel.endNode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.rel.endNode(rel Rel) - returns the end node for the given virtual relationship.
Signature
None
Copy to Clipboard
apoc.rel.endNode(rel :: RELATIONSHIP?) :: (NODE?)
Input parameters
Name Type Default
rel
RELATIONSHIP?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'})
CREATE (s2:Student {name: 'Joachim'})
CREATE (s3:Student {name: 'Dominic'})
CREATE (s4:Student {name: 'Amir'})
CREATE (s5:Student {name: 'Natasha'})
CREATE (s6:Student {name: 'Elena'})

CREATE (t1:TestScore {score: 87})
CREATE (t2:TestScore {score: 90})
CREATE (t3:TestScore {score: 78})
CREATE (t4:TestScore {score: 84})
CREATE (t5:TestScore {score: 76})
CREATE (t6:TestScore {score: 92})

CREATE (a:Level {level: 'beginner'})
 (b: {level: })
 (c: {level: })

 (s1)-[:]->(t1)-[:]->(b)
 (s2)-[:]->(t2)-[:]->(c)
 (s3)-[:]->(t3)-[:]->(a)
 (s4)-[:]->(t4)-[:]->(b)
 (s5)-[:]->(t5)-[:]->(a)
 (s6)-[:]->(t6)-[:]->(c);
View all (9 more lines)
If we create virtual relationships between students to see which students have the same understanding level of class material, we can use apoc.rel.startNode to return the relationship id of those virtual relationships:
Cypher
apoc.create.vRelationship Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student)-[:HAS]->(:TestScore)-[:ASSIGNED_TO]->(l:Level)<-[:ASSIGNED_TO]-(:TestScore)<-[:HAS]-(s2:Student)
CALL apoc.create.vRelationship(s1,'SIMILAR_LEVEL',{level: l.level},s2)
YIELD rel
RETURN apoc.rel.endNode(rel) AS endNode;
Table 1. Results
endNode
(:Student {name: ""Amir""})
(:Student {name: ""Elena""})
(:Student {name: ""Natasha""})
(:Student {name: ""Priya""})
(:Student {name: ""Dominic""})
(:Student {name: ""Joachim""})
apoc.rel
apoc.rel.id
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.rel;"apoc.rel
Qualified Name Type
apoc.rel.endNode
apoc.rel.endNode(rel Rel) - returns the end node for the given virtual relationship.
Function
apoc.rel.id
apoc.rel.id(rel Rel) - returns the id for the given virtual relationship.
Function
apoc.rel.startNode
apoc.rel.startNode(rel Rel) - returns the start node for the given virtual relationship.
Function
apoc.rel.type
apoc.rel.type(rel Rel) - returns the type for the given virtual relationship.
Function
apoc.refactor.to
apoc.rel.endNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.to;"apoc.refactor.to
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.to(rel Rel, endNode Node) - redirects the given relationship to the given end node.
Signature
None
Copy to Clipboard
apoc.refactor.to(relationship :: RELATIONSHIP?, newNode :: NODE?) :: (input :: INTEGER?, output :: RELATIONSHIP?, error :: STRING?)
Input parameters
Name Type Default
relationship
RELATIONSHIP?
null
newNode
NODE?
null
Output parameters
Name Type
input
INTEGER?
output
RELATIONSHIP?
error
STRING?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (person1:Person {name: ""Michael""})
MERGE (person2:Person {name: ""Ryan""})
MERGE (person3:Person {name: ""Jennifer""})

MERGE (person1)-[:FRIENDS]->(person2);
The following makes Jennifer the end node in the FOLLOWS relationship instead of Ryan:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name: ""Michael""})-[rel:FRIENDS]->()
MATCH (jennifer:Person {name: ""Jennifer""})
CALL apoc.refactor.to(rel, jennifer)
YIELD input, output
RETURN input, output;
If we execute this query, it will result in the following output:
Table 1. Results
input output
32
[:`FRIENDS`]
And the graph now looks like this:
More documentation of apoc.refactor.to
apoc.refactor.setType
apoc.rel
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.setType;"apoc.refactor.setType
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.setType(rel Rel, newType String) - changes the type of the given relationship.
Signature
None
Copy to Clipboard
apoc.refactor.setType(relationship :: RELATIONSHIP?, newType :: STRING?) :: (input :: INTEGER?, output :: RELATIONSHIP?, error :: STRING?)
Input parameters
Name Type Default
relationship
RELATIONSHIP?
null
newType
STRING?
null
Output parameters
Name Type
input
INTEGER?
output
RELATIONSHIP?
error
STRING?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo)-[rel:FOOBAR]->(b:Bar);
The following changes the relationship type from FOOBAR to NEW-TYPE:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo)-[rel:FOOBAR]->(b:Bar)
CALL apoc.refactor.setType(rel, 'NEW-TYPE')
YIELD input, output
RETURN input, output;
If we execute this query, it will result in the following output:
Table 1. Results
input output
30
[:`NEW-TYPE`]
And the graph now looks like this:
More documentation of apoc.refactor.setType
apoc.refactor.rename.typeProperty
apoc.refactor.to
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.rename.typeProperty;"apoc.refactor.rename.typeProperty
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.rename.typeProperty(oldName String, newName String, rels [Rel], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all relationships. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Signature
None
Copy to Clipboard
apoc.refactor.rename.typeProperty(oldName :: STRING?, newName :: STRING?, rels = [] :: LIST? OF RELATIONSHIP?, config = {} :: MAP?) :: (batches :: INTEGER?, total :: INTEGER?, timeTaken :: INTEGER?, committedOperations :: INTEGER?, failedOperations :: INTEGER?, failedBatches :: INTEGER?, retries :: INTEGER?, errorMessages :: MAP?, batch :: MAP?, operations :: MAP?, constraints :: LIST? OF STRING?, indexes :: LIST? OF STRING?)
Input parameters
Name Type Default
oldName
STRING?
null
newName
STRING?
null
rels
LIST? OF RELATIONSHIP?
[]
config
MAP?
{}
Output parameters
Name Type
batches
INTEGER?
total
INTEGER?
timeTaken
INTEGER?
committedOperations
INTEGER?
failedOperations
INTEGER?
failedBatches
INTEGER?
retries
INTEGER?
errorMessages
MAP?
batch
MAP?
operations
MAP?
constraints
LIST? OF STRING?
indexes
LIST? OF STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Engineer {name: ""Mark"", city: ""London""})
CREATE (jennifer:Engineer {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Engineer {name: ""Michael"", city: ""Dresden""})
CREATE (jim:Engineer {name: ""Jim"", city: ""London""})
CREATE (alistair:Engineer {name: ""Alistair"", city: ""London""})

MERGE (jim)-[:COLLEAGUES {since: date(""2006-05-01"")}]->(alistair)
MERGE (mark)-[:COLLEAGUES {since: date(""2018-02-01"")}]->(jennifer)
MERGE (mark)-[:COLLEAGUES {since: date(""2013-05-01"")}]->(michael);
The following query changes the relationship property since to from for all relationships:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[rel]->()
WITH collect(rel) AS rels
CALL apoc.refactor.rename.typeProperty(""since"", ""from"", rels)
YIELD batches, total, timeTaken, committedOperations
RETURN batches, total, timeTaken, committedOperations;
Table 1. Results
batches total timeTaken committedOperations
1
3
0
3
The following query returns all the paths in our graph after this refactoring has been done:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[]->()
RETURN path
Table 2. Results
path
[{""name"":""Mark"",""location"":""London""},{""from"":""2018-02-01""},{""name"":""Jennifer"",""location"":""St Louis""}]
[{""name"":""Mark"",""location"":""London""},{""from"":""2013-05-01""},{""name"":""Michael"",""location"":""Dresden""}]
[{""name"":""Jim"",""city"":""London""},{""from"":""2006-05-01""},{""name"":""Alistair"",""city"":""London""}]
More documentation of apoc.refactor.rename.typeProperty
apoc.refactor.rename.type
apoc.refactor.setType
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/rename-label-type-property;"Rename labels, types, and properties
Contents
Procedures for renaming labels, types, and properties
Config parameters
Examples
Renaming node labels
Renaming relationship types
Renaming node properties
Renaming relationship properties
The APOC library contains procedures that can be used to rename labels, relationship types, and properties of nodes and relationships.
Procedures for renaming labels, types, and properties
Qualified Name Type
apoc.refactor.rename.label
apoc.refactor.rename.label(oldLabel String, newLabel String, nodes [Node]) - renames the given label from 'oldLabel' to 'newLabel' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.nodeProperty
apoc.refactor.rename.nodeProperty(oldName String, newName String, nodes [Node], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.type
apoc.refactor.rename.type(oldType String, newType String, rels [Rel], config Map<String, Any>) - renames all relationships with type 'oldType' to 'newType'. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
apoc.refactor.rename.typeProperty
apoc.refactor.rename.typeProperty(oldName String, newName String, rels [Rel], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all relationships. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
Config parameters
As the collection of data is processed in batches using apoc.periodic.iterate, these procedures support the following config parameters:
Table 1. Config
name type default description
batchSize
Long
10000
run the specified number of operation statements in a single tx - params: {_count, _batch}
parallel
boolean
true
run operation statements in parallel (note that statements might deadlock if conflicting)
Please note that, in case of parallel: false, APOC is designed to reuse the same java.util.concurrent.ThreadPoolExecutor with a maximum pool size equal 1, in order to prevent parallelism; this means that if you want to execute multiple apoc.periodic.iterate each one will be executed when the previous one has been completed. Instead, with parallel: true, APOC will use a ThreadPoolExecutor with a configurable maximum pool size via the apoc.jobs.pool.num_threads config or as default with the number of available processor * 2. Therefore, if we execute multiple apoc.periodic.iterate each one will be executed in parallel if the queue pool size can accept new tasks. Furthermore, to be noted that running in parallel affects all databases, and not the single database you are using. So with e.g. 2 databases db1 and db2, the apoc.periodic.iterate on db1 will impact on performance if we execute an apoc.periodic.iterate on db2.
retries
Long
0
if the operation statement fails with an error, sleep 100ms and retry until retries-count is reached - param {_retry}
batchMode
String
""BATCH""
how data-driven statements should be processed by operation statement. Valid values are:
* ""BATCH"" - execute operation statement once per batchSize. Operation statement is prefixed with the following, which extracts each field returned in the data-driven statement from the $_batch parameter: [source,cypher] ---- UNWIND $_batch AS _batch WITH _batch.field1 AS field1, _batch.field2 AS field2 ---- * ""SINGLE"" - execute operation statement one at a time * ""BATCH_SINGLE"" - execute operation statement once per batchSize, but leaves unpacking of batch to the operation statement. The operation query can access the batched values via the $_batch parameter.
concurrency
Long
Number of processors available
number of concurrent tasks are generated when using parallel:true
Examples
The below examples will further explain these procedures.
Cypher
The following creates a graph contains nodes with the label Engineer connected by COLLEAGUES relationships:
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Engineer {name: ""Mark"", city: ""London""})
CREATE (jennifer:Engineer {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Engineer {name: ""Michael"", city: ""Dresden""})
CREATE (jim:Engineer {name: ""Jim"", city: ""London""})
CREATE (alistair:Engineer {name: ""Alistair"", city: ""London""})

MERGE (jim)-[:COLLEAGUES {since: date(""2006-05-01"")}]->(alistair)
MERGE (mark)-[:COLLEAGUES {since: date(""2018-02-01"")}]->(jennifer)
MERGE (mark)-[:COLLEAGUES {since: date(""2013-05-01"")}]->(michael)
If the above query is run, it will result in the following graph:
Renaming node labels
Cypher
The following changes the label on Mark, Jennifer, and Michael from Engineer to DevRel:
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Engineer)
WHERE person.name IN [""Mark"", ""Jennifer"", ""Michael""]
WITH collect(person) AS people
CALL apoc.refactor.rename.label(""Engineer"", ""DevRel"", people)
YIELD committedOperations
RETURN committedOperations
If the above query is run, it will result in the following graph:
Renaming relationship types
Cypher
The following changes the relationship type between Jim and Alistair from COLLEAGUES to FROLLEAGUES:
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Engineer {name: ""Jim""})-[rel]->(:Engineer {name: ""Alistair""})
WITH collect(rel) AS rels
CALL apoc.refactor.rename.type(""COLLEAGUES"", ""FROLLEAGUES"", rels)
YIELD committedOperations
RETURN committedOperations
Renaming node properties
Cypher
The following query changes the node property city to location for all nodes with the DevRel label:
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:DevRel)
WITH collect(person) AS people
CALL apoc.refactor.rename.nodeProperty(""city"", ""location"", people)
YIELD committedOperations
RETURN committedOperations
Cypher
The following query returns all the nodes in our graph after this refactoring has been done:
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
RETURN (n)
Table 2. Results
n
(:DevRel {name: ""Jennifer"", location: ""St Louis""})
(:DevRel {name: ""Michael"", location: ""Dresden""})
(:Engineer {city: ""London"", name: ""Jim""})
(:DevRel {name: ""Mark"", location: ""London""})
(:Engineer {city: ""London"", name: ""Alistair""})
Renaming relationship properties
Cypher
The following query changes the relationship property since to from for all relationships:
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[rel]->()
WITH collect(rel) AS rels
CALL apoc.refactor.rename.typeProperty(""since"", ""from"", rels)
YIELD committedOperations
RETURN committedOperations
Cypher
The following query returns all the paths in our graph after this refactoring has been done:
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[]->()
RETURN path
Table 3. Results
path
[{""name"":""Mark"",""location"":""London""},{""from"":""2018-02-01""},{""name"":""Jennifer"",""location"":""St Louis""}]
[{""name"":""Mark"",""location"":""London""},{""from"":""2013-05-01""},{""name"":""Michael"",""location"":""Dresden""}]
[{""name"":""Jim"",""city"":""London""},{""from"":""2006-05-01""},{""name"":""Alistair"",""city"":""London""}]
Redirect relationships
Set relationship types
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.rename.nodeProperty;"apoc.refactor.rename.nodeProperty
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.rename.nodeProperty(oldName String, newName String, nodes [Node], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Signature
None
Copy to Clipboard
apoc.refactor.rename.nodeProperty(oldName :: STRING?, newName :: STRING?, nodes = [] :: LIST? OF NODE?, config = {} :: MAP?) :: (batches :: INTEGER?, total :: INTEGER?, timeTaken :: INTEGER?, committedOperations :: INTEGER?, failedOperations :: INTEGER?, failedBatches :: INTEGER?, retries :: INTEGER?, errorMessages :: MAP?, batch :: MAP?, operations :: MAP?, constraints :: LIST? OF STRING?, indexes :: LIST? OF STRING?)
Input parameters
Name Type Default
oldName
STRING?
null
newName
STRING?
null
nodes
LIST? OF NODE?
[]
config
MAP?
{}
Output parameters
Name Type
batches
INTEGER?
total
INTEGER?
timeTaken
INTEGER?
committedOperations
INTEGER?
failedOperations
INTEGER?
failedBatches
INTEGER?
retries
INTEGER?
errorMessages
MAP?
batch
MAP?
operations
MAP?
constraints
LIST? OF STRING?
indexes
LIST? OF STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Engineer {name: ""Mark"", city: ""London""})
CREATE (jennifer:Engineer {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Engineer {name: ""Michael"", city: ""Dresden""})
CREATE (jim:Engineer {name: ""Jim"", city: ""London""})
CREATE (alistair:Engineer {name: ""Alistair"", city: ""London""})

MERGE (jim)-[:COLLEAGUES {since: date(""2006-05-01"")}]->(alistair)
MERGE (mark)-[:COLLEAGUES {since: date(""2018-02-01"")}]->(jennifer)
MERGE (mark)-[:COLLEAGUES {since: date(""2013-05-01"")}]->(michael);
The following query changes the node property city to location for all nodes with the DevRel label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:DevRel)
WITH collect(person) AS people
CALL apoc.refactor.rename.nodeProperty(""city"", ""location"", people)
YIELD batches, total, timeTaken, committedOperations
RETURN batches, total, timeTaken, committedOperations;
Table 1. Results
batches total timeTaken committedOperations
1
3
0
3
The following query returns all the nodes in our graph after this refactoring has been done:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
RETURN (n)
Table 2. Results
n
(:DevRel {name: ""Jennifer"", location: ""St Louis""})
(:DevRel {name: ""Michael"", location: ""Dresden""})
(:Engineer {city: ""London"", name: ""Jim""})
(:DevRel {name: ""Mark"", location: ""London""})
(:Engineer {city: ""London"", name: ""Alistair""})
More documentation of apoc.refactor.rename.nodeProperty
apoc.refactor.rename.label
apoc.refactor.rename.type
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.rename.label;"apoc.refactor.rename.label
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.rename.label(oldLabel String, newLabel String, nodes [Node]) - renames the given label from 'oldLabel' to 'newLabel' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Signature
None
Copy to Clipboard
apoc.refactor.rename.label(oldLabel :: STRING?, newLabel :: STRING?, nodes = [] :: LIST? OF NODE?) :: (batches :: INTEGER?, total :: INTEGER?, timeTaken :: INTEGER?, committedOperations :: INTEGER?, failedOperations :: INTEGER?, failedBatches :: INTEGER?, retries :: INTEGER?, errorMessages :: MAP?, batch :: MAP?, operations :: MAP?, constraints :: LIST? OF STRING?, indexes :: LIST? OF STRING?)
Input parameters
Name Type Default
oldLabel
STRING?
null
newLabel
STRING?
null
nodes
LIST? OF NODE?
[]
Output parameters
Name Type
batches
INTEGER?
total
INTEGER?
timeTaken
INTEGER?
committedOperations
INTEGER?
failedOperations
INTEGER?
failedBatches
INTEGER?
retries
INTEGER?
errorMessages
MAP?
batch
MAP?
operations
MAP?
constraints
LIST? OF STRING?
indexes
LIST? OF STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Engineer {name: ""Mark"", city: ""London""})
CREATE (jennifer:Engineer {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Engineer {name: ""Michael"", city: ""Dresden""})
CREATE (jim:Engineer {name: ""Jim"", city: ""London""})
CREATE (alistair:Engineer {name: ""Alistair"", city: ""London""})

MERGE (jim)-[:COLLEAGUES {since: date(""2006-05-01"")}]->(alistair)
MERGE (mark)-[:COLLEAGUES {since: date(""2018-02-01"")}]->(jennifer)
MERGE (mark)-[:COLLEAGUES {since: date(""2013-05-01"")}]->(michael);
The following changes the relationship type between Jim and Alistair from COLLEAGUES to FROLLEAGUES:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Engineer {name: ""Jim""})-[rel]->(:Engineer {name: ""Alistair""})
WITH collect(rel) AS rels
CALL apoc.refactor.rename.type(""COLLEAGUES"", ""FROLLEAGUES"", rels)
YIELD batches, total, timeTaken, committedOperations
RETURN batches, total, timeTaken, committedOperations;
Table 1. Results
batches total timeTaken committedOperations
1
1
0
1
After this query has run, we’ll have the following graph:
More documentation of apoc.refactor.rename.label
apoc.refactor.normalizeAsBoolean
apoc.refactor.rename.nodeProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.normalizeAsBoolean;"apoc.refactor.normalizeAsBoolean
Contents
Signature
Input parameters
Usage Examples
Procedure
apoc.refactor.normalizeAsBoolean(entity Any, propertyKey String, trueValues [Any], falseValues [Any]) - refactors the given property to a boolean.
Signature
None
Copy to Clipboard
apoc.refactor.normalizeAsBoolean(entity :: ANY?, propertyKey :: STRING?, true_values :: LIST? OF ANY?, false_values :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
entity
ANY?
null
propertyKey
STRING?
null
true_values
LIST? OF ANY?
null
false_values
LIST? OF ANY?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {prop: 'Y', name:'A'}),
       (:Person {prop: 'Yes', name:'B'}),
       (:Person {prop: 'NO', name:'C'}),
       (:Person {prop: 'X', name:'D'});
We want to transform some properties into a boolean, Y, Yes into true and the properties NO into false. The other properties that don’t match these possibilities will be set as null.
Cypher
The following normalizes all applicable boolean values for all nodes that have the prop property:
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
CALL apoc.refactor.normalizeAsBoolean(n,'prop',['Y','Yes'],['NO'])
WITH n
ORDER BY n.id
RETURN n.name AS name, n.prop AS prop;
Table 1. Results
name prop
""A""
TRUE
""B""
TRUE
""C""
FALSE
""D""
NULL
apoc.refactor.mergeRelationships
apoc.refactor.rename.label
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.mergeRelationships;"apoc.refactor.mergeRelationships
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.refactor.mergeRelationships(rels [Rel], config Map<String, Any>) - merges the given list of relationships onto the first relationship in the list.
Signature
None
Copy to Clipboard
apoc.refactor.mergeRelationships(rels :: LIST? OF RELATIONSHIP?, config = {} :: MAP?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
rels
LIST? OF RELATIONSHIP?
null
config
MAP?
{}
Output parameters
Name Type
rel
RELATIONSHIP?
More documentation of apoc.refactor.mergeRelationships
apoc.refactor.mergeNodes
apoc.refactor.normalizeAsBoolean
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.mergeNodes;"apoc.refactor.mergeNodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.mergeNodes(nodes [Node], config Map<String, Any>) - merges the given list of nodes onto the first node in the list. All relationships are merged onto that node as well.
Signature
None
Copy to Clipboard
apoc.refactor.mergeNodes(nodes :: LIST? OF NODE?, config = {} :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n1:Person {name:'Tom'}),
(n2:Person {name:'John'}),
(n3:Company {name:'Company1'}),
(n5:Car {brand:'Ferrari'}),
(n6:Animal:Cat {name:'Derby'}),
(n7:City {name:'London'}),

(n1)-[:WORKS_FOR {since:2015}]->(n3),
(n2)-[:WORKS_FOR {since:2018}]->(n3),
(n3)-[:HAS_HQ {since:2004}]->(n7),
(n1)-[:DRIVE {since:2017}]->(n5),
(n2)-[:HAS {since:2013}]->(n6);
The following merges John and Tom into a single node:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (a1:Person{name:'John'}), (a2:Person {name:'Tom'})
WITH head(collect([a1,a2])) as nodes
CALL apoc.refactor.mergeNodes(nodes,{
  properties:""combine"",
  mergeRels:true
})
YIELD node
RETURN node;
Table 1. Results
node
(:Person {name: [""John"", ""Tom""]})
More documentation of apoc.refactor.mergeNodes
apoc.refactor.invert
apoc.refactor.mergeRelationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/merge-nodes;"Merge nodes
Contents
Procedure for merging nodes
Config options
Examples
Same start and end nodes
Different start and end nodes
The APOC library contains a procedure that can be used to merge nodes.
This procedure allows for merging a list of nodes onto the first node in the list (all relationships are merged onto that node as well). The merge behaviour can be specified for properties globally and/or individually.
Procedure for merging nodes
Qualified Name Type
apoc.refactor.mergeNodes
apoc.refactor.mergeNodes(nodes [Node], config Map<String, Any>) - merges the given list of nodes onto the first node in the list. All relationships are merged onto that node as well.
Procedure
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p ORDER BY p.created DESC // newest one first
WITH p.email AS email, collect(p) as nodes
CALL apoc.refactor.mergeNodes(nodes, {properties: {
    name:'discard',
    age:'overwrite',
    kids:'combine',
    `addr.*`: 'overwrite',
    `.*`: 'discard'
}})
YIELD node
RETURN node
Config options
Below are the config options for this procedure: These config option also works for apoc.refactor.mergeRelationships([rels],{config}).
type operations
discard
the property from the first node will remain if already set, otherwise the first property in list will be written
overwrite / override
last property in list wins
combine
if there is only one property in list, it will be set / kept as single property otherwise create an array, tries to coerce values
In addition, mergeNodes supports the following config properties:
type operations
mergeRels
true/false: give the possibility to merge relationships with same type and direction.
produceSelfRel
true/false: if true (default), any eventual new self-relationship that would be created from the nodes merged into target node are inserted, otherwise not. Please note that this param is independent from mergeRels config and doesn’t affect on pre-existing self-relationships (in this case it is used the preserveExistingSelfRels config).
preserveExistingSelfRels
true/false: is valid only with mergeRels:true. If true (default), the pre-existing self-relationships in the final node will remain, otherwise will be deleted.
singleElementAsArray
false/true: if is false (default) and type is combine in case the merge of two arrays is a new array with size 1 it extracts the single value.
Properties with a name not included in the config map are overridden.
Relationships properties are managed with the same method, except when the config map is null, in which case the entity properties are combined.
Examples
The below examples will further explain this procedure.
Same start and end nodes
Cypher
The following creates a graph containings relationships that have the same start and end nodes
Copy to Clipboard
Run in Neo4j Browser
CREATE (n1:Person {name:'Tom'}),
(n2:Person {name:'John'}),
(n3:Company {name:'Company1'}),
(n5:Car {brand:'Ferrari'}),
(n6:Animal:Cat {name:'Derby'}),
(n7:City {name:'London'}),

(n1)-[:WORKS_FOR {since:2015}]->(n3),
(n2)-[:WORKS_FOR {since:2018}]->(n3),
(n3)-[:HAS_HQ {since:2004}]->(n7),
(n1)-[:DRIVE {since:2017}]->(n5),
(n2)-[:HAS {since:2013}]->(n6);
return *;
Cypher
The following merges John and Tom into a single node:
Copy to Clipboard
Run in Neo4j Browser
MATCH (a1:Person{name:'John'}), (a2:Person {name:'Tom'})
WITH head(collect([a1,a2])) as nodes
CALL apoc.refactor.mergeNodes(nodes,{properties:""combine"", mergeRels:true})
YIELD node
RETURN count(*)
If the above query is run, it will result in the following graph:
Since the relationships have the same start and end nodes, the relationships are merged and properties are combined.
Different start and end nodes
Cypher
The following creates a graph containings relationships that have different start or end nodes:
Copy to Clipboard
Run in Neo4j Browser
Create (n1:Person {name:'Tom'}),
(n2:Person {name:'John'}),
(n3:Company {name:'Company1'}),
(n4:Company {name:'Company2'}),
(n5:Car {brand:'Ferrari'}),
(n6:Animal:Cat {name:'Derby'}),
(n7:City {name:'London'}),
(n8:City {name:'Liverpool'}),
(n1)-[:WORKS_FOR{since:2015}]->(n3),
(n2)-[:WORKS_FOR{since:2018}]->(n4),
(n3)-[:HAS_HQ{since:2004}]->(n7),
(n4)-[:HAS_HQ{since:2007}]->(n8),
(n1)-[:DRIVE{since:2017}]->(n5),
(n2)-[:HAS{since:2013}]->(n6)
return *;
Cypher
The following merges John and Tom into a single node:
Copy to Clipboard
Run in Neo4j Browser
MATCH (a1:Person{name:'John'}), (a2:Person {name:'Tom'})
WITH head(collect([a1,a2])) as nodes
CALL apoc.refactor.mergeNodes(nodes,{
    properties:""combine"",
    mergeRels:true
})
YIELD node
RETURN count(*)
If the above query is run, it will result in the following graph:
Since the relationships have different end nodes, all relationships and properties are maintained.
Invert relationships
Normalize as boolean
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/invert-relationship;"Invert relationships
Contents
Procedure for inverting the direction of relationships
Example
The APOC library contains a procedure that can be used to invert the direction of relationships.
Procedure for inverting the direction of relationships
Qualified Name Type
apoc.refactor.invert
apoc.refactor.invert(rel Rel) - inverts the direction of the given relationship.
Procedure
Example
The below example will further explain this procedure.
Cypher
The following creates a graph containing two nodes connected by a relationship:
Copy to Clipboard
Run in Neo4j Browser
CREATE path=(c:Car {make:""Volvo""})-[rel:DRIVES {year:2001}]->(p:Person {name:""Dan""}) RETURN path
Cypher
The following inverts the direction of the relationship:
Copy to Clipboard
Run in Neo4j Browser
MATCH (c:Car)-[rel:DRIVES]->(p:Person)
CALL apoc.refactor.invert(rel)
yield input, output
RETURN input, output
Table 1. Results
input output
2
{""identity"":3,""start"":9,""end"":8,""type"":""DRIVES"",""properties"":{""year"":2001}}
Cypher
The relationship has now been inverted
Copy to Clipboard
Run in Neo4j Browser
 ----
MATCH path=(c:Car {make:""Volvo""})-[rel:DRIVES {year:2001}]-(p:Person {name:""Dan""}) RETURN path
----
Extract node from relationships
Merge nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/extract-node-from-relationship;"Extract node from relationships
Contents
Procedure for creating nodes from relationships
Example
The APOC library contains a procedure that can be used to create nodes from relationships.
Procedure for creating nodes from relationships
Qualified Name Type
apoc.refactor.extractNode
apoc.refactor.extractNode(rels Any, labels [String], outType String, inType String) - expands the given relationships into intermediate nodes. The intermediate nodes are connected by the given 'OUT' and 'IN' types.
Procedure
Example
The example below will further explain this procedure.
Cypher
The following creates a graph containing two nodes connected by a relationship:
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo)-[rel:FOOBAR {a:1}]->(b:Bar)
Cypher
The following converts the FOOBAR relationship into a node with label FOOBAR that has an incoming FOO relationship and outgoing BAR relationship:
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo)-[rel:FOOBAR {a:1}]->(b:Bar)
CALL apoc.refactor.extractNode(rel,['FooBar'],'FOO','BAR')
YIELD input, output
RETURN input, output
If the above query is run, it will result in the following graph:
Collapse nodes to relationships
Invert relationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.extractNode;"apoc.refactor.extractNode
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.extractNode(rels Any, labels [String], outType String, inType String) - expands the given relationships into intermediate nodes. The intermediate nodes are connected by the given 'OUT' and 'IN' types.
Signature
None
Copy to Clipboard
apoc.refactor.extractNode(relationships :: ANY?, labels :: LIST? OF STRING?, outType :: STRING?, inType :: STRING?) :: (input :: INTEGER?, output :: NODE?, error :: STRING?)
Input parameters
Name Type Default
relationships
ANY?
null
labels
LIST? OF STRING?
null
outType
STRING?
null
inType
STRING?
null
Output parameters
Name Type
input
INTEGER?
output
NODE?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (origin:Airport {code: ""LHR""})
CREATE (destination:Airport {code: ""AMS""})
CREATE (origin)-[:FLIGHT {number: ""BA001""}]->(destination);
The following creates a Flight node with an IN relationship from LHR and an OUT relationship to AMS:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Airport)-[rel:FLIGHT]->(:Airport)
WITH collect(rel) AS rels
CALL apoc.refactor.extractNode(rels,['Flight'],'OUT','IN')
YIELD input, output
RETURN input, output;
Table 1. Results
input output
0
(:Flight {number: ""BA001""})
We can list all the Flight nodes by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (origin)-[:IN]->(:Flight)-[:OUT]->(destination)
RETURN path;
Table 2. Results
path
(:Airport {code: ""LHR""})-[:IN]→(:Flight {number: ""BA001""})-[:OUT]→(:Airport {code: ""AMS""})
apoc.refactor.deleteAndReconnect
apoc.refactor.from
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.from;"apoc.refactor.from
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.from(rel Rel, newNode Node) - redirects the given relationship to the given start node.
Signature
None
Copy to Clipboard
apoc.refactor.from(relationship :: RELATIONSHIP?, newNode :: NODE?) :: (input :: INTEGER?, output :: RELATIONSHIP?, error :: STRING?)
Input parameters
Name Type Default
relationship
RELATIONSHIP?
null
newNode
NODE?
null
Output parameters
Name Type
input
INTEGER?
output
RELATIONSHIP?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Person {name: ""Mark"", city: ""London""})
CREATE (jennifer:Person {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Person {name: ""Michael"", city: ""Dresden""})
CREATE (mark)-[:FOLLOWS]->(jennifer);
The following makes Michael the start node in the FOLLOWS relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (michael:Person {name: ""Michael""})
MATCH ()-[rel:FOLLOWS]->()
CALL apoc.refactor.from(rel, michael)
YIELD input, output
RETURN input, output;
Table 1. Results
input output
14
[:FOLLOWS]
We can list all the Person nodes by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[rel:FOLLOWS]->()
RETURN path;
Table 2. Results
path
(:Person {name: ""Michael"", city: ""Dresden""})-[:FOLLOWS]→(:Person {name: ""Jennifer"", city: ""St Louis""})
More documentation of apoc.refactor.from
apoc.refactor.extractNode
apoc.refactor.invert
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.invert;"apoc.refactor.invert
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.invert(rel Rel) - inverts the direction of the given relationship.
Signature
None
Copy to Clipboard
apoc.refactor.invert(relationship :: RELATIONSHIP?) :: (input :: INTEGER?, output :: RELATIONSHIP?, error :: STRING?)
Input parameters
Name Type Default
relationship
RELATIONSHIP?
null
Output parameters
Name Type
input
INTEGER?
output
RELATIONSHIP?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Person {name: ""Mark"", city: ""London""})
CREATE (jennifer:Person {name: ""Jennifer"", city: ""St Louis""})
CREATE (mark)-[:FOLLOWS]->(jennifer);
The following reverses the direction of the FOLLOWS relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[rel:FOLLOWS]->()
CALL apoc.refactor.invert(rel)
YIELD input, output
RETURN input, output;
Table 1. Results
input output
0
[:FOLLOWS]
We can list all the Person nodes by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[rel:FOLLOWS]->()
RETURN path;
Table 2. Results
path
(:Person {name: ""Jennifer"", city: ""St Louis""})-[:FOLLOWS]→(:Person {name: ""Mark"", city: ""London""})
More documentation of apoc.refactor.invert
apoc.refactor.from
apoc.refactor.mergeNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/redirect-relationship;"Redirect relationships
Contents
Procedures for redirecting relationships
Examples
Redirect Target Node
Redirect Source Node
The APOC library contains procedures that can be used to redirect relationships to target nodes.
Procedures for redirecting relationships
Qualified Name Type
apoc.refactor.from
apoc.refactor.from(rel Rel, newNode Node) - redirects the given relationship to the given start node.
Procedure
apoc.refactor.to
apoc.refactor.to(rel Rel, endNode Node) - redirects the given relationship to the given end node.
Procedure
Examples
The below examples will further explain this procedure.
Redirect Target Node
Cypher
The following creates Foo and Bar nodes that are connected by a FOOBAR relationship, as well as a solitary Antony node:
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo {value: ""Foo""})-[rel:FOOBAR {a:1}]->(b:Bar {value: ""Bar""})
CREATE (p:Person {name:'Antony'})
RETURN *
Cypher
The following will change the target node of the FOOBAR relationship from the Bar node to the Antony node:
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo)-[rel:FOOBAR {a:1}]->(b:Bar)
MATCH (p:Person {name:'Antony'})
CALL apoc.refactor.to(rel, p)
YIELD input, output
RETURN input, output
If the above query is run, it will result in the following graph:
Redirect Source Node
Cypher
The following creates Foo2 and Bar2 nodes that are connected by a FOOBAR2 relationship, as well as a solitary David node:
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo2 {value: ""Foo2""})-[rel:FOOBAR2 {a:1}]->(b:Bar2 {value: ""Bar2""})
CREATE (p:Person {name:'David'})
RETURN *
Cypher
The following will change the source node of the FOOBAR2 relationship from the Foo node to the David node:
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo2)-[rel:FOOBAR2 {a:1}]->(b:Bar2)
MATCH (p:Person {name:'David'})
CALL apoc.refactor.from(rel, p)
YIELD input, output
RETURN input, output
If the above query is run, it will result in the following graph:
Property value to a label
Rename labels, types, and properties
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/property-value-label;"Property value to a label
Contents
Procedure for creating a label from a property value
Example
The APOC library contains a procedure that can be used to create a label from a property value.
Procedure for creating a label from a property value
Qualified Name Type
apoc.create.addLabels
apoc.create.addLabels(nodes Any, label [String]) - adds the given labels to the given nodes.
Procedure
Example
The below example will further explain this procedure.
Cypher
The following creates a Movie node with title and genre properties
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Movie {title: 'A Few Good Men', genre: 'Drama'})
Cypher
The following moves the 'genre' property to a label and removes it as a property
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
CALL apoc.create.addLabels( id(n), [ n.genre ] )
YIELD node
REMOVE node.genre
RETURN node
Normalize as boolean
Redirect relationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/normalize-boolean;"Normalize as boolean
Contents
Procedure for translating string values into booleans
Example
The APOC library contains a procedure that can be used to translate string values into booleans.
Procedure for translating string values into booleans
Qualified Name Type
apoc.refactor.normalizeAsBoolean
apoc.refactor.normalizeAsBoolean(entity Any, propertyKey String, trueValues [Any], falseValues [Any]) - refactors the given property to a boolean.
Procedure
Example
The below example will further explain this procedure.
Cypher
The following creates a graph containing nodes with boolean properties representented in different formats:
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {prop: 'Y', name:'A'}),
       (:Person {prop: 'Yes', name:'B'}),
       (:Person {prop: 'NO', name:'C'}),
       (:Person {prop: 'X', name:'D'})
We want to transform some properties into a boolean, Y, Yes into true and the properties NO into false. The other properties that don’t match these possibilities will be set as null.
Cypher
The following normalizes all applicable boolean values for all nodes that have the prop property:
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
CALL apoc.refactor.normalizeAsBoolean(n,'prop',['Y','Yes'],['NO'])
WITH n
ORDER BY n.id
RETURN n.prop AS prop
If the above query is run, the following will be returned:
Merge nodes
Property value to a label
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.deleteAndReconnect;"apoc.refactor.deleteAndReconnect
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.deleteAndReconnect(path Path, nodes [Node], config Map<String, Any>) - removes the given nodes from the path and reconnects the remaining nodes.
Signature
None
Copy to Clipboard
apoc.refactor.deleteAndReconnect(path :: PATH?, nodes :: LIST? OF NODE?, config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
path
PATH?
null
nodes
LIST? OF NODE?
null
config
MAP?
{}
Config parameters
The procedure supports the following config parameters:
Table 1. Config parameters
name type default description
relationshipSelectionStrategy
Enum[incoming, outgoing, merge]
true
if incoming, the incoming relationship will be attached to the next node. If outgoing, the outgoing relationship will be attached. If merge, a merge of the incoming and outgoing relationships will be attached. If they share some property names, the incoming relationship properties have higher precedence by default.
properties
Enum
override
Will be considered only if relationshipSelectionStrategy is merge. See below
Table 2. Properties parameters
type operations
discard
start node property wins
overwrite / override
end node property wins
combine
if there is only one property between incoming and outgoing node, it will be set / kept as single property otherwise create an array, tries to coerce values
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Let’s suppose we have a simple data set like:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:One)-[:ALPHA {a:'b'}]->(b:Two)-[:BETA {a:'d', e:'f', g: 'h'}]->(c:Three)-[:GAMMA {aa: 'one'}]->(d:Four)-[:DELTA {aa: 'bb', cc: 'dd', ee: 'ff'}]->(e:Five {foo: 'bar', baz: 'baa'}), (:Other)-[:Pippo {goku: 'gohan', vegeta: 'trunks'}]->(:Other2), (:Other)-[:Pippo2 {krilin: 'maron'}]->(:Other2)
So, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five) WITH p, [b,d] as list CALL apoc.refactor.deleteAndReconnect(p, list) YIELD nodes, relationships RETURN nodes, relationships;
Table 3. Results
nodes relationships
[{""identity"":0,""labels"":[""One""],""properties"":{}},{""identity"":2,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":6,""start"":0,""end"":2,""type"":""ALPHA"",""properties"":{""a"":""b""}},{""identity"":7,""start"":2,""end"":4,""type"":""GAMMA"",""properties"":{""aa"":""one""}}]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five) WITH p, [b,d] as list CALL apoc.refactor.deleteAndReconnect(p, list, {relationshipSelectionStrategy: 'outgoing'}) YIELD nodes, relationships RETURN nodes, relationships;
Table 4. Results
nodes relationships
[{""identity"":1,""labels"":[""One""],""properties"":{}},{""identity"":0,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":6,""start"":1,""end"":0,""type"":""BETA"",""properties"":{""a"":""d"",""e"":""f"",""g"":""h""}},{""identity"":7,""start"":0,""end"":4,""type"":""DELTA"",""properties"":{""aa"":""bb"",""cc"":""dd"",""ee"":""ff""}}]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five) WITH p, [b,d] as list CALL apoc.refactor.deleteAndReconnect(p, list, {relationshipSelectionStrategy: 'merge'}) YIELD nodes, relationships RETURN nodes, relationships;
Table 5. Results
nodes relationships
[{""identity"":2,""labels"":[""One""],""properties"":{}},{""identity"":0,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":6,""start"":2,""end"":0,""type"":""ALPHA_BETA"",""properties"":{""a"":""d"",""e"":""f"",""g"":""h""}},{""identity"":7,""start"":0,""end"":4,""type"":""GAMMA_DELTA"",""properties"":{""aa"":""bb"",""cc"":""dd"",""ee"":""ff""}}]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five) WITH p, [b,d] as list CALL apoc.refactor.deleteAndReconnect(p, list, {properties: 'combine', relationshipSelectionStrategy: 'merge'}) YIELD nodes, relationships RETURN nodes, relationships;
Table 6. Results
nodes relationships
[{""identity"":2,""labels"":[""One""],""properties"":{}},{""identity"":0,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":4,""start"":2,""end"":0,""type"":""ALPHA_BETA"",""properties"":{""a"":[""b"",""d""],""e"":""f"",""g"":""h""}},{""identity"":5,""start"":0,""end"":4,""type"":""GAMMA_DELTA"",""properties"":{""aa"":[""one"",""bb""],""cc"":""dd"",""ee"":""ff""}}]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five) WITH p, [b,d] as list CALL apoc.refactor.deleteAndReconnect(p, list, {relTypesToAttach: ['one', 'two']}) YIELD nodes, relationships RETURN nodes, relationships;
Table 7. Results
nodes relationships
[{""identity"":0,""labels"":[""One""],""properties"":{}},{""identity"":2,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":6,""start"":1,""end"":0,""type"":""ALPHA"",""properties"":{""a"":""b""}},{""identity"":7,""start"":0,""end"":4,""type"":""GAMMA"",""properties"":{""aa"":""one""}}]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(f:One)-->(b:Two)-->(c:Three)-->(d:Four)-->(e:Five), ()-[rel:Pippo]->(), ()-[rel2:Pippo2]->() WITH p, [b,d] as list, collect(rel)+rel2 as rels CALL apoc.refactor.deleteAndReconnect(p, list, {relsToAttach: rels}) YIELD nodes, relationships RETURN nodes, relationships
Table 8. Results
nodes relationships
[{""identity"":1,""labels"":[""One""],""properties"":{}},{""identity"":0,""labels"":[""Three""],""properties"":{}},{""identity"":4,""labels"":[""Five""],""properties"":{""baz"":""baa"",""foo"":""bar""}}]
[{""identity"":4,""start"":1,""end"":0,""type"":""ALPHA"",""properties"":{""a"":""b""}},{""identity"":5,""start"":0,""end"":4,""type"":""GAMMA"",""properties"":{""aa"":""one""}}]
apoc.refactor.collapseNode
apoc.refactor.extractNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.collapseNode;"apoc.refactor.collapseNode
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.collapseNode(nodes Any, relType String) - collapses the given node and replaces it with a relationship of the given type.
Signature
None
Copy to Clipboard
apoc.refactor.collapseNode(nodes :: ANY?, type :: STRING?) :: (input :: INTEGER?, output :: RELATIONSHIP?, error :: STRING?)
Input parameters
Name Type Default
nodes
ANY?
null
type
STRING?
null
Output parameters
Name Type
input
INTEGER?
output
RELATIONSHIP?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (flight:Flight {number: ""BA001""})
CREATE (origin:Airport {code: ""LHR""})
CREATE (destination:Airport {code: ""AMS""})
CREATE (flight)<-[:OUT]-(origin)
CREATE (flight)-[:IN]->(destination);
The following query collapses the Flight node, replacing it with a CONNECTED to relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (flight:Flight {number: ""BA001""})
CALL apoc.refactor.collapseNode([flight],'CONNECTED_TO')
YIELD input, output
RETURN input, output;
Table 1. Results
input output
10
[:CONNECTED_TO {number: ""BA001""}]
If we execute this query, it will result in the following graph:
apoc.refactor.cloneSubgraphFromPaths
apoc.refactor.deleteAndReconnect
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.cloneSubgraphFromPaths;"apoc.refactor.cloneSubgraphFromPaths
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.cloneSubgraphFromPaths(paths [Path], config Map<String, Any>) - clones a sub-graph defined by the given list of paths. It is possible to skip any node properties using the skipProperties list via the config map.
Signature
None
Copy to Clipboard
apoc.refactor.cloneSubgraphFromPaths(paths :: LIST? OF PATH?, config = {} :: MAP?) :: (input :: INTEGER?, output :: NODE?, error :: STRING?)
Input parameters
Name Type Default
paths
LIST? OF PATH?
null
config
MAP?
{}
Output parameters
Name Type
input
INTEGER?
output
NODE?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE  (rootA:Root{name:'A'}),
        (rootB:Root{name:'B'}),
        (n1:Node{name:'node1', id:1}),
        (n2:Node{name:'node2', id:2}),
        (n3:Node{name:'node3', id:3}),
        (n4:Node{name:'node4', id:4}),
        (n5:Node{name:'node5', id:5}),
        (n6:Node{name:'node6', id:6}),
        (n7:Node{name:'node7', id:7}),
        (n8:Node{name:'node8', id:8}),
        (n9:Node{name:'node9', id:9}),
        (n10:Node{name:'node10', id:10}),
        (n11:Node{name:'node11', id:11}),
        (n12:Node{name:'node12', id:12})
        CREATE (rootA)-[:LINK]->(n1)-[:LINK]->(n2)-[:LINK]->(n3)-[:LINK]->(n4)
                          (n1)-[:]->(n5)-[:]->(n6)<-[:]-(n7)
                                        (n5)-[:]->(n8)
                                        (n5)-[:]->(n9)-[:]->(n10)
         (rootB)-[:]->(n11);
View all (4 more lines)
Figure 1. Graph before subgraph cloning
This procedure clones a subgraph defined by a list of paths. This is useful when you want to ensure the cloned subgraph isn’t connected to the original nodes, or to nodes outside the subgraph.
The following query clones a subtree starting from rootA consisting of outgoing :LINK relationships, and attaches that subgraph to rootB. rootB acts as a standin for rootA, which is not cloned:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH  (rootA:Root{name:'A'}),
       (rootB:Root{name:'B'})
MATCH path = (rootA)-[:LINK*]->(node)
WITH rootA, rootB, collect(path) as paths
CALL apoc.refactor.cloneSubgraphFromPaths(paths, {
    standinNodes:[[rootA, rootB]]
})
YIELD input, output, error
RETURN input, output, error;
Table 1. Results
input output error
31424
(:Node {name: ""node3"", id: 3})
NULL
31425
(:Node {name: ""node4"", id: 4})
NULL
31426
(:Node {name: ""node5"", id: 5})
NULL
31427
(:Node {name: ""node6"", id: 6})
NULL
31429
(:Node {name: ""node8"", id: 8})
NULL
31430
(:Node {name: ""node9"", id: 9})
NULL
31422
(:Node {name: ""node1"", id: 1})
NULL
31423
(:Node {name: ""node2"", id: 2})
NULL
Figure 2. Graph after subgraph cloning
apoc.refactor.cloneSubgraph
apoc.refactor.collapseNode
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.cloneSubgraph;"apoc.refactor.cloneSubgraph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.cloneSubgraph(nodes [Node], rels [Rel], config Map<String, Any>) - clones the given nodes with their labels and properties (optionally skipping any properties in the skipProperties list via the config map), and clones the given relationships. If no relationships are provided, all existing relationships between the given nodes will be cloned.
Signature
None
Copy to Clipboard
apoc.refactor.cloneSubgraph(nodes :: LIST? OF NODE?, rels = [] :: LIST? OF RELATIONSHIP?, config = {} :: MAP?) :: (input :: INTEGER?, output :: NODE?, error :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
[]
config
MAP?
{}
Output parameters
Name Type
input
INTEGER?
output
NODE?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE  (rootA:Root{name:'A'}),
        (rootB:Root{name:'B'}),
        (n1:Node{name:'node1', id:1}),
        (n2:Node{name:'node2', id:2}),
        (n3:Node{name:'node3', id:3}),
        (n4:Node{name:'node4', id:4}),
        (n5:Node{name:'node5', id:5}),
        (n6:Node{name:'node6', id:6}),
        (n7:Node{name:'node7', id:7}),
        (n8:Node{name:'node8', id:8}),
        (n9:Node{name:'node9', id:9}),
        (n10:Node{name:'node10', id:10}),
        (n11:Node{name:'node11', id:11}),
        (n12:Node{name:'node12', id:12})
        CREATE (rootA)-[:LINK]->(n1)-[:LINK]->(n2)-[:LINK]->(n3)-[:LINK]->(n4)
                          (n1)-[:]->(n5)-[:]->(n6)<-[:]-(n7)
                                        (n5)-[:]->(n8)
                                        (n5)-[:]->(n9)-[:]->(n10)
         (rootB)-[:]->(n11);
View all (4 more lines)
Figure 1. Graph before subgraph cloning
This procedure clones a subgraph defined by a list of nodes and a list of relationships. If relationships are not provided, all relationships between the given nodes will be cloned. This is useful when you want to ensure the cloned subgraph isn’t connected to the original nodes, or to nodes outside the subgraph.
We can get the nodes and relationships from the yielded output of apoc.path.subgraphAll, filtering to the relationship types in the call to that procedure.
The following query clones a subtree starting from rootA consisting of outgoing :LINK relationships, and attaches that subgraph to rootB. rootB acts as a standin for rootA, which is not cloned:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH  (rootA:Root{name:'A'}),
       (rootB:Root{name:'B'})
CALL apoc.path.subgraphAll(rootA, {relationshipFilter:'LINK>'})
YIELD nodes, relationships
CALL apoc.refactor.cloneSubgraph(
    nodes,
    [rel in relationships WHERE type(rel) = 'LINK'],
    { standinNodes:[[rootA, rootB]] })
YIELD input, output, error
RETURN input, output, error;
Table 1. Results
input output error
31378
(:Node {name: ""node1"", id: 1})
NULL
31382
(:Node {name: ""node5"", id: 5})
NULL
31379
(:Node {name: ""node2"", id: 2})
NULL
31386
(:Node {name: ""node9"", id: 9})
NULL
31383
(:Node {name: ""node6"", id: 6})
NULL
31385
(:Node {name: ""node8"", id: 8})
NULL
31380
(:Node {name: ""node3"", id: 3})
NULL
31381
(:Node {name: ""node4"", id: 4})
NULL
Figure 2. Graph after subgraph cloning
apoc.refactor.cloneNodes
apoc.refactor.cloneSubgraphFromPaths
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.cloneNodes;"apoc.refactor.cloneNodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.cloneNodes(nodes [Node], withRelationships Boolean, skipProperties [String]) - clones the given nodes with their labels and properties. It is possible to skip any node properties using skipProperties (note: this only skips properties on nodes and not their relationships).
Signature
None
Copy to Clipboard
apoc.refactor.cloneNodes(nodes :: LIST? OF NODE?, withRelationships = false :: BOOLEAN?, skipProperties = [] :: LIST? OF STRING?) :: (input :: INTEGER?, output :: NODE?, error :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
withRelationships
BOOLEAN?
false
skipProperties
LIST? OF STRING?
[]
Output parameters
Name Type
input
INTEGER?
output
NODE?
error
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Person {name: ""Mark"", city: ""London""})
CREATE (jennifer:Person {name: ""Jennifer"", city: ""St Louis""});
The following creates copies of all Person nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH collect(p) AS people
CALL apoc.refactor.cloneNodes(people)
YIELD input, output
RETURN input, output;
Table 1. Results
input output
4
(:Person {name: ""Mark"", city: ""London""})
5
(:Person {name: ""Jennifer"", city: ""St Louis""})
We can list all the Person nodes by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN p;
Table 2. Results
p
(:Person {name: ""Mark"", city: ""London""})
(:Person {name: ""Jennifer"", city: ""St Louis""})
(:Person {name: ""Mark"", city: ""London""})
(:Person {name: ""Jennifer"", city: ""St Louis""})
apoc.refactor.categorize
apoc.refactor.cloneSubgraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.categorize;"apoc.refactor.categorize
Contents
Signature
Input parameters
Usage Examples
Procedure
apoc.refactor.categorize(sourceKey String, type String, outgoing Boolean, label String, targetKey String, copiedKeys [String], batchSize Integer) - creates new category nodes from nodes in the graph with the specified sourceKey as one of its property keys. The new category nodes are then connected to the original nodes with a relationship of the given type.
Signature
None
Copy to Clipboard
apoc.refactor.categorize(sourceKey :: STRING?, type :: STRING?, outgoing :: BOOLEAN?, label :: STRING?, targetKey :: STRING?, copiedKeys :: LIST? OF STRING?, batchSize :: INTEGER?) :: VOID
Input parameters
Name Type Default
sourceKey
STRING?
null
type
STRING?
null
outgoing
BOOLEAN?
null
label
STRING?
null
targetKey
STRING?
null
copiedKeys
LIST? OF STRING?
null
batchSize
INTEGER?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Movie {title: 'A Few Good Men', genre: 'Drama'});
We want to move the genre from the Movie node to a new node with the Genre label and name property. We’ll also create a GENRE relationship from the Movie node to that genre node.
This procedure requires us to create a unique constraint on the Genre label, name property, otherwise we’ll get the following exception:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.refactor.categorize('genre', 'GENRE', true, ""Genre"", ""name"", [], 100);
Text
Results
Copy to Clipboard
Failed to invoke procedure `apoc.refactor.categorize`: Caused by: java.lang.IllegalArgumentException: Before execute this procedure you must define an unique constraint for the label and the targetKey:
CREATE CONSTRAINT FOR (n:`Genre`) REQUIRE n.`name` IS UNIQUE
Once we’ve created the constraint, we can re-run the procedure, and then see the new graph structure by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=()-[:GENRE]->()
RETURN p;
Figure 1. New graph structure
apoc.refactor
apoc.refactor.cloneNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor;"apoc.refactor
Qualified Name Type
apoc.refactor.categorize
apoc.refactor.categorize(sourceKey String, type String, outgoing Boolean, label String, targetKey String, copiedKeys [String], batchSize Integer) - creates new category nodes from nodes in the graph with the specified sourceKey as one of its property keys. The new category nodes are then connected to the original nodes with a relationship of the given type.
Procedure
apoc.refactor.cloneNodes
apoc.refactor.cloneNodes(nodes [Node], withRelationships Boolean, skipProperties [String]) - clones the given nodes with their labels and properties. It is possible to skip any node properties using skipProperties (note: this only skips properties on nodes and not their relationships).
Procedure
apoc.refactor.cloneSubgraph
apoc.refactor.cloneSubgraph(nodes [Node], rels [Rel], config Map<String, Any>) - clones the given nodes with their labels and properties (optionally skipping any properties in the skipProperties list via the config map), and clones the given relationships. If no relationships are provided, all existing relationships between the given nodes will be cloned.
Procedure
apoc.refactor.cloneSubgraphFromPaths
apoc.refactor.cloneSubgraphFromPaths(paths [Path], config Map<String, Any>) - clones a sub-graph defined by the given list of paths. It is possible to skip any node properties using the skipProperties list via the config map.
Procedure
apoc.refactor.collapseNode
apoc.refactor.collapseNode(nodes Any, relType String) - collapses the given node and replaces it with a relationship of the given type.
Procedure
apoc.refactor.deleteAndReconnect
apoc.refactor.deleteAndReconnect(path Path, nodes [Node], config Map<String, Any>) - removes the given nodes from the path and reconnects the remaining nodes.
Procedure
apoc.refactor.extractNode
apoc.refactor.extractNode(rels Any, labels [String], outType String, inType String) - expands the given relationships into intermediate nodes. The intermediate nodes are connected by the given 'OUT' and 'IN' types.
Procedure
apoc.refactor.from
apoc.refactor.from(rel Rel, newNode Node) - redirects the given relationship to the given start node.
Procedure
apoc.refactor.invert
apoc.refactor.invert(rel Rel) - inverts the direction of the given relationship.
Procedure
apoc.refactor.mergeNodes
apoc.refactor.mergeNodes(nodes [Node], config Map<String, Any>) - merges the given list of nodes onto the first node in the list. All relationships are merged onto that node as well.
Procedure
apoc.refactor.mergeRelationships
apoc.refactor.mergeRelationships(rels [Rel], config Map<String, Any>) - merges the given list of relationships onto the first relationship in the list.
Procedure
apoc.refactor.normalizeAsBoolean
apoc.refactor.normalizeAsBoolean(entity Any, propertyKey String, trueValues [Any], falseValues [Any]) - refactors the given property to a boolean.
Procedure
apoc.refactor.rename.label
apoc.refactor.rename.label(oldLabel String, newLabel String, nodes [Node]) - renames the given label from 'oldLabel' to 'newLabel' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.nodeProperty
apoc.refactor.rename.nodeProperty(oldName String, newName String, nodes [Node], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.type
apoc.refactor.rename.type(oldType String, newType String, rels [Rel], config Map<String, Any>) - renames all relationships with type 'oldType' to 'newType'. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
apoc.refactor.rename.typeProperty
apoc.refactor.rename.typeProperty(oldName String, newName String, rels [Rel], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all relationships. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
apoc.refactor.setType
apoc.refactor.setType(rel Rel, newType String) - changes the type of the given relationship.
Procedure
apoc.refactor.to
apoc.refactor.to(rel Rel, endNode Node) - redirects the given relationship to the given end node.
Procedure
apoc.periodic.truncate
apoc.refactor.categorize
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.refactor/apoc.refactor.rename.type;"apoc.refactor.rename.type
Contents
Input parameters
Output parameters
Usage Examples
Procedure
apoc.refactor.rename.type(oldType String, newType String, rels [Rel], config Map<String, Any>) - renames all relationships with type 'oldType' to 'newType'. If a list of relationships is provided, the renaming is applied to the relationships within this list only. == Signature
None
Copy to Clipboard
apoc.refactor.rename.type(oldType :: STRING?, newType :: STRING?, rels = [] :: LIST? OF RELATIONSHIP?, config = {} :: MAP?) :: (batches :: INTEGER?, total :: INTEGER?, timeTaken :: INTEGER?, committedOperations :: INTEGER?, failedOperations :: INTEGER?, failedBatches :: INTEGER?, retries :: INTEGER?, errorMessages :: MAP?, batch :: MAP?, operations :: MAP?, constraints :: LIST? OF STRING?, indexes :: LIST? OF STRING?)
Input parameters
Name Type Default
oldType
STRING?
null
newType
STRING?
null
rels
LIST? OF RELATIONSHIP?
[]
config
MAP?
{}
Output parameters
Name Type
batches
INTEGER?
total
INTEGER?
timeTaken
INTEGER?
committedOperations
INTEGER?
failedOperations
INTEGER?
failedBatches
INTEGER?
retries
INTEGER?
errorMessages
MAP?
batch
MAP?
operations
MAP?
constraints
LIST? OF STRING?
indexes
LIST? OF STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (mark:Engineer {name: ""Mark"", city: ""London""})
CREATE (jennifer:Engineer {name: ""Jennifer"", city: ""St Louis""})
CREATE (michael:Engineer {name: ""Michael"", city: ""Dresden""})
CREATE (jim:Engineer {name: ""Jim"", city: ""London""})
CREATE (alistair:Engineer {name: ""Alistair"", city: ""London""})

MERGE (jim)-[:COLLEAGUES {since: date(""2006-05-01"")}]->(alistair)
MERGE (mark)-[:COLLEAGUES {since: date(""2018-02-01"")}]->(jennifer)
MERGE (mark)-[:COLLEAGUES {since: date(""2013-05-01"")}]->(michael);
The following changes the label on Mark, Jennifer, and Michael from Engineer to DevRel:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Engineer)
WHERE person.name IN [""Mark"", ""Jennifer"", ""Michael""]
WITH collect(person) AS people
CALL apoc.refactor.rename.label(""Engineer"", ""DevRel"", people)
YIELD batches, total, timeTaken, committedOperations
RETURN batches, total, timeTaken, committedOperations;
Table 1. Results
batches total timeTaken committedOperations
1
3
0
3
After this query has run, we’ll have the following graph:
More documentation of apoc.refactor.rename.type
apoc.refactor.rename.nodeProperty
apoc.refactor.rename.typeProperty
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.path/apoc.path.subgraphAll;"apoc.path.subgraphAll
Contents
Signature
Input parameters
Config parameters
Relationship Filters
Label Filters
Output parameters
Usage Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
Procedure
apoc.path.subgraphAll(startNode Any, config Map<String, Any>) - returns the sub-graph reachable from the start node following the given relationship types to max-depth.
Signature
None
Copy to Clipboard
apoc.path.subgraphAll(start :: ANY?, config :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
start
ANY?
null
config
MAP?
null
Config parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the subgraph reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Praveena.
Figure 2. Subgraph from Praveena
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the subgraph o Engineering people reachable by the KNOWS relationship at 1 to 2 hops from Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph of Engineering nodes from Praveena.
Figure 3. Subgraph of Engineering nodes from Praveena
We lose Lju and Stefan because those nodes don’t have the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the subgraph of people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia.
Figure 4. Subgraph from Alicia
This subgraph includes all but one of the people in our graph, which means that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the subgraph reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia terminating at Engineering nodes.
Figure 5. Subgraph from Alicia terminating at Engineering nodes
We’re now down to only 2 people - Zhen and Praveena. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns the subgraph of Engineering people reachable by the FOLLOWS or KNOWS relationships at 1 to 3 hops from Alicia
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia ending at Engineering nodes.
Figure 6. Subgraph from Alicia ending at Engineering nodes
Our subgraph now also includes Martin, who is reached via a relationship from Zhen.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want the returned subgraph to stop as soon as the Mark, Joe, Zhen, or Praveena nodes are reached. We can do that by passing those nodes to the terminatorNodes parameter.
Cypher
The following returns the subgraph of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (terminator:Person)
WHERE terminator.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(terminator) AS terminatorNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: terminatorNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia terminating at Mark, Joe, Zhen, or Rik.
Figure 7. Subgraph from Alicia terminating at Mark, Joe, Zhen, or Rik
We have paths to Mark and Joe, but Zhen and Rik can’t be reached This could be because there is no path to Zhen and Rik that doesn’t go through Mark and Joe, or it could mean that there’s no path based on the other traversal criteria.
We can find out whether Mark, Joe, Zhen, or Rik are reachable by passing these nodes to the endNodes parameter.
Cypher
The following returns the subgraph of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, ending as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(end) AS endNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia ending at Mark, Joe, Zhen, or Rik.
Figure 8. Subgraph from Alicia ending at Mark, Joe, Zhen, or Rik
We can now reach Joe, Mark, and Zhen, but Rik is still unreachable.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia where paths to nodes include Mark, Jonny, or Zhen.
Figure 9. Subgraph from Alicia where paths to nodes include Mark, Jonny, or Zhen
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns nodes reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.subgraphAll(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Alicia where paths to nodes can’t go via Joe.
Figure 10. Subgraph from Alicia where paths to nodes can’t go via Joe
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.subgraphAll(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD nodes, relationships
RETURN nodes, relationships;
We can see a Neo4j Browser visualization of the returned subgraph in Subgraph from Joe via alternate FOLLOWS and KNOWS relationship types.
Figure 11. Subgraph from Joe via alternate FOLLOWS and KNOWS relationship types
More documentation of apoc.path.subgraphAll
apoc.path.spanningTree
apoc.path.subgraphNodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/collapse-node-to-relationship;"Collapse nodes to relationships
Contents
Procedure for collapsing nodes
Example
The APOC library contains a procedure that can be used to collapse a node into a relationship.
Procedure for collapsing nodes
Qualified Name Type
apoc.refactor.collapseNode
apoc.refactor.collapseNode(nodes Any, relType String) - collapses the given node and replaces it with a relationship of the given type.
Procedure
Example
The example below will further explain this procedure.
Cypher
The following creates a graph containing a Flight node and two Airport nodes (origin and destination)
Copy to Clipboard
Run in Neo4j Browser
CREATE (flight:Flight {number: ""BA001""})
CREATE (origin:Airport {code: ""LHR""})
CREATE (destination:Airport {code: ""AMS""})
CREATE (flight)<-[:OUT]-(origin)
CREATE (flight)-[:IN]->(destination)
Cypher
The following query collapses the Flight node, replacing it with a CONNECTED to relationship:
Copy to Clipboard
Run in Neo4j Browser
MATCH (flight:Flight {number: ""BA001""})
CALL apoc.refactor.collapseNode([flight],'CONNECTED_TO')
YIELD input, output , error
RETURN input, output, error
If the above query is run, it will result in the following graph:
Clone subgraph
Extract node from relationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/clone-subgraph;"Clone subgraph
Contents
Procedures for cloning subgraphs
Examples
The APOC library contains procedures that can be used to clone subgraphs. These procedures can be used to clone a subgraph defined either by a list of nodes and a list of relationships, or a list of paths. This is useful when you want to ensure the cloned subgraph is not connected to the original nodes, or to nodes outside the subgraph.
If relationships are not provided, all relationships between the given nodes will be cloned. In the config map, a list of standinNodes (of pairs of nodes) can be provided, allowing an existing node in the graph to act as a standin for another node in the cloned subgraph. This can be useful for attaching the cloned subgraph to another node in the graph (rather than cloning a node).
Procedures for cloning subgraphs
Qualified Name Type
apoc.refactor.cloneSubgraph
apoc.refactor.cloneSubgraph(nodes [Node], rels [Rel], config Map<String, Any>) - clones the given nodes with their labels and properties (optionally skipping any properties in the skipProperties list via the config map), and clones the given relationships. If no relationships are provided, all existing relationships between the given nodes will be cloned.
Procedure
apoc.refactor.cloneSubgraphFromPaths
apoc.refactor.cloneSubgraphFromPaths(paths [Path], config Map<String, Any>) - clones a sub-graph defined by the given list of paths. It is possible to skip any node properties using the skipProperties list via the config map.
Procedure
Examples
The examples below will further explain these procedures.
Cypher
The following creates a dataset containing two trees:
Copy to Clipboard
Run in Neo4j Browser
CREATE  (rootA:Root{name:'A'}),
        (rootB:Root{name:'B'}),
        (n1:Node{name:'node1', id:1}),
        (n2:Node{name:'node2', id:2}),
        (n3:Node{name:'node3', id:3}),
        (n4:Node{name:'node4', id:4}),
        (n5:Node{name:'node5', id:5}),
        (n6:Node{name:'node6', id:6}),
        (n7:Node{name:'node7', id:7}),
        (n8:Node{name:'node8', id:8}),
        (n9:Node{name:'node9', id:9}),
        (n10:Node{name:'node10', id:10}),
        (n11:Node{name:'node11', id:11}),
        (n12:Node{name:'node12', id:12})
        CREATE (rootA)-[:LINK]->(n1)-[:LINK]->(n2)-[:LINK]->(n3)-[:LINK]->(n4)
                          (n1)-[:]->(n5)-[:]->(n6)<-[:]-(n7)
                                        (n5)-[:]->(n8)
                                        (n5)-[:]->(n9)-[:]->(n10)
         (rootB)-[:]->(n11)
View all (4 more lines)
Cypher
The following query clones a subtree starting from rootA consisting of outgoing :LINK relationships, and attaches that subgraph to rootB. rootB acts as a standin for rootA, which is not cloned:
Copy to Clipboard
Run in Neo4j Browser
MATCH  (rootA:Root{name:'A'}),
       (rootB:Root{name:'B'})
MATCH path = (rootA)-[:LINK*]->(node)
WITH rootA, rootB, collect(path) as paths
CALL apoc.refactor.cloneSubgraphFromPaths(paths, {
    standinNodes:[[rootA, rootB]]
})
YIELD input, output, error
RETURN input, output, error
If the above query is run, it will result in the following graph:
Another approach is to use apoc.refactor.cloneSubgraph(), providing the lists of nodes and relationships which form the subgraph. The nodes and relationships from the yielded output can be obtained using apoc.path.subgraphAll(), filtering to the relationship types in the call to that procedure.
Cypher
The following query creates a dataset containing two trees:
Copy to Clipboard
Run in Neo4j Browser
CREATE  (rootA:Root2{name:'A'}),
        (rootB:Root2{name:'B'}),
        (n1:Node2{name:'node1', id:1}),
        (n2:Node2{name:'node2', id:2}),
        (n3:Node2{name:'node3', id:3}),
        (n4:Node2{name:'node4', id:4}),
        (n5:Node2{name:'node5', id:5}),
        (n6:Node2{name:'node6', id:6}),
        (n7:Node2{name:'node7', id:7}),
        (n8:Node2{name:'node8', id:8}),
        (n9:Node2{name:'node9', id:9}),
        (n10:Node2{name:'node10', id:10}),
        (n11:Node2{name:'node11', id:11}),
        (n12:Node2{name:'node12', id:12})
        CREATE (rootA)-[:LINK]->(n1)-[:LINK]->(n2)-[:LINK]->(n3)-[:LINK]->(n4)
                          (n1)-[:]->(n5)-[:]->(n6)<-[:]-(n7)
                                        (n5)-[:]->(n8)
                                        (n5)-[:]->(n9)-[:]->(n10)
         (rootB)-[:]->(n11)
View all (4 more lines)
Cypher
The following query clones a subtree starting from rootA consisting of outgoing :LINK relationships, and attaches that subgraph to rootB. rootB acts as a standin for rootA, which is not cloned:
Copy to Clipboard
Run in Neo4j Browser
MATCH  (rootA:Root2{name:'A'}),
       (rootB:Root2{name:'B'})
CALL apoc.path.subgraphAll(rootA, {relationshipFilter:'LINK>'})
YIELD nodes, relationships
CALL apoc.refactor.cloneSubgraph(
    nodes,
    [rel in relationships WHERE type(rel) = 'LINK'],
    { standinNodes:[[rootA, rootB]] })
YIELD input, output, error
RETURN input, output, error
The resulting graph will be the same as that returned in the previous example, where apoc.refactor.cloneSubgraphFromPaths() was called.
Clone nodes
Collapse nodes to relationships
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/clone-nodes;"Clone nodes
Contents
Procedure for cloning nodes and relationships
Examples
Clone nodes only
Clone nodes and constraints
Skipping properties on cloned nodes
The APOC library contains a procedure that can be used to clone nodes.
Procedure for cloning nodes and relationships
Qualified Name Type
apoc.refactor.cloneNodes
apoc.refactor.cloneNodes(nodes [Node], withRelationships Boolean, skipProperties [String]) - clones the given nodes with their labels and properties. It is possible to skip any node properties using skipProperties (note: this only skips properties on nodes and not their relationships).
Procedure
Examples
The examples below will explain this procedure in more detail.
Clone nodes only
Cypher
The following creates a graph with two nodes, Foo and Bar:
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo{name:'Foo'}),(b:Bar{name:'Bar'})
Cypher
The following creates copies of both of these nodes:
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo{name:'Foo'}),(b:Bar{name:'Bar'})
CALL apoc.refactor.cloneNodes([f,b])
YIELD input, output, error
RETURN *
In the above query, input is the source node id, output is the node cloned, and error is the possible error message.
This query will result in the following graph:
Clone nodes and constraints
The below example will demonstrate what happens when apoc.refactor.cloneNodes is called using nodes with constraints on them.
Cypher
The following creates a property constraint for all nodes with a specific label
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT ON (n:UniqueLabel) ASSERT n.key IS UNIQUE
Cypher
The following creates a node with a key property set to 1
Copy to Clipboard
Run in Neo4j Browser
CREATE (:UniqueLabel {key: 1})
Cypher
The following attempts to clone the node with a constraint on it
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:UniqueLabel)
CALL apoc.refactor.cloneNodes([n])
YIELD error, output
RETURN error, output
The result of the above query will result in an error because of the uniqueness constraint placed on the original node.
Table 1. Results
error
output
""Node(<NNN>) already exists with label `UniqueLabel` and property `key` = 1""
null
Skipping properties on cloned nodes
It is possible to exclude propertes when cloning nodes. This is done by specifying the skipProperties list in the parameter.
In the below example, the age property of the original node is skipped in the cloned node.
Cypher
The following creates a node
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo{name:'Bar', surname: 'Baz', age: 66})
Cypher
The following clones the node, skipping its age property
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Foo)
CALL apoc.refactor.cloneNodes([n], false, [""age""])
YIELD output
RETURN properties(output) AS props
Table 2. Results
props
{ ""surname"": ""Baz"", ""name"": ""Bar"" }
Categorize
Clone subgraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/categorize;"Categorize
Contents
Procedure to create category nodes
Example
The APOC library contains a procedure that replaces string property values on nodes with a relationship with a unique category node for that property value.
Procedure to create category nodes
Qualified Name Type
apoc.refactor.categorize
apoc.refactor.categorize(sourceKey String, type String, outgoing Boolean, label String, targetKey String, copiedKeys [String], batchSize Integer) - creates new category nodes from nodes in the graph with the specified sourceKey as one of its property keys. The new category nodes are then connected to the original nodes with a relationship of the given type.
Procedure
Example
The below example will explain this procedure in more detail.
Cypher
The following creates nodes with a favoriteColor property:
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Mark"", favoriteColor: ""Red""})
CREATE (:Person {name: ""Jennifer"", favoriteColor: ""Blue""})
CREATE (:Person {name: ""David"", favoriteColor: ""Red""})
In order to run this procedure, a unique constraint must exist on the new node label. In this case:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT ON (n:Color) ASSERT n.Color IS UNIQUE
Cypher
The following turns all favoriteColor properties into FAVORITE_COLOR relationships to Color nodes with a matching color property.
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.refactor.categorize('favoriteColor', 'FAVORITE_COLOR', true, 'Color', 'color', [], 100)
The above query will return the following graph:
Graph Refactoring
Clone nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring;"Graph Refactoring
The APOC library contains procedures that can be used for graph refactoring. For more information on how to use these procedures, see:
Categorize
Clone nodes
Clone subgraph
Collapse nodes to relationships
Extract node from relationships
Invert relationships
Merge nodes
Normalize as boolean
Property value to a label
Redirect relationships
Rename labels, types, and properties
Set relationship types
Export to GraphML
Categorize
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-refactoring/set-relationship-type;"Set relationship types
Contents
Procedure for changing relationship types
Example
The APOC library contains a procedure that can be used to change relationship types.
Procedure for changing relationship types
Qualified Name Type
apoc.refactor.setType
apoc.refactor.setType(rel Rel, newType String) - changes the type of the given relationship.
Procedure
Example
The below example will further explain this procedure.
Cypher
The following creates a graph containing two nodes connected by a relationship:
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo)-[rel:FOOBAR]->(b:Bar)
Cypher
The following changes the relationship type from FOOBAR to NEW-TYPE
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo)-[rel:FOOBAR]->(b:Bar)
CALL apoc.refactor.setType(rel, 'NEW-TYPE')
YIELD input, output
RETURN input, output
If the above query is run, it will result in the following graph:
Rename labels, types, and properties
Graph updates
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates;"Graph updates
The APOC library adds functionality for updating a graph. For more information on how to use these procedures, see:
Atomic property updates
Creating data
Deleting data
Locks
Periodic execution
Set relationship types
Creating data
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-updates/periodic-execution;"Periodic execution
Contents
Functions for batch transactions
Periodic Iterate
Periodic Iterate Examples
Periodic Commit
Progress logs
The APOC library contains procedures that can be used to batch transactions when executing large write operations.
Functions for batch transactions
Qualified Name Type
apoc.periodic.commit
apoc.periodic.commit(statement String, params Map<String, Any>) - runs the given statement in separate batched transactions.
Procedure
apoc.periodic.iterate
apoc.periodic.iterate(cypherIterate String, cypherAction String, config Map<String, Any>) - runs the second statement for each item returned by the first statement. This procedure returns the number of batches and the total number of processed rows.
Procedure
Periodic Iterate
The apoc.periodic.iterate procedure is helpful when you need to handle large amounts of data for import, refactoring, and other cases that require large transactions. It provides a way to batch the data by dividing the workload into two parts:
a data-driven statement
This defines how you select what data needs handled. You can provide a Cypher statement to select from existing graph data, read external data from a file or API, or retrieve data from another datastore.
an operation statement
This defines what you want done to the selected data. You can do things like execute Cypher for updating or creating/deleting the data or run other procedures to manipulate and transform values before loading.
The data-driven statement is provided as the first statement that results in a stream of values to be processed. The operation statement is provided as the second statement to process one element at a time or (with batchMode: ""BATCH"") a batch at a time. The results of the data-driven statement are passed to the operation statement as parameters, so they are automatically made available with their names.
Table 1. Config
name type default description
batchSize
Long
10000
run the specified number of operation statements in a single tx - params: {_count, _batch}
parallel
boolean
false
run operation statements in parallel (note that statements might deadlock if conflicting)
Please note that, in case of parallel: false, APOC is designed to reuse the same java.util.concurrent.ThreadPoolExecutor with a maximum pool size equal 1, in order to prevent parallelism; this means that if you want to execute multiple apoc.periodic.iterate each one will be executed when the previous one has been completed. Instead, with parallel: true, APOC will use a ThreadPoolExecutor with a configurable maximum pool size via the apoc.jobs.pool.num_threads config or as default with the number of available processor * 2. Therefore, if we execute multiple apoc.periodic.iterate each one will be executed in parallel if the queue pool size can accept new tasks. Furthermore, to be noted that running in parallel affects all databases, and not the single database you are using. So with e.g. 2 databases db1 and db2, the apoc.periodic.iterate on db1 will impact on performance if we execute an apoc.periodic.iterate on db2.
retries
Long
0
if the operation statement fails with an error, sleep 100ms and retry until retries-count is reached - param {_retry}
batchMode
String
""BATCH""
how data-driven statements should be processed by operation statement. Valid values are:
""BATCH"" - execute operation statement once per batchSize. Operation statement is prefixed with the following, which extracts each field returned in the data-driven statement from the $_batch parameter:
UNWIND $_batch AS _batch
WITH _batch.field1 AS field1, _batch.field2 AS field2
""SINGLE"" - execute operation statement one at a time
""BATCH_SINGLE"" - execute operation statement once per batchSize, but leaves unpacking of batch to the operation statement. The operation query can access the batched values via the $_batch parameter.
params
Map
{}
externally pass in map of params
concurrency
Long
Number of processors available
number of concurrent tasks are generated when using parallel:true
failedParams
Long
-1
if set to a non-negative value, each failed batch up to failedParams parameter sets are returned in yield failedParams.
In APOC versions 4.0.0.11 and earlier, the iterateList config key was used to control the batching of values returned by the data-driven statement. This was replaced by batchMode in version 4.0.0.12. These config keys are treated as follows:
If batchMode is provided, its value takes precedence over iterateList
If batchMode is not provided and iterateList is provided, the value of iterateList will be translated as described in the table below.
If neither batchMode nor iterateList are provided, batchMode defaults to BATCH, which is the same as iterateList:true
Table 2. Deprecated Config
param default description
iterateList
true
execute operation statements once per batchSize (whole batchSize list is passed in as parameter {_batch})
A value of true is equivalent to batchMode: ""BATCH""
A value of false is equivalent to batchMode: ""SINGLE""
Periodic Iterate Examples
Let’s go through some examples.
If you were to add an :Actor label to several million :Person nodes, you could run the following code:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (p:Person) WHERE (p)-[:ACTED_IN]->() RETURN p"",
  ""SET p:Actor"",
  {batchSize:10000, parallel:true})
Let’s break down the parameters passed to the procedure:
Our first Cypher statement selects all the Person nodes with an ACTED_IN relationship to another node and returns those persons. This is the data-driven portion where we select the data that we want to change.
Our second Cypher statement sets the :Actor label on each of the Person nodes selected. This is the operation portion where we apply the change to the data from our first statement.
And finally, we specify any configuration we want the procedure to use. We have defined a batchSize of 10,000 and to run the statements in parallel.
Executing this procedure would take all of our Person nodes gathered in the first Cypher statement and update each of them with the second Cypher statement. It divides the work into batches - taking 10,000 Person nodes from the stream and updating them in a single transaction. If we have 30,000 Person nodes in our graph with an ACTED_IN relationship, then it would break this down into 3 batches.
Finally, it runs those in parallel, as updating node labels or properties do not conflict.
For more complex operations like updating or removing relationships, either do not use parallel: true OR make sure that you batch the work in a way that each subgraph of data is updated in one operation, such as by transferring the root objects. If you attempt complex operations, also enable retrying failed operations, e.g. with retries:3.
Now let us look at a more complex example.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (o:Order) WHERE o.date > '2016-10-13' RETURN o"",
  ""MATCH (o)-[:HAS_ITEM]->(i) WITH o, sum(i.value) as value SET o.value = value"",
  {batchSize:100, parallel:true})
Let’s break down the parameters passed to the procedure:
Our first Cypher statement selects all the Order nodes that have an order date greater than October 13, 2016 (first Cypher statement).
Our second Cypher statement takes those groups and finds the nodes that have a HAS_ITEM relationship to other nodes, then sums up the value of those items and sets that sum as a property (o.value) for the total order value.
Our configuration will batch those nodes into groups of 100 (batchSize:100) and run the batches in parallel for the second statement to process.
Batch mode: BATCH_SINGLE
If our operation statement calls a procedure that takes in a batch of values, we can use batchMode: ""BATCH_SINGLE"" to get access to a batch of values to pass to that procedure. When we use BATCH_SINGLE, the operation statement will have access to the $_batch parameter, which will contain a list of the fields returned in the data-driven statement.
For example, if the data driven statement is:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN 'mark' AS a, 'michael' AS b
UNION
RETURN 'jennifer' AS a, 'andrea' AS b
The contents of the $_batch variable passed to the operation statement would be:
Text
Copy to Clipboard
[
  {a: ""mark"", b: ""michael""},
  {a: ""jennifer"", b: ""andrea""}
]
Let’s see an example of this in action. We’ll start by creating some nodes:
Cypher
The following query creates 100,000 nodes with the label Person and property id
Copy to Clipboard
Run in Neo4j Browser
UNWIND range(1,100000) as id create (:Person {id: id})
We can delete these nodes using the apoc.nodes.delete procedure. See Deleting data.
This procedure takes in a list of nodes, which we can extract from the $_batch parameter.
Cypher
The following query streams all the Person nodes and deletes them in batches of 100
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  ""MATCH (p:Person) RETURN p"",
  // Extract `p` variable using list comprehension
  ""CALL apoc.nodes.delete([item in $_batch | item.p], size($_batch))"",
  {batchMode: ""BATCH_SINGLE"", batchSize: 100}
)
YIELD batch, operations;
The contents of the $_batch parameter that is used in the operation statement would be as follows:
Text
Copy to Clipboard
[
  {p: Node<1>},
  {p: Node<2>},
  ...
]
We can use a list comprehension to extract the p variable from each item in the list.
If we run this query, we’ll see the following output:
Table 3. Results
batch operations
{total: 1000, committed: 1000, failed: 0, errors: {}}
{total: 100000, committed: 100000, failed: 0, errors: {}}
Periodic Commit
Especially for graph processing it is useful to run a query repeatedly in separate transactions until it doesn’t process and generates any results anymore. So you can iterate in batches over elements that don’t fulfill a condition and update them so that they do afterwards.
as a safety net your statement used inside apoc.periodic.commit must contain a LIMIT clause.
The query is executed repeatedly in separate transactions until it returns 0.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.periodic.commit(
  ""match (user:User) WHERE user.city IS NOT NULL
   with user limit $limit
   MERGE (city:City {name:user.city})
   MERGE (user)-[:LIVES_IN]->(city)
   REMOVE user.city
   RETURN count(*)"",
  {limit:10000})
Table 4. Results
Updates Executions
2000000
200
Progress logs
To visualize the verbose progress log for apoc.periodic.iterate or apoc.periodic.commit, set dbms.logs.debug.level to DEBUG in neo4j.conf file.
In the below query, dbms.logs.debug.level has ben set to DEBUG.
Cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND range(1,100) AS x CREATE (:TestLog{bar:'TestLog_'+x});
CALL apoc.periodic.iterate('match (p:TestLog) return p', 'SET p.foo =p.bar REMOVE p.bar', {batchSize:10,parallel:true});
The following logs are returned:
None
Copy to Clipboard
2020-11-27 09:03:44.279+0000 INFO  Starting periodic iterate from `match (p:TestLog) return p` operation using iteration `SET p.foo =p.bar REMOVE p.bar` in separate thread with id: `fc8ff303-bfdd-49f0-a724-603f03b0da45`
2020-11-27 09:03:44.279+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.280+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 10 total
2020-11-27 09:03:44.280+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.280+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 20 total
2020-11-27 09:03:44.280+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.294+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 30 total
2020-11-27 09:03:44.294+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.295+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 40 total
2020-11-27 09:03:44.295+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.295+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 50 total
2020-11-27 09:03:44.297+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.298+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 60 total
2020-11-27 09:03:44.298+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.298+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 70 total
2020-11-27 09:03:44.298+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.298+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 80 total
2020-11-27 09:03:44.298+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.299+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 90 total
2020-11-27 09:03:44.299+0000 DEBUG Execute, in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, no 10 batch size
2020-11-27 09:03:44.300+0000 DEBUG Processed in periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45, 10 iterations of 100 total
2020-11-27 09:03:44.512+0000 DEBUG Terminated periodic iterate with id fc8ff303-bfdd-49f0-a724-603f03b0da45 with 100 executions
View all (8 more lines)
Creating data
Atomic property updates
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo/apoc.algo.aStarConfig;"apoc.algo.aStarConfig
Contents
Input parameters
Output parameters
Procedure
apoc.algo.aStarConfig(startNode Node, endNode Node, relTypesAndDirections String, config Map<String, Any>) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function. This procedure looks for weight, latitude and longitude properties in the config. == Signature
None
Copy to Clipboard
apoc.algo.aStarConfig(startNode :: NODE?, endNode :: NODE?, relationshipTypesAndDirections :: STRING?, config :: MAP?) :: (path :: PATH?, weight :: FLOAT?)
Input parameters
Name Type Default
startNode
NODE?
null
endNode
NODE?
null
relationshipTypesAndDirections
STRING?
null
config
MAP?
null
Output parameters
Name Type
path
PATH?
weight
FLOAT?
More documentation of apoc.algo.aStarConfig
apoc.algo.aStar
apoc.algo.allSimplePaths
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo/apoc.algo.aStar;"apoc.algo.aStar
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.algo.aStar(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, latPropertyName String, lonPropertyName String) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function.
Signature
None
Copy to Clipboard
apoc.algo.aStar(startNode :: NODE?, endNode :: NODE?, relationshipTypesAndDirections :: STRING?, weightPropertyName :: STRING?, latPropertyName :: STRING?, lonPropertyName :: STRING?) :: (path :: PATH?, weight :: FLOAT?)
Input parameters
Name Type Default
startNode
NODE?
null
endNode
NODE?
null
relationshipTypesAndDirections
STRING?
null
weightPropertyName
STRING?
null
latPropertyName
STRING?
null
lonPropertyName
STRING?
null
Output parameters
Name Type
path
PATH?
weight
FLOAT?
More documentation of apoc.algo.aStar
apoc.algo
apoc.algo.aStarConfig
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.algo;"apoc.algo
Qualified Name Type
apoc.algo.aStar
apoc.algo.aStar(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, latPropertyName String, lonPropertyName String) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function.
Procedure
apoc.algo.aStarConfig icon[book]
apoc.algo.aStarConfig(startNode Node, endNode Node, relTypesAndDirections String, config Map<String, Any>) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function. This procedure looks for weight, latitude and longitude properties in the config.
Procedure
apoc.algo.allSimplePaths
apoc.algo.allSimplePaths(startNode Node, endNode Node, relTypesAndDirections String, maxNodes Integer) - runs a search algorithm to find all of the simple paths between the given relationships, up to a max depth described by maxNodes. The returned paths will not contain loops.
Procedure
apoc.algo.cover
apoc.algo.cover(nodes Any) - returns all relationships between a given set of nodes.
Procedure
apoc.algo.dijkstra
apoc.algo.dijkstra(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, defaultWeight Float, numberOfWantedPaths Integer) - runs Dijkstra’s algorithm using the given relationship property as the cost function.
Procedure
apoc.agg.statistics
apoc.algo.aStar
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.statistics;"apoc.agg.statistics
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.statistics(value Number, percentiles [Float]) - returns the following statistics on the numerical values in the given collection: percentiles, min, minNonZero, max, total, mean, stdev.
Signature
None
Copy to Clipboard
apoc.agg.statistics(value :: NUMBER?, percentiles = [0.5, 0.75, 0.9, 0.95, 0.99] :: LIST? OF FLOAT?) :: (MAP?)
Input parameters
Name Type Default
value
NUMBER?
null
percentiles
LIST? OF FLOAT?
[0.5, 0.75, 0.9, 0.95, 0.99]
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TopGun:Movie {title:""Top Gun"", released:1986, tagline:'I feel the need, the need for speed.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})
CREATE (AsGoodAsItGets:Movie {title:'As Good as It Gets', released:1997, tagline:'A comedy from the heart that goes for the throat.'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (SnowFallingonCedars:Movie {title:'Snow Falling on Cedars', released:1999, tagline:'First loves last. Forever.'})
CREATE (JerryMaguire:Movie {title:'Jerry Maguire', released:2000, tagline:'The rest of his life begins now.'});
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
We can find the release year of movies for different statistical measures, by running the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
RETURN apoc.agg.statistics(movie.released) AS stats;
Table 1. Results
stats
{total: 10, min: 1986, minNonZero: 1986.0, max: 2003, mean: 1996.8, 0.5: 1997, 0.99: 2003, 0.75: 1999, 0.9: 2000, 0.95: 2003, stdev: 4.3772137256478585}
We can expand the map of values to have one key per row by using the UNWIND clause on the keys of the map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WITH apoc.agg.statistics(movie.released) AS stats
UNWIND keys(stats) AS key
RETURN key, stats[key] AS value;
Table 2. Results
key value
""total""
10
""min""
1986
""minNonZero""
1986.0
""max""
2003
""mean""
1996.8
""0.5""
1997
""0.99""
2003
""0.75""
1999
""0.9""
2000
""0.95""
2003
""stdev""
4.3772137256478585
By default, the function will return the 0.5, 0.75, 0.9, 0.95, and 0.99 percentiles, but we can pass in our own percentiles (2nd parameter):
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WITH apoc.agg.statistics(movie.released, [0.1, 0.25]) AS stats
UNWIND keys(stats) AS key
RETURN key, stats[key] AS value;
Table 3. Results
key value
""total""
10
""min""
1986
""minNonZero""
1986.0
""0.1""
1986
""max""
2003
""mean""
1996.8
""0.25""
1996
""stdev""
4.3772137256478585
apoc.agg.slice
apoc.algo
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.slice;"apoc.agg.slice
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.slice(value Any, from Integer, to Integer) - returns subset of non-null values from the given collection (the collection is considered to be zero-indexed). To specify the range from start until the end of the collection, the length should be set to -1.
Signature
None
Copy to Clipboard
apoc.agg.slice(value :: ANY?, from = 0 :: INTEGER?, to = -1 :: INTEGER?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
value
ANY?
null
from
INTEGER?
0
to
INTEGER?
-1
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas);
View all (9 more lines)
This function provides a more efficient way of getting values in a collection. For example, to find the earliest 3 movies that each person has acted in, we could write the following query:
Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, collect(movie)[0..3] AS movies;
This query collects all of the movies into memory, before returning the first three. We can avoid this build up of in memory state by using the apoc.agg.slice aggregation function, as shown below:
Cypher
apoc.agg.slice
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, apoc.agg.slice(movie, 0, 3) AS movies;
Table 1. Results
person movies
""Keanu Reeves""
[(:Movie {tagline: ""Evil has its winning ways"", title: ""The Devil’s Advocate"", released: 1997}), (:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Movie {tagline: ""Free your mind"", title: ""The Matrix Reloaded"", released: 2003})]
""Tom Hanks""
[(:Movie {tagline: ""What if someone you never met, someone you never saw, someone you never knew was the only someone for you?"", title: ""Sleepless in Seattle"", released: 1993}), (:Movie {tagline: ""In every life there comes a time when that thing you dream becomes that thing you do"", title: ""That Thing You Do"", released: 1996}), (:Movie {tagline: ""At odds in life… in love on-line."", title: ""You’ve Got Mail"", released: 1998})]
apoc.agg.product
apoc.agg.statistics
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.product;"apoc.agg.product
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.product(value Number) - returns the product of all non-null numerical values in the collection.
Signature
None
Copy to Clipboard
apoc.agg.product(number :: NUMBER?) :: (NUMBER?)
Input parameters
Name Type Default
number
NUMBER?
null
Usage examples
We can compute the product of rows of numeric values, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND range(1,10) AS value
RETURN apoc.agg.product(value),
       1*2*3*4*5*6*7*8*9*10 AS manualEquivalent;
Table 1. Results
apoc.agg.product(value) manualEquivalent
3628800
3628800
apoc.agg.percentiles
apoc.agg.slice
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.percentiles;"apoc.agg.percentiles
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.percentiles(value Number, percentiles [Float]) - returns the given percentiles over the range of numerical values in the given collection.
Signature
None
Copy to Clipboard
apoc.agg.percentiles(value :: NUMBER?, percentiles = [0.5, 0.75, 0.9, 0.95, 0.99] :: LIST? OF FLOAT?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
value
NUMBER?
null
percentiles
LIST? OF FLOAT?
[0.5, 0.75, 0.9, 0.95, 0.99]
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TopGun:Movie {title:""Top Gun"", released:1986, tagline:'I feel the need, the need for speed.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})
CREATE (AsGoodAsItGets:Movie {title:'As Good as It Gets', released:1997, tagline:'A comedy from the heart that goes for the throat.'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (SnowFallingonCedars:Movie {title:'Snow Falling on Cedars', released:1999, tagline:'First loves last. Forever.'})
CREATE (JerryMaguire:Movie {title:'Jerry Maguire', released:2000, tagline:'The rest of his life begins now.'});
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
We can find the release year of movies for different percentiles, by running the query below:
Cypher
apoc.agg.median
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
RETURN apoc.agg.percentiles(movie.released, [0.25, 0.5, 0.75, 1.0]) AS percentiles;
Table 1. Results
percentiles
[1996, 1997, 1999, 2003]
apoc.agg.nth
apoc.agg.product
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.nth;"apoc.agg.nth
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.nth(value Any, offset Integer) - returns the nth value in the given collection (to fetch the last item of an unknown length collection, -1 can be used).
Signature
None
Copy to Clipboard
apoc.agg.nth(value :: ANY?, value :: INTEGER?) :: (ANY?)
Input parameters
Name Type Default
value
ANY?
null
value
INTEGER?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixRevolutions)

CREATE (TomH)-[:ACTED_IN {roles:['Joe Fox']}]->(YouveGotMail)
CREATE (TomH)-[:ACTED_IN {roles:['Sam Baldwin']}]->(SleeplessInSeattle);
This function provides a more efficient way of getting the nth value in a collection. For example, to find the 2nd earliest movie that each person has acted in, we could write the following query:
Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, collect(movie)[1] AS nthMovie;
This query collects all of the movies into memory, before returning just the second one. We can avoid this build up of in memory state by using the apoc.agg.nth aggregation function, as shown below:
Cypher
apoc.agg.nth
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, apoc.agg.nth(movie, 1) AS nthMovie;
Table 1. Results
person nthMovie
""Keanu Reeves""
(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999})
""Tom Hanks""
(:Movie {tagline: ""In every life there comes a time when that thing you dream becomes that thing you do"", title: ""That Thing You Do"", released: 1996})
apoc.agg.minItems
apoc.agg.percentiles
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.minItems;"apoc.agg.minItems
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.minItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the minimum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Signature
None
Copy to Clipboard
apoc.agg.minItems(item :: ANY?, value :: ANY?, groupLimit = -1 :: INTEGER?) :: (ANY?)
Input parameters
Name Type Default
item
ANY?
null
value
ANY?
null
groupLimit
INTEGER?
-1
Usage examples
The examples in this section are based on the following sample graph of people and their dates of birth:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Tom Hanks"", dateOfBirth: date(""1956-07-09"")});
CREATE (:Person {name: ""Tom Cruise"", dateOfBirth: date(""1962-07-03"")});
CREATE (:Person {name: ""Nicole Kidman"", dateOfBirth: date(""1967-06-20"")});
CREATE (:Person {name: ""Matt Damon"", dateOfBirth: date(""1970-10-08"")});
CREATE (:Person {name: ""Carrie Fisher"", dateOfBirth: date(""1956-10-21"")});
CREATE (:Person {name: ""Bryan Cranston"", dateOfBirth: date(""1956-03-07"")});
You can collect the people that have the minimal year of birth by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH apoc.agg.minItems(p, p.dateOfBirth.year) AS minItems
RETURN minItems.value AS value, minItems.items AS items;
Table 1. Results
value items
1956
[(:Person {name: ""Tom Hanks"", dateOfBirth: 1956-07-09}), (:Person {name: ""Carrie Fisher"", dateOfBirth: 1956-10-21}), (:Person {name: ""Bryan Cranston"", dateOfBirth: 1956-03-07})]
You can set the groupLimit (3rd parameter) to set a limit on the number of items returned:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH apoc.agg.minItems(p, p.dateOfBirth.year, 2) AS minItems
RETURN minItems.value AS value, minItems.items AS items;
Table 2. Results
value items
1956
[(:Person {name: ""Tom Hanks"", dateOfBirth: 1956-07-09}), (:Person {name: ""Carrie Fisher"", dateOfBirth: 1956-10-21})]
apoc.agg.median
apoc.agg.nth
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.median;"apoc.agg.median
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.median(value Any) - returns the mathematical median for all non-null numeric values.
Signature
None
Copy to Clipboard
apoc.agg.median(value :: ANY?) :: (ANY?)
Input parameters
Name Type Default
value
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})

CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo);
View all (3 more lines)
We can find the median release year of the movies acted in by each person, by running the query below:
Cypher
apoc.agg.median
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
RETURN p.name AS person, apoc.agg.median(movie.released) AS medianReleaseYear;
Table 1. Results
person medianReleaseYear
""Keanu Reeves""
1999.0
""Tom Hanks""
1996.0
apoc.agg.maxItems
apoc.agg.minItems
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.maxItems;"apoc.agg.maxItems
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.maxItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the maximum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Signature
None
Copy to Clipboard
apoc.agg.maxItems(item :: ANY?, value :: ANY?, groupLimit = -1 :: INTEGER?) :: (ANY?)
Input parameters
Name Type Default
item
ANY?
null
value
ANY?
null
groupLimit
INTEGER?
-1
Usage examples
The examples in this section are based on the following sample graph of people and their dates of birth:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Christopher Nolan"", dateOfBirth: date(""1970-07-30"")});
CREATE (:Person {name: ""Tom Cruise"", dateOfBirth: date(""1962-07-03"")});
CREATE (:Person {name: ""Nicole Kidman"", dateOfBirth: date(""1967-06-20"")});
CREATE (:Person {name: ""Matt Damon"", dateOfBirth: date(""1970-10-08"")});
CREATE (:Person {name: ""Jennifer Connelly"", dateOfBirth: date(""1970-12-12"")});
You can collect the people that have the maximal year of birth by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH apoc.agg.maxItems(p, p.dateOfBirth.year) AS maxItems
RETURN maxItems.value AS value, maxItems.items AS items;
Table 1. Results
value items
1970
[(:Person {name: ""Christopher Nolan"", dateOfBirth: 1970-07-30}), (:Person {name: ""Matt Damon"", dateOfBirth: 1970-10-08}), (:Person {name: ""Jennifer Connelly"", dateOfBirth: 1970-12-12})]
You can set the groupLimit (3rd parameter) to set a limit on the number of items returned:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH apoc.agg.maxItems(p, p.dateOfBirth.year, 2) AS maxItems
RETURN maxItems.value AS value, maxItems.items AS items;
Table 2. Results
value items
1970
[(:Person {name: ""Christopher Nolan"", dateOfBirth: 1970-07-30}), (:Person {name: ""Matt Damon"", dateOfBirth: 1970-10-08})]
apoc.agg.last
apoc.agg.median
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.last;"apoc.agg.last
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.last(value Any) - returns the last value from the given collection.
Signature
None
Copy to Clipboard
apoc.agg.last(value :: ANY?) :: (ANY?)
Input parameters
Name Type Default
value
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixRevolutions)

CREATE (TomH)-[:ACTED_IN {roles:['Joe Fox']}]->(YouveGotMail)
CREATE (TomH)-[:ACTED_IN {roles:['Sam Baldwin']}]->(SleeplessInSeattle);
This function provides a more efficient way of getting the last value in a collection. For example, to find the newest movie that each person has acted in, we could write the following query:
Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, collect(movie)[-1] AS latestMovie;
This query collects all of the movies into memory, before returning just the last one. We can avoid this build up of in memory state by using the apoc.agg.last aggregation function, as shown below:
Cypher
apoc.agg.last
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, apoc.agg.last(movie) AS latestMovie;
Table 1. Results
person latestMovie
""Keanu Reeves""
(:Movie {title: ""Something’s Gotta Give"", released: 2003})
""Tom Hanks""
(:Movie {tagline: ""Everything is connected"", title: ""Cloud Atlas"", released: 2012})
apoc.agg.graph
apoc.agg.maxItems
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.graph;"apoc.agg.graph
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.graph(path Any) - returns all distinct nodes and relationships collected into a map with the keys nodes and relationships.
Signature
None
Copy to Clipboard
apoc.agg.graph(element :: ANY?) :: (MAP?)
Input parameters
Name Type Default
element
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})

CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo);
View all (3 more lines)
We can extract a sub graph of the movies that Keanu Reeves and Tom Hanks acted in before 1998, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (person:Person)-[:ACTED_IN]->(movie)
WHERE movie.released < 1998
WITH apoc.agg.graph(path) AS g
RETURN g.nodes AS nodes, g.relationships AS relationships;
Table 1. Results
nodes relationships
[(:Person {name: ""Keanu Reeves"", born: 1964}), (:Person {name: ""Tom Hanks"", born: 1956}), (:Movie {tagline: ""Evil has its winning ways"", title: ""The Devil’s Advocate"", released: 1997}), (:Movie {tagline: ""What if someone you never met, someone you never saw, someone you never knew was the only someone for you?"", title: ""Sleepless in Seattle"", released: 1993}), (:Movie {tagline: ""In every life there comes a time when that thing you dream becomes that thing you do"", title: ""That Thing You Do"", released: 1996})]
[[:ACTED_IN {roles: [""Neo""]}], [:ACTED_IN {roles: [""Sam Baldwin""]}], [:ACTED_IN {roles: [""Mr. White""]}]]
apoc.agg.first
apoc.agg.last
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg/apoc.agg.first;"apoc.agg.first
Contents
Signature
Input parameters
Usage examples
Function
apoc.agg.first(value Any) - returns the first value from the given collection.
Signature
None
Copy to Clipboard
apoc.agg.first(value :: ANY?) :: (ANY?)
Input parameters
Name Type Default
value
ANY?
null
Usage examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})

CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixReloaded)
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrixRevolutions)

CREATE (TomH)-[:ACTED_IN {roles:['Joe Fox']}]->(YouveGotMail)
CREATE (TomH)-[:ACTED_IN {roles:['Sam Baldwin']}]->(SleeplessInSeattle);
This function provides a more efficient way of getting the first value in a collection. For example, to find the earliest movie that each person has acted in, we could write the following query:
Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, collect(movie)[0] AS earliestMovie;
This query collects all of the movies into memory, before returning just the first one. We can avoid this build up of in memory state by using the apoc.agg.first aggregation function, as shown below:
Cypher
apoc.agg.first
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:ACTED_IN]->(movie)
WITH p, movie
ORDER BY p, movie.released
RETURN p.name AS person, apoc.agg.first(movie) AS earliestMovie;
Table 1. Results
person earliestMovie
""Tom Hanks""
(:Movie {tagline: ""What if someone you never met, someone you never saw, someone you never knew was the only someone for you?"", title: ""Sleepless in Seattle"", released: 1993})
""Keanu Reeves""
(:Movie {tagline: ""Evil has its winning ways"", title: ""The Devil’s Advocate"", released: 1997})
apoc.agg
apoc.agg.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.agg;"apoc.agg
Qualified Name Type
apoc.agg.first
apoc.agg.first(value Any) - returns the first value from the given collection.
Function
apoc.agg.graph
apoc.agg.graph(path Any) - returns all distinct nodes and relationships collected into a map with the keys nodes and relationships.
Function
apoc.agg.last
apoc.agg.last(value Any) - returns the last value from the given collection.
Function
apoc.agg.maxItems
apoc.agg.maxItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the maximum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Function
apoc.agg.median
apoc.agg.median(value Any) - returns the mathematical median for all non-null numeric values.
Function
apoc.agg.minItems
apoc.agg.minItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the minimum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Function
apoc.agg.nth
apoc.agg.nth(value Any, offset Integer) - returns the nth value in the given collection (to fetch the last item of an unknown length collection, -1 can be used).
Function
apoc.agg.percentiles
apoc.agg.percentiles(value Number, percentiles [Float]) - returns the given percentiles over the range of numerical values in the given collection.
Function
apoc.agg.product
apoc.agg.product(value Number) - returns the product of all non-null numerical values in the collection.
Function
apoc.agg.slice
apoc.agg.slice(value Any, from Integer, to Integer) - returns subset of non-null values from the given collection (the collection is considered to be zero-indexed). To specify the range from start until the end of the collection, the length should be set to -1.
Function
apoc.agg.statistics
apoc.agg.statistics(value Number, percentiles [Float]) - returns the following statistics on the numerical values in the given collection: percentiles, min, minNonZero, max, total, mean, stdev.
Function
apoc.version
apoc.agg.first
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc/apoc.version;"apoc.version
Contents
Signature
Usage examples
Function
apoc.version() - returns the APOC version currently installed.
Signature
None
Copy to Clipboard
apoc.version() :: (STRING?)
Usage examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.version() AS output;
Table 1. Results
output
""5.0.0-rc01""
apoc.when
apoc.agg
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc/apoc.when;"apoc.when
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - this procedure will run the read-only ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Signature
None
Copy to Clipboard
apoc.when(condition :: BOOLEAN?, ifQuery :: STRING?, elseQuery =  :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
condition
BOOLEAN?
null
ifQuery
STRING?
null
elseQuery
STRING?
params
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.when(false, 'RETURN 7 as b');
Table 1. Results
value
{}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.when(true, 'RETURN $a + 7 as b', 'RETURN $a as b',{a:3})
Table 2. Results
value
{b: 10}
More documentation of apoc.when
apoc.help
apoc.version
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc/apoc.help;"apoc.help
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.help() - returns descriptions of the available APOC procedures and functions. If a keyword is provided, it will return only those procedures and functions that have the keyword in their name.
Signature
None
Copy to Clipboard
apoc.help(proc :: STRING?) :: (type :: STRING?, name :: STRING?, text :: STRING?, signature :: STRING?, roles :: LIST? OF STRING?, writes :: BOOLEAN?, core :: BOOLEAN?)
Input parameters
Name Type Default
proc
STRING?
null
Output parameters
Name Type
type
STRING?
name
STRING?
text
STRING?
signature
STRING?
roles
LIST? OF STRING?
writes
BOOLEAN?
core
BOOLEAN?
apoc.case
apoc.when
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc/apoc.case;"apoc.case
Contents
Signature
Input parameters
Output parameters
Usage examples
Procedure
apoc.case(conditionals [Any], elseQuery String, params Map) - for each pair of conditional and read-only queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Signature
None
Copy to Clipboard
apoc.case(conditionals :: LIST? OF ANY?, elseQuery =  :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
conditionals
LIST? OF ANY?
null
elseQuery
STRING?
params
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.case([
  false, 'RETURN ""firstFalse"" as b',
  false, 'RETURN ""secondFalse"" as b',
  true, 'RETURN ""firstTrue"" as b'
]);
Table 1. Results
value
{b: ""firstTrue""}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.case([
  false, 'RETURN ""firstFalse"" as b',
  false, 'RETURN ""secondFalse"" as b',
  false, 'RETURN ""thirdFalse"" as b'
  ],
  'RETURN ""elseBranch"" as b'
);
Table 2. Results
value
{b: ""elseBranch""}
More documentation of apoc.case
apoc
apoc.help
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc;"apoc
Qualified Name Type
apoc.case
apoc.case(conditionals [Any], elseQuery String, params Map) - for each pair of conditional and read-only queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Procedure
apoc.help
apoc.help - apoc.help() - returns descriptions of the available APOC procedures and functions. If a keyword is provided, it will return only those procedures and functions that have the keyword in their name.
Procedure
apoc.when
apoc.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - this procedure will run the read-only ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Procedure
apoc.version
apoc.version() - returns the APOC version currently installed.
Function
Procedures & Functions
apoc.case
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview;"Procedures & Functions
Contents
apoc
apoc.agg
apoc.algo
apoc.any
apoc.atomic
apoc.bitwise
apoc.coll
apoc.convert
apoc.create
apoc.cypher
apoc.data
apoc.date
apoc.diff
apoc.do
apoc.example
apoc.export
apoc.graph
apoc.hashing
apoc.import
apoc.json
apoc.label
apoc.load
apoc.lock
apoc.log
apoc.map
apoc.math
apoc.merge
apoc.meta
apoc.neighbors
apoc.node
apoc.nodes
apoc.number
apoc.path
apoc.periodic
apoc.refactor
apoc.rel
apoc.schema
apoc.scoring
apoc.search
apoc.spatial
apoc.stats
apoc.temporal
apoc.text
apoc.trigger
apoc.util
apoc.warmup
apoc.xml
This is the page for APOC Core documentation. For APOC Extended, go to the APOC Extended page.
apoc
Qualified Name Type
apoc.case
apoc.case(conditionals [Any], elseQuery String, params Map) - for each pair of conditional and read-only queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Procedure
apoc.help
apoc.help() - returns descriptions of the available APOC procedures and functions. If a keyword is provided, it will return only those procedures and functions that have the keyword in their name.
Procedure
apoc.version
apoc.version() - returns the APOC version currently installed.
Function
apoc.when
apoc.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - this procedure will run the read-only ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Procedure
apoc.agg
Qualified Name Type
apoc.agg.first
apoc.agg.first(value Any) - returns the first value from the given collection.
Function
apoc.agg.graph
apoc.agg.graph(path Any) - returns all distinct nodes and relationships collected into a map with the keys nodes and relationships.
Function
apoc.agg.last
apoc.agg.last(value Any) - returns the last value from the given collection.
Function
apoc.agg.maxItems
apoc.agg.maxItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the maximum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Function
apoc.agg.median
apoc.agg.median(value Any) - returns the mathematical median for all non-null numeric values.
Function
apoc.agg.minItems
apoc.agg.minItems(items Any, value Any, groupLimit Integer) - returns a map {items:[], value:n} where the value key is the minimum value present, and items represent all items with the same value. The size of the list of items can be limited to a given max size.
Function
apoc.agg.nth
apoc.agg.nth(value Any, offset Integer) - returns the nth value in the given collection (to fetch the last item of an unknown length collection, -1 can be used).
Function
apoc.agg.percentiles
apoc.agg.percentiles(value Number, percentiles [Float]) - returns the given percentiles over the range of numerical values in the given collection.
Function
apoc.agg.product
apoc.agg.product(value Number) - returns the product of all non-null numerical values in the collection.
Function
apoc.agg.slice
apoc.agg.slice(value Any, from Integer, to Integer) - returns subset of non-null values from the given collection (the collection is considered to be zero-indexed). To specify the range from start until the end of the collection, the length should be set to -1.
Function
apoc.agg.statistics
apoc.agg.statistics(value Number, percentiles [Float]) - returns the following statistics on the numerical values in the given collection: percentiles, min, minNonZero, max, total, mean, stdev.
Function
apoc.algo
Qualified Name Type
apoc.algo.aStar
apoc.algo.aStar(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, latPropertyName String, lonPropertyName String) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function.
Procedure
apoc.algo.aStarConfig
apoc.algo.aStarConfig(startNode Node, endNode Node, relTypesAndDirections String, config Map<String, Any>) - runs the A* search algorithm to find the optimal path between two nodes, using the given relationship property name for the cost function. This procedure looks for weight, latitude and longitude properties in the config.
Procedure
apoc.algo.allSimplePaths
apoc.algo.allSimplePaths(startNode Node, endNode Node, relTypesAndDirections String, maxNodes Integer) - runs a search algorithm to find all of the simple paths between the given relationships, up to a max depth described by maxNodes. The returned paths will not contain loops.
Procedure
apoc.algo.cover
apoc.algo.cover(nodes Any) - returns all relationships between a given set of nodes.
Procedure
apoc.algo.dijkstra
apoc.algo.dijkstra(startNode Node, endNode Node, relTypesAndDirections String, weightPropertyName String, defaultWeight Float, numberOfWantedPaths Integer) - runs Dijkstra’s algorithm using the given relationship property as the cost function.
Procedure
apoc.any
Qualified Name Type
apoc.any.isDeleted
apoc.any.isDeleted(object Any) - returns true if the given node or relationship no longer exists.
Function
apoc.any.properties
apoc.any.properties(object Any, keys [String]) - returns all properties of the given object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Function
apoc.any.property
apoc.any.property(object Any, key String) - returns the property for the given key from an object. The object can be a virtual node, a real node, a virtual relationship, a real relationship, or a map.
Function
apoc.atomic
Qualified Name Type
apoc.atomic.add
apoc.atomic.add(container Any, propertyName String, number Number, times Integer) - sets the given property to the sum of itself and the number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.concat
apoc.atomic.concat(container Any, propertyName String, string String, times Integer) - sets the given property to the concatenation of itself and the string value. The procedure then sets the property to the returned string.
Procedure
apoc.atomic.insert
apoc.atomic.insert(container Any, propertyName String, position Integer, value Any, times Integer) - inserts a value at position into the array value of a property. The procedure then sets the result back on the property.
Procedure
apoc.atomic.remove
apoc.atomic.remove(container Any, propertyName String, position Integer, times Integer) - removes the element at position from the array value of a property. The procedure then sets the property to the resulting array value.
Procedure
apoc.atomic.subtract
apoc.atomic.subtract(container Any, propertyName String, number Number, times Integer) - sets the property of a value to itself minus the given number value. The procedure then sets the property to the returned sum.
Procedure
apoc.atomic.update
apoc.atomic.update(container Any, propertyName String, operation String, times Integer) - updates the value of a property with a Cypher operation.
Procedure
apoc.bitwise
Qualified Name Type
apoc.bitwise.op
apoc.bitwise.op(a Integer, operator String, b Integer) - returns the result of the bitwise operation.
Function
apoc.coll
Qualified Name Type
apoc.coll.elements
apoc.coll.elements(coll [Any], limit Integer, offset Integer) - deconstructs a list of mixed types into identifiers indicating their specific type.
Procedure
apoc.coll.split
apoc.coll.split(coll [Any], value Any) - splits a collection by the given value. The value itself will not be part of the resulting lists.
Procedure
apoc.coll.zipToRows apoc.coll.zipToRows(list1 [Any], list2 [Any]) - returns the two lists zipped together, with one row per zipped pair.
Procedure
apoc.coll.avg
apoc.coll.avg(coll [Number]) - returns the average of the numbers in the list.
Function
apoc.coll.combinations
apoc.coll.combinations(coll [Any], minSelect Integer, maxSelect Integer) - returns a collection of all combinations of list elements between the selection size minSelect and maxSelect (default: minSelect).
Function
apoc.coll.contains
apoc.coll.contains(coll [Any], value Any) - returns whether or not the given value exists in the given collection (using a HashSet).
Function
apoc.coll.containsAll
apoc.coll.containsAll(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values exist in the given collection (using a HashSet).
Function
apoc.coll.containsAllSorted
apoc.coll.containsAllSorted(coll1 [Any], coll2 [Any]) - returns whether or not all of the given values in the second list exist in an already sorted collection (using a binary search).
Function
apoc.coll.containsDuplicates
apoc.coll.containsDuplicates(coll [Any]) - returns true if a collection contains duplicate elements.
Function
apoc.coll.containsSorted
apoc.coll.containsSorted(coll [Any], value Any) - returns whether or not the given value exists in an already sorted collection (using a binary search).
Function
apoc.coll.different
apoc.coll.different(coll [Any]) - returns true if any of the values in the given list are different.
Function
apoc.coll.disjunction
apoc.coll.disjunction(list1 [Any], list2[Any]) - returns the disjunct set of two lists.
Function
apoc.coll.dropDuplicateNeighbors
apoc.coll.dropDuplicateNeighbors(list [Any]) - removes duplicate consecutive objects in the list.
Function
apoc.coll.duplicates
apoc.coll.duplicates(coll [Any]) - returns a list of duplicate items in the collection.
Function
apoc.coll.duplicatesWithCount
apoc.coll.duplicatesWithCount(coll [Any]) - returns a list of duplicate items in the collection and their count, keyed by item and count.
Function
apoc.coll.fill
apoc.coll.fill(items String, count Integer) - returns a list with the given count of items.
Function
apoc.coll.flatten
apoc.coll.flatten(coll [Any], recursive Boolean) - flattens the given list (to flatten nested lists, set recursive to true).
Function
apoc.coll.frequencies
apoc.coll.frequencies(coll [Any]) - returns a list of frequencies of the items in the collection, keyed by item and count.
Function
apoc.coll.frequenciesAsMap
apoc.coll.frequenciesAsMap(coll [Any]) - returns a map of frequencies of the items in the collection, keyed by item and count.
Function
apoc.coll.indexOf
apoc.coll.indexOf(coll [Any], value Any) - returns the index for the first occurrence of the specified value in the list.
Function
apoc.coll.insert
apoc.coll.insert(coll [Any], index Integer, value Any) - inserts a value into the specified index in the list.
Function
apoc.coll.insertAll
apoc.coll.insertAll(coll [Any], index Integer, values [Any]) - inserts all of the values into the list, starting at the specified index.
Function
apoc.coll.intersection
apoc.coll.intersection(list1 [Any], list2[Any]) - returns the distinct intersection of two lists.
Function
apoc.coll.isEqualCollection
apoc.coll.isEqualCollection(coll [Any], values [Any]) - returns true if the two collections contain the same elements with the same cardinality in any order (using a HashMap).
Function
apoc.coll.max
apoc.coll.max(values [Any]) - returns the maximum of all values in the given list.
Function
apoc.coll.min
apoc.coll.min(values [Any]) - returns the minimum of all values in the given list.
Function
apoc.coll.occurrences
apoc.coll.occurrences(coll [Any], item Any) - returns the count of the given item in the collection.
Function
apoc.coll.pairs
apoc.coll.pairs(list [Any]) - returns a list of adjacent elements in the list ([1,2],[2,3],[3,null]).
Function
apoc.coll.pairsMin
apoc.coll.pairsMin(list [Any]) - returns lists of adjacent elements in the list ([1,2],[2,3]), skipping the final element.
Function
apoc.coll.pairWithOffset
apoc.coll.pairWithOffset(coll [Any], offset Integer) - returns a list of pairs defined by the offset.
Function
apoc.coll.partition
apoc.coll.partition(coll [Any], batchSize Integer) - partitions the original list into sub-lists of the given batch size. The final list may be smaller than the given batch size.
Function
apoc.coll.randomItem
apoc.coll.randomItem(coll [Any])- returns a random item from the list, or null on an empty or null list.
Function
apoc.coll.randomItems
apoc.coll.randomItems(coll [Any], itemCount Integer, allowRepick Boolean) - returns a list of itemCount random items from the original list (optionally allowing elements in the original list to be selected more than once).
Function
apoc.coll.remove
apoc.coll.remove(coll [Any], index Integer, length Integer) - removes a range of values from the list, beginning at position index for the given length of values.
Function
apoc.coll.removeAll
apoc.coll.removeAll(list1 [Any], list2 [Any]) - returns the first list with all elements of the second list removed.
Function
apoc.coll.runningTotal
apoc.coll.runningTotal(list [Number]) - returns an accumulative array.
Function
apoc.coll.set
apoc.coll.set(coll [Any], index Integer, value Any) - sets the element at the given index to the new value.
Function
apoc.coll.shuffle
apoc.coll.shuffle(coll [Any]) - returns the list shuffled.
Function
apoc.coll.sort
apoc.coll.sort(coll [Any]) - sorts the given list into ascending order.
Function
apoc.coll.sortMaps
apoc.coll.sortMaps(list [Map<String, Any>], prop String) - sorts the given list into ascending order, based on the map property indicated by prop.
Function
apoc.coll.sortMulti
apoc.coll.sortMulti(coll [Map<String, Any>], orderFields [String], limit Integer, skip Integer) - sorts the given list of maps by the given fields. To indicate that a field should be sorted according to ascending values, prefix it with a caret (^). It is also possible to add limits to the list and to skip values.
Function
apoc.coll.sortNodes
apoc.coll.sortNodes(coll [Node], prop String) - sorts the given list of nodes by their property into ascending order.
Function
apoc.coll.sortText
apoc.coll.sortText(coll [String], conf Map<String, Any>) - sorts the given list of strings into ascending order.
Function
apoc.coll.stdev
apoc.coll.stdev(list [Number], isBiasCorrected Boolean) - returns sample or population standard deviation with isBiasCorrected true or false respectively.
Function
apoc.coll.subtract
apoc.coll.subtract(list1 [Any], list2 [Any]) - returns the first list as a set with all the elements of the second list removed.
Function
apoc.coll.sum
apoc.coll.sum(coll [Number]) - returns the sum of all the numbers in the list.
Function
apoc.coll.sumLongs
apoc.coll.sumLongs(coll [Number]) - returns the sum of all the numbers in the list.
Function
apoc.coll.toSet
apoc.coll.toSet(coll [Any]) - returns a unique list from the given list.
Function
apoc.coll.union
apoc.coll.union(list1 [Any], list2 [Any]) - returns the distinct union of the two given lists.
Function
apoc.coll.unionAll
apoc.coll.unionAll(list1 [Any], list2 [Any]) - returns the full union of the two given lists (duplicates included).
Function
apoc.coll.zip
apoc.coll.zip(list1 [Any], list2 [Any]) - returns the two given lists zipped together as a list of lists.
Function
apoc.convert
Qualified Name Type
apoc.convert.setJsonProperty
apoc.convert.setJsonProperty(node Node, key String, value Any) - serializes the given JSON object and sets it as a property on the given node.
Procedure
apoc.convert.toTree
apoc.convert.toTree(paths [Path], lowerCaseRels Boolean, config Map<String, Any>) - returns a stream of maps, representing the given paths as a tree with at least one root.
Procedure
apoc.convert.fromJsonList
apoc.convert.fromJsonList(list [String], path String, pathOptions [String]) - converts the given JSON list into a Cypher list.
Function
apoc.convert.fromJsonMap
apoc.convert.fromJsonMap(map String, path String, pathOptions [String]) - converts the given JSON map into a Cypher map.
Function
apoc.convert.getJsonProperty
apoc.convert.getJsonProperty(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into the equivalent Cypher structure (e.g. map, list).
Function
apoc.convert.getJsonPropertyMap
apoc.convert.getJsonPropertyMap(node Node, key String, path String, pathOptions [String]) - converts a serialized JSON object from the property of the given node into a Cypher map.
Function
apoc.convert.toJson
apoc.convert.toJson(value Any) - serializes the given JSON value.
Function
apoc.convert.toList
apoc.convert.toList(value Any) - converts the given value into a list.
Function
apoc.convert.toMap
apoc.convert.toMap(map Any) - converts the given value into a map.
Function
apoc.convert.toNode
apoc.convert.toNode(node Any) - converts the given value into a node.
Function
apoc.convert.toNodeList
apoc.convert.toNodeList(list [Any]) - converts the given value into a list of nodes.
Function
apoc.convert.toRelationship
apoc.convert.toRelationship(rel Any) - converts the given value into a relationship.
Function
apoc.convert.toRelationshipList
apoc.convert.toRelationshipList(relList [Any]) - converts the given value into a list of relationships.
Function
apoc.convert.toSet
apoc.convert.toSet(list [Any]) - converts the given value into a set.
Function
apoc.convert.toSortedJsonMap
apoc.convert.toSortedJsonMap(value Any, ignoreCase Boolean) - converts a serialized JSON object from the property of a given node into a Cypher map.
Function
apoc.create
Qualified Name Type
apoc.create.addLabels
apoc.create.addLabels(nodes Any, labels [String]) - adds the given labels to the given nodes.
Procedure
apoc.create.clonePathToVirtual
apoc.create.clonePathToVirtual(path Path) - takes the given path and returns a virtual representation of it.
Procedure
apoc.create.clonePathsToVirtual
apoc.create.clonePathsToVirtual(paths [Path]) - takes the given paths and returns a virtual representation of them.
Procedure
apoc.create.node
apoc.create.node(labels [String], props Map<String, Any>) - creates a node with the given dynamic labels.
Procedure
apoc.create.nodes
apoc.create.nodes(labels [String], props [Map<String, Any>]) - creates nodes with the given dynamic labels.
Procedure
apoc.create.relationship
apoc.create.relationship(from Node, relType String, props Map<String, Any>, to Node) - creates a relationship with the given dynamic relationship type.
Procedure
apoc.create.removeLabels
apoc.create.removeLabels(nodes Any, labels [String]) - removes the given labels from the given node(s).
Procedure
apoc.create.removeProperties
apoc.create.removeProperties(nodes Any, keys [String]) - removes the given properties from the given node(s).
Procedure
apoc.create.removeRelProperties
apoc.create.removeRelProperties(rels Any, keys [String]) - removes the given properties from the given relationship(s).
Procedure
apoc.create.setLabels
apoc.create.setLabels(nodes Any, labels [String]) - sets the given labels to the given node(s). Non-matching labels are removed from the nodes.
Procedure
apoc.create.setProperties
apoc.create.setProperties(nodes Any, keys [String], values [Any]) - sets the given properties to the given node(s).
Procedure
apoc.create.setProperty
apoc.create.setProperty(nodes Any, key String, value [Any]) - sets the given property to the given node(s).
Procedure
apoc.create.setRelProperties
apoc.create.setRelProperties(rels Any, keys [String], values [Any]) - sets the given properties on the relationship(s).
Procedure
apoc.create.setRelProperty
apoc.create.setRelProperty(rels Any, key String, value Any) - sets the given property on the relationship(s).
Procedure
apoc.create.uuids
apoc.create.uuids(count Integer) - returns a stream of UUIDs.
Procedure
apoc.create.vNode
apoc.create.vNode(labels [String], props Map<String, Any>) - returns a virtual node.
Procedure
apoc.create.vNodes
apoc.create.vNodes(labels [String], props [Map<String, Any>]) - returns virtual nodes.
Procedure
apoc.create.vRelationship
apoc.create.vRelationship(from Node, relType String, props Map<String, Any>, to Node) - returns a virtual relationship.
Procedure
apoc.create.virtualPath
apoc.create.virtualPath(labelsN [String],n Map<String, Any>, relType String, props Map<String, Any>, labelsM [String], m Map<String, Any>) - returns a virtual path.
Procedure
apoc.create.uuid
apoc.create.uuid() - returns a UUID.
Function
apoc.create.uuidBase64
apoc.create.uuidBase64() - returns a UUID encoded with base64.
Function
apoc.create.uuidBase64ToHex
apoc.create.uuidBase64ToHex(base64Uuid String) - takes the given base64 encoded UUID and returns it as a hexadecimal string.
Function
apoc.create.uuidHexToBase64
apoc.create.uuidHexToBase64(uuid String) - takes the given UUID represented as a hexadecimal string and returns it encoded with base64.
Function
apoc.create.virtual.fromNode
apoc.create.virtual.fromNode(node Node, propertyNames [String]) - returns a virtual node from the given existing node. The virtual node only contains the requested properties.
Function
apoc.create.vNode
apoc.create.vNode(labels [String], props Map<String, Any>) - returns a virtual node.
Function
apoc.create.vRelationship
apoc.create.vRelationship(from Node, relType String, props Map<String, Any>, to Node) - returns a virtual relationship.
Function
apoc.cypher
Qualified Name Type
apoc.cypher.doIt
apoc.cypher.doIt(statement String, params Map<String, Any>) - runs a dynamically constructed string with the given parameters. This procedure allows for both read and write statements.
Procedure
apoc.cypher.run
apoc.cypher.run(statement String, params Map<String, Any>) - runs a dynamically constructed read-only string with the given parameters.
Procedure
apoc.cypher.runMany
apoc.cypher.runMany(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated statement and returns a summary of the statement outcomes.
Procedure
apoc.cypher.runManyReadOnly
apoc.cypher.runManyReadOnly(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated read-only statement and returns a summary of the statement outcomes.
Procedure
apoc.cypher.runSchema
apoc.cypher.runSchema(statement String, params Map<String, Any>) - runs the given query schema statement with the given parameters.
Procedure
apoc.cypher.runTimeboxed
apoc.cypher.runTimeboxed(statement String, params Map<String, Any>, timeout Integer) - terminates a Cypher statement if it has not finished before the set timeout (ms).
Procedure
apoc.cypher.runWrite
apoc.cypher.runWrite(statement String, params Map<String, Any>) - alias for apoc.cypher.doIt.
Procedure
apoc.cypher.runFirstColumnMany
apoc.cypher.runFirstColumnMany(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first column collected into a list.
Function
apoc.cypher.runFirstColumnSingle
apoc.cypher.runFirstColumnSingle(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first element of the first column.
Function
apoc.data
Qualified Name Type
apoc.data.url
apoc.data.url(url String) - turns a URL into a map.
Function
apoc.date
Qualified Name Type
apoc.date.add
apoc.date.add(time Long, unit String, addValue Integer, addUnit String) - adds a unit of specified time to the given timestamp.
Function
apoc.date.convert
apoc.date.convert(time Long, unit String, toUnit String) - converts the given timestamp from one time unit into a timestamp of a different time unit.
Function
apoc.date.convertFormat
apoc.date.convertFormat(temporal String, currentFormat String, convertTo String) - converts a string of one type of date format into a string of another type of date format.
Function
apoc.date.currentTimestamp
apoc.date.currentTimestamp() - returns the current Unix epoch timestamp in milliseconds.
Function
apoc.date.field
apoc.date.field(time Long, unit String, timezone String) - returns the value of one field from the given date time.
Function
apoc.date.fields
apoc.date.fields(date String, pattern String) - splits the given date into fields returning a map containing the values of each field.
Function
apoc.date.format
apoc.date.format(time Long, unit String, format String, timezone String) - returns a string representation of the time value. The time unit (default: ms), date format (default: ISO), and time zone (default: current time zone) can all be changed.
Function
apoc.date.fromISO8601
apoc.date.fromISO8601(time String) - converts the given date string (ISO8601) to an integer representing the time value in milliseconds.
Function
apoc.date.parse
apoc.date.parse(time String, unit String, format String, timezone String) - parses the given date string from a specified format into the specified time unit.
Function
apoc.date.systemTimezone
apoc.date.systemTimezone() - returns the display name of the system time zone (e.g. Europe/London).
Function
apoc.date.toISO8601
apoc.date.toISO8601(time Long, unit String) - returns a string representation of a specified time value in the ISO8601 format.
Function
apoc.date.toYears
apoc.date.toYears(value Any, format String) - converts the given timestamp or the given date into a floating point representing years.
Function
apoc.diff
Qualified Name Type
apoc.diff.nodes
apoc.diff.nodes(leftNode Node, rightNode Node) - returns a list detailing the differences between the two given nodes.
Function
apoc.do
Qualified Name Type
apoc.do.case
apoc.do.case(conditionals [Any], elseQuery String, params Map<String, Any>) - for each pair of conditional queries in the given list, this procedure will run the first query for which the conditional is evaluated to true. If none of the conditionals are true, the ELSE query will run instead.
Procedure
apoc.do.when
apoc.do.when(condition Boolean, ifQuery String, elseQuery String, params Map<String, Any>) - runs the given read/write ifQuery if the conditional has evaluated to true, otherwise the elseQuery will run.
Procedure
apoc.example
Qualified Name Type
apoc.example.movies
apoc.example.movies()- seeds the database with the Neo4j movie dataset.
Procedure
apoc.export
Qualified Name Type
apoc.export.arrow.all
apoc.export.arrow.all(file String, config Map<String, Any>) - exports the full database as an arrow file.
Procedure
apoc.export.arrow.graph
apoc.export.arrow.graph(file String, graph Any, config Map<String, Any>) - exports the given graph as an arrow file.
Procedure
apoc.export.arrow.query
apoc.export.arrow.query(file String, query String, config Map<String, Any>) - exports the results from the given Cypher query as an arrow file.
Procedure
apoc.export.arrow.stream.all
apoc.export.arrow.stream.all(config Map<String, Any>) - exports the full database as an arrow byte array.
Procedure
apoc.export.arrow.stream.graph
apoc.export.arrow.stream.graph(graph Any, config Map<String, Any>) - exports the given graph as an arrow byte array.
Procedure
apoc.export.arrow.stream.query
apoc.export.arrow.stream.query(query String, config Map<String, Any>) - exports the given Cypher query as an arrow byte array.
Procedure
apoc.export.csv.all
apoc.export.csv.all(file String, config Map<String, Any>) - exports the full database to the provided CSV file.
Procedure
apoc.export.csv.data
apoc.export.csv.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided CSV file.
Procedure
apoc.export.csv.graph
apoc.export.csv.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided CSV file.
Procedure
apoc.export.csv.query
apoc.export.csv.query(query String, file String, config Map<String, Any>) - exports the results from running the given Cypher query to the provided CSV file.
Procedure
apoc.export.cypher.all
apoc.export.cypher.all(file String, config Map<String, Any>) - exports the full database (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.data
apoc.export.cypher.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.graph
apoc.export.cypher.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.query
apoc.export.cypher.query(statement String, file String, config Map<String, Any>) - exports the nodes and relationships from the given Cypher query (incl. indexes) as Cypher statements to the provided file (default: Cypher Shell).
Procedure
apoc.export.cypher.schema
apoc.export.cypher.schema(file String, config Map<String, Any>) - exports all schema indexes and constraints to Cypher statements.
Procedure
apoc.export.graphml.all
apoc.export.graphml.all(file String, config Map<String, Any>) - exports the full database to the provided GraphML file.
Procedure
apoc.export.graphml.data
apoc.export.graphml.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided GraphML file.
Procedure
apoc.export.graphml.graph
apoc.export.graphml.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided GraphML file.
Procedure
apoc.export.graphml.query
apoc.export.graphml.query(statement String, file String, config Map<String, Any>) - exports the given nodes and relationships from the Cypher statement to the provided GraphML file.
Procedure
apoc.export.json.all
apoc.export.json.all(file String, config Map<String, Any>) - exports the full database to the provided JSON file.
Procedure
apoc.export.json.data
apoc.export.json.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided JSON file.
Procedure
apoc.export.json.graph
apoc.export.json.graph(graph Map<String, Any>, file String , config Map<String, Any>) - exports the given graph to the provided JSON file.
Procedure
apoc.export.json.query
apoc.export.json.query(statement String, file String, config Map<String, Any>) - exports the results from the Cypher statement to the provided JSON file.
Procedure
apoc.graph
Qualified Name Type
apoc.graph.from
apoc.graph.from(data Any, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Procedure
apoc.graph.fromCypher
apoc.graph.fromCypher(statement String, params Map<String, Any>, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given Cypher statement.
Procedure
apoc.graph.fromData
apoc.graph.fromData(nodes [Node], rels [Rel], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Procedure
apoc.graph.fromDB
apoc.graph.fromDB(name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given database.
Procedure
apoc.graph.fromDocument
apoc.graph.fromDocument(json Any, config Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given JSON file.
Procedure
apoc.graph.fromPath
apoc.graph.fromPath(path Path, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given path.
Procedure
apoc.graph.fromPaths
apoc.graph.fromPaths(paths [Path], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given paths.
Procedure
apoc.graph.validateDocument
apoc.graph.validateDocument(json Any, config Map<String, Any>) - validates the JSON file and returns the result of the validation.
Procedure
apoc.hashing
Qualified Name Type
apoc.hashing.fingerprint
apoc.hashing.fingerprint(object Any, excludedPropertyKeys [String]) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unsuitable for cryptographic use-cases.
Function
apoc.hashing.fingerprinting
apoc.hashing.fingerprinting(object Any, config Map<String, Any>) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unlike apoc.hashing.fingerprint(), this function supports a number of config parameters. Unsuitable for cryptographic use-cases.
Function
apoc.hashing.fingerprintGraph
apoc.hashing.fingerprintGraph(propertyExcludes [String]) - calculates a MD5 checksum over the full graph. This function uses in-memory data structures. Unsuitable for cryptographic use-cases.
Function
apoc.import
Qualified Name Type
apoc.import.csv
apoc.import.csv(nodes [Map<String, Any>], rels [Map<String, Any>], config Map<String, Any>) - imports nodes and relationships with the given labels and types from the provided CSV file.
Procedure
apoc.import.graphml
apoc.import.graphml(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided GraphML file.
Procedure
apoc.import.json
apoc.import.json(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided JSON file.
Procedure
apoc.import.xml
apoc.import.xml(urlOrBinary Any, config Map<String, Any>) - imports a graph from the provided XML file.
Procedure
apoc.json
Qualified Name Type
apoc.json.path
apoc.json.path(json String, path String, pathOptions [String]) - returns the given JSON path.
Function
apoc.label
Qualified Name Type
apoc.label.exists
apoc.label.exists(node Any, label String) - returns true or false depending on whether or not the given label exists.
Function
apoc.load
Qualified Name Type
apoc.load.arrow
apoc.load.arrow(file String, config Map<String, Any>) - imports nodes and relationships from the provided arrow file.
Procedure
apoc.load.arrow.stream
apoc.load.arrow.stream(source ByteArray, config Map<String, Any>) - imports nodes and relationships from the provided arrow byte array.
Procedure
apoc.load.json
apoc.load.json(urlOrKeyOrBinary Any, path String, config Map<String, Any>) - imports JSON file as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead.
Procedure
apoc.load.jsonArray
apoc.load.jsonArray(url String, path String, config Map<String, Any>) - loads array from a JSON URL (e.g. web-API) to then import the given JSON file as a stream of values.
Procedure
apoc.load.jsonParams
apoc.load.jsonParams(urlOrKeyOrBinary Any, headers Map<String, Any>, payload String, path String, config Map<String, Any>) - loads parameters from a JSON URL (e.g. web-API) as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead.
Procedure
apoc.load.xml
apoc.load.xml(urlOrBinary Any, path String, config Map<String, Any>, simple Boolean) - loads a single nested map from an XML URL (e.g. web-API).
Procedure
apoc.lock
Qualified Name Type
apoc.lock.all
apoc.lock.all(nodes [Node], rels [Rel]) - acquires a write lock on the given nodes and relationships.
Procedure
apoc.lock.nodes
apoc.lock.nodes(nodes [Node]) - acquires a write lock on the given nodes.
Procedure
apoc.lock.read.nodes
apoc.lock.read.nodes(nodes [Node]) - acquires a read lock on the given nodes.
Procedure
apoc.lock.read.rels
apoc.lock.read.rels(rels [Rel]) - acquires a read lock on the given relationships.
Procedure
apoc.lock.rels
apoc.lock.rels(rels [Rels]) - acquires a write lock on the given relationships.
Procedure
apoc.log
Qualified Name Type
apoc.log.stream
apoc.log.stream(path String, config Map<String, Any>) - returns the file contents from the given log, optionally returning only the last n lines. This procedure requires users to have an admin role.
Procedure
apoc.map
Qualified Name Type
apoc.map.clean
apoc.map.clean(map Map<String, Any>, keys [String], values [Any]) - filters the keys and values contained in the given lists.
Function
apoc.map.flatten
apoc.map.flatten(map Map<String, Any>, delimiter String) - flattens nested items in the given map. This function is the reverse of the apoc.map.unflatten function.
Function
apoc.map.fromLists
apoc.map.fromLists(keys [String], values [Any]) - creates a map from the keys and values in the given lists.
Function
apoc.map.fromNodes
apoc.map.fromNodes(label String, prop String) - returns a map of the given prop to the node of the given label.
Function
apoc.map.fromPairs
apoc.map.fromPairs(pairs [[key Any, value Any]]) - creates a map from the given list of key-value pairs.
Function
apoc.map.fromValues
apoc.map.fromValues(values [Any]) - creates a map from the alternating keys and values in the given list.
Function
apoc.map.get
apoc.map.get(map Map<String, Any>, key String, value Any, fail Boolean) - returns a value for the given key. If the given key does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.groupBy
apoc.map.groupBy(values [Any], key String) - creates a map of the list keyed by the given property, with single values.
Function
apoc.map.groupByMulti
apoc.map.groupByMulti(values [Any], key String) - creates a map of the lists keyed by the given property, with the list values.
Function
apoc.map.merge
apoc.map.merge(map1 Map<String, Any>, map2 Map<String, Any>) - merges the two given maps into one map.
Function
apoc.map.mergeList
apoc.map.mergeList(maps [Map<String, Value>]) - merges all maps in the given list into one map.
Function
apoc.map.mget
apoc.map.mget(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a list of values for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.removeKey
apoc.map.removeKey(map Map<String, Any>, key String, config Map<String, Any>) - removes the given key from the map (recursively if recursive is true).
Function
apoc.map.removeKeys
apoc.map.removeKeys(map Map<String, Any>, keys [String], config Map<String, Any>) - removes the given keys from the map (recursively if recursive is true).
Function
apoc.map.setEntry
apoc.map.setEntry(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Function
apoc.map.setKey
apoc.map.setKey(map Map<String, Any>, key String, value Any) - adds or updates the given entry in the map.
Function
apoc.map.setLists
apoc.map.setLists(map Map<String, Any>, keys [String], values [Any]) - adds or updates the given keys/value pairs provided in list format (e.g. [key1, key2],[value1, value2]) in a map.
Function
apoc.map.setPairs
apoc.map.setPairs(map Map<String, Any>, pairs [[key Any, value Any]]) - adds or updates the given key/value pairs (e.g. [key1,value1],[key2,value2]) in a map.
Function
apoc.map.setValues
apoc.map.setValues(map Map<String, Any>, pairs [key Any, value Any]) - adds or updates the alternating key/value pairs (e.g. [key1,value1,key2,value2]) in a map.
Function
apoc.map.sortedProperties
apoc.map.sortedProperties(map Map<String, Any>, ignoreCase Boolean) - returns a list of key/value pairs. The pairs are sorted by alphabetically by key, with optional case sensitivity.
Function
apoc.map.submap
apoc.map.submap(map Map<String, Any>, keys [String], values [Any], fail Boolean) - returns a sub-map for the given keys. If one of the keys does not exist, or lacks a default value, this function will throw an exception.
Function
apoc.map.unflatten
apoc.map.unflatten(map Map<String, Any>, delimiter String) - unflattens items in the given map to nested items. This function is the reverse of the apoc.map.flatten function.
Function
apoc.map.updateTree
apoc.map.updateTree(tree Map<String, Any>, key String, data [[key Any, value Any]])- adds the data map on each level of the nested tree, where the key-value pairs match.
Function
apoc.map.values
apoc.map.values(map Map<String, Any>, keys [String], addNullsForMissing Boolean) - returns a list of values indicated by the given keys (returns a null value if a given key is missing).
Function
apoc.math
Qualified Name Type
apoc.math.regr
apoc.math.regr(label String, propertyY String, propertyX String) - returns the coefficient of determination (R-squared) for the values of propertyY and propertyX in the given label.
Procedure
apoc.math.cosh
apoc.math.cosh(value Float) - returns the hyperbolic cosine.
Function
apoc.math.coth
apoc.math.coth(value Float) - returns the hyperbolic cotangent.
Function
apoc.math.csch
apoc.math.csch(value Float) - returns the hyperbolic cosecant.
Function
apoc.math.maxByte
apoc.math.maxByte() - returns the maximum value of a byte.
Function
apoc.math.maxDouble
apoc.math.maxDouble() - returns the largest positive finite value of type double.
Function
apoc.math.maxInt
apoc.math.maxInt() - returns the maximum value of an integer.
Function
apoc.math.maxLong
apoc.math.maxLong() - returns the maximum value of a long.
Function
apoc.math.minByte
apoc.math.minByte() - returns the minimum value of a byte.
Function
apoc.math.minDouble
apoc.math.minDouble() - returns the smallest positive non-zero value of type double.
Function
apoc.math.minInt
apoc.math.minInt() - returns the minimum value of an integer.
Function
apoc.math.minLong
apoc.math.minLong() - returns the minimum value of a long.
Function
apoc.math.sech
apoc.math.sech(value Float) - returns the hyperbolic secant of the given value.
Function
apoc.math.sigmoid
apoc.math.sigmoid(value Float) - returns the sigmoid of the given value.
Function
apoc.math.sigmoidPrime
apoc.math.sigmoidPrime(value Float) - returns the sigmoid prime [ sigmoid(val) * (1 - sigmoid(val)) ] of the given value.
Function
apoc.math.sinh
apoc.math.sinh(value Float) - returns the hyperbolic sine of the given value.
Function
apoc.math.tanh
apoc.math.tanh(value Float) - returns the hyperbolic tangent of the given value.
Function
apoc.merge
Qualified Name Type
apoc.merge.node
apoc.merge.node(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels.
Procedure
apoc.merge.node.eager
apoc.merge.node.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly.
Procedure
apoc.merge.nodeWithStats
apoc.merge.nodeWithStats(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels. Provides queryStatistics in the result.
Procedure
apoc.merge.nodeWithStats.eager
apoc.merge.nodeWithStats.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly. Provides queryStatistics in the result.
Procedure
apoc.merge.relationship
apoc.merge.relationship(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties.
Procedure
apoc.merge.relationship.eager
apoc.merge.relationship.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly.
Procedure
apoc.merge.relationshipWithStats
apoc.merge.relationshipWithStats(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties. Provides queryStatistics in the result.
Procedure
apoc.merge.relationshipWithStats.eager
apoc.merge.relationshipWithStats.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly. Provides queryStatistics in the result.
Procedure
apoc.meta
Qualified Name Type
apoc.meta.data
apoc.meta.data(config Map<String, Any>) - examines the full graph and returns a table of metadata.
Procedure
apoc.meta.data.of
apoc.meta.data.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a table of metadata.
Procedure
apoc.meta.graph
apoc.meta.graph(config Map<String, Any>) - examines the full graph and returns a meta-graph.
Procedure
apoc.meta.graph.of
apoc.meta.graph.of(graph Any, config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Procedure
apoc.meta.graphSample
apoc.meta.graphSample(config Map<String, Any>) - examines the full graph and returns a meta-graph. Unlike apoc.meta.graph, this procedure does not filter away non-existing paths.
Procedure
apoc.meta.nodeTypeProperties
apoc.meta.nodeTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the nodes therein.
Procedure
apoc.meta.relTypeProperties
apoc.meta.relTypeProperties(config Map<String, Any>) - examines the full graph and returns a table of metadata with information about the relationships therein.
Procedure
apoc.meta.schema
apoc.meta.schema(config Map<String, Any>) - examines the given sub-graph and returns metadata as a map.
Procedure
apoc.meta.stats
apoc.meta.stats() - returns the metadata stored in the transactional database statistics.
Procedure
apoc.meta.subGraph
apoc.meta.subGraph(config Map<String, Any>) - examines the given sub-graph and returns a meta-graph.
Procedure
apoc.meta.cypher.isType
apoc.meta.cypher.isType(value Any, type String) - returns true if the given value matches the given type.
Function
apoc.meta.cypher.type
apoc.meta.cypher.type(value Any) - returns the type name of the given value.
Function
apoc.meta.cypher.types
apoc.meta.cypher.types(props Any) - returns a map containing the type names of the given values.
Function
apoc.meta.nodes.count
apoc.meta.nodes.count(nodes [String], config Map<String, Any>) - returns the sum of the nodes with the given labels in the list.
Function
apoc.neighbors
Qualified Name Type
apoc.neighbors.athop
apoc.neighbors.athop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types at the specified distance.
Procedure
apoc.neighbors.athop.count
apoc.neighbors.athop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types at the specified distance.
Procedure
apoc.neighbors.byhop
apoc.neighbors.byhop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Returns lists of nodes, where each path of nodes represents one row of lists.
Procedure
apoc.neighbors.byhop.count
apoc.neighbors.byhop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationship types within the specified distance.
Procedure
apoc.neighbors.tohop
apoc.neighbors.tohop(node Node, relTypes String, distance Integer) - returns all nodes connected by the given relationship types within the specified distance. Nodes are returned individually for each row.
Procedure
apoc.neighbors.tohop.count
apoc.neighbors.tohop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationships in the pattern within the specified distance.
Procedure
apoc.node
Qualified Name Type
apoc.node.degree
apoc.node.degree(node Node, relTypes String) - returns the total degrees for the given node.
Function
apoc.node.degree.in
apoc.node.degree.in(node Node, relTypes String) - returns the total number of incoming relationships to the given node.
Function
apoc.node.degree.out
apoc.node.degree.out(node Node, relTypes String) - returns the total number of outgoing relationships from the given node.
Function
apoc.node.id
apoc.node.id(node Node) - returns the id for the given virtual node.
Function
apoc.node.labels
apoc.node.labels(node Node) - returns the labels for the given virtual node.
Function
apoc.node.relationship.exists
apoc.node.relationship.exists(node Node, relTypes String) - returns a boolean based on whether the given node has a relationship (or whether the given node has a relationship of the given type and direction).
Function
apoc.node.relationship.types
apoc.node.relationship.types(node Node, relTypes String) - returns a list of distinct relationship types for the given node.
Function
apoc.node.relationships.exist
apoc.node.relationships.exist(node Node, relTypes String) - returns a boolean based on whether the given node has relationships (or whether the given nodes has relationships of the given type and direction).
Function
apoc.nodes
Qualified Name Type
apoc.nodes.collapse
apoc.nodes.collapse(nodes [Node], config Map<String, Any>) - merges nodes together in the given list. The nodes are then combined to become one node, with all labels of the previous nodes attached to it, and all relationships pointing to it.
Procedure
apoc.nodes.cycles
apoc.nodes.cycles(nodes [Node], config Map<String, Any>) - detects all path cycles in the given node list. This procedure can be limited on relationships as well.
Procedure
apoc.nodes.delete
apoc.nodes.delete(nodes Any, batchSize Integer) - deletes all nodes with the given ids.
Procedure
apoc.nodes.get
apoc.nodes.get(nodes Any) - returns all nodes with the given ids.
Procedure
apoc.nodes.group
apoc.nodes.group(labels [String], groupByProperties [String], aggregations [Map<String, Any>], config Map<String, Any>) - allows for the aggregation of nodes based on the given properties. This procedure returns virtual nodes.
Procedure
apoc.nodes.link
apoc.nodes.link(nodes [Node], type String, config Map<String, Any>) - creates a linked list of the given nodes connected by the given relationship type.
Procedure
apoc.nodes.rels
apoc.nodes.rels(rels Any) - returns all relationships with the given ids.
Procedure
apoc.nodes.connected
apoc.nodes.connected(startNode Node, endNode Node, types String) - returns true when a given node is directly connected to another given node. This function is optimized for dense nodes.
Function
apoc.nodes.isDense
apoc.nodes.isDense(node Node) - returns true if the given node is a dense node.
Function
apoc.nodes.relationship.types
apoc.nodes.relationship.types(nodes Any, types String) - returns a list of distinct relationship types from the given list of nodes.
Function
apoc.nodes.relationships.exist
apoc.nodes.relationships.exist(nodes Any, types String) - returns a boolean based on whether or not the given nodes have the given relationships.
Function
apoc.number
Qualified Name Type
apoc.number.arabicToRoman
apoc.number.arabicToRoman(number Any) - converts the given Arabic numbers to Roman numbers.
Function
apoc.number.exact.add
apoc.number.exact.add(stringA String, stringB String) - returns the result of adding the two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.div
apoc.number.exact.div(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of dividing a given large number with another given large number (using Java BigDecimal).
Function
apoc.number.exact.mul
apoc.number.exact.mul(stringA String, stringB String, precision Integer, roundingMode String) - returns the result of multiplying two given large numbers (using Java BigDecimal).
Function
apoc.number.exact.sub
apoc.number.exact.sub(stringA String, stringB String) - returns the result of subtracting a given large number from another given large number (using Java BigDecimal).
Function
apoc.number.exact.toExact
apoc.number.exact.toExact(number Integer) - returns the exact value of the given number (using Java BigDecimal).
Function
apoc.number.exact.toFloat
apoc.number.exact.toFloat(string String, precision Integer, roundingMode String) - returns the float value of the given large number (using Java BigDecimal).
Function
apoc.number.exact.toInteger
apoc.number.exact.toInteger(string String, precision Integer, roundingMode String) - returns the integer value of the given large number (using Java BigDecimal).
Function
apoc.number.format
apoc.number.format(number Any, pattern String, language String) - formats the given long or double using the given pattern and language to produce a string.
Function
apoc.number.parseFloat
apoc.number.parseFloat(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a double.
Function
apoc.number.parseInt
apoc.number.parseInt(text String, pattern String, language String) - parses the given string using the given pattern and language to produce a long.
Function
apoc.number.romanToArabic
apoc.number.romanToArabic(romanNumber String) - converts the given Roman numbers to Arabic numbers.
Function
apoc.path
Qualified Name Type
apoc.path.expand
apoc.path.expand(startNode Any, relFilter String, labelFilter String, minDepth Integer, maxDepth Integer) - returns paths expanded from the start node following the given relationship types from min-depth to max-depth.
Procedure
apoc.path.expandConfig
apoc.path.expandConfig(startNode Any, config Map<String, Any>) - returns paths expanded from the start node the given relationship types from min-depth to max-depth.
Procedure
apoc.path.spanningTree
apoc.path.spanningTree(startNode Any, config Map<String, Any>) - returns spanning tree paths expanded from the start node following the given relationship types to max-depth.
Procedure
apoc.path.subgraphAll
apoc.path.subgraphAll(startNode Any, config Map<String, Any>) - returns the sub-graph reachable from the start node following the given relationship types to max-depth.
Procedure
apoc.path.subgraphNodes
apoc.path.subgraphNodes(startNode Any, config Map<String, Any>) - returns the nodes in the sub-graph reachable from the start node following the given relationship types to max-depth.
Procedure
apoc.path.combine
apoc.path.combine(path1 Path, path2 Path) - combines the two given paths into one path.
Function
apoc.path.create
apoc.path.create(startNode Node, rels [Rel]) - returns a path from the given start node and a list of relationships.
Function
apoc.path.elements
apoc.path.elements(path Path) - converts the given path into a list of nodes and relationships.
Function
apoc.path.slice
apoc.path.slice(path Path, offset Integer, length Integer) - returns a sub-path of the given length and offset from the given path.
Function
apoc.periodic
Qualified Name Type
apoc.periodic.cancel
apoc.periodic.cancel(name String) - cancels the given background job. Background jobs are created using apoc.periodic.submit.
Procedure
apoc.periodic.commit
apoc.periodic.commit(statement String, params Map<String, Any>) - runs the given statement in separate batched transactions.
Procedure
apoc.periodic.countdown
apoc.periodic.countdown(name String, statement String, rate Integer) - runs a repeatedly called background statement until it returns 0.
Procedure
apoc.periodic.iterate
apoc.periodic.iterate(cypherIterate String, cypherAction String, config Map<String, Any>) - runs the second statement for each item returned by the first statement. This procedure returns the number of batches and the total number of processed rows.
Procedure
apoc.periodic.list
apoc.periodic.list() - returns a list of all background jobs.
Procedure
apoc.periodic.repeat
apoc.periodic.repeat(name String, statement String, rate Integer, config Map<String, Any>) - runs a repeatedly called background job. To stop this procedure, use apoc.periodic.cancel.
Procedure
apoc.periodic.submit
apoc.periodic.submit(name String, statement String, params Map<String, Any>) - creates a background job which runs the given Cypher statement once.
Procedure
apoc.periodic.truncate
apoc.periodic.truncate(config Map<String, Any>) - removes all entities (and optionally indexes and constraints) from the database using the apoc.periodic.iterate procedure.
Procedure
apoc.refactor
Qualified Name Type
apoc.refactor.categorize
apoc.refactor.categorize(sourceKey String, type String, outgoing Boolean, label String, targetKey String, copiedKeys [String], batchSize Integer) - creates new category nodes from nodes in the graph with the specified sourceKey as one of its property keys. The new category nodes are then connected to the original nodes with a relationship of the given type.
Procedure
apoc.refactor.cloneNodes
apoc.refactor.cloneNodes(nodes [Node], withRelationships Boolean, skipProperties [String]) - clones the given nodes with their labels and properties. It is possible to skip any node properties using skipProperties (note: this only skips properties on nodes and not their relationships).
Procedure
apoc.refactor.cloneSubgraph
apoc.refactor.cloneSubgraph(nodes [Node], rels [Rel], config Map<String, Any>) - clones the given nodes with their labels and properties (optionally skipping any properties in the skipProperties list via the config map), and clones the given relationships. If no relationships are provided, all existing relationships between the given nodes will be cloned.
Procedure
apoc.refactor.cloneSubgraphFromPaths
apoc.refactor.cloneSubgraphFromPaths(paths [Path], config Map<String, Any>) - clones a sub-graph defined by the given list of paths. It is possible to skip any node properties using the skipProperties list via the config map.
Procedure
apoc.refactor.collapseNode
apoc.refactor.collapseNode(nodes Any, relType String) - collapses the given node and replaces it with a relationship of the given type.
Procedure
apoc.refactor.deleteAndReconnect
apoc.refactor.deleteAndReconnect(path Path, nodes [Node], config Map<String, Any>) - removes the given nodes from the path and reconnects the remaining nodes.
Procedure
apoc.refactor.extractNode
apoc.refactor.extractNode(rels Any, labels [String], outType String, inType String) - expands the given relationships into intermediate nodes. The intermediate nodes are connected by the given 'OUT' and 'IN' types.
Procedure
apoc.refactor.from
apoc.refactor.from(rel Rel, newNode Node) - redirects the given relationship to the given start node.
Procedure
apoc.refactor.invert
apoc.refactor.invert(rel Rel) - inverts the direction of the given relationship.
Procedure
apoc.refactor.mergeNodes
apoc.refactor.mergeNodes(nodes [Node], config Map<String, Any>) - merges the given list of nodes onto the first node in the list. All relationships are merged onto that node as well.
Procedure
apoc.refactor.mergeRelationships
apoc.refactor.mergeRelationships(rels [Rel], config Map<String, Any>) - merges the given list of relationships onto the first relationship in the list.
Procedure
apoc.refactor.normalizeAsBoolean
apoc.refactor.normalizeAsBoolean(entity Any, propertyKey String, trueValues [Any], falseValues [Any]) - refactors the given property to a boolean.
Procedure
apoc.refactor.rename.label
apoc.refactor.rename.label(oldLabel String, newLabel String, nodes [Node]) - renames the given label from 'oldLabel' to 'newLabel' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.nodeProperty
apoc.refactor.rename.nodeProperty(oldName String, newName String, nodes [Node], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all nodes. If a list of nodes is provided, the renaming is applied to the nodes within this list only.
Procedure
apoc.refactor.rename.type
apoc.refactor.rename.type(oldType String, newType String, rels [Rel], config Map<String, Any>) - renames all relationships with type 'oldType' to 'newType'. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
apoc.refactor.rename.typeProperty
apoc.refactor.rename.typeProperty(oldName String, newName String, rels [Rel], config Map<String, Any>) - renames the given property from 'oldName' to 'newName' for all relationships. If a list of relationships is provided, the renaming is applied to the relationships within this list only.
Procedure
apoc.refactor.setType
apoc.refactor.setType(rel Rel, newType String) - changes the type of the given relationship.
Procedure
apoc.refactor.to
apoc.refactor.to(rel Rel, endNode Node) - redirects the given relationship to the given end node.
Procedure
apoc.rel
Qualified Name Type
apoc.rel.endNode
apoc.rel.endNode(rel Rel) - returns the end node for the given virtual relationship.
Function
apoc.rel.id
apoc.rel.id(rel Rel) - returns the id for the given virtual relationship.
Function
apoc.rel.startNode
apoc.rel.startNode(rel Rel) - returns the start node for the given virtual relationship.
Function
apoc.rel.type
apoc.rel.type(rel Rel) - returns the type for the given virtual relationship.
Function
apoc.schema
Qualified Name Type
apoc.schema.assert
apoc.schema.assert(indexes Map<String, [Any]>, constraints Map<String, [Any]>, dropExisting Boolean) - drops all other existing indexes and constraints when dropExisting is true (default is true). Asserts at the end of the operation that the given indexes and unique constraints are there.
Procedure
apoc.schema.nodes
apoc.schema.nodes(config Map<String, Any>) - returns all indexes and constraints information for all node labels in the database. It is possible to define a set of labels to include or exclude in the config parameters.
Procedure
apoc.schema.properties.distinct
apoc.schema.properties.distinct(label String, key String) - returns all distinct node property values for the given key.
Procedure
apoc.schema.properties.distinctCount
apoc.schema.properties.distinctCount(label String, key String) - returns all distinct property values and counts for the given key.
Procedure
apoc.schema.relationships
apoc.schema.relationships(config Map<String, Any>) - returns the indexes and constraints information for all the relationship types in the database. It is possible to define a set of relationship types to include or exclude in the config parameters.
Procedure
apoc.schema.node.constraintExists
apoc.schema.node.constraintExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given node label with the given property names.
Function
apoc.schema.node.indexExists
apoc.schema.node.indexExists(labelName String, propertyName [String]) - returns a boolean depending on whether or not an index exists for the given node label with the given property names.
Function
apoc.schema.relationship.constraintExists
apoc.schema.relationship.constraintExists(type String, propertyName [String]) - returns a boolean depending on whether or not a constraint exists for the given relationship type with the given property names.
Function
apoc.schema.relationship.indexExists
apoc.schema.relationship.indexExists(type String, propertyName [String])- returns a boolean depending on whether or not an index exists for the given relationship type with the given property names.
Function
apoc.scoring
Qualified Name Type
apoc.scoring.existence
apoc.scoring.existence(score Integer, exists Boolean) - returns the given score if true, 0 if false.
Function
apoc.scoring.pareto
apoc.scoring.pareto(minimumThreshold Integer, eightyPercentValue Integer, maximumValue Integer, score Integer) - applies a Pareto scoring function over the given integers.
Function
apoc.search
Qualified Name Type
apoc.search.multiSearchReduced
apoc.search.multiSearchReduced(labelPropertyMap Any, operator String, value String) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Procedure
apoc.search.node
apoc.search.node(labelPropertyMap Any, operator String, value String) - returns all the distinct nodes found after a parallel search over multiple indexes.
Procedure
apoc.search.nodeAll
apoc.search.nodeAll(labelPropertyMap Any, operator String, value String) - returns all the nodes found after a parallel search over multiple indexes.
Procedure
apoc.search.nodeAllReduced
apoc.search.nodeAllReduced(labelPropertyMap Any, operator String, value Any) - returns a reduced representation of the nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Procedure
apoc.search.nodeReduced
apoc.search.nodeReduced(labelPropertyMap Any, operator String, value String) - returns a reduced representation of the distinct nodes found after a parallel search over multiple indexes. The reduced node representation includes: node id, node labels and the searched properties.
Procedure
apoc.spatial
Qualified Name Type
apoc.spatial.geocode
apoc.spatial.geocode(location String, maxResults Integer, quotaException Boolean, config Map<String, Any>)) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap).
Procedure
apoc.spatial.geocodeOnce
apoc.spatial.geocodeOnce(location String, config Map<String, Any>) - returns the geographic location (latitude, longitude, and description) of the given address using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Procedure
apoc.spatial.reverseGeocode
apoc.spatial.reverseGeocode(latitude Float, longitude Float, quotaException Boolean, config Map<String, Any>) - returns a textual address from the given geographic location (latitude, longitude) using a geocoding service (default: OpenStreetMap). This procedure returns at most one result.
Procedure
apoc.spatial.sortByDistance
apoc.spatial.sortByDistance(paths [Path]) - sorts the given collection of paths by the sum of their distance based on the latitude/longitude values on the nodes.
Procedure
apoc.stats
Qualified Name Type
apoc.stats.degrees
apoc.stats.degrees(relTypes String) - returns the percentile groupings of the degrees on the nodes connected by the given relationship types.
Procedure
apoc.temporal
Qualified Name Type
apoc.temporal.format
apoc.temporal.format(temporal Any, format String) - formats the given temporal value into the given time format.
Function
apoc.temporal.formatDuration
apoc.temporal.formatDuration(input Any, format String) - formats the given duration into the given time format.
Function
apoc.temporal.toZonedTemporal
apoc.temporal.toZonedTemporal(time String, format String, timezone String) - parses the given date string using the specified format into the given time zone.
Function
apoc.text
Qualified Name Type
apoc.text.phoneticDelta
apoc.text.phoneticDelta(text1 String, text2 String) - returns the US_ENGLISH soundex character difference between the two given strings.
Procedure
apoc.text.base64Decode
apoc.text.base64Decode(text String) - decodes the given Base64 encoded string.
Function
apoc.text.base64Encode
apoc.text.base64Encode(text String) - encodes the given string with Base64.
Function
apoc.text.base64UrlDecode
apoc.text.base64UrlDecode(url String) - decodes the given Base64 encoded URL.
Function
apoc.text.base64UrlEncode
apoc.text.base64UrlEncode(url String) - encodes the given URL with Base64.
Function
apoc.text.byteCount
apoc.text.byteCount(text String, charset String) - returns the size of the given string in bytes.
Function
apoc.text.bytes
apoc.text.bytes(text String, charset String) - returns the given string as bytes.
Function
apoc.text.camelCase
apoc.text.camelCase(text String) - converts the given string to camel case.
Function
apoc.text.capitalize
apoc.text.capitalize(text String) - capitalizes the first letter of the given string.
Function
apoc.text.capitalizeAll
apoc.text.capitalizeAll(text String) - capitalizes the first letter of every word in the given string.
Function
apoc.text.charAt
apoc.text.charAt(text String, index Integer) - returns the long value of the character at the given index.
Function
apoc.text.clean
apoc.text.clean(text String) - strips the given string of everything except alpha numeric characters and converts it to lower case.
Function
apoc.text.code
apoc.text.code(codepoint Long) - converts the long value into a string.
Function
apoc.text.compareCleaned
apoc.text.compareCleaned(text1 String, text2 String) - compares two given strings stripped of everything except alpha numeric characters converted to lower case.
Function
apoc.text.decapitalize
apoc.text.decapitalize(text String) - turns the first letter of the given string from upper case to lower case.
Function
apoc.text.decapitalizeAll
apoc.text.decapitalizeAll(text String) - turns the first letter of every word in the given string to lower case.
Function
apoc.text.distance
apoc.text.distance(text1 String, text2 String) - compares the two given strings using the Levenshtein distance algorithm.
Function
apoc.text.doubleMetaphone
apoc.text.doubleMetaphone(value String) - returns the double metaphone phonetic encoding of all words in the given string value.
Function
apoc.text.format
apoc.text.format(text String, params [Any], language String) - formats the given string with the given parameters.
Function
apoc.text.fuzzyMatch
apoc.text.fuzzyMatch(text1 String, text2 String) - performs a fuzzy match search of the two given strings.
Function
apoc.text.hammingDistance
apoc.text.hammingDistance(text1 String, text2 String) - compares the two given strings using the Hamming distance algorithm.
Function
apoc.text.hexCharAt
apoc.text.hexCharAt(text String, index Integer) - returns the hexadecimal value of the given string at the given index.
Function
apoc.text.hexValue
apoc.text.hexValue(value Integer) - returns the hexadecimal value of the given value.
Function
apoc.text.indexOf
apoc.text.indexOf(text String, lookup String, from Integer, to Integer) - returns the first occurrence of the lookup string in the given string, or -1 if not found.
Function
apoc.text.indexesOf
apoc.text.indexesOf(text String, lookup String, from Integer, to Integer) - returns all occurences of the lookup string in the given string, or an empty list if not found.
Function
apoc.text.jaroWinklerDistance
apoc.text.jaroWinklerDistance(text1 String, text2 String) - compares the two given strings using the Jaro-Winkler distance algorithm.
Function
apoc.text.join
apoc.text.join(texts [String], delimiter String) - joins the given strings using the given delimiter.
Function
apoc.text.levenshteinDistance
apoc.text.levenshteinDistance(text1 String, text2 String) - compares the given strings using the Levenshtein distance algorithm.
Function
apoc.text.levenshteinSimilarity
apoc.text.levenshteinSimilarity(text1 String, text2 String) - returns the similarity (a value within 0 and 1) between the two given strings based on the Levenshtein distance algorithm.
Function
apoc.text.lpad
apoc.text.lpad(text String, count Integer, delimiter String) - left pads the given string by the given width.
Function
apoc.text.phonetic
apoc.text.phonetic(text String) - returns the US_ENGLISH phonetic soundex encoding of all words of the string.
Function
apoc.text.random
apoc.text.random(length Integer, valid String) - generates a random string to the given length using a length parameter and an optional string of valid characters.
Function
apoc.text.regexGroups
apoc.text.regexGroups(text String, regex String) - returns all groups matching the given regular expression in the given text.
Function
apoc.text.regreplace
apoc.text.regreplace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Function
apoc.text.repeat
apoc.text.repeat(item String, count Integer) - returns the result of the given item multiplied by the given count.
Function
apoc.text.replace
apoc.text.replace(text String, regex String, replacement String) - finds and replaces all matches found by the given regular expression with the given replacement.
Function
apoc.text.rpad
apoc.text.rpad(text String, count Integer, delimiter String) - right pads the given string by the given width.
Function
apoc.text.slug
apoc.text.slug(text String, delimiter String) - replaces the whitespace in the given string with the given delimiter.
Function
apoc.text.snakeCase
apoc.text.snakeCase(text String) - converts the given string to snake case.
Function
apoc.text.sorensenDiceSimilarity
apoc.text.sorensenDiceSimilarityWithLanguage(text1 String, text2 String, languageTag String) - compares the two given strings using the Sørensen–Dice coefficient formula, with the provided IETF language tag.
Function
apoc.text.split
apoc.text.split(text String, regex String, limit Integer) - splits the given string using a given regular expression as a separator.
Function
apoc.text.swapCase
apoc.text.swapCase(text String) - swaps the cases in the given string.
Function
apoc.text.toCypher
apoc.text.toCypher(value Any, config Map<String, Any>) - converts the given value to a Cypher property string.
Function
apoc.text.toUpperCase
apoc.text.toUpperCase(text String) - converts the given string to upper case.
Function
apoc.text.upperCamelCase
apoc.text.upperCamelCase(text String) - converts the given string to upper camel case.
Function
apoc.text.urldecode
apoc.text.urldecode(text String) - decodes the given URL encoded string.
Function
apoc.text.urlencode
apoc.text.urlencode(text String) - encodes the given URL string.
Function
apoc.trigger
Qualified Name Type
apoc.trigger.add
apoc.trigger.add(name String, statement String, selector Map<String, Any>, config Map<String, Any>) - adds a trigger to the given Cypher statement. The selector for this procedure is {phase:'before/after/rollback/afterAsync'}.
Procedure
apoc.trigger.list
apoc.trigger.list() - lists all installed triggers.
Procedure
apoc.trigger.pause
apoc.trigger.pause(name String) - pauses the given trigger.
Procedure
apoc.trigger.remove
apoc.trigger.remove(name String) - removes the given trigger.
Procedure
apoc.trigger.removeAll
apoc.trigger.removeAll() - removes all previously added triggers.
Procedure
apoc.trigger.resume
apoc.trigger.resume(name String) - resumes the given paused trigger.
Procedure
apoc.util
Qualified Name Type
apoc.util.sleep
apoc.util.sleep(duration Integer) - causes the currently running Cypher to sleep for the given duration of milliseconds (the transaction termination is honored).
Procedure
apoc.util.validate
apoc.util.validate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown.
Procedure
apoc.util.compress
apoc.util.compress(data String, config Map<String, Any>) - zips the given string.
Function
apoc.util.decompress
apoc.util.decompress(data ByteArray, config Map<String, Any>) - unzips the given byte array.
Function
apoc.util.md5
apoc.util.md5(values [Any]) - returns the MD5 checksum of the concatenation of all string values in the given list. MD5 is a weak hashing algorithm which is unsuitable for cryptographic use-cases.
Function
apoc.util.sha1
apoc.util.sha1(values [Any]) - returns the SHA1 of the concatenation of all string values in the given list.
Function
apoc.util.sha256
apoc.util.sha256(values [Any]) - returns the SHA256 of the concatenation of all string values in the given list.
Function
apoc.util.sha384
apoc.util.sha384(values [Any]) - returns the SHA384 of the concatenation of all string values in the given list.
Function
apoc.util.sha512
apoc.util.sha512(values [Any]) - returns the SHA512 of the concatenation of all string values in the list.
Function
apoc.util.validatePredicate
apoc.util.validatePredicate(predicate Boolean, message String, params [Any]) - if the given predicate is true an exception is thrown, otherwise it returns true (for use inside WHERE subclauses).
Function
apoc.warmup
Qualified Name Type
apoc.warmup.run
apoc.warmup.run(loadProperties Boolean, loadDynamicProperties Boolean, loadIndexes Boolean) - loads all nodes and relationships in the database into memory.
Procedure
apoc.xml
Qualified Name Type
apoc.xml.parse
apoc.xml.parse(data String, path String, config Map<String, Any>, simple Boolean) - parses the given XML string as a map.
Function
Built in Help
apoc
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.hashing/apoc.hashing.fingerprintGraph;"apoc.hashing.fingerprintGraph
Contents
Signature
Input parameters
Usage Examples
Function
apoc.hashing.fingerprinting(object Any, config Map<String, Any>) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unlike apoc.hashing.fingerprint(), this function supports a number of config parameters. Unsuitable for cryptographic use-cases.
Signature
None
Copy to Clipboard
apoc.hashing.fingerprintGraph(propertyExcludes = [] :: LIST? OF STRING?) :: (STRING?)
Input parameters
Name Type Default
propertyExcludes
LIST? OF STRING?
[]
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (joe:Person {name: ""Joe""})
MERGE (ryan:Person {name: ""Ryan""})
MERGE (ryan)-[:FOLLOWS {since: datetime(""2020-11-04"")}]->(joe);
This function computes a fingerprint of the whole graph using the MD5 checksum:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.hashing.fingerprintGraph() AS output;
Table 1. Results
output
""655408F901B554A8999AEF61EA6D5AE5""
We can pass in a list of properties to exclude from the fingerprint, as shown in the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.hashing.fingerprintGraph([""since""]) AS output;
Table 2. Results
output
""0583812D25093B4CD03C96DF15215048""
More documentation of apoc.hashing.fingerprintGraph
apoc.hashing.fingerprint
apoc.hashing.fingerprinting
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.hashing/apoc.hashing.fingerprint;"apoc.hashing.fingerprint
Contents
Signature
Input parameters
Usage Examples
Function
apoc.hashing.fingerprint(object Any, excludedPropertyKeys [String]) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unsuitable for cryptographic use-cases.
Signature
None
Copy to Clipboard
apoc.hashing.fingerprint(some object :: ANY?, propertyExcludes = [] :: LIST? OF STRING?) :: (STRING?)
Input parameters
Name Type Default
some object
ANY?
null
propertyExcludes
LIST? OF STRING?
[]
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (joe:Person {name: ""Joe""})
MERGE (ryan:Person {name: ""Ryan""})
MERGE (ryan)-[:FOLLOWS {since: datetime(""2020-11-04"")}]->(joe);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person {name: ""Ryan""})
RETURN apoc.hashing.fingerprint(person) AS output;
Table 1. Results
output
""81C99DD6C9382C4E01A1873F9E818CE0""
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[rel:FOLLOWS]->()
RETURN apoc.hashing.fingerprint(rel) AS output;
Table 2. Results
output
""C5A4B9FA273CC723D96BF93FFDD42858""
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.hashing.fingerprint({name: ""Michael""}) AS output;
Table 3. Results
output
""F582CEF35FA83F3691BB756313191948""
If we want more control over fingerprint generation, see apoc.hashing.fingerprinting.
More documentation of apoc.hashing.fingerprint
apoc.hashing
apoc.hashing.fingerprintGraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.hashing;"apoc.hashing
Qualified Name Type
apoc.hashing.fingerprint
apoc.hashing.fingerprint(object Any, excludedPropertyKeys [String]) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unsuitable for cryptographic use-cases.
Function
apoc.hashing.fingerprinting
apoc.hashing.fingerprinting(object Any, config Map<String, Any>) - calculates a MD5 checksum over a node or a relationship (identical entities share the same checksum). Unlike apoc.hashing.fingerprint(), this function supports a number of config parameters. Unsuitable for cryptographic use-cases.
Function
apoc.hashing.fingerprintGraph
apoc.hashing.fingerprintGraph(propertyExcludes [String]) - calculates a MD5 checksum over the full graph. This function uses in-memory data structures. Unsuitable for cryptographic use-cases.
Function
apoc.graph.validateDocument
apoc.hashing.fingerprint
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.validateDocument;"apoc.graph.validateDocument
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.validateDocument(json Any, config Map<String, Any>) - validates the JSON file and returns the result of the validation.
Signature
None
Copy to Clipboard
apoc.graph.validateDocument(json :: ANY?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
json
ANY?
null
config
MAP?
{}
Output parameters
Name Type
row
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.validateDocument('[{""foo"": ""foo""}, {""bar"": ""bar"", ""id"": 1, ""type"": ""label""}, {""fooBar"": ""fooBar"", ""id"": 1}]');
Table 1. Results
row
{message: ""The object {\""foo\"":\""foo\"",\""id\"":\""9447525f-8a2b-4ab9-b440-b80396741683\""} must have type as label-field name"", index: 0}
{message: ""The object {\""fooBar\"":\""fooBar\"",\""id\"":1} must have type as label-field name"", index: 2}
More documentation of apoc.graph.fromDB
apoc.graph.fromPaths
apoc.hashing
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromPaths;"apoc.graph.fromPaths
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromPaths(paths [Path], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given paths.
Signature
None
Copy to Clipboard
apoc.graph.fromPaths(paths :: LIST? OF PATH?, name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
paths
LIST? OF PATH?
null
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[:ACTED_IN]->(:Movie)
WITH collect(path) AS paths
CALL apoc.graph.fromPaths(paths,'test', {})
YIELD graph AS g
RETURN g.nodes AS nodes, g.relationships AS relationships;
Table 1. Results
nodes relationships
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Keanu Reeves"", born: 1964}), (:Person {name: ""Carrie-Anne Moss"", born: 1967}), (:Person {name: ""Laurence Fishburne"", born: 1961}), (:Person {name: ""Hugo Weaving"", born: 1960})]
[[:ACTED_IN {roles: [""Neo""]}], [:ACTED_IN {roles: [""Trinity""]}], [:ACTED_IN {roles: [""Morpheus""]}], [:ACTED_IN {roles: [""Agent Smith""]}]]
More documentation of apoc.graph.fromDB
apoc.graph.fromPath
apoc.graph.validateDocument
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromPath;"apoc.graph.fromPath
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromPath(path Path, name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given path.
Signature
None
Copy to Clipboard
apoc.graph.fromPath(path :: PATH?, name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
path
PATH?
null
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[:ACTED_IN]->(:Movie)
CALL apoc.graph.fromPath(path,'test', {})
YIELD graph AS g
RETURN g.nodes AS nodes, g.relationships AS relationships;
Table 1. Results
nodes relationships
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Hugo Weaving"", born: 1960})]
[[:ACTED_IN {roles: [""Agent Smith""]}]]
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Laurence Fishburne"", born: 1961})]
[[:ACTED_IN {roles: [""Morpheus""]}]]
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Carrie-Anne Moss"", born: 1967})]
[[:ACTED_IN {roles: [""Trinity""]}]]
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Keanu Reeves"", born: 1964})]
[[:ACTED_IN {roles: [""Neo""]}]]
More documentation of apoc.graph.fromDB
apoc.graph.fromDocument
apoc.graph.fromPaths
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromDocument;"apoc.graph.fromDocument
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromDocument(json Any, config Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the data returned by the given JSON file.
Signature
None
Copy to Clipboard
apoc.graph.fromDocument(json :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
json
ANY?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
write
boolean
false
persist the graph otherwise return a Virtual Graph
labelField
String
type
the field name that became the label of the node
idField
String
id
the document field name that will become the id field of the created nodes (used for node resolution when you create relationships between nodes)
generateId
boolean
true
in case of missing id-field value it generates a UUID for it
defaultLabel
String
""""
in case of missing label-field value is uses the provided default label
skipValidation
boolean
false
in case you want skip the validation process into the apoc.graph.fromDocument
mappings
Map<String, String>
{}
click on link below for more detail
Output parameters
Name Type
graph
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument(""{'id': 1,'type': 'artist','name':'Genesis','members': ['Tony Banks','Mike Rutherford','Phil Collins'],'years': [1967, 1998, 1999, 2000, 2006],'albums': [{'type': 'album','id': 1,'producer': 'Jonathan King','title': 'From Genesis to Revelation'}]}"", {write: false})
YIELD graph AS g
RETURN g.nodes AS nodes, g.relationships AS rels;
Table 2. Results
nodes rels
[(:Artist {name: ""Genesis"", id: 1, type: ""artist"", years: [1967, 1998, 1999, 2000, 2006], members: [""Tony Banks"", ""Mike Rutherford"", ""Phil Collins""]}), (:Album {producer: ""Jonathan King"", id: 1, type: ""album"", title: ""From Genesis to Revelation""})]
[[:ALBUMS]]
Cypher
Virtual graph from JSON with labelField
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument(""{'id': 1,'type': 'artist','name':'Genesis','members': ['Tony Banks','Mike Rutherford','Phil Collins'],'years': [1967, 1998, 1999, 2000, 2006],'albums': [{'type': 'album','id': 1,'producer': 'Jonathan King','title': 'From Genesis to Revelation'}]}"", {write: false})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with labelField
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""id"":10,""myCustomType"":""labelArtist"",""name"":""Genesis"",""albums"":[{""myCustomType"":""labelAlbum"",""producer"":""Jonathan King"",""id"":20,""title"":""From Genesis to Revelation""}]}', {labelField: ""myCustomType""})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with labelField and idField
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""myCustomType"":""labelArtist"",""name"":""Genesis"",""myCustomId"":1,""albums"":[{""myCustomType"":""labelAlbum"",""producer"":""Jonathan King"",""myCustomId"":1,""title"":""From Genesis to Revelation""}]}',
{labelField: ""myCustomType"", idField: ""myCustomId""})
YIELD graph
RETURN *
As a result we have a virtual graph with two nodes and one relationship:
Cypher
Virtual graph from JSON with mappings
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument('{""id"":1,""type"":""Person"",""name"":""Andrea"",""sizes"":{""weight"":{""value"":70,""um"":""Kg""},""height"":{""value"":174,""um"":""cm""},""array"":[""foo"",""bar""]},""books"":[{""title"":""Flow My Tears, the Policeman Said"",""released"":1974},{""title"":""The man in the High Castle"",""released"":1962}]}',
{mappings:{`$`:""Person:Reader{*,@sizes}"",`$.books`:""Book{!title, released}""}})
yield graph
RETURN *
As a result we have a virtual graph with three nodes and two relationship:
Virtual graph from JSON with relMapping
We can pass a relMapping to customize relationship names, passing a map with the relationships you want to change as keys. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.graph.fromDocument(""{'id': 1,'type': 'artist','name':'Genesis','members': ['Tony Banks','Mike Rutherford','Phil Collins'],'years': [1967, 1998, 1999, 2000, 2006],'albums': [{'type': 'album','id': 1,'producer': 'Jonathan King','title': 'From Genesis to Revelation'}]}"",
{relMapping: {albums: ""CUSTOM_REL""}});
More documentation of apoc.graph.fromDB
apoc.graph.fromData
apoc.graph.fromPath
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.graph/apoc.graph.fromData;"apoc.graph.fromData
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.graph.fromData(nodes [Node], rels [Rel], name String, props Map<String, Any>) - generates a virtual sub-graph by extracting all of the nodes and relationships from the given data.
Signature
None
Copy to Clipboard
apoc.graph.fromData(nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?, name :: STRING?, properties :: MAP?) :: (graph :: MAP?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
relationships
LIST? OF RELATIONSHIP?
null
name
STRING?
null
properties
MAP?
null
Output parameters
Name Type
graph
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[r:ACTED_IN]->(m:Movie)
WITH collect(m) + collect(p) AS nodes, collect(r) AS relationships
CALL apoc.graph.fromData(nodes, relationships, ""movies"", {})
YIELD graph AS g
UNWIND keys(g) AS key
RETURN key, g[key] AS value;
Table 1. Results
key value
""name""
""movies""
""relationships""
[[:ACTED_IN {roles: [""Neo""]}], [:ACTED_IN {roles: [""Trinity""]}], [:ACTED_IN {roles: [""Morpheus""]}], [:ACTED_IN {roles: [""Agent Smith""]}]]
""nodes""
[(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999}), (:Person {name: ""Keanu Reeves"", born: 1964}), (:Person {name: ""Carrie-Anne Moss"", born: 1967}), (:Person {name: ""Laurence Fishburne"", born: 1961}), (:Person {name: ""Hugo Weaving"", born: 1960})]
""properties""
{}
More documentation of apoc.graph.fromData
apoc.graph.fromDB
apoc.graph.fromDocument
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.hashing/apoc.hashing.fingerprinting;"apoc.hashing.fingerprinting
Contents
Signature
Input parameters
Config parameters
Usage Examples
Function
apoc.hashing.fingerprintGraph(propertyExcludes [String]) - calculates a MD5 checksum over the full graph. This function uses in-memory data structures. Unsuitable for cryptographic use-cases.
Signature
None
Copy to Clipboard
apoc.hashing.fingerprinting(some object :: ANY?, conf = {} :: MAP?) :: (STRING?)
Input parameters
Name Type Default
some object
ANY?
null
conf
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
digestAlgorithm
String
""MD5""
The algorithm used to compute the fingerprint. Supported values are: MD5, SHA-1, SHA-256
strategy
String
""LAZY""
Property loading strategy. Supported values are:
LAZY - does not include properties
EAGER - uses all properties
nodeAllowMap
Map<String, List<String>>
{}
Properties to include per node label
nodeDisallowMap
Map<String, List<String>>
[]
Properties to exclude per node label
relAllowMap
Map<String, List<String>>
{}
Properties to include per relationship type
relDisallowMap
Map<String, List<String>>
[]
Properties to exclude per relationship type
mapAllowList
List<String>
[]
Map properties to include
mapDisallowList
List<String>
[]
Map properties to exclude
allNodesAllowList
List<String>
[]
Node properties to include
allNodesDisallowList
List<String>
[]
Node properties to exclude
allRelsAllowList
List<String>
[]
Relationship properties to include
allRelsDisallowList
List<String>
[]
Relationship properties to exclude
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (joe:Person {name: ""Joe""})
MERGE (ryan:Person {name: ""Ryan""})
MERGE (ryan)-[:FOLLOWS {since: datetime(""2020-11-04"")}]->(joe);
The following generates the fingerprint for Ryan:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person {name: ""Ryan""})
RETURN apoc.hashing.fingerprinting(person) AS output;
Table 2. Results
output
""D41D8CD98F00B204E9800998ECF8427E""
The following generates the fingerprint for Ryan, using the EAGER strategy, which includes node properties:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person {name: ""Ryan""})
RETURN apoc.hashing.fingerprinting(person, {
  strategy: ""EAGER""
}) AS output;
Table 3. Results
output
""81C99DD6C9382C4E01A1873F9E818CE0""
The following generates the fingerprint for Ryan, excluding the name property:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person {name: ""Ryan""})
RETURN apoc.hashing.fingerprinting(person, {
  allNodesDisallowList: [""name""]
}) AS output;
Table 4. Results
output
""D41D8CD98F00B204E9800998ECF8427E""
The following generates the fingerprint for Ryan, using the SHA-256 algorithm:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person {name: ""Ryan""})
RETURN apoc.hashing.fingerprinting(person, {
  digestAlgorithm: ""SHA-256""
}) AS output;
Table 5. Results
output
""E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855""
If we want less control over the generation of the fingerprint, see apoc.hashing.fingerprint.
More documentation of apoc.hashing.fingerprinting
apoc.hashing.fingerprintGraph
apoc.import
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.import;"apoc.import
Qualified Name Type
apoc.import.csv
apoc.import.csv(nodes [Map<String, Any>], rels [Map<String, Any>], config Map<String, Any>) - imports nodes and relationships with the given labels and types from the provided CSV file.
Procedure
apoc.import.graphml
apoc.import.graphml(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided GraphML file.
Procedure
apoc.import.json
apoc.import.json(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided JSON file.
Procedure
apoc.import.xml
apoc.import.xml(urlOrBinary Any, config Map<String, Any>) - imports a graph from the provided XML file.
Procedure
apoc.hashing.fingerprinting
apoc.import.csv
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.import/apoc.import.csv;"apoc.import.csv
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Nodes
Nodes and relationships
Binary file
Properties
Procedure
apoc.import.csv(nodes [Map<String, Any>], rels [Map<String, Any>], config Map<String, Any>) - imports nodes and relationships with the given labels and types from the provided CSV file.
Signature
None
Copy to Clipboard
apoc.import.csv(nodes :: LIST? OF MAP?, relationships :: LIST? OF MAP?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF MAP?
null
relationships
LIST? OF MAP?
null
config
MAP?
null
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description import tool counterpart
delimiter
String
,
delimiter character between columns
--delimiter=,
arrayDelimiter
String
;
delimiter character in arrays
--array-delimiter=;
ignoreDuplicateNodes
Boolean
false
for duplicate nodes, only load the first one and skip the rest (true) or fail the import (false)
--ignore-duplicate-nodes=false
quotationCharacter
String
""
quotation character
--quote='""'
stringIds
Boolean
true
treat ids as strings
--id-type=STRING
skipLines
Integer
1
lines to skip (incl. header)
N/A
ignoreBlankString
Boolean
false
if true ignore properties with a blank string
N/A
ignoreEmptyCellArray
Boolean
false
if true ignore array properties containing a single empty string, like the import tool
N/A
compression
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
Allow taking binary data, either not compressed (value: NONE) or compressed (other values) .
N/A
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
This procedure imports CSV files that comply with the Neo4j import tool’s header format.
Nodes
The following file contains two people:
Text
persons.csv
Copy to Clipboard
id:ID,name:STRING
1,John
2,Jane
We’ll place this file into the import directory of our Neo4j instance.
We can create two Person nodes with their name properties set, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv([{fileName: 'file:/persons.csv', labels: ['Person']}], [], {});
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""progress.csv""
""file""
""csv""
2
0
4
7
0
-1
0
TRUE
NULL
We can check what’s been imported by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN p;
Table 3. Results
p
(:Person {name: ""John"", id: ""1""})
(:Person {name: ""Jane"", id: ""2""})
Nodes and relationships
The following files contain nodes and relationships in CSV format:
Text
people-nodes.csv
Copy to Clipboard
:ID|name:STRING|speaks:STRING[]
1|John|en,fr
2|Jane|en,de
Text
knows-rels.csv
Copy to Clipboard
:START_ID|:END_ID|since:INT
1|2|2016
We will import two Person nodes and a KNOWS relationship between them (with the value of the since property set). The field terminators and the array delimiters are changed from the default value, and the CSVs use numeric ids.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv(
  [{fileName: 'file:/people-nodes.csv', labels: ['Person']}],
  [{fileName: 'file:/knows-rels.csv', type: 'KNOWS'}],
  {delimiter: '|', arrayDelimiter: ',', stringIds: false}
);
Table 4. Results
file source format nodes relationships properties time rows batchSize batches done data
""progress.csv""
""file""
""csv""
2
1
7
7
0
-1
0
TRUE
NULL
We can check what’s been imported by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (p1:Person)-[:KNOWS]->(p2:Person)
RETURN path;
Table 5. Results
path
(:Person {name: ""John"", speaks: [""en"", ""fr""], csv_id: 1})-[:KNOWS {since: 2016}]→(:Person {name: ""Jane"", speaks: [""en"", ""de""], csv_id: 2})
Binary file
You can also import a file from a binary byte[] (not compressed, with default value NONE) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY). Note that in this case, for both relations and nodes parameter maps, the key for the file is data instead of fileName, that is:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv([{data: `binaryGzipByteArray`, labels: ['Person']}], [{data: `binaryGzipByteArray`, type: 'KNOWS'}], {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv([{data: `binaryFileNotCompressed`, labels: ['Person']}], [{data: `binaryFileNotCompressed`, type: 'KNOWS'}], {compression: 'NONE'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress(':ID|firstname:STRING|lastname:IGNORE|age:INT\n1|John|Doe|25\n2|Jane|Doe|26', {compression: 'DEFLATE'}) AS nodeCsv
WITH apoc.util.compress(':START_ID|:END_ID|prop1:IGNORE|prop2:INT\n1|2|a|3\n2|1|b|6', {compression: 'DEFLATE'}) AS relCsv, nodeCsv
CALL apoc.import.csv([{data: nodeCsv, labels: ['Person']}], [{data: relCsv, type: 'KNOWS'}], {delimiter: '|', compression: 'DEFLATE'})
YIELD source, format, nodes, relationships, properties
RETURN source, format, nodes, relationships, properties
Table 6. Results
source format nodes relationships properties
""binary""
""csv""
2
2
8
Properties
For properties, the <name> part of the field designates the property key, while the <field_type> part (after :) assigns a data type (see below). You can have properties in both node data files and relationship data files.
Use one of int, long, float, double, boolean, byte, short, char, string, point, date, localtime, time, localdatetime, datetime, and duration to designate the data type for properties. If no data type is given, this defaults to string. To define an array type, append [] to the type. For example:
Text
test.csv
Copy to Clipboard
:ID,name,joined:date,active:boolean,points:int
user01,Joe Soap,2017-05-05,true,10
user02,Jane Doe,2017-08-21,true,15
user03,Moe Know,2018-02-17,false,7
Point
A point is specified using the Cypher syntax for maps. The map allows the same keys as the input to the Point function. The point data type in the header can be amended with a map of default values used for all values of that column, e.g. point{crs: 'WGS-84'}. Specifying the header this way allows you to have an incomplete map in the value position in the data file. Optionally, a value in a data file may override default values from the header.
Text
point.csv
Copy to Clipboard
:ID,name,location:point{crs:WGS-84}
city01,""Malmö"",""{latitude:55.6121514, longitude:12.9950357}""
city02,""London"",""{y:51.507222, x:-0.1275}""
city03,""San Mateo"",""{latitude:37.554167, longitude:-122.313056, height: 100, crs:'WGS-84-3D'}""
In the above csv:
the first city’s location is defined using latitude and longitude, as expected when using the coordinate system defined in the header.
the second city uses x and y instead. This would normally lead to a point using the coordinate reference system cartesian. Since the header defines crs:WGS-84, that coordinate reference system will be used.
the third city overrides the coordinate reference system defined in the header, and sets it explicitly to WGS-84-3D.
Temporal
The format for all temporal data types must be defined as described in Temporal instants syntax and Durations syntax. Two of the temporal types, Time and DateTime, take a time zone parameter which might be common between all or many of the values in the data file. It is therefore possible to specify a default time zone for Time and DateTime values in the header, for example: time{timezone:+02:00} and: datetime{timezone:Europe/Stockholm}.
Text
point.csv
Copy to Clipboard
:ID,date1:datetime{timezone:Europe/Stockholm},date2:datetime
1,2018-05-10T10:30,2018-05-10T12:30
2,2018-05-10T10:30[Europe/Berlin],2018-05-10T12:30[Europe/Berlin]
In the above csv:
the first row has two values that do not specify an explicit timezone. The value for date1 will use the Europe/Stockholm time zone that was specified for that field in the header. The value for date2 will use the configured default time zone of the database.
in the second row, both date1 and date2 set the time zone explicitly to be Europe/Berlin. This overrides the header definition for date1, as well as the configured default time zone of the database.
apoc.import
apoc.import.graphml
Was this page helpful?"
https://neo4j.com/docs/graph-data-science-client/current;"The Neo4j Graph Data Science Client Library Manual v1.5
© 2022
License: Creative Commons 4.0
To help users of the Neo4j Graph Data Science library who work with Python as their primary language and environment, there is an official GDS client package called graphdatascience. It enables users to write pure Python code to project graphs, run algorithms, and define and use machine learning pipelines in GDS. To avoid naming confusion with the server-side GDS library, we will here refer to the Neo4j Graph Data Science client as the Python client.
The Python client API is designed to mimic the GDS Cypher procedure API in Python code. It wraps and abstracts the necessary operations of the Neo4j Python driver to offer a simpler surface. Except for those listed in Known limitations, every operation of the GDS Cypher API should be represented in the Python client API. For a high level explanation of how the Cypher API maps to the Python client API please see Mapping between Cypher and Python.
This manual is divided into the following chapters:
Installation
Getting started
The graph object
Running algorithms
Machine learning pipelines
The model object
Known limitations
The source code of the library is available at GitHub. If you have a suggestion on how we can improve the library or want to report a problem, you can create a new issue.
Installation
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/algorithms/dijkstra-source-target;"Dijkstra Source-Target Shortest Path
Contents
1. Introduction
2. Syntax
3. Examples
3.1. Memory Estimation
3.2. Stream
3.3. Mutate
3.4. Write
Supported algorithm traits:
Directed
Undirected
Homogeneous
Heterogeneous
Weighted
1. Introduction
The Dijkstra Shortest Path algorithm computes the shortest path between nodes. The algorithm supports weighted graphs with positive relationship weights. The Dijkstra Source-Target algorithm computes the shortest path between a source and a target node. To compute all paths from a source node to all reachable nodes, Dijkstra Single-Source can be used.
The GDS implementation is based on the original description and uses a binary heap as priority queue. The implementation is also used for the A* and Yen’s algorithms. The algorithm implementation is executed using a single thread. Altering the concurrency configuration has no effect.
2. Syntax
This section covers the syntax used to execute the Dijkstra algorithm in each of its execution modes. We are describing the named graph variant of the syntax. To learn more about general syntax variants, see Syntax overview.
Dijkstra syntax per mode
Stream mode
Mutate mode
Write mode
Cypher
Run Dijkstra in stream mode on a named graph.
Copy to Clipboard
CALL gds.shortestPath.dijkstra.stream(
  graphName: String,
  configuration: Map
)
YIELD
  index: Integer,
  sourceNode: Integer,
  targetNode: Integer,
  totalCost: Float,
  nodeIds: List of Integer,
  costs: List of Float,
  path: Path
Table 1. Parameters
Name Type Default Optional Description
graphName
String
n/a
no
The name of a graph stored in the catalog.
configuration
Map
{}
yes
Configuration for algorithm-specifics and/or graph filtering.
Table 2. Configuration
Name Type Default Optional Description
nodeLabels
List of String
['*']
yes
Filter the named graph using the given node labels.
relationshipTypes
List of String
['*']
yes
Filter the named graph using the given relationship types.
concurrency
Integer
4
yes
The number of concurrent threads used for running the algorithm.
jobId
String
Generated internally
yes
An ID that can be provided to more easily track the algorithm’s progress.
sourceNode
Integer
n/a
no
The Neo4j source node or node id.
targetNode
Integer
n/a
no
The Neo4j target node or node id.
relationshipWeightProperty
String
null
yes
Name of the relationship property to use as weights. If unspecified, the algorithm runs unweighted.
Table 3. Results
Name Type Description
index
Integer
0-based index of the found path.
sourceNode
Integer
Source node of the path.
targetNode
Integer
Target node of the path.
totalCost
Float
Total cost from source to target.
nodeIds
List of Integer
Node ids on the path in traversal order.
costs
List of Float
Accumulated costs for each node on the path.
path
Path
The path represented as Cypher entity.
3. Examples
In this section we will show examples of running the Dijkstra algorithm on a concrete graph. The intention is to illustrate what the results look like and to provide a guide in how to make use of the algorithm in a real setting. We will do this on a small transport network graph of a handful nodes connected in a particular pattern. The example graph looks like this:
Cypher
The following Cypher statement will create the example graph in the Neo4j database:
Copy to Clipboard
CREATE (a:Location {name: 'A'}),
       (b:Location {name: 'B'}),
       (c:Location {name: 'C'}),
       (d:Location {name: 'D'}),
       (e:Location {name: 'E'}),
       (f:Location {name: 'F'}),
       (a)-[:ROAD {cost: 50}]->(b),
       (a)-[:ROAD {cost: 50}]->(c),
       (a)-[:ROAD {cost: 100}]->(d),
       (b)-[:ROAD {cost: 40}]->(d),
       (c)-[:ROAD {cost: 40}]->(d),
       (c)-[:ROAD {cost: 80}]->(e),
       (d)-[:ROAD {cost: 30}]->(e),
       (d)-[:ROAD {cost: 80}]->(f),
       (e)-[:ROAD {cost: 40}]->(f);
This graph builds a transportation network with roads between locations. Like in the real world, the roads in the graph have different lengths. These lengths are represented by the cost relationship property.
In the examples below we will use named graphs and native projections as the norm. However, Cypher projections can also be used.
Cypher
The following statement will project a graph using a native projection and store it in the graph catalog under the name 'myGraph'.
Copy to Clipboard
CALL gds.graph.project(
    'myGraph',
    'Location',
    'ROAD',
    {
        relationshipProperties: 'cost'
    }
)
In the following example we will demonstrate the use of the Dijkstra Shortest Path algorithm using this graph.
3.1. Memory Estimation
First off, we will estimate the cost of running the algorithm using the estimate procedure. This can be done with any execution mode. We will use the write mode in this example. Estimating the algorithm is useful to understand the memory impact that running the algorithm on your graph will have. When you later actually run the algorithm in one of the execution modes the system will perform an estimation. If the estimation shows that there is a very high probability of the execution going over its memory limitations, the execution is prohibited. To read more about this, see Automatic estimation and execution blocking.
For more details on estimate in general, see Memory Estimation.
Cypher
The following will estimate the memory requirements for running the algorithm in write mode:
Copy to Clipboard
MATCH (source:Location {name: 'A'}), (target:Location {name: 'F'})
CALL gds.shortestPath.dijkstra.write.estimate('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'cost',
    writeRelationshipType: 'PATH'
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
RETURN nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
Table 10. Results
nodeCount relationshipCount bytesMin bytesMax requiredMemory
6
9
696
696
""696 Bytes""
3.2. Stream
In the stream execution mode, the algorithm returns the shortest path for each source-target-pair. This allows us to inspect the results directly or post-process them in Cypher without any side effects.
For more details on the stream mode in general, see Stream.
Cypher
The following will run the algorithm and stream results:
Copy to Clipboard
MATCH (source:Location {name: 'A'}), (target:Location {name: 'F'})
CALL gds.shortestPath.dijkstra.stream('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'cost'
})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
RETURN
    index,
    gds.util.asNode(sourceNode).name AS sourceNodeName,
    gds.util.asNode(targetNode).name AS targetNodeName,
    totalCost,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).name] AS nodeNames,
    costs,
    nodes(path) as path
ORDER BY index
Table 11. Results
index sourceNodeName targetNodeName totalCost nodeNames costs path
0
""A""
""F""
160.0
[A, B, D, E, F]
[0.0, 50.0, 90.0, 120.0, 160.0]
[Node[0], Node[1], Node[3], Node[4], Node[5]]
The result shows the total cost of the shortest path between node A and node F. It also shows an ordered list of node ids that were traversed to find the shortest path as well as the accumulated costs of the visited nodes. This can be verified in the example graph. Cypher Path objects can be returned by the path return field. The Path objects contain the node objects and virtual relationships which have a cost property.
3.3. Mutate
The mutate execution mode updates the named graph with new relationships. Each new relationship represents a path from source node to target node. The relationship type is configured using the mutateRelationshipType option. The total path cost is stored using the totalCost property.
The mutate mode is especially useful when multiple algorithms are used in conjunction.
For more details on the mutate mode in general, see Mutate.
Cypher
The following will run the algorithm in mutate mode:
Copy to Clipboard
MATCH (source:Location {name: 'A'}), (target:Location {name: 'F'})
CALL gds.shortestPath.dijkstra.mutate('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'cost',
    mutateRelationshipType: 'PATH'
})
YIELD relationshipsWritten
RETURN relationshipsWritten
Table 12. Results
relationshipsWritten
1
After executing the above query, the projected graph will be updated with a new relationship of type PATH. The new relationship will store a single property totalCost.
The relationship produced is always directed, even if the input graph is undirected.
3.4. Write
The write execution mode updates the Neo4j database with new relationships. Each new relationship represents a path from source node to target node. The relationship type is configured using the writeRelationshipType option. The total path cost is stored using the totalCost property. The intermediate node ids are stored using the nodeIds property. The accumulated costs to reach an intermediate node are stored using the costs property.
For more details on the write mode in general, see Write.
Cypher
The following will run the algorithm in write mode:
Copy to Clipboard
MATCH (source:Location {name: 'A'}), (target:Location {name: 'F'})
CALL gds.shortestPath.dijkstra.write('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'cost',
    writeRelationshipType: 'PATH',
    writeNodeIds: true,
    writeCosts: true
})
YIELD relationshipsWritten
RETURN relationshipsWritten
Table 13. Results
relationshipsWritten
1
The above query will write a single relationship of type PATH back to Neo4j. The relationship stores three properties describing the path: totalCost, nodeIds and costs.
The relationship written is always directed, even if the input graph is undirected.
Delta-Stepping Single-Source Shortest Path
Dijkstra Single-Source Shortest Path
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-supported-versions;"Neo4j Supported Versions
Author Phil Stott Applicable versions all Tags support
Neo4j Database Enterprise Edition 5
For reference and planning purposes, the following represents a list of Neo4j 5.x releases, release date, and when that release will no longer be supported by hotfixes. This is the release of the next minor release with the 5.x family and will be on a regular cadence.
Review our Neo4j 5.x Support Terms for reference.
Release Release Date Hotfixes until Compatible Driver Versions
5.3
December 15, 2022
Release of 5.4
5.x, 4.4
5.2
November 21, 2022
Release of 5.3
5.x, 4.4
5.1 GA
October 24, 2022
Release of 5.2
5.x, 4.4
5.0 LA
October 06, 2022
October 24, 2022
5.x, 4.4
Notes:
GA denotes Neo4j 5.1 was the first General Availability (GA) release version, being publicly available for all customers to use.
LA denotes that Neo4j 5.0 was a Limited Availabilty release only and was released to specific customers.
Neo4j Database Enterprise Edition 4
For reference and planning purposes, the following represents a list of Neo4j 4.x releases, their release date, and date at which that release will no longer be supported.
Review our Neo4j Pre-5.x Support Terms for reference.
Release Release Date End of Support Date Compatible Driver Versions
4.4 LTS
December 2, 2021
June 30, 2025
5.x, 4.4, 4.3, 4.2, 4.1, 4.0
4.3
June 17, 2021
December 16, 2022
4.4, 4.3, 4.2, 4.1, 4.0
4.2
November 17, 2020
May 16, 2022
4.4, 4.3, 4.2, 4.1, 4.0
4.1
June 23, 2020
December 22, 2021
4.4, 4.3, 4.2, 4.1, 4.0
4.0
January 15, 2020
July 14, 2021
4.4, 4.3, 4.2, 4.1, 4.0
Notes:
LTS denotes this is the final version within a major release family and is supported for a longer duration than standard releases.
Neo4j Database Enterprise Edition (1.x-3.x)
Release Release Date End of Support Date Compatible Driver Versions
3.5n1
November 29, 2018
May 27, 2022 n3
4.4, 4.3, 4.2, 4.1, 4.0, 1.7
3.4
May 17, 2018
March 31, 2020 n2
1.7, 1.6
3.3
October 24, 2017
April 28, 2019
1.7, 1.6, 1.5, 1.4
3.2
May 11, 2017
November 31, 2018
1.6, 1.5, 1.4, 1.3
3.1
December 13, 2016
June 13, 2018
1.6, 1.5, 1.4, 1.3, 1.2, 1.1
3.0
April 16, 2016
October 31, 2017
1.5, 1.4, 1.3, 1.2, 1.1, 1.0
2.3
October 21, 2015
April 21, 2017
2.2
March 25, 2015
September 25, 2016
2.1
May 29, 2014
November 29, 2015
2.0
December 11, 2013
June 11, 2015
1.9
May 21, 2013
November 21, 2014
1.8
September 28, 2012
March 28, 2014
1.7
April 18, 2012
October 18, 2013
1.6
January 22, 2012
July 22, 2013
1.5
November 9, 2011
March 9, 2013
1.4
July 8, 2011
January 8, 2013
1.3
April 12, 2011
September 12, 2012
1.2
December 29, 2010
June 29, 2012
1.1
July 30, 2010
January 30, 2012
1.0
February 23, 2010
August 23, 2011
Notes:
n1 Last minor version of the major version.
n2 One-time extension for 3.4 only.
n3 One-time extension for 3.5 only.
The driver major.minor version number describes the feature set available within that driver. Across languages, drivers are generally released at similar times, although patches are driver-dependent. The 1.x series drivers have been built for Neo4j 3.x. It is recommended to always use the latest driver release available. This will ensure that all server functionality is made available to client applications.
Was this page helpful?"
https://neo4j.com/developer/kb;"Promoted Articles
Neo4j 3.5 to 4.x Migration Help and Resources
This guide is designed to provide key details and links on various 3.5 to 4.x migration resources. With this document, you should be able to read and/or find everything you…
Read more
Neo4j 4.2.x Security Vulnerability Fixed in Release 4.2.8
Affected products Neo4j 4.2.x Enterprise and Aura Cloud before 2021-06-18 Unaffected versions: Neo4j Community Edition, all Enterprise versions prior to 4.2 and Aura Cloud from 2021-06-18. Additionally Neo4j 4.3.x includes…
Read more
Neo4j Supported Versions
Neo4j Database Enterprise Edition 5 For reference and planning purposes, the following represents a list of Neo4j 5.x releases, release date, and when that release will no longer be supported…
Read more
Split between APOC Core and APOC Extended
With the release of Neo4j 5, the APOC library has been split into two separate packages: APOC Core and APOC Extended. APOC Core Neo4j 5 brings substantially more support to…
Read more
Browse By Category
bloom
bloom
2
perspectives
1
recovery
1
browser
cypher
57
configuration
24
bolt
13
browser
10
cypher-shell
7
cluster
configuration
24
cluster
15
backup
14
import
13
bolt
13
cypher
cypher
57
configuration
24
performance
21
apoc
19
cluster
15
desktop
configuration
24
import
13
installation
11
linux
9
desktop
5
development
logging
20
apoc
19
installation
11
upgrade
11
procedures
7
developmnt
cypher-shell
7
favorites
1
drivers
cypher
57
security
15
cluster
15
bolt
13
transaction
8
gds
storage
6
analytics
1
graph
1
gds
1
geospatial
cypher
57
configuration
24
import-export
cypher
57
logging
20
apoc
19
import
13
server
13
installation
configuration
24
performance
21
security
15
server
13
installation
11
neo4j-indexes
cypher
57
schema
4
indexes
1
capacity planning
1
neo4j-spark-connector
spark
1
pyspark
1
databricks
1
neo4j-spark-connector
1
operations
cypher
57
configuration
24
performance
21
logging
20
apoc
19
performance
configuration
24
performance
21
memory
11
transaction
8
disk
7
security
cypher
57
configuration
24
security
15
operations
11
tls
6
server
apoc
19
bolt
13
upgrade
11
cpu
5
store
4
support
support
3
tools
cypher
57
performance
21
sql
8
jdbc
5
tableau
5"
https://neo4j.com/developer/kb/what-works-with-the-bi-connector;"What Works with the BI Connector
Author Shashi Dookhee Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jdbc sql tableau visualization bi-connector
This article provides an overview of what third-party applications to expect the BI connector work with.
Prerequisites
Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version 3.5.0.9 or 4.0.0.4 of the APOC library respectively.
General overview
The Neo4j BI connector is a JDBC-compliant driver for third-party tools that allows those tools to execute SQL queries directly against a Neo4j server. Other than the prerequisite of APOC (see above), the connector should be seamless for end users.
In principle the connector will work as a data source with any JDBC-compliant application. One thing to note though is that this connector is currently READ ONLY. This means that only select-style queries will work - INSERT, UPDATE or DELETE will NOT work.
Functions and procedures
As the connector translates SQL to Cypher ""under the covers"", it does not support standard Cypher built-in functions or procedure calls from the SQL layer. However, there are a few functions that are supported at the driver level, as follows:
CURDATE() - This will return the current date in m/d/yyyy format.
CURRENT_TIMESTAMP() - This will return the current datetime in ""m/d/yyyy HH:MM:SS [AM|PM]"" format.
NOW() - This will return the current datetime in ""m/d/yyyy HH:MM:SS [AM|PM]"" format.
Known working applications
The following tools have been tested to work with the connector:
Tableau Desktop
Tableau Server
SQuirreL SQL
SQLLine
Expected to work applications
TIBCO SpotFire Server
Looker Server
Looker Hosted
Oracle Analytics Cloud
MicroStrategy Secure Analytics
ThoughtSpot
IBM Cognos
SAP Business Objects
Applications not yet supported
Due to ODBC and/or cloud requirements, the following applications will likely not work natively:
Microsoft PowerBI
Qlik Sense (any version)
TIBCO SpotFire Desktop
TIBCO SpotFire Cloud
Looker Cloud
Domo
Bridge software
Some BI tools recommend the use of bridge software (e.g. TIQ Java Service Connector for Qlik). However, we have not tested this configuration, and cannot confirm that it will work without issues (functional or performance).
Support
The BI connector is a Neo4j supported plugin under existing customer contracts. However, we do NOT support the actual tools (e.g. Tableau), so any support cases must validate that the issue raised by the customer is related specifically to the connector and/or Neo4j server - and not the tool they are using it with. This can generally be confirmed by executing the SQL query the tool is attempting within a JDBC-compliant SQL client, such as SQuirreL SQL.
Additionally, connector support will be limited to Monday to Friday, 9AM to 6PM, Pacific Standard Time.
Things to watch out for
For performance reasons ensure that the Neo4j server has adequate resources. The driver may ""overfetch"" data depending on the query, so adequate resources (especially memory) would make a noticeable impact.
Further reading
See the detailed user guide contained within the distribution package for more information.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-use-the-bi-connector-with-tableau-desktop;"How to use the BI Connector with Tableau Desktop
Author Shashi Dookhee Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jdbc sql tableau visualization bi-connector
This article describes how to use the BI Connector integration with Tableau Desktop.
Prerequisites
Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version 3.5.0.9 or 4.0.0.4 of the APOC library respectively.
Install BI Connector on Tableau Desktop
The first step is to ensure the JAR file has been installed on Tableau Desktop as the data source must be published from Desktop to Server. Install the plugin by dropping the JDBC JAR file in to the appropriate driver directory depending on the platform:
Windows: C:\Program Files\Tableau\Drivers
Mac: ~/Library/Tableau/Drivers
Linux: /opt/tableau/tableau_driver/jdbc
Create datasource to connect to a Neo4j instance
Using Tableau’s ""Other JDBC Connection"" option, you need to create a datasource connected to a Neo4j instance using the appropriate JDBC connection string. For example:
jdbc:neo4j://10.0.0.50:7687
Enter the appropriate credentials in to the connection dialog and you should be able to connect.
Query for some data
Once connected, select the appropriate database on the left side of the screen, following by the appropriate schema (""Node"" or ""Relationship""). This should present a set of found tables. You can drag these tables to create join queries to pull data from Neo4j.
Additional Options
The driver provides for a number of additional options. See the BI Connector user guide (packaged with the JAR file) for details.
Things to watch out for
For performance reasons ensure that the Neo4j server has adequate resources. The driver may ""overfetch"" data depending on the query, so adequate resources (especially memory) would make a noticeable impact.
Was this page helpful?"
https://neo4j.com/developer/kb/query-to-kill-transactions-that-take-longer;"Query to kill transactions that take longer than X seconds and doesn’t contain certain keywords
Author Rohan Kharwar Applicable versions 3.1 3.2 Tags timeout cancel query cypher
In Neo4j we currently have the configuration property referred to as execution guard:
Properties
Copy to Clipboard
dbms.transaction.timeout=30s
that can be set automatically to kill transactions that take more than “x” seconds (x is equal to what is assigned to dbms.transaction.timeout, in this case 30s). However, this is at global level and can’t be controlled for specific User or Query type.
So in order to implement this, a small script can be written and scheduled to run and kill the queries that take more than 30 seconds. This script can be triggered via cypher-shell. The query to kill the transaction that are not part of LOAD CSV and taking more than 30 seconds can be written as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.listQueries() yield query, elapsedTimeMillis, queryId, username
where  NOT query contains toLower(“LOAD"")
and elapsedTimeMillis >30000
with query, collect(queryId) as q
call dbms.killQueries(q) yield queryId
return query, queryId
The query to kill the transaction where the user executing the query is not ""neo4j"" and taking more than 30 seconds:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.listQueries() yield query, elapsedTimeMillis, queryId, username
where  NOT username contains toLower(""neo4j"")
and elapsedTimeMillis >30000
with query, collect(queryId) as q
call dbms.killQueries(q) yield queryId
return query, queryId
You can modify the above query based on either certain parameters for queries or for certain users that should not be killed.
Note: This applies to Neo4j 3.1 and newer only!
So far, so good. If we execute the above query once, it will check once for those long running queries. No repetition what so ever, so far. In order to automate this, we can use apoc:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.repeat(""kill long-running queries"", ""
    call dbms.listQueries() yield query, elapsedTimeMillis, queryId, username
    where NOT username contains toLower(""neo4j"")
    and elapsedTimeMillis >30000
    with query, collect(queryId) as q
    call dbms.killQueries(q) yield queryId
    return query, queryId
"", 10)
In that case, the query to check for the long running queries would be executed every ten seconds on the instance and database, where we have executed the apoc command. Adjust the timing parameters to your needs.
In case you want to manually cancel the job, you can use:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.cancel(""kill long-running queries"")
Note, that those jobs added via apoc.periodic.repeat do not survive restarts of the database. So if we want to install that permanently, we can use apoc’s initializer (https://neo4j.com/labs/apoc/4.4/operational/init-script/):
Add the following line to your conf/apoc.conf file (see also https://neo4j.com/labs/apoc/4.4/config/):
Properties
Copy to Clipboard
apoc.initializer.cypher.1=CALL apoc.periodic.repeat(""kill long-running queries"", ""CALL dbms.listQueries() yield query, elapsedTimeMillis, queryId, username WHERE username contains toLower('neo4j') AND elapsedTimeMillis > 10000 WITH query, collect(queryId) as q CALL dbms.killQueries(q) yield queryId return query, queryId"", 10)
Note that this is on instance level and applies to all databases.
You might want to use a dedicated cypher file on disk to store the query, so that you don’t have complex queries in the config file. Here is an example for doing so: https://neo4j.com/labs/apoc/4.4/operational/init-script/
Was this page helpful?"
https://neo4j.com/developer/kb/ha-proxy-configuration-for-online-backup;"HA Proxy Configuration for Online Backup
Author Dave Gordon Applicable versions 3.5 Tags cluster backup ha-proxy
What are we trying to achieve?
Online backup should be scheduled to run periodically on a production cluster. You only need to run it on one instance, since each has its own full copy of the database. Because a full backup also runs a consistency check, and the copy itself does use some system resources, it is recommended to run this on a slave instance (in HA mode) or a follower or read-replica (in CC mode).
For incremental backups to work, you need to take a backup from the same instance each time and have transaction logs from the last backup. If you do not run from the same instance the store won’t match and it will fallback to taking a full backup. If you want to control which instance you take the backup from, you would need to modify this example or just take a backup directly to that instance without a proxy in between. If you are OK to fallback to full backup, this approach may work for you.
Causal Clustering: Directing online backup to a follower or read-replica
The sample configuration below defines a front-end where the backup utility will connect to the running database, and a set of instances to check whether they are a slave currently. We assume that online backup is enabled in the conf/neo4j.conf file as follows:
Properties
Copy to Clipboard
online_backup_enabled=true
online_backup_server=0.0.0.0:6362
The haproxy.cfg file for Causal Clustering backup from a Follower would look like this:
Haproxy
Copy to Clipboard
defaults
  mode http
  timeout connect 5000ms
  timeout client 30000ms
  timeout server 30000ms

# Available at http://localhost:8080/haproxy?stats
listen admin
  balance
  mode http
  bind *:8080
  stats enable

frontend neo4j-backup
  mode tcp
  bind *:6362
  default_backend cores-backup

backend cores-backup
  balance roundrobin
  option httpchk GET /db/server/core/read-only HTTP/1.0
  mode tcp

  server neo4j-1 neo4j-1:6362
  server neo4j-2 neo4j-2:6362
  server neo4j-3 neo4j-3:6362
View all (11 more lines)
To backup from a read-replica, replace the option httpchk line with:
option httpchk GET /db/manage/server/read-replica/available HTTP/1.0
HA: Directing online backup to a slave
The haproxy.cfg file for HA mode would look like this:
Haproxy
Copy to Clipboard
defaults
  mode http
  timeout connect 5000ms
  timeout client 30000ms
  timeout server 30000ms

# Available at http://localhost:8080/haproxy?stats
listen admin
  balance
  mode http
  bind *:8080
  stats enable

frontend neo4j-backup
  mode tcp
  bind *:6362
  default_backend slaves-backup

backend slaves-backup
  balance roundrobin
  option httpchk GET /db/manage/server/ha/slave HTTP/1.0
  mode tcp

  server neo4j-1 neo4j-1:6362
  server neo4j-2 neo4j-2:6362
  server neo4j-3 neo4j-3:6362
View all (11 more lines)
Assuming the haproxy DNS name is something like neo4j-backup-slaves, the backup command would look like the following:
Shell
Copy to Clipboard
$ ./bin/neo4j-admin backup --name=backup.db --backup-dir /tmp/backups --from=neo4j-backup-slaves:6362
Or the now deprecated neo4j-backup tool:
Shell
Copy to Clipboard
$ ./bin/neo4j-backup -to /tmp/backups -host neo4j-backup-slaves -port 6362
Was this page helpful?"
https://neo4j.com/developer/kb/how-can-i-skip-consistency-check-during-backup;"Retired: How can I skip Consistency Check during Backup?
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags backup consistency performance
Backups in Neo4j automatically run a consistency check against the backed-up store. The backup itself does not take overly long, but the consistency check can take much more time to complete, depending on the store.
In some cases, you want to skip the check on backup, with the option to run it manually at some other (more convenient) time. To do this, run the neo4j-backup tool with the -verify false option:
$ ./bin/neo4j-backup -from single://127.0.0.1 -to /tmp/foo -verify false
Now, if you skip the consistency check during backup and run it manually later, you have the option to try to tune it to run faster.
The instructions and configuration options are documented in a separate article link:run consistency check manually.adoc[here].
Was this page helpful?"
https://neo4j.com/developer/kb/copy-store-between-instances;"How do I resolve inconsistency problems on an instance of a cluster
Author Jose Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster master slave backup consistency
(if using HA (High Availability, please read Leader and Follower instead of Master and Slave respectively)
Sometimes, when running a clustered Neo4j environment, a slave’s store may become inconsistent. On a normal day-to-day operation, if a slave becomes inconsistent, it will automatically try to resolve the problem by fetching data from the master instance. At times though, this may not be possible. For example, if a slave is offline for an extended period of time, this may result in missing transaction log files on the master instance, making it impossible to replay all the transactions on the slave instance and therefore making it impossible to catch up. This will result in the slave not being able to join the cluster due to an inconsistent store. If this happens, the following steps can be used in order to fully restore a slave store with a full backup from the master instance.
Due to the dangerous nature of this operation, we advise always logging a support ticket before proceeding with it.
Steps:
Identify error in log files
Identify master instance
Run backup on master
Move backup to faulty slave
Stop instance
Backup the old storage [Optional]
Restore backup
Start instance
Clean old files [Optional]
1. Identify error in log files
2017-02-12 15:33:37.334+0000 INFO  [o.n.k.h.c.SwitchToSlaveBranchThenCopy] The store is inconsistent. Will treat it as branched and fetch a new one from the master
2017-02-12 15:33:37.334+0000 WARN  [o.n.k.h.c.SwitchToSlaveBranchThenCopy] Current store is unable to participate in the cluster; fetching new store from master The master is missing the log required to complete the consistency check
2. Identify master instance
If you’re running an High Availability (HA) cluster
We can make use of a HTTP endpoint to discover which instance is the master: /db/manage/server/ha/master. From the command line, a common way to ask those endpoints is to use curl. With no arguments, curl will do an HTTP GET on the URI provided and will output the body text, if any. If you also want to get the response code, just add the -v flag for verbose output:
Shell
Copy to Clipboard
$ curl -v localhost:7474/db/manage/server/ha/master
*   Trying 127.0.0.1
* Connected to localhost (127.0.0.1) port 7474 (#0)
> GET /db/manage/server/ha/master HTTP/1.1
> Host: localhost:7474
> Accept: */*
>
< HTTP/1.1 200 OK
< Date: Fri, 17 Feb 2017 16:38:37 GMT
< Content-Type: text/plain
< Access-Control-Allow-Origin: *
< Transfer-Encoding: chunked
< Server: Jetty(6.1.25)
<
* Connection #0 to host localhost left intact
true
Table 1. HA HTTP endpoint responses:
Endpoint Instance State Returned Code Body text
/db/manage/server/ha/master
Master
200 OK
true
Slave
404 Not Found
False
Unknown
404 Not Found
UNKNOWN
(If the Neo4j server has Basic Security enabled, the HA status endpoints will also require authentication credentials. If authentication is required, run the curl command with the --user switch (curl -v localhost:7474/db/manage/server/ha/master --user <username>:<password>)
More information on HA HTTP endpoints can be found here: https://neo4j.com/docs/operations-manual/current/clustering/high-availability/http-endpoints/
If you’re running Causal Cluster (CC) (Neo4j v3.1.x forward)
There are two ways of getting the instance role when using CC, procedures or HTTP endpoints:
1) Procedure dbms.cluster.role() or dbms.cluster.overview()
CALL dbms.cluster.role()
The procedure dbms.cluster.role() can be called on every instance in a Causal Cluster to return the role of the instance. Returns a string with the role of the current instance.
CALL dbms.cluster.overview()
The procedure dbms.cluster.overview() provides an overview of cluster topology by returning details on all the instances in the cluster. Returns the IDs, addresses and roles of the cluster instances (this procedure can only be called from Core instances, since they are the only ones that have the full view of the cluster).
2) HTTP endpoints for CC
As in HA, we can make use of a HTTP endpoint to discover which instance is the master: /db/manage/server/core/writable. From the command line, a common way to ask those endpoints is to use curl. With no arguments, curl will do an HTTP GET on the URI provided and will output the body text, if any. If you also want to get the response code, just add the -v flag for verbose output:
Shell
Copy to Clipboard
$ curl -v localhost:7474/db/manage/server/core/writable
*   Trying ::127.0.0.1
* Connected to localhost (127.0.0.1) port 7474 (#0)
> GET /db/manage/server/core/writable HTTP/1.1
> Host: localhost:7474
> Accept: */*
>
< HTTP/1.1 200 OK
< Date: Fri, 17 Feb 2017 16:38:37 GMT
< Content-Type: text/plain
< Access-Control-Allow-Origin: *
< Transfer-Encoding: chunked
< Server: Jetty(9.2.9 v20150224)
<
* Connection #0 to host localhost left intact
true
Table 2. CC HTTP endpoint responses:
Endpoint Instance State Returned Code Body text
/db/manage/server/core/writable
Leader
200 OK
true
Follower
404 Not Found
False
Unknown
404 Not Found
UNKNOWN
(If the Neo4j server has Basic Security enabled, the CC status endpoints will also require authentication credentials. If authentication is required, run the curl command with the --user switch (curl -v localhost:7474/db/manage/server/ha/master --user <username>:<password>)
3. Run backup on master
Perform a full backup: Create an empty directory (i.e: /mnt/backup) and run the backup command:
Shell
v3.0.x
Copy to Clipboard
$ neo4j-backup -host <address> -to <backup-path>
Shell
v3.1.x+
Copy to Clipboard
$ neo4j-admin backup --backup-dir=<backup-path> --name=<graph.db-backup> [--from=<address>] [--fallback-to-full[=<true|false>]] [--check-consistency[=<true|false>]] [--cc-report-dir=<directory>] [--additional-config=<config-file-path>] [--timeout=<timeout>]
Shell
Copy to Clipboard
neo4j-home> mkdir /mnt/backup
neo4j-home> bin/neo4j-admin backup --from=192.168.1.34 --backup-dir=/mnt/backup --name=graph.db-backup
Doing full backup...
2017-02-01 14:09:09.510+0000 INFO  [o.n.c.s.StoreCopyClient] Copying neostore.nodestore.db.labels
2017-02-01 14:09:09.537+0000 INFO  [o.n.c.s.StoreCopyClient] Copied neostore.nodestore.db.labels 8.00 kB
2017-02-01 14:09:09.538+0000 INFO  [o.n.c.s.StoreCopyClient] Copying neostore.nodestore.db
2017-02-01 14:09:09.540+0000 INFO  [o.n.c.s.StoreCopyClient] Copied neostore.nodestore.db 16.00 kB
...
...
...
If you do a directory listing of /mnt/backup you will see that you have a backup of Neo4j called graph.db-backup.
More information on performing backups can be found here: https://neo4j.com/docs/operations-manual/current/backup/perform-backup/
4. Move backup to faulty slave
To copy a file from master to slave while logged into master:
Shell
Copy to Clipboard
$ scp -r /path/to/neo4j/backup username@<SLAVE_ADDRESS>:/path/to/destination
5. Stop instance
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/neo4j stop
6. Backup the old storage [Optional]
It is advisable to keep the current slave store in order to rollback the operation if needed. To do this, we only need to rename the current store directory:
Shell
Copy to Clipboard
$ mv $NEO4J_HOME/data/databases/graph.db $NEO4J_HOME/data/databases/graph.db-old
7. Restore backup (for Neo4j 3.0 and earlier simply copy the backup directory into graph.db)
Restore backup based on the backup created on the master instance (assuming backup location /mnt/backup and database backup name graph.db-backup, please change accordingly)
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/neo4j-admin restore --from=/mnt/backup --database=graph.db-backup --force
More information on restoring backups can be found here: https://neo4j.com/docs/operations-manual/current/backup/restore-backup/
8. Start instance
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/neo4j start
The slave should now start normally. It will catch up with the master in order to fetch the missed transactions from the period when the backup was created until the moment of the restore.
9. Clean old files [Optional]
This step is only relevant if you backed up the old storage on the slave instance (step 6)
Once you confirm the system is healthy, the slave is back online and consistent with the master instance, we can remove the old store:
Shell
Copy to Clipboard
$ rm -rf $NEO4J_HOME/data/databases/graph.db-old
Was this page helpful?"
https://neo4j.com/developer/kb/causal-cluster-faq-for-heavy-workloads;"Causal Cluster FAQ for heavy workloads
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster leader follower writes latency bookmark
Lagging of follower instances and what causes it?
The main reason for followers to fall behind is highly concurrent and continuous read/write workloads. This can cause the instances get overwhelmed which causes some extra latency in propagating the data to the followers (mainly due to lack of available threads to do so).
How can I have a general expectation regarding latency?
We don’t have numbers, nor do we have tools to know the expected latency (in time) because this depends on a combination of different factors such as size of transactions, concurrency, volume of workload, hardware, network latency, etc. It’s virtually impossible to correlate all of this and come up with general expectations regarding latency.
We use transaction IDs to determine how far (in transaction number) a follower is behind its leader. You can check this KB article on How to monitor if a Follower is in sync with the Leader
Causal Clustering relies on the Raft protocol to ensure that the data is safely durable before confirming transaction commit. In practice this means a majority of Core Servers in your cluster will already have (accepted) that transaction thus making it closer to the Leader in terms of sync due to the nature of the Raft protocol (you can have a look at this: http://thesecretlivesofdata.com/raft/ which explains the raft protocol in an interactive way).
One way to measure the lag would be to set up a simple test case with 2 clients using bookmarks whilst under heavy load. This test case would have client 1 write to the database and use a bookmark, recording the time of commit; then have client 2 try to read the data using the same bookmark and record the time it took for the data to be available. Measuring this with different workloads will give you an idea of what to expect and how that value changes with your load.
You can read more about specific driver causal chaining and bookmarks in the below links JAVA documentation JavaScript documentation Go documentation .NET documentation Python documentation
Should I consider using the leader for read-only transactions
This question arises because of the usage of explicit write transactions for reads, in order to get routed directly to the leader and thus getting the most up-to-date data faster.
While this may seem like a way to work around latency issues, our best practices are very straightforward in this aspect: use write transactions for writes; read transactions for reads. Using write transactions for reads means that the leader is being used to serve most (or all!) of your requests. This will cause even more stress on the leader, consequently increasing the possibility of the leader getting overwhelmed and ultimately causing even more lag on the followers.
If your leader is always under constant heavy load, this alone may increase the latency. Distributing the load across the cluster is the recommended approach. The less work the leader has to do the faster it propagates the data to the rest of the instances in the cluster. This means that the followers will have the data more promptly, making it feasible to use followers for reads and the leader only for writes - as per the best practices.
How to minimize the impact of lagging on followers?
There are 2 main things you should aim to do in order to minimise the lagging:
Lower the number of concurrent transactions because this is effectively what makes the followers fall behind.
Decrease transaction size. Obviously larger transactions will take longer to commit, not only on the leader but also on the follower instances which may also cause lagging
We’re constantly working towards improving all areas of Neo4j and this is one is no exception. Recent deliveries have features that improve the experience in situations of heavy workloads such as:
Cache pre-warming: to enable instances to have their cache warmed on startup, preventing the new instances from falling behind immediately after joining the cluster due to not having the cache as ready as the Leader (thus increasing query duration and lagging possibility)
Improvements in raft consensus: this significantly improves write performance across the cluster for large transactions. We can now process much larger transactions at the same rate as smaller ones.
Transaction state consumes less memory (moving transactions off-heap, working together with native indexing): to put less stress on the JVM making the overall system more stable and less prone to GC pauses and lagging
Bolt thread pooling: to limit and push-back the number of active threads on the leader. This is what will make a more significant impact on this behaviour because this is the way we now have to throttle the load on the leader. With this feature, we can play around with the config settings in order to achieve the maximum possible throughput, without putting the leader in a situation that it cannot even propagate the data across the cluster. You can read more about the bolt thread pooling feature and how to configure it here.
Should I use causal chaining/bookmarks? (and its impact on propagation time)
In order to better understand this topic, we recommend having a look at our documentation first, namely an introduction to Neo4j Causal Clustering.
In a short explanation, we can say that - when invoked - causal consistency ensures that a client is guaranteed to read at least its own writes. The way to enforce this is by using bookmarks, and these come into play when executing a transaction. The client can ask for a bookmark which it then presents as a parameter to subsequent transactions. Using that bookmark, the cluster can ensure that only servers which have processed the client’s bookmarked transaction will run its next transaction.
This will not have an impact on data propagation. Your data will be propagated the same way, as per the Raft protocol rules (see the link mentioned above). Having said that, depending on your use case requirements, you may need to make a design choice:
If you absolutely need to read your own writes, using bookmarks will ensure that. Your subsequent requests will be served by an instance that has the data corresponding to the bookmark used on the write. You will take a hit on data access time because you need to wait for the information to be available. An example of this can be a comment on a news feed: you write a comment to the database and you absolutely need that information to pop up straight after.
Not using bookmarks means that subsequent reads may or may not have the latest data. You will have a faster access to data but since you do not provide the means for a casual chain, the data you read might not be up to date and you may retrieve unwanted results. An example of this might be an online store’s (non-real-time) recommendation system: you will be recommended products based on your past purchases and if you purchase something new, you will update the database. However, that newly added information will only be used to recommend products for a future purchase.
You need to decide whether your use case requires this causal chain to ensure truly consistent results or does it require the fastest data access, even though it may not be the most up to date? Or maybe some clients require a stronger consistency than others? As said above, this is a design choice and one must choose what fits the use case better.
Was this page helpful?"
https://neo4j.com/docs/apoc/5/help;"Built in Help
Contents
Procedure & Function Signatures
The APOC library ships with the apoc.help procedure, which can be used for procedure and function discovery.
Running call apoc.help('keyword') will lists all procedures and functions that have the keyword in their name. If no keyword is provided, it will return a list of all APOC procedures and functions, along with their signatures and descriptions.
If you use RETURN apoc.version() it displays the current APOC version.
To generate the help output, this procedure uses SHOW PROCEDURES and SHOW FUNCTIONS.
Procedure & Function Signatures
To call procedures correctly, you need to know their parameter names, types and positions. And for YIELDing their results, you have to know the output column names and types.
INFO:The signatures are shown in error messages, if you use a procedure incorrectly.
You can see the procedures signature in the output of CALL apoc.help(""name"")
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.help(""levenshteinDistance"")
The signature is always name : : TYPE, so in this case:
apoc.text.levenshteinDistance
(text1 :: STRING?, text2 :: STRING?)
:: (INTEGER?)
Table 1. Parameter Explanation
Name Type
Procedure Parameters
text1
String
text2
String
Output Return Columns
result
Integer
Installation
Procedures & Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/installation;"Installation
Contents
APOC
Neo4j Desktop
Neo4j Server
Docker
Restricted procedures/functions
APOC is packaged with Neo4j and can be found in the $NEO4J_HOME/labs directory.
APOC
APOC can be installed by moving the APOC jar file from the $NEO4J_HOME/labs directory to the $NEO4J_HOME/plugins directory and restarting Neo4j.
Neo4j Desktop
APOC can be installed with Neo4j Desktop, after creating your database, by going to the Manage screen, and then the Plugins tab. Click Install in the APOC box and wait until you see a green check mark near ""APOC"".
Neo4j Server
Since APOC relies on Neo4j’s internal APIs you need to use the matching APOC version for your Neo4j installation. Make sure that the first two version numbers match between Neo4j and APOC.
Go to the latest release for Neo4j version 5.0 and download the binary jar to place into your $NEO4J_HOME/plugins folder.
You can find all releases here.
After you move the jar file to the plugins folder you have to restart neo4j with neo4j restart
APOC uses a consistent versioning scheme: <neo4j-version>.<apoc> version. The trailing <apoc> part of the version number will be incremented with every apoc release.
The version compatibility matrix explains the mapping between Neo4j and APOC versions:
apoc version neo4j version
5.3.0
5.3.0 (5.3.x)
5.2.1
5.2.0 (5.2.x)
5.1.0
5.1.0 (5.1.x)
5.0.0
5.0.0 (5.0.x)
4.4.0.1
4.4.0 (4.4.x)
If by mistake a jar not compatible with the neo4j version is inserted, a log.warn like this will appear in neo4j.log:
None
Copy to Clipboard
The apoc version (<APOC_VERSION>) and the Neo4j DBMS versions [NEO4J_VERSION] are incompatible.
To view the correct version of the compatibility matrix, go to: https://neo4j.com/labs/apoc/5.0/installation/
Docker
APOC can be used with the Neo4j Docker image via the NEO4J_PLUGINS environment variable. If we use this environment variable, the APOC plugin will be downloaded and configured at runtime.
This feature is intended to facilitate using APOC in development environments, but it is not recommended for use in production environments.
Bash
The following runs Neo4j 5.0 in a Docker container with the latest version of the APOC Library
Copy to Clipboard
docker run \
    -p 7474:7474 -p 7687:7687 \
    -v $PWD/data:/data -v $PWD/plugins:/plugins \
    --name neo4j-apoc \
    -e apoc.export.file.enabled=true \
    -e apoc.import.file.enabled=true \
    -e apoc.import.file.use_neo4j_config=true \
    -e NEO4J_PLUGINS=\[\""apoc\""\] \
    neo4j:5.0
We should see the following two lines in the output after running this command:
Text
Copy to Clipboard
Fetching versions.json for Plugin 'apoc' from https://neo4j.github.io/apoc/versions.json
Installing Plugin 'apoc' from https://github.com/neo4j/apoc/releases/download/5.0.0-rc01/5.0.0-rc01.jar to /plugins/apoc.jar
In a production environment we should download the APOC release matching our Neo4j version and, copy it to a local folder, and supply it as a data volume mounted at /plugins.
Bash
The following downloads the APOC Library into the plugins directory and then mounts that folder to the Neo4j Docker container
Copy to Clipboard
mkdir plugins
pushd plugins
wget https://github.com/neo4j/apoc/releases/download/5.0.0-rc01/apoc-5.0.0-rc01.jar
popd
docker run --rm -e NEO4J_AUTH=none -p 7474:7474 -v $PWD/plugins:/plugins -p 7687:7687 neo4j:5.0
If you want to pass custom apoc config to your Docker instance, you can use environment variables, like here:
Bash
Copy to Clipboard
docker run \
    -p 7474:7474 -p 7687:7687 \
    -v $PWD/data:/data -v $PWD/plugins:/plugins \
    --name neo4j-apoc \
    -e apoc.export.file.enabled=true \
    -e apoc.import.file.enabled=true \
    -e apoc.import.file.use_neo4j_config=true \
    neo4j
Restricted procedures/functions
For security reasons, procedures that use internal APIs are disabled by default. They can be enabled by specifying config in $NEO4J_HOME/conf/neo4j.conf e.g. dbms.security.procedures.unrestricted=apoc.*
If you want to do this when using the Neo4j Docker container, you need to amend -e NEO4J_dbms_security_procedures_unrestricted=apoc.\\\* to your docker run … command. The three backslashes are necessary to prevent wildcard expansions.
You can also whitelist procedures and functions in general to be loaded using: dbms.security.procedures.whitelist=apoc.coll.*,apoc.load.*
Introduction
Built in Help
Was this page helpful?"
https://neo4j.com/docs/apoc/5/introduction;"Introduction
Contents
History
Example
Note about the Neo4j memory tracker
This introduction contains a brief history of the APOC Library, an example of an APOC procedure used within a Cypher statement, and a note about the Neo4j memory tracker.
History
For a brief introduction to the history and development of the APOC Library by Michael Hunger, Senior Director of User Innovation at Neo4j, watch this short video:
Neo4j 3.x introduced the concept of user-defined procedures and functions. These procedures and functions are implemented in Java and can be deployed into a Neo4j instance, and then be called from Cypher directly.
There are over 400 different procedures and functions in the APOC library. Their purpose is to increase functionality in areas such as data integration, graph algorithms and data conversion.
APOC Name History
APOC was the first bundled Package Of Component for Neo4j in 2009. It stands for ""Awesome Procedures On Cypher"".
Apoc was also the technician and driver on board of the Nebuchadnezzar in the first Matrix movie. He was killed by another character called Cypher.
APOC is available in Neo4j AuraDB. For a full list of the APOC procedures and functions supported by Aura, go to the Aura page for APOC. APOC is also available in Neo4j Sandbox, Docker, and Neo4j Desktop. Finally, the APOC library can be made available in self-hosted databases by installing the APOC jar.
A full list of all the functions and procedures available in the APOC library can be found in Procedures & Functions.
As of Neo4j version 5.0, APOC has been split into separate repositories, one being the main, officially supported, APOC Library. The other belonging to APOC Extended. This documentation handles the officially supported part of APOC.
Example
User defined functions can be used in any expression or predicate, similar to built-in functions.
Procedures can be called stand-alone using CALL procedure.name();
Procedures can also be integrated into Cypher statements.
The below example demonstrates how the procedure apoc.load.json can be integrated in a Cypher statement:
Cypher
Load JSON example
Copy to Clipboard
Run in Neo4j Browser
WITH 'https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/person.json' AS url

CALL apoc.load.json(url) YIELD value as person

MERGE (p:Person {name: person.name})
   ON CREATE SET p.age = person.age, p.children = size(person.children)
For further examples using specific APOC procedures and functions, please see the Procedures & Functions.
Note about the Neo4j memory tracker
Before using the APOC library, it is important to note that APOC procedures are not detected by the Neo4j Memory Tracker. They will, therefore, not terminate if they exceed the available memory in the database.
For example, the procedure apoc.path.expand will not stop if dbms.memory.transaction.database_max_size is reached.
Moreover, it is not possible to use the SHOW TRANSACTIONS YIELD currentQuery, estimatedUsedHeapMemory command to monitor the memory usage of a query.
In order to avoid Java Heap Space errors, the APOC procedures should therefore be used carefully.
Overview
Installation
Was this page helpful?"
https://neo4j.com/docs/apoc/5;"APOC user guide for Neo4j v5
This is the page for APOC Core documentation. For APOC Extended, go to the APOC Extended page.
The guide covers the following areas:
Introduction — An Introduction to the APOC library.
Installation — Installation instructions for the library.
Built in Help — In-built help in the library.
Procedures & Functions — A list of all APOC procedures and functions.
Configuration Options — Configuration options used by the library.
Import — A detailed guide to procedures that can be used to import data from different formats including JSON, CSV, and XLS.
Export — A detailed guide to procedures that can be used to export data to different formats including JSON, CSV, GraphML, and Gephi.
Graph Refactoring — A detailed guide to procedures that can be used to refactor graphs.
Graph updates — A detailed guide to procedures that can be used to apply graph updates.
Data Structures — A detailed guide to procedures and functions, that can be used to work with data structures.
Temporal (Date Time) — A detailed guide to procedures that can be used to format temporal types.
Mathematical Operations — A detailed guide to procedures and functions that can be used for mathematical operations.
Advanced Graph Querying — A detailed guide to procedures that can be used for advanced graph querying.
Comparing Graphs — A detailed guide to procedures that can be used to compare graphs.
Cypher Execution — A detailed guide to procedures that can be used for Cypher scripting.
Virtual Nodes & Relationships (Graph Projections) — A detailed guide to procedures that can be used to create virtual nodes and relationships.
Background Operations — A detailed guide to procedures that can be used for background job management.
Database Introspection — A detailed guide to procedures that can be used to introspect the database.
Operational — A detailed guide to operational procedures.
Miscellaneous — A detailed guide to miscellaneous procedures and functions, including map and collection functions, text functions, and spatial functionality.
Text and Lookup Indexes — A detailed guide to indexing procedures.
Graph Algorithms — A detailed guide to Graph Algorithms.
Introduction
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview;"Procedures & Functions
Contents
apoc.couchbase
apoc.custom
apoc.cypher
apoc.dv
apoc.es
apoc.export
apoc.generate
apoc.load
apoc.log
apoc.metrics
apoc.mongo
apoc.mongodb
apoc.monitor
apoc.nlp
apoc.redis
apoc.static
apoc.trigger
apoc.ttl
apoc.uuid
This is the page for APOC Extended documentation. For the officially supported APOC Core, go to the APOC Core page.
apoc.bolt
Qualified Name Type
apoc.bolt.load
apoc.bolt.load(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for read
Procedure
apoc.bolt.load.fromLocal
Procedure
apoc.config
Qualified Name Type
apoc.config.list
apoc.config.list | Lists the Neo4j configuration as key,value table
Procedure
apoc.config.map
apoc.config.map | Lists the Neo4j configuration as map
Procedure
apoc.couchbase
Qualified Name Type
apoc.couchbase.append
apoc.couchbase.append(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - append a couchbase json document to an existing one.
Procedure
apoc.couchbase.exists
apoc.couchbase.exists(hostOrKey, bucket, documentId, config) yield value - check whether a couchbase json document with the given ID does exist.
Procedure
apoc.couchbase.get
apoc.couchbase.get(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - retrieves a couchbase json document by its unique ID.
Procedure
apoc.couchbase.insert
apoc.couchbase.insert(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - insert a couchbase json document with its unique ID.
Procedure
apoc.couchbase.namedParamsQuery
apoc.couchbase.namedParamsQuery(hostkOrKey, bucket, statement, paramNames, paramValues, config) yield queryResult - executes a N1QL statement with named parameters.
Procedure
apoc.couchbase.posParamsQuery
apoc.couchbase.posParamsQuery(hostOrKey, bucket, statement, params, config) yield queryResult - executes a N1QL statement with positional parameters.
Procedure
apoc.couchbase.prepend
apoc.couchbase.prepend(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - prepend a couchbase json document to an existing one.
Procedure
apoc.couchbase.query
apoc.couchbase.query(hostOrKey, bucket, statement, config) yield queryResult - executes a plain un-parameterized N1QL statement.
Procedure
apoc.couchbase.remove
apoc.couchbase.remove(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - remove the couchbase json document identified by its unique ID.
Procedure
apoc.couchbase.replace
apoc.couchbase.replace(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - replace the content of the couchbase json document identified by its unique ID.
Procedure
apoc.couchbase.upsert
apoc.couchbase.upsert(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - insert or overwrite a couchbase json document with its unique ID.
Procedure
apoc.custom
Qualified Name Type
apoc.custom.declareFunction
apoc.custom.declareFunction(signature, statement, forceSingle, description) - register a custom cypher function
Procedure
apoc.custom.declareProcedure
apoc.custom.declareProcedure(signature, statement, mode, description) - register a custom cypher procedure
Procedure
apoc.custom.list
apoc.custom.list() - provide a list of custom procedures/function registered
Procedure
apoc.custom.removeFunction
apoc.custom.removeFunction(name, type) - remove the targeted custom function
Procedure
apoc.custom.removeProcedure
apoc.custom.removeProcedure(name) - remove the targeted custom procedure
Procedure
apoc.cypher
Qualified Name Type
apoc.cypher.mapParallel
apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
apoc.cypher.mapParallel2
apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
apoc.cypher.parallel
apoc.cypher.parallel(fragment, paramMap, keyList) yield value - executes fragments in parallel through a list defined in paramMap with a key keyList
Procedure
apoc.cypher.parallel2
apoc.cypher.parallel2(fragment, paramMap, keyList) yield value - executes fragments in parallel batches through a list defined in paramMap with a key keyList
Procedure
apoc.cypher.runFile
apoc.cypher.runFile(file or url,[{statistics:true,timeout:10,parameters:{}}]) - runs each statement in the file, all semicolon separated - currently no schema operations
Procedure
apoc.cypher.runFiles
apoc.cypher.runFiles([files or urls],[{statistics:true,timeout:10,parameters:{}}])) - runs each statement in the files, all semicolon separated
Procedure
apoc.cypher.runSchemaFile
apoc.cypher.runSchemaFile(file or url,[{statistics:true,timeout:10}]) - allows only schema operations, runs each schema statement in the file, all semicolon separated
Procedure
apoc.cypher.runSchemaFiles
apoc.cypher.runSchemaFiles([files or urls],{statistics:true,timeout:10}) - allows only schema operations, runs each schema statement in the files, all semicolon separated
Procedure
apoc.data
Qualified Name Type
apoc.data.email
apoc.data.email('email_address') as {personal,user,domain} - extract the personal name, user and domain as a map
Function
apoc.dv
Qualified Name Type
apoc.dv.catalog.add
Add a virtualized resource configuration
Procedure
apoc.dv.catalog.list
List all virtualized resource configs
Procedure
apoc.dv.catalog.remove
Remove a virtualized resource config by name
Procedure
apoc.dv.query
Query a virtualized resource by name and return virtual nodes
Procedure
apoc.dv.queryAndLink
Query a virtualized resource by name and return virtual nodes linked using virtual rels to the node passed as first param
Procedure
apoc.es
Qualified Name Type
apoc.es.get
apoc.es.get(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a GET operation on elastic search
Procedure
apoc.es.getRaw
apoc.es.getRaw(host-or-port,path,payload-or-null) yield value - perform a raw GET operation on elastic search
Procedure
apoc.es.post
apoc.es.post(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a POST operation on elastic search
Procedure
apoc.es.postRaw
apoc.es.postRaw(host-or-port,path,payload-or-null) yield value - perform a raw POST operation on elastic search
Procedure
apoc.es.put
apoc.es.put(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a PUT operation on elastic search
Procedure
apoc.es.query
apoc.es.query(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a SEARCH operation on elastic search
Procedure
apoc.es.stats
apoc.es.stats(host-url-Key) - elastic search statistics
Procedure
apoc.export
Qualified Name Type
apoc.export.xls.all
apoc.export.xls.all(file,config) - exports whole database as xls to the provided file
Procedure
apoc.export.xls.data
apoc.export.xls.data(nodes,rels,file,config) - exports given nodes and relationships as xls to the provided file
Procedure
apoc.export.xls.graph
apoc.export.xls.graph(graph,file,config) - exports given graph object as xls to the provided file
Procedure
apoc.export.xls.query
apoc.export.xls.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as xls to the provided file
Procedure
apoc.generate
Qualified Name Type
apoc.generate.ba
apoc.generate.ba(noNodes, edgesPerNode, label, type) - generates a random graph according to the Barabasi-Albert model
Procedure
apoc.generate.complete
apoc.generate.complete(noNodes, label, type) - generates a random complete graph
Procedure
apoc.generate.er
apoc.generate.er(noNodes, noEdges, label, type) - generates a random graph according to the Erdos-Renyi model
Procedure
apoc.generate.simple
apoc.generate.simple(degrees, label, type) - generates a simple random graph according to the given degree distribution
Procedure
apoc.generate.ws
apoc.generate.ws(noNodes, degree, beta, label, type) - generates a random graph according to the Watts-Strogatz model
Procedure
apoc.gephi
Qualified Name Type
apoc.gephi.add
apoc.gephi.add(url-or-key, workspace, data, weightproperty, ['exportproperty']) | streams passed in data to Gephi
Procedure
apoc.get
Qualified Name Type
apoc.get.nodes
apoc.get.nodes(node|id|[ids]) - quickly returns all nodes with these id’s
Procedure
apoc.get.rels
apoc.get.rels(rel|id|[ids]) - quickly returns all relationships with these id’s
Procedure
apoc.load
Qualified Name Type
apoc.load.csv
apoc.load.csv('urlOrBinary',{config}) YIELD lineNo, list, map - load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Procedure
apoc.load.csvParams
apoc.load.csvParams('urlOrBinary', {httpHeader: value}, payload, {config}) YIELD lineNo, list, map - load from CSV URL (e.g. web-api) while sending headers / payload to load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Procedure
apoc.load.directory
apoc.load.directory('pattern', 'urlDir', {config}) YIELD value - Loads list of all files in folder specified by urlDir or in import folder if urlDir string is empty or not specified
Procedure
apoc.load.directory.async.add
apoc.load.directory.async.add(name, cypher, pattern, urlDir, {}) YIELD name, status, pattern, cypher, urlDir, config, error - Add or replace a folder listener with a specific name, pattern and url directory that execute the specified cypher query when an event is triggered and return listener list
Procedure
apoc.load.directory.async.list
apoc.load.directory.async.list() YIELD name, status, pattern, cypher, urlDir, config, error - List of all folder listeners
Procedure
apoc.load.directory.async.remove
apoc.load.directory.async.remove(name) YIELD name, status, pattern, cypher, urlDir, config, error - Remove a folder listener by name and return remaining listeners, if any
Procedure
apoc.load.directory.async.removeAll
apoc.load.directory.async.removeAll() - Remove all folder listeners
Procedure
apoc.load.driver
apoc.load.driver('org.apache.derby.jdbc.EmbeddedDriver') register JDBC driver of source database
Procedure
apoc.load.html
apoc.load.html('url',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Procedure
apoc.load.htmlPlainText
apoc.load.htmlPlainText('urlOrHtml',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Procedure
apoc.load.jdbc
apoc.load.jdbc('key or url','table or statement', params, config) YIELD row - load from relational database, from a full table or a sql statement
Procedure
apoc.load.jdbcUpdate
apoc.load.jdbcUpdate('key or url','statement',[params],config) YIELD row - update relational database, from a SQL statement with optional parameters
Procedure
apoc.load.ldap
apoc.load.ldap(""key"" or {connectionMap},{searchMap}) Load entries from an ldap source (yield entry)
Procedure
apoc.load.xls
apoc.load.xls('url','selector',{config}) YIELD lineNo, list, map - load XLS fom URL as stream of row values, config contains any of: {skip:1,limit:5,header:false,ignore:['tmp'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false, dateFormat:'iso_date', dateParse:['dd-MM-yyyy']}}
Procedure
apoc.log
Qualified Name Type
apoc.log.debug
apoc.log.debug(message, params) - logs debug message
Procedure
apoc.log.error
apoc.log.error(message, params) - logs error message
Procedure
apoc.log.info
apoc.log.info(message, params) - logs info message
Procedure
apoc.log.warn
apoc.log.warn(message, params) - logs warn message
Procedure
apoc.metrics
Qualified Name Type
apoc.metrics.get
apoc.metrics.get(metricName, {}) - retrieve a system metric by its metric name. Additional configuration options may be passed matching the options available for apoc.load.csv.
Procedure
apoc.metrics.list
apoc.metrics.list() - get a list of available metrics
Procedure
apoc.metrics.storage
apoc.metrics.storage(directorySetting) - retrieve storage metrics about the devices Neo4j uses for data storage. directorySetting may be any valid neo4j directory setting name, such as 'server.directories.data'. If null is provided as a directorySetting, you will get back all available directory settings. For a list of available directory settings, see the Neo4j operations manual reference on configuration settings. Directory settings are not paths, they are a neo4j.conf setting key name
Procedure
apoc.model
Qualified Name Type
apoc.model.jdbc
apoc.model.jdbc('key or url', {schema:'<schema>', write: <true/false>, filters: { tables:[], views: [], columns: []}) YIELD nodes, relationships - load schema from relational database
Procedure
apoc.mongo
Qualified Name Type
apoc.mongo.aggregate
apoc.mongo.aggregate(uri, pipeline, $config) yield value - perform an aggregate operation on mongodb collection
Procedure
apoc.mongo.count
apoc.mongo.count(uri, query, $config) yield value - perform a count operation on mongodb collection
Procedure
apoc.mongo.delete
apoc.mongo.delete(uri, query, $config) - delete the given documents from the mongodb collection and returns the number of affected documents
Procedure
apoc.mongo.find
apoc.mongo.find(uri, query, $config) yield value - perform a find operation on mongodb collection
Procedure
apoc.mongo.insert
apoc.mongo.insert(uri, documents, $config) yield value - inserts the given documents into the mongodb collection
Procedure
apoc.mongo.update
apoc.mongo.update(uri, query, update, $config) - updates the given documents from the mongodb collection and returns the number of affected documents
Procedure
apoc.mongodb
Qualified Name Type
apoc.mongodb.get.byObjectId
apoc.mongodb.get.byObjectId(hostOrKey, db, collection, objectIdValue, config(default:{})) - get the document by Object id value
Procedure
apoc.monitor
Qualified Name Type
apoc.monitor.ids
apoc.monitor.ids() returns the object ids in use for this neo4j instance
Procedure
apoc.monitor.kernel
apoc.monitor.kernel() returns informations about the neo4j kernel
Procedure
apoc.monitor.store
apoc.monitor.store() returns informations about the sizes of the different parts of the neo4j graph store
Procedure
apoc.monitor.tx
apoc.monitor.tx() returns informations about the neo4j transaction manager
Procedure
apoc.nlp
Qualified Name Type
apoc.nlp.aws.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
apoc.nlp.aws.entities.stream
Returns a stream of entities for provided text
Procedure
apoc.nlp.aws.keyPhrases.graph
Creates a (virtual) key phrases graph for provided text
Procedure
apoc.nlp.aws.keyPhrases.stream
Returns a stream of key phrases for provided text
Procedure
apoc.nlp.aws.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
apoc.nlp.aws.sentiment.stream
Returns stream of sentiment for items in provided text
Procedure
apoc.nlp.azure.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
apoc.nlp.azure.entities.stream
Provides a entity analysis for provided text
Procedure
apoc.nlp.azure.keyPhrases.graph
Creates a (virtual) key phrase graph for provided text
Procedure
apoc.nlp.azure.keyPhrases.stream
Provides a entity analysis for provided text
Procedure
apoc.nlp.azure.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
apoc.nlp.azure.sentiment.stream
Provides a sentiment analysis for provided text
Procedure
apoc.nlp.gcp.classify.graph
Classifies a document into categories.
Procedure
apoc.nlp.gcp.classify.stream
Classifies a document into categories.
Procedure
apoc.nlp.gcp.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
apoc.nlp.gcp.entities.stream
Returns a stream of entities for provided text
Procedure
apoc.redis
Qualified Name Type
apoc.redis.append
apoc.redis.append(uri, key, value, {config}) | Execute the 'APPEND key value' command
Procedure
apoc.redis.configGet
apoc.redis.configGet(uri, parameter, {config}) | Execute the 'CONFIG GET parameter' command
Procedure
apoc.redis.configSet
apoc.redis.configSet(uri, parameter, {config}) | Execute the 'CONFIG SET parameter value' command
Procedure
apoc.redis.copy
apoc.redis.copy(uri, source, destination, {config}) | Execute the 'COPY source destination' command and returns true if source was copied and false otherwise
Procedure
apoc.redis.eval
apoc.redis.eval(uri, script, outputType, keys, values, {config}) | Execute the 'EVAL script' command. In the parameters provided to the procedure, keys are bound to the KEYS[n] like special array of the Lua script and values are bound to the ARGV[n] like special array of the Lua script.
Procedure
apoc.redis.exists
apoc.redis.exists(uri, keys, {config}) | Execute the 'EXISTS keys' command
Procedure
apoc.redis.get
apoc.redis.get(uri, key, {config}) | Execute the 'GET key' command
Procedure
apoc.redis.hdel
apoc.redis.hdel(uri, key, fields, {config}) | Execute the 'HDEL key fields' command
Procedure
apoc.redis.hexists
apoc.redis.hexists(uri, key, field, {config}) | Execute the 'HEXISTS key field' command
Procedure
apoc.redis.hget
apoc.redis.hget(uri, key, field, {config}) | Execute the 'HGET key field' command
Procedure
apoc.redis.hgetall
apoc.redis.hgetall(uri, key, {config}) | Execute the 'HGETALL key' command
Procedure
apoc.redis.hincrby
apoc.redis.hincrby(uri, key, field, amount, {config}) | Execute the 'HINCRBY key field amount' command
Procedure
apoc.redis.hset
apoc.redis.hset(uri, key, field, value, {config}) | Execute the 'HSET key field value' command and returns true if it is a new field in the hash or false if the field already exists
Procedure
apoc.redis.incrby
apoc.redis.incrby(uri, key, amount, {config}) | Execute the 'INCRBY key increment' command
Procedure
apoc.redis.info
apoc.redis.info(uri, {config}) | Execute the 'INFO' command
Procedure
apoc.redis.lrange
apoc.redis.lrange(uri, key, start, stop, {config}) | Execute the 'LRANGE key start stop' command
Procedure
apoc.redis.persist
apoc.redis.persist(uri, key, {config}) | Execute the 'PERSIST key' command
Procedure
apoc.redis.pexpire
apoc.redis.pexpire(uri, key, time, isExpireAt {config}) | Execute the 'PEXPIRE key time' command, or the 'PEPXPIREAT' if isExpireAt=true
Procedure
apoc.redis.pop
apoc.redis.pop(uri, key, {config}) | Execute the 'LPOP key' command, or the 'RPOP' if config right=true (default)
Procedure
apoc.redis.pttl
apoc.redis.pttl(uri, key, {config}) | Execute the 'PTTL key' command
Procedure
apoc.redis.push
apoc.redis.push(uri, key, values, {config}) | Execute the 'LPUSH key field values' command, or the 'RPUSH' if config right=true (default)
Procedure
apoc.redis.sadd
apoc.redis.sadd(uri, key, members, {config}) | Execute the 'SADD key members' command
Procedure
apoc.redis.scard
apoc.redis.scard(uri, key, {config}) | Execute the 'SCARD key' command
Procedure
apoc.redis.smembers
apoc.redis.smembers(uri, key, {config}) | Execute the 'SMEMBERS key' command
Procedure
apoc.redis.spop
apoc.redis.spop(uri, key, {config}) | Execute the 'SPOP key' command
Procedure
apoc.redis.sunion
apoc.redis.sunion(uri, keys, {config}) | Execute the 'SUNION keys' command
Procedure
apoc.redis.zadd
apoc.redis.zadd(uri, keys, scoresAndMembers, {config}) | Execute the 'ZADD key scoresAndMembers' command, where scoresAndMembers is a list of score,member,score,member,…
Procedure
apoc.redis.zcard
apoc.redis.zcard(uri, key, {config}) | Execute the 'ZCARD key' command
Procedure
apoc.redis.zrangebyscore
apoc.redis.zrangebyscore(uri, key, min, max, {config}) | Execute the 'ZRANGEBYSCORE key min max' command
Procedure
apoc.redis.zrem
apoc.redis.zrem(uri, key, members, {config}) | Execute the 'ZREM key members' command
Procedure
apoc.static
Qualified Name Type
apoc.static.list
apoc.static.list(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Procedure
apoc.static.set
apoc.static.set(name, value) - stores value under key for server lifetime storage, returns previously stored or configured value
Procedure
apoc.static.get
apoc.static.get(name) - returns statically stored value from config (apoc.static.<key>) or server lifetime storage
Function
apoc.static.getAll
apoc.static.getAll(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Function
apoc.systemdb
Qualified Name Type
apoc.systemdb.execute
Procedure
apoc.systemdb.export.metadata
Procedure
apoc.systemdb.graph
Procedure
apoc.trigger
Qualified Name Type
apoc.trigger.nodesByLabel
Function
apoc.trigger.propertiesByKey
Function
apoc.ttl
Qualified Name Type
apoc.ttl.expire
CALL apoc.ttl.expire(node,time,'time-unit') - expire node at specified time by setting :TTL label and ttl property
Procedure
apoc.ttl.expireIn
CALL apoc.ttl.expireIn(node,timeDelta,'time-unit') - expire node after specified length of time time by setting :TTL label and ttl property
Procedure
apoc.ttl.config
Function
apoc.uuid
Qualified Name Type
apoc.uuid.install
CALL apoc.uuid.install(label, {addToExistingNodes: true/false, uuidProperty: 'uuid'}) yield label, installed, properties, batchComputationResult | it will add the uuid transaction handler for the provided label and uuidProperty, in case the UUID handler is already present it will be replaced by the new one
Procedure
apoc.uuid.list
CALL apoc.uuid.list() yield label, installed, properties | provides a list of all the uuid handlers installed with the related configuration
Procedure
apoc.uuid.remove
CALL apoc.uuid.remove(label) yield label, installed, properties | remove previously added uuid handler and returns uuid information. All the existing uuid properties are left as-is
Procedure
apoc.uuid.removeAll
CALL apoc.uuid.removeAll() yield label, installed, properties | it removes all previously added uuid handlers and returns uuids information. All the existing uuid properties are left as-is
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.parallel;"apoc.cypher.parallel
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.cypher.parallel(fragment, paramMap, keyList) yield value - executes fragments in parallel through a list defined in paramMap with a key keyList
Signature
None
Copy to Clipboard
apoc.cypher.parallel(fragment :: STRING?, params :: MAP?, parallelizeOn :: STRING?) :: (value :: MAP?)
Input parameters
Name Type Default
fragment
STRING?
null
params
MAP?
null
parallelizeOn
STRING?
null
Output parameters
Name Type
value
MAP?
More documentation of apoc.cypher.parallel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/cypher-execution/parallel;"Parallel Cypher Execution
Contents
Procedure and Function Overview
apoc.cypher.parallel
apoc.cypher.parallel2
This section describes procedures and functions for parallel execution of Cypher statements.
Procedure and Function Overview
The available procedures and functions are described below:
Qualified Name Type Release
apoc.cypher.parallel
- executes fragments in parallel through a list defined in paramMap with a key keyList
Procedure
Apoc Extended
apoc.cypher.parallel2
- executes fragments in parallel batches through a list defined in paramMap with a key keyList
Procedure
Apoc Extended
apoc.cypher.mapParallel
apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
Apoc Extended
apoc.cypher.mapParallel2
apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
Apoc Extended
apoc.cypher.parallel
Given this dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
UNWIND range(0, 9999) as idx CREATE (:Person {name: toString(idx)})
we can execute parallel statements through (:Person) nodes with this procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person) WITH collect(p) as people
CALL apoc.cypher.parallel('RETURN a.name + t as title', {a: people, t: ' - suffix'}, 'a')
YIELD value RETURN value.title as title
In the above query, we passed a map as a second parameter and a string from the previous map as a third parameter. The value with key 'a' will be the list to cycle in parallel. Note that it is not needed to pass a and t as query parameters (that is $a and $t) because, under the hood, the procedure will prepend them in the query WITH $parameterName as parameterName. So in this case, WITH $a as a, $t as t.
In this example, we execute multiple queries in parallel WITH $a as a, $t as t RETURN a.name + t as title, where a is one of the (:Person) nodes included in people list.
The result of the procedure is:
Table 1. Result
title
""0 - suffix""
""1 - suffix""
""2 - suffix""
""3 - suffix""
""4 - suffix""
…
…
…
…
apoc.cypher.parallel2
This procedure is similar to apoc.cypher.parallel2, but works differently under the hood (see below). With the previous dataset, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person) WITH collect(p) as people
CALL apoc.cypher.parallel('RETURN a.name + t as title', {a: people, t: $suffix}, 'a')
YIELD value RETURN value.title as title
The result of the procedure is:
Table 2. Result
title
""0 - suffix""
""1 - suffix""
""2 - suffix""
""3 - suffix""
""4 - suffix""
…
…
…
…
The parallel put the collection to parallelize - in this case, people in a java.util.parallelStream() - and then executed multiple queries like this: WITH $a as a, $t as t RETURN a.name + t as title.
In the parallel2 transformation example, the fragment parameter first split the collection people into batchSizes of total / partitions, where partitions are 100 * number of processors available to the JVM (or 1 if total / partitions < 1). Then, it created a java.util.concurrent.Future for each batch, where each Future executed a query like this: WITH $t AS t UNWIND $a AS a RETURN a.name + $t as title (where $a is the current batch of people). Finally, it computed the futures.
Generally, the apoc.cypher.parallel2 procedure is more recommended than the apoc.cypher.parallel.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.mapParallel2;"apoc.cypher.mapParallel2
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Signature
None
Copy to Clipboard
apoc.cypher.mapParallel2(fragment :: STRING?, params :: MAP?, list :: LIST? OF ANY?, partitions :: INTEGER?, timeout = 10 :: INTEGER?) :: (value :: MAP?)
Input parameters
Name Type Default
fragment
STRING?
null
params
MAP?
null
list
LIST? OF ANY?
null
partitions
INTEGER?
null
timeout
INTEGER?
10
Output parameters
Name Type
value
MAP?
More documentation of apoc.cypher.mapParallel2
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.parallel2;"apoc.cypher.parallel2
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.cypher.parallel2(fragment, paramMap, keyList) yield value - executes fragments in parallel batches through a list defined in paramMap with a key keyList
Signature
None
Copy to Clipboard
apoc.cypher.parallel2(fragment :: STRING?, params :: MAP?, parallelizeOn :: STRING?) :: (value :: MAP?)
Input parameters
Name Type Default
fragment
STRING?
null
params
MAP?
null
parallelizeOn
STRING?
null
Output parameters
Name Type
value
MAP?
More documentation of apoc.cypher.parallel2
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.mapParallel;"apoc.cypher.mapParallel
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Signature
None
Copy to Clipboard
apoc.cypher.mapParallel(fragment :: STRING?, params :: MAP?, list :: LIST? OF ANY?) :: (value :: MAP?)
Input parameters
Name Type Default
fragment
STRING?
null
params
MAP?
null
list
LIST? OF ANY?
null
Output parameters
Name Type
value
MAP?
More documentation of apoc.cypher.mapParallel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.ttl;"apoc.ttl
Qualified Name Type
apoc.ttl.expire
CALL apoc.ttl.expire(node,time,'time-unit') - expire node at specified time by setting :TTL label and ttl property
Procedure
apoc.ttl.expireIn
CALL apoc.ttl.expireIn(node,timeDelta,'time-unit') - expire node after specified length of time time by setting :TTL label and ttl property
Procedure
apoc.ttl.config
Function
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.ttl/apoc.ttl.expireIn;"apoc.ttl.expireIn
Contents
Signature
Input parameters
Enable TTL
Usage Examples
Procedure Apoc Extended
CALL apoc.ttl.expireIn(node,timeDelta,'time-unit') - expire node after specified length of time time by setting :TTL label and ttl property
Signature
None
Copy to Clipboard
apoc.ttl.expireIn(node :: NODE?, timeDelta :: INTEGER?, timeUnit :: STRING?) :: VOID
Input parameters
Name Type Default
node
NODE?
null
timeDelta
INTEGER?
null
timeUnit
STRING?
null
Enable TTL
By default TTL is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.ttl.enabled=true
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
We can expire any people that have produced a movie by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
CALL apoc.ttl.expireIn(person, 10,'s')
RETURN movie, produced, person;
Table 1. Results
movie produced person
(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999})
[:PRODUCED]
(:Person:TTL {name: ""Joel Silver"", ttl: 1605698768575, born: 1952}
This node (and its relationships) will expire at 1605698768575 (10 seconds from now at the time of writing):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN datetime({epochMillis: 1605698768575}) AS expiryTime;
Table 2. Results
expiryTime
2020-11-18T11:26:08.575Z
The next time that the expiration job runs, we’ll see the following output in neo4j.log:
Text
neo4j.log
Copy to Clipboard
2020-11-18 11:26:40.357+0000 INFO  [apoc] TTL: Expired 1 nodes 1 relationships
And if we try to look for our producer:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
RETURN movie, produced, person;
We won’t get any results:
Table 3. Results
movie produced person
More documentation of apoc.ttl.expireIn
Was this page helpful?"
https://neo4j.com/labs/apoc/5/graph-updates/ttl;"Time To Live (TTL) - Expire Nodes
Contents
Available Procedures
Configuration and Parameters
Examples: Time-To-Live
Expire node(s) at specified time
Expire node(s) after specified time period
Manual Process: How TTL Works
Some nodes are not meant to live forever. That’s why with APOC you can specify a time by when they are removed from the database, by utilizing a schema index and an additional label. A few procedures help with that.
Available Procedures
The table below describes the available procedures:
Qualified Name Type Release
apoc.ttl.expire
CALL apoc.ttl.expire(node,time,'time-unit') - expire node at specified time by setting :TTL label and ttl property
Procedure
Apoc Extended
apoc.ttl.expireIn
CALL apoc.ttl.expireIn(node,timeDelta,'time-unit') - expire node after specified length of time time by setting :TTL label and ttl property
Procedure
Apoc Extended
apoc.ttl.config
Function
Apoc Extended
Configuration and Parameters
For configuration, you will need to enable time-to-live functionality with the following settings in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.ttl.enabled=true

# Optional: controls the repeat frequency
# apoc.ttl.schedule=5

# Optional: controls how many nodes are deleted in each batch
# apoc.ttl.limit=5000
In the available procedures listed above, there are several parameters with specific values. The table below outlines values and formats for the valid parameters.
Parameter Description Possible Values Examples
node
The entity or entities to add the label and property of time-to-live (previous selection statement needed)
Any node or group of nodes fitting desired criteria
n, person, group
epochTime
The datetime value of when the node(s) should expire
Any value in epoch seconds or millisecond format
1540944000, 1582209630000
time-unit
Measurement of units for input value
ms, s, m, h, d (long forms: millis, milliseconds, seconds, minutes, hours, days)
milliseconds, h
Examples: Time-To-Live
This section includes examples showing how to use the time-to-live procedures. These examples are based on a movies dataset, which can be imported by running the following Cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
Expire node(s) at specified time
The apoc.ttl.expire procedure deletes a node or group of nodes after the datetime specified.
To remove a single node or set of nodes, we can use a selection query prior to calling the procedure that defines which nodes we want to apply the time-to-live label and property. We then call the procedure and pass in the selected node(s), the future datetime at which we want the nodes to be removed, and the specificity of the datetime (seconds, milliseconds, etc).
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
CALL apoc.ttl.expire(person,1585176720,'s')
RETURN movie, produced, person
Table 1. Results
""movie"" ""produced"" ""person""
{""title"":""The Matrix"",""tagline"":""Welcome to the Real World"",""released"":1999}
{}
{""name"":""Joel Silver"",""ttl"":1585176720000,""born"":1952}
After the point in time specified (in this case, after 2020-03-25 17:52:00), the node(s) will be expired and deleted from the graph. Running the statement below will return no results for our example graph.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
RETURN movie, produced, person
Expire node(s) after specified time period
The apoc.ttl.expireIn procedure deletes a node or group of nodes after the length of time specified. Just as with the similar procedure above, we can use a selection query prior to calling the procedure that defines which nodes we want to apply the time-to-live label and property. We then call the procedure and pass in the selected node(s), the time delta from current time at which we want the nodes to be removed, and the specificity of the time amount (seconds, milliseconds, etc).
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[directed:DIRECTED]-(person:Person)
CALL apoc.ttl.expireIn(person,120,'s')
RETURN movie, directed, person
Table 2. Results
""movie"" ""directed"" ""person""
{""title"":""The Matrix"",""tagline"":""Welcome to the Real World"",""released"":1999}
{}
{""name"":""Lana Wachowski"",""ttl"":1618008344450,""born"":1965}
{""title"":""The Matrix"",""tagline"":""Welcome to the Real World"",""released"":1999}
{}
{""name"":""Lilly Wachowski"",""ttl"":1618008344450,""born"":1967}
After the length of time specified has passed (in this case, after 120 seconds), the node(s) will be expired and deleted from the graph. Running the statement below will return no results for our example graph.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[directed:DIRECTED]-(person:Person)
RETURN movie, directed, person
Manual Process: How TTL Works
You can also do the time-to-live process manually by running the following steps:
Set the :TTL label and ttl property on the node(s) you want to expire.
Cypher
Copy to Clipboard
Run in Neo4j Browser
SET n:TTL
SET n.ttl = timestamp() + 3600
The ttl property holds the time when the node is expired in milliseconds since epoch.
Create an index on the time-to-live label and property.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE INDEX FOR (n:TTL) ON (n.ttl)
When using the procedure, the index is created 30 seconds after startup/new database created.
Remove node(s) that have passed the expiration time or length of time
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (t:TTL) where t.ttl < timestamp() WITH t LIMIT 1000 DETACH DELETE t
When using the procedure, the deletion statement to remove nodes past expiration will run every 60 seconds. You can also configure the schedule by adding the following setting in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
# Optional: controls the repeat frequency
apoc.ttl.schedule=120
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.ttl/apoc.ttl.expire;"apoc.ttl.expire
Contents
Signature
Input parameters
Enable TTL
Usage Examples
Procedure Apoc Extended
CALL apoc.ttl.expire(node,time,'time-unit') - expire node at specified time by setting :TTL label and ttl property
Signature
None
Copy to Clipboard
apoc.ttl.expire(node :: NODE?, time :: INTEGER?, timeUnit :: STRING?) :: VOID
Input parameters
Name Type Default
node
NODE?
null
time
INTEGER?
null
timeUnit
STRING?
null
Enable TTL
By default TTL is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.ttl.enabled=true
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
We can expire any people that have produced a movie by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.add(datetime().epochSeconds, ""s"", 5, ""s"") AS fiveSecondsTime
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
CALL apoc.ttl.expire(person,fiveSecondsTime,'s')
RETURN movie, produced, person;
Table 1. Results
movie produced person
(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999})
[:PRODUCED]
(:Person:TTL {name: ""Joel Silver"", ttl: 1605698172000, born: 1952})
This node (and its relationships) will expire at 1605698172000 (5 seconds from now at the time of writing):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN datetime({epochMillis: 1605698172000}) AS expiryTime;
Table 2. Results
expiryTime
2020-11-18T11:16:12Z
The next time that the expiration job runs, we’ll see the following output in neo4j.log:
Text
neo4j.log
Copy to Clipboard
2020-11-18 11:16:40.348+0000 INFO  [apoc] TTL: Expired 1 nodes 1 relationships
And if we try to look for our producer:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[produced:PRODUCED]-(person:Person)
RETURN movie, produced, person;
We won’t get any results:
Table 3. Results
movie produced person
More documentation of apoc.ttl.expire
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.ttl/apoc.ttl.config;"apoc.ttl.config
Contents
Signature
Function Apoc Extended
Signature
None
Copy to Clipboard
apoc.ttl.config() :: (MAP?)
More documentation of apoc.ttl.config
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.get;"apoc.redis.get
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.get(uri, key, {config}) | Execute the 'GET key' command
Signature
None
Copy to Clipboard
apoc.redis.get(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.get
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/redis;"Redis
Contents
Install Dependencies
URI description
Configuration parameters
Examples
Strings commands
List commands
Sets commands
Sorted sets commands
Hashes commands
Keys commands
Eval command
Server command
Here is a list of all available Redis procedures:
name signature description
apoc.redis.append
apoc.redis.append(uri :: STRING?, key :: STRING?, value :: STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.append(uri, key, value, {config}) | Execute the 'APPEND key value' command
apoc.redis.configGet
apoc.redis.configGet(uri :: STRING?, parameter :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
apoc.redis.configGet(uri, parameter, {config}) | Execute the 'CONFIG GET parameter' command
apoc.redis.configSet
apoc.redis.configSet(uri :: STRING?, parameter :: STRING?, value :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.configSet(uri, parameter, {config}) | Execute the 'CONFIG SET parameter value' command
apoc.redis.copy
apoc.redis.copy(uri :: STRING?, source :: STRING?, destination :: STRING?, config = {} :: MAP?) :: (value :: BOOLEAN?)
apoc.redis.copy(uri, source, destination, {config}) | Execute the 'COPY source destination' command and returns true if source was copied and false otherwise
apoc.redis.eval
apoc.redis.eval(uri :: STRING?, script :: STRING?, outputType :: STRING?, keys :: LIST? OF STRING?, values :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: ANY?)
apoc.redis.eval(uri, script, outputType, keys, values, {config}) | Execute the 'EVAL script' command. In the parameters provided to the procedure, keys are bound to the KEYS[n] like special array of the Lua script and values are bound to the ARGV[n] like special array of the Lua script.
apoc.redis.exists
apoc.redis.exists(uri :: STRING?, keys :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.exists(uri, keys, {config}) | Execute the 'EXISTS keys' command
apoc.redis.get
apoc.redis.get(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.get(uri, key, {config}) | Execute the 'GET key' command
apoc.redis.hdel
apoc.redis.hdel(uri :: STRING?, key :: STRING?, fields :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.hdel(uri, key, fields, {config}) | Execute the 'HDEL key fields' command
apoc.redis.hexists
apoc.redis.hexists(uri :: STRING?, key :: STRING?, field :: STRING?, config = {} :: MAP?) :: (value :: BOOLEAN?)
apoc.redis.hexists(uri, key, field, {config}) | Execute the 'HEXISTS key field' command
apoc.redis.hget
apoc.redis.hget(uri :: STRING?, key :: STRING?, field :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.hget(uri, key, field, {config}) | Execute the 'HGET key field' command
apoc.redis.hgetall
apoc.redis.hgetall(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
apoc.redis.hgetall(uri, key, {config}) | Execute the 'HGETALL key' command
apoc.redis.hincrby
apoc.redis.hincrby(uri :: STRING?, key :: STRING?, field :: STRING?, amount :: INTEGER?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.hincrby(uri, key, field, amount, {config}) | Execute the 'HINCRBY key field amount' command
apoc.redis.hset
apoc.redis.hset(uri :: STRING?, key :: STRING?, field :: MAP?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.hset(uri, key, value, {config}) | Execute the 'HSET key mapFields' command, where mapFields is a map of field1, value1, field2, value2,…
apoc.redis.incrby
apoc.redis.incrby(uri :: STRING?, key :: STRING?, amount :: INTEGER?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.incrby(uri, key, amount, {config}) | Execute the 'INCRBY key increment' command
apoc.redis.info
apoc.redis.info(uri :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.info(uri, {config}) | Execute the 'INFO' command
apoc.redis.lrange
apoc.redis.lrange(uri :: STRING?, key :: STRING?, start :: INTEGER?, stop :: INTEGER?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
apoc.redis.lrange(uri, key, start, stop, {config}) | Execute the 'LRANGE key start stop' command
apoc.redis.persist
apoc.redis.persist(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: BOOLEAN?)
apoc.redis.persist(uri, key, {config}) | Execute the 'PERSIST key' command
apoc.redis.pexpire
apoc.redis.pexpire(uri :: STRING?, key :: STRING?, time :: INTEGER?, config = {} :: MAP?) :: (value :: BOOLEAN?)
apoc.redis.pexpire(uri, key, time, isExpireAt {config}) | Execute the 'PEXPIRE key time' command, or the 'PEPXPIREAT' if isExpireAt=true
apoc.redis.pop
apoc.redis.pop(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.pop(uri, key, {config}) | Execute the 'LPOP key' command, or the 'RPOP' if config right=true (default)
apoc.redis.pttl
apoc.redis.pttl(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.pttl(uri, key, {config}) | Execute the 'PTTL key' command
apoc.redis.push
apoc.redis.push(uri :: STRING?, key :: STRING?, value :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.push(uri, key, values, {config}) | Execute the 'LPUSH key field values' command, or the 'RPUSH' if config right=true (default)
apoc.redis.sadd
apoc.redis.sadd(uri :: STRING?, key :: STRING?, members :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.sadd(uri, key, members, {config}) | Execute the 'SADD key members' command
apoc.redis.scard
apoc.redis.scard(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.scard(uri, key, {config}) | Execute the 'SCARD key' command
apoc.redis.getSet
apoc.redis.getSet(uri :: STRING?, key :: STRING?, value :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.getSet(uri, key, value, {config}) | Execute the 'SET key value' command and return old value stored (or null if did not exists)
apoc.redis.smembers
apoc.redis.smembers(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
apoc.redis.smembers(uri, key, {config}) | Execute the 'SMEMBERS key' command
apoc.redis.spop
apoc.redis.spop(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
apoc.redis.spop(uri, key, {config}) | Execute the 'SPOP key' command
apoc.redis.sunion
apoc.redis.sunion(uri :: STRING?, keys :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
apoc.redis.sunion(uri, keys, {config}) | Execute the 'SUNION keys' command
apoc.redis.zadd
apoc.redis.zadd(uri :: STRING?, key :: STRING?, value :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.zadd(uri, keys, scoresAndMembers, {config}) | Execute the 'ZADD key scoresAndMembers' command, where scoresAndMembers is a list of score,member,score,member,…
apoc.redis.zcard
apoc.redis.zcard(uri :: STRING?, key :: STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.zcard(uri, key, {config}) | Execute the 'ZCARD key' command
apoc.redis.zrangebyscore
apoc.redis.zrangebyscore(uri :: STRING?, key :: STRING?, min :: INTEGER?, max :: INTEGER?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
apoc.redis.zrangebyscore(uri, key, min, max, {config}) | Execute the 'ZRANGEBYSCORE key min max' command
apoc.redis.zrem
apoc.redis.zrem(uri :: STRING?, key :: STRING?, members :: LIST? OF STRING?, config = {} :: MAP?) :: (value :: INTEGER?)
apoc.redis.zrem(uri, key, members, {config}) | Execute the 'ZREM key members' command
Install Dependencies
The Redis procedures have dependencies on a client library that is not included in the APOC Extended library. You can download it from the lettuce-core repository(except for netty jars because they are already included within neo4j) or apoc repository Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
URI description
The first parameter of Redis procedure is always the URI. This URI follows this sintax. One example of valid uri is redis://myPassword@localhost:6379
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
charset
String
""UTF-8""
The charset to encode keys and values
timeout
Long
60
The connection timeout (in seconds)
scriptCharset
String
""UTF-8""
The Lua script charset to encode scripts
autoReconnect
Boolean
true
Enables or disables auto reconnection on connection loss
right
Boolean
true
To choose the direction case of procedure with ""two sides"", for example in apoc.redis.push to choose between RPUSH and LPUSH (right/left push)
expireAt
Boolean
true
Converts MongoDB data types into Neo4j data types
codec
Enum[STRING, BYTE_ARRAY]
String
The Redis Codec used for encode key and values (see the Strings commands example)
Examples
Let’s see some examples divided by command category.
Strings commands
SET command (return the old value stored):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.getSet($uri, 'myKey', 'myValue')
Table 2. Results
value
null
Or with codec: BYTE_ARRAY:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.getSet($uri, `BYTES_KEY`, `BYTES_VALUE`, {codec: ""BYTE_ARRAY""})
Table 3. Results
value
{""0"":31.0,""1"":-117.0,""2"":8.0,""3"":0.0,""4"":0.0,""5"":0.0,""6"":0.0,""7"":0.0,""8"":0.0,""9"":-1.0,""10"":75.0,""11"":4.0,""12"":0.0,""13"":67.0,""14"":-66.0,""15"":-73.0,""16"":-24.0,""17"":1.0,""18"":0.0,""19"":0.0,""20"":0.0}
GET command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.get($uri, 'myKey')
Table 4. Results
value
myValue
APPEND command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.append($uri, 'myKey', '2')
Table 5. Results
value
myValue2
INCRBY command, with a initial value '1'':
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.incrby($uri, 'myKey', 2)
Table 6. Results
value
3
List commands
RPUSH command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.push($uri, 'myListKey', ['foo','bar','baz'])
Table 7. Results
value
3
LPUSH command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.push($uri, 'myListKey', ['prefix1'], {right: false})
Table 8. Results
value
4
LRANGE command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.lrange($uri, 'myListKey', 0 , 10)
Table 9. Results
value
[""prefix1"", ""foo"", ""bar"", ""baz""]
RPOP command, with the previous value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.pop($uri, 'myListKey')
Table 10. Results
value
""baz""
LPOP command, with the previous value:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.pop($uri, 'myListKey', {right: false})
Table 11. Results
value
""prefix1""
Sets commands
SADD command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.sadd($uri, 'mySetKey', ['foo','bar','baz'])
Table 12. Results
value
3
SUNION command, with the previous one and a second key with ['alpha', 'beta'] values:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.sunion($uri, ['mySetKey', 'mySetKeyTwo'])
Table 13. Results
value
[""foo"", ""bar"", ""baz"", ""alpha"", ""beta""]
SCARD command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.scard($uri, 'mySetKey')
Table 14. Results
value
3
SMEMBERS command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.smembers($uri, 'mySetKey')
Table 15. Results
value
[""foo"", ""bar"", ""baz""]
SPOP command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.smembers($uri, 'mySetKey')
Table 16. Results
value
""baz""
Sorted sets commands
ZADD command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.zadd($uri, 'mySortedSetKey', [0, 'first', 100, 'third', 1, 'second'])
Table 17. Results
value
3
ZCARD command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.zcard($uri, 'mySortedSetKey')
Table 18. Results
value
3
ZRANGEBYSCORE command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.zrangebyscore($uri, 'mySortedSetKey', 0, 100)
Table 19. Results
value
[""first"", ""second"", ""third""]
ZREM command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.zrem($uri, 'mySortedSetKey', ['first', 'second'])
Table 20. Results
value
2
Hashes commands
HSET command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.hset($uri, 'mapKey', {alpha: 'beta', gamma: 'delta', epsilon: 'zeta', number: '1'})
Table 21. Results
value
4
HDEL command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.hdel($uri, 'mapKey', ['alpha', 'gamma'])
Table 22. Results
value
2
HEXISTS command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.hexists($uri, 'mapKey', 'epsilon')
Table 23. Results
value
true
HGET command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.hget($uri, 'mapKey', 'epsilon')
Table 24. Results
value
""zeta""
HINCRBY command, with the previous key:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.hincrby($uri, 'mapKey', 'number', 3)
Table 25. Results
value
4
Keys commands
COPY command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.copy($uri, 'from', 'to')
Table 26. Results
value
true
EXISTS command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.exists($uri, ['to'])
Table 27. Results
value
true
PEXPIRE command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.pexpire($uri, 'to', 100, false)
Table 28. Results
value
true
PTTL command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.pexpire($uri, 'to')
Table 29. Results
value
95
PERSIST command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.persist($uri, 'to')
Table 30. Results
value
true
Eval command
We can execute an eval command with a return value BOOLEAN, INTEGER, STATUS, VALUE or MULTI (of these types). With a keyEval with a value valueEval, we can execute an EVAL return redis.call(""get"", KEYS[1]) testEval 'key:name' command, with a return value 'VALUE':
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.eval($uri, 'return redis.call(""get"", KEYS[1])', 'VALUE', ['testEval'], ['key:name'])
Table 31. Results
value
valueEval
Server command
INFO command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.info($uri)
Table 32. Results
value
…INFO SERVER…
CONFIG GET command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.configGet($uri, ""slowlog-max-len"")
Table 33. Results
value
128
CONFIG SET command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.configSet($uri, $keyConfig, '64')
Table 34. Results
value
""OK""
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongodb/apoc.mongodb.get.byObjectId;"apoc.mongodb.get.byObjectId
Contents
Signature
Input parameters
Config parameters
Output parameters
Install Dependencies
Usage Examples
Field description
Examples
Procedure Apoc Extended
apoc.mongodb.get.byObjectId(hostOrKey, db, collection, objectIdValue, config(default:{})) - get the document by Object id value
Signature
None
Copy to Clipboard
apoc.mongodb.get.byObjectId(host :: STRING?, db :: STRING?, collection :: STRING?, objectIdValue :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
db
STRING?
null
collection
STRING?
null
objectIdValue
STRING?
null
config
MAP?
{}
Config parameters
The procedure supports the following config parameters:
Table 1. Config parameters
name type default description
compatibleValues
boolean
true
converts MongoDB data types into Neo4j data types
extractReferences
boolean
false
if true and a field contains an ObjectId, it will include the related document instead of the ObjectId
objectIdAsMap
boolean
true
extract the _id as map
idFieldName
String
_id
the field name of the ObjectId
Output parameters
Name Type
value
MAP?
Install Dependencies
The Mongo procedures have dependencies on a client library that is not included in the APOC Extended library.
This dependency is included in apoc-mongodb-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you could copy these jars into the plugins directory:
bson-3.4.2.jar
mongo-java-driver-3.4.2.jar,
mongodb-driver-3.4.2.jar
mongodb-driver-core-3.4.2.jar
You should be able to get them from the following links:
mongo-java-driver
mongodb-driver
mongodb-driver-core
BSON
Usage Examples
Field description
host: the MongoDB host in the format mongodb://<HOST_NAME>:<PORT> or a url defined into the apoc config apoc.mongodb.myInstance.url=mongodb://<HOST_NAME>:<PORT>, which can be invoked by simply passing myInstance
db: the db name
collection: the collection name
objectIdValue: the ObjectId of the document to retrieve
config: the config map
Examples
Given the following collections:
None
Copy to Clipboard
// Product
...
{""_id"": ObjectId(""product1""), ""name"": ""Product 1"", ""price"": 100}
{""_id"": ObjectId(""product3""), ""name"": ""Product 2"", ""price"": 200}
{""_id"": ObjectId(""product3""), ""name"": ""Product 3"", ""price"": 300}
{""_id"": ObjectId(""product4""), ""name"": ObjectId(""507f191e810c19729de860ea""), ""price"": 400}
...
None
Copy to Clipboard
// Person
...
{""_id"": ObjectId(""person""), ""name"": ""Andrea"", ""bought"": [ObjectId(""product1""), ObjectId(""product3"")]}
...
With CALL apoc.mongodb.get.byObjectId(<HOST>, <DB>, ""product"", ""product1""):
None
Copy to Clipboard
{
  ""_id"": {
   ""timestamp"": <...>,
 ""machineIdentifier"": <...>,
 ""processIdentifier"": <...>,
 ""counter"": <...>,
  }
  ""name"": ""Product 1"",
  ""price"": 100L
}
With CALL apoc.mongodb.get.byObjectId(<HOST>, <DB>, ""product"", ""product4"", {idFieldName: ""name""}):
None
Copy to Clipboard
{
  ""_id"": {
   ""timestamp"": <...>,
 ""machineIdentifier"": <...>,
 ""processIdentifier"": <...>,
 ""counter"": <...>,
  }
  ""name"": ""507f191e810c19729de860ea"",
  ""price"": 400L
}
With CALL apoc.mongodb.get.byObjectId(<HOST>, <DB>, ""product"", ""product1"", ""_id"", {extractReferences: true, objectIdAsMap: true, compatibleValues: false}):
None
Copy to Clipboard
{
  ""_id"": {
   ""timestamp"": <...>,
 ""machineIdentifier"": <...>,
 ""processIdentifier"": <...>,
 ""counter"": <...>,
  },
  ""name"": ""Andrea"",
  ""bought"": [
    {
      ""_id"": {
    ""timestamp"": <...>,
  ""machineIdentifier"": <...>,
  ""processIdentifier"": <...>,
  ""counter"": <...>,
   },
   ""name"": ""Product 1"",
   ""price"": 100
 },
    {
      ""_id"": {
    ""timestamp"": <...>,
  ""machineIdentifier"": <...>,
  ""processIdentifier"": <...>,
  ""counter"": <...>,
   },
   ""name"": ""Product 3"",
   ""price"": 300
 },
  ]
}
View all (16 more lines)
More documentation of apoc.mongodb.get.byObjectId
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.log;"apoc.log
Qualified Name Type
apoc.log.debug
apoc.log.debug(message, params) - logs debug message
Procedure
apoc.log.error
apoc.log.error(message, params) - logs error message
Procedure
apoc.log.info
apoc.log.info(message, params) - logs info message
Procedure
apoc.log.warn
apoc.log.warn(message, params) - logs warn message
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.log/apoc.log.error;"apoc.log.error
Contents
Signature
Input parameters
Config parameters
Usage Examples
Procedure Apoc Extended
apoc.log.error(message, params) - logs error message
Signature
None
Copy to Clipboard
apoc.log.error(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
message
STRING?
null
params
LIST? OF ANY?
[]
Config parameters
The procedure support the following properties in the APOC configuration file (apoc.conf):
Table 1. Config parameters
name type default description
apoc.user.log.type
String
safe
Type of logging.
node: disable the procedures
safe: replace all . and whitespace (space and tab) with underscore and lowercase all characters
raw: left the messages as-is
apoc.user.log.window.ops
Long
10
Number of log messages permitted in a time-window. If this quota is exceeded, log messags will be skipped.
apoc.user.log.window.time
Long
10000
Length (in milliseconds) of the time-window.
Usage Examples
We can log a message to neo4j.log using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.log.error('Hello %s', ['World']);
Text
neo4j.log
Copy to Clipboard
2020-11-18 10:22:28.923+0000 ERROR hello_world
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.log/apoc.log.debug;"apoc.log.debug
Contents
Signature
Input parameters
Config parameters
Usage Examples
Procedure Apoc Extended
apoc.log.debug(message, params) - logs debug message
Signature
None
Copy to Clipboard
apoc.log.debug(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
message
STRING?
null
params
LIST? OF ANY?
[]
Config parameters
The procedure support the following properties in the APOC configuration file (apoc.conf):
Table 1. Config parameters
name type default description
apoc.user.log.type
String
safe
Type of logging.
node: disable the procedures
safe: replace all . and whitespace (space and tab) with underscore and lowercase all characters
raw: left the messages as-is
apoc.user.log.window.ops
Long
10
Number of log messages permitted in a time-window. If this quota is exceeded, log messags will be skipped.
apoc.user.log.window.time
Long
10000
Length (in milliseconds) of the time-window.
Usage Examples
For this procedure to log messages, we need to set the following config in the Neo4j configuration file:
Properties
$NEO4J_HOME/neo4j.conf
Copy to Clipboard
dbms.logs.debug.level=DEBUG
We can log a message to neo4j.log using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.log.debug('Hello %s', ['World']);
Text
neo4j.log
Copy to Clipboard
CALL apoc.log.debug('Hello %s', ['World']);
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.log/apoc.log.info;"apoc.log.info
Contents
Signature
Input parameters
Config parameters
Usage Examples
Procedure Apoc Extended
apoc.log.info(message, params) - logs info message
Signature
None
Copy to Clipboard
apoc.log.info(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
message
STRING?
null
params
LIST? OF ANY?
[]
Config parameters
The procedure support the following properties in the APOC configuration file (apoc.conf):
Table 1. Config parameters
name type default description
apoc.user.log.type
String
safe
Type of logging.
node: disable the procedures
safe: replace all . and whitespace (space and tab) with underscore and lowercase all characters
raw: left the messages as-is
apoc.user.log.window.ops
Long
10
Number of log messages permitted in a time-window. If this quota is exceeded, log messags will be skipped.
apoc.user.log.window.time
Long
10000
Length (in milliseconds) of the time-window.
Usage Examples
We can log a message to neo4j.log using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.log.info('Hello %s', ['World']);
Text
neo4j.log
Copy to Clipboard
2020-11-18 10:18:08.673+0000 INFO  hello_world
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.log/apoc.log.warn;"apoc.log.warn
Contents
Signature
Input parameters
Config parameters
Usage Examples
Procedure Apoc Extended
apoc.log.warn(message, params) - logs warn message
Signature
None
Copy to Clipboard
apoc.log.warn(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID
Input parameters
Name Type Default
message
STRING?
null
params
LIST? OF ANY?
[]
Config parameters
The procedure support the following properties in the APOC configuration file (apoc.conf):
Table 1. Config parameters
name type default description
apoc.user.log.type
String
safe
Type of logging.
node: disable the procedures
safe: replace all . and whitespace (space and tab) with underscore and lowercase all characters
raw: left the messages as-is
apoc.user.log.window.ops
Long
10
Number of log messages permitted in a time-window. If this quota is exceeded, log messags will be skipped.
apoc.user.log.window.time
Long
10000
Length (in milliseconds) of the time-window.
Usage Examples
We can log a message to neo4j.log using the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.log.warn('Hello %s', ['World']);
Text
neo4j.log
Copy to Clipboard
2020-11-18 10:21:37.365+0000 WARN  hello_world
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.runSchemaFile;"apoc.cypher.runSchemaFile
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Procedure Apoc Extended
apoc.cypher.runSchemaFile(file or url,[{statistics:true,timeout:10}]) - allows only schema operations, runs each schema statement in the file, all semicolon separated
Signature
None
Copy to Clipboard
apoc.cypher.runSchemaFile(file :: STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the following file:
Cypher
$NEO4J_HOME/import/schema.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE INDEX FOR (n:Node) ON (n.id);
We can run the Cypher commands in schema.cypher, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchemaFile(""schema.cypher"");
Table 1. Results
row result
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 0, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 1, labelsAdded: 0, relationshipsCreated: 0, time: 0}
If we don’t want to see statistics for each Cypher statement, we can set statistics: false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchemaFile(""schema.cypher"", {statistics: false});
Table 2. Results
row result
More documentation of apoc.cypher.runSchemaFile
Was this page helpful?"
https://neo4j.com/labs/apoc/5/cypher-execution;"Cypher Execution
This section includes:
Running Cypher fragments
Run Cypher Script Files
Custom, Cypher Based Procedures and Functions
Parallel Cypher Execution
Was this page helpful?"
https://neo4j.com/labs/apoc/5/cypher-execution/run-cypher-scripts;"Run Cypher Script Files
Contents
Procedure Overview
Data Operations only
Schema Operations only
Runs each statement in the file / each file, all semicolon separated
These procedures can be used to run files that are usually run by cypher-shell. They automatically skip :begin/:commit/:rollback operations as they are executed in a single transaction per file.
Procedure Overview
The available procedures and functions are described in the following table:
Qualified Name Type Release
apoc.cypher.runFile
apoc.cypher.runFile(file or url,[{statistics:true,timeout:10,parameters:{}}]) - runs each statement in the file, all semicolon separated
Procedure
Apoc Extended
apoc.cypher.runFiles
apoc.cypher.runFiles([files or urls],[{statistics:true,timeout:10,parameters:{}}])) - runs each statement in the files, all semicolon separated
Procedure
Apoc Extended
apoc.cypher.runSchemaFile
apoc.cypher.runSchemaFile(file or url,[{statistics:true,timeout:10}]) - allows only schema operations, runs each schema statement in the file, all semicolon separated
Procedure
Apoc Extended
apoc.cypher.runSchemaFiles
apoc.cypher.runSchemaFiles([files or urls],{statistics:true,timeout:10}) - allows only schema operations, runs each schema statement in the files, all semicolon separated
Procedure
Apoc Extended
Data Operations only
apoc.cypher.runFile(file or url,[{config}])
apoc.cypher.runFiles([files or urls],[{config})])
The apoc.cypher.run*File(s) procedures have some optional configuration:
{statistics:true/false} to output a row of update-stats per statement, default is true
{timeout:1 or 10} for how long the stream waits for new data, default is 10
Schema Operations only
apoc.cypher.runSchemaFile(file or url,[{config}])
apoc.cypher.runSchemaFiles([files or urls],[{config})])
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.runFile;"apoc.cypher.runFile
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Procedure Apoc Extended
apoc.cypher.runFile(file or url,[{statistics:true,timeout:10,parameters:{}}]) - runs each statement in the file, all semicolon separated - currently no schema operations
Signature
None
Copy to Clipboard
apoc.cypher.runFile(file :: STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the following file:
Cypher
$NEO4J_HOME/import/create_delete.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:Node {id:1});

MATCH (n:Node)
DELETE n;
We can run the Cypher commands in create_delete.cypher, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runFile(""create_delete.cypher"");
Table 1. Results
row result
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 1, rows: 0, propertiesSet: 1, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 1, relationshipsCreated: 0, time: 0}
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 0, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 1, indexesAdded: 0, labelsAdded: 0, relationshipsCreated: 0, time: 0}
If we don’t want to see statistics for each Cypher statement, we can set statistics: false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runFile(""create_delete.cypher"", {statistics: false});
Table 2. Results
row result
More documentation of apoc.cypher.runFile
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.runFiles;"apoc.cypher.runFiles
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Procedure Apoc Extended
apoc.cypher.runFiles([files or urls],[{statistics:true,timeout:10,parameters:{}}])) - runs each statement in the files, all semicolon separated
Signature
None
Copy to Clipboard
apoc.cypher.runFiles(file :: LIST? OF STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
file
LIST? OF STRING?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the following file:
Cypher
$NEO4J_HOME/import/create.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:Node {id:1});
Cypher
$NEO4J_HOME/import/update.cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Node {id:1})
SET n.city = ""London"";
We can run the Cypher commands in create.cypher and update.cypher, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runFiles([""create.cypher"", ""update.cypher""]);
Table 1. Results
row result
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 1, rows: 0, propertiesSet: 1, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 1, relationshipsCreated: 0, time: 0}
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 1, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 0, relationshipsCreated: 0, time: 0}
We can see the contents of the database, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Node)
RETURN n;
Table 2. Results
n
(:Node {city: ""London"", id: 1})
If we don’t want to see statistics for each Cypher statement, we can set statistics: false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runFiles([""create.cypher"", ""update.cypher""], {statistics: false});
Table 3. Results
row result
More documentation of apoc.cypher.runFiles
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher/apoc.cypher.runSchemaFiles;"apoc.cypher.runSchemaFiles
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Procedure Apoc Extended
apoc.cypher.runSchemaFiles([files or urls],{statistics:true,timeout:10}) - allows only schema operations, runs each schema statement in the files, all semicolon separated
Signature
None
Copy to Clipboard
apoc.cypher.runSchemaFiles(file :: LIST? OF STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
file
LIST? OF STRING?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the following file:
Cypher
$NEO4J_HOME/import/createConstraint.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT uniqueConstraint FOR (n:Person) REQUIRE n.name IS UNIQUE;
Cypher
$NEO4J_HOME/import/dropConstraint.cypher
Copy to Clipboard
Run in Neo4j Browser
DROP CONSTRAINT uniqueConstraint;
We can run the Cypher commands in createConstraint.cypher and dropConstraint.cypher, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchemaFiles([""createConstraint.cypher"", ""dropConstraint.cypher""]);
Table 1. Results
row result
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 0, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 1, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 0, relationshipsCreated: 0, time: 0}
-1
{constraintsRemoved: 1, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 0, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 0, relationshipsCreated: 0, time: 0}
If we don’t want to see statistics for each Cypher statement, we can set statistics: false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchemaFiles([""createConstraint.cypher"", ""dropConstraint.cypher""], {statistics: false});
Table 2. Results
row result
More documentation of apoc.cypher.runSchemaFiles
Was this page helpful?"
https://neo4j.com/labs/apoc/5/cypher-execution/cypher-based-procedures-functions;"Custom, Cypher Based Procedures and Functions
Contents
Custom Procedures with apoc.custom.declareProcedure
Input parameters
Custom Functions with apoc.custom.declareFunction
Input parameters
List of registered procedures/function with apoc.custom.list
Remove a procedure apoc.custom.removeProcedure
Remove a procedure apoc.custom.removeFunction
How to manage procedure/function replication in a Causal Cluster
Export metadata
I wanted for a long time to be able to register Cypher statements as proper procedures and functions, so that they become callable in a standalone way.
You can achieve that with the apoc.custom.declareProcedure and apoc.custom.dclareFunction procedure calls. Those register a given Cypher statement, prefixed with the custom.* namespace, overriding potentially existing ones, so you can redefine them as needed.
Here is a simple example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareProcedure('answer() :: INT','RETURN 42 as answer')
This registers the statement as procedure custom.answer that you then can call. As no information on parameter and return types is given, it just returns a stream of columns of maps called row.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL custom.answer() YIELD row
RETURN row.answer()
The same is possible as a function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareFunction('answer() :: (result::INT)','RETURN 42')
If you override procedures or functions you might need to call call dbms.clearQueryCaches() as lookups to internal ids are kept in compiled query plans.
Custom Procedures with apoc.custom.declareProcedure
The given statement will be registered as a procedure, the results will be turned into a stream of records.
Input parameters
Name Type Default
signature
STRING?
null
statement
STRING?
null
mode
STRING?
read
description
STRING?
The type names are what you would expect and see in outputs of SHOW PROCEDURES or apoc.help just without the ?. The default values are parsed as JSON.
Type Names
FLOAT, DOUBLE, INT, INTEGER, NUMBER, LONG
TEXT, STRING
BOOL, BOOLEAN
POINT, GEO, GEOMETRY
DATE, DATETIME, LOCALDATETIME, TIME, LOCALTIME, DURATION
NODE, REL, RELATIONSHIP, EDGE, PATH
MAP
LIST TYPE, LIST OF TYPE (where TYPE can be one of the previous values)
ANY
Cypher
Find neighbours of a node by name
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareProcedure('neighbours(name::STRING) :: NODE',
  'MATCH (n:Person {name:$name})-->(nb) RETURN nb as neighbour','read',
  'get neighbours of a person');

CALL custom.neighbours('Keanu Reeves') YIELD neighbour;
Custom Functions with apoc.custom.declareFunction
Given statement will be registered as a statement, the results into a single value. If the given output type is a list, results will be collected into a list, otherwise the first row will be used. The statement needs to return a single column, otherwise an error is thrown.
Input parameters
Name Type Default
signature
STRING?
null
statement
STRING?
null
forceSingle
BOOLEAN?
false
description
STRING?
The type names are what you would expect and see in outputs of SHOW PROCEDURES or apoc.help just without the ?. The default values are parsed as JSON.
List of registered procedures/function with apoc.custom.list
The procedure apoc.custom.list provide a list of all registered procedures/function via apoc.custom.declareProcedure and apoc.custom.declareFunction
Given the this call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.list
The the output will look like the following table:
type name description mode statement inputs outputs forceSingle
""function""
""answer""
<null>
<null>
""RETURN $input as answer""
[[""input"",""number""]]
""long""
false
""procedure""
""answer""
""Procedure that answer to the Ultimate Question of Life, the Universe, and Everything""
""read""
""RETURN $input as answer""
[[""input"",""int"",""42""]]
[[""answer"",""number""]]
<null>
Remove a procedure apoc.custom.removeProcedure
The procedure apoc.custom.removeProcedure allows to delete the targeted custom procedure.
Given the this call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.removeProcedure(<name>)
Fields:
argument description
name
the procedure name
Remove a procedure apoc.custom.removeFunction
The procedure apoc.custom.removeFunction allows to delete the targeted custom function.
Given the this call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.removeFunction(<name>)
Fields:
argument description
name
the function name
How to manage procedure/function replication in a Causal Cluster
In order to replicate the procedure/function in a cluster environment you can tune the following parameters:
name type description
apoc.custom.procedures.refresh
long (default 60000)
the refresh time that allows replicating the procedure/function changes to each cluster member
Export metadata
To import custom procedures in another database (for example after a ./neo4j-admin backup and /neo4j-admin restore), please see the apoc.systemdb.export.metadata procedure.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.systemdb/apoc.systemdb.export.metadata;"apoc.systemdb.export.metadata
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure Apoc Extended
Signature
None
Copy to Clipboard
apoc.systemdb.export.metadata(config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
filename
String
""metadata""
The filename prefix. For example, metadata.customProcedures.dbName.cypher
features
List<String>
[""CypherProcedure"", ""CypherFunction"", ""Uuid"", ""Trigger"", ""DataVirtualizationCatalog""]
A list indicating which functions are to be exported. Possible values are ""CypherProcedure"", ""CypherFunction"", ""Uuid"", ""Trigger"", ""DataVirtualizationCatalog"".
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
To use this procedure, we have to enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.export.file.enabled=true
If we execute in a database neo4j the following queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('trig','RETURN $alpha', {phase: 'after'}, {params: {alpha: 1} });
CALL apoc.trigger.add('trigTwo','RETURN 1', null);
CALL apoc.trigger.pause('trigTwo');
CALL apoc.custom.declareFunction('funNameOne(val = 2 :: INTEGER) :: NODE ', 'MATCH (t:Target {value : $val}) RETURN t');
CALL apoc.custom.declareProcedure('procNameOne(one = 2 ::INTEGER?, two = 3 :: INTEGER?) :: (sum :: INTEGER) ', 'RETURN $one + $two as sum');
CALL apoc.custom.asProcedure('procName','RETURN $input as answer','read',[['answer','number']],[['input','int','42']], 'Procedure that answer to the Ultimate Question of Life, the Universe, and Everything');
CALL apoc.custom.asFunction('funName','RETURN $input as answer','long', [['input','number']], false);
CREATE CONSTRAINT person_cons ON (p:Person) ASSERT p.alpha IS UNIQUE;
CALL apoc.uuid.install('Person', {addToSetLabels: true, uuidProperty: 'alpha'});
CALL apoc.dv.catalog.add(""dvName"", {type: 'CSV', url: 'file://myUrl', query: 'map.name = $name and map.age = $age', desc: ""person's details"", labels: ['Person']});
and in a database another:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('trigAnother','RETURN 1', null);
If we execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.export.metadata()
we obtain the following files:
Cypher
metadata.customProcedures.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareFunction('funNameOne(val = 2 :: INTEGER?) :: (NODE?)', 'MATCH (t:Target {value : $val}) RETURN t' , false, '');
CALL apoc.custom.declareProcedure('procNameOne(one = 2 :: INTEGER?, two = 3 :: INTEGER?) :: (sum :: INTEGER?)', 'RETURN $one + $two as sum' , 'READ', '');
CALL apoc.custom.declareProcedure('procName(input = 42 :: INTEGER?) :: (answer :: NUMBER?)', 'RETURN $input as answer' , 'READ', 'Procedure that answer to the Ultimate Question of Life, the Universe, and Everything');
CALL apoc.custom.declareFunction('funName(input :: NUMBER?) :: (INTEGER?)', 'RETURN $input as answer' , false, '');
Cypher
metadata.dvCatalogs.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.catalog.add('dvName', {name:""dvName"",url:""file://myUrl"",desc:""person's details"",labels:[""Person""],query:""map.name = $name and map.age = $age"",params:[""$name"",""$age""],type:""CSV""});
Cypher
metadata.triggers.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add('trig', 'RETURN $alpha', {phase:""after""},{params: {alpha:1}});
CALL apoc.trigger.add('trigTwo', 'RETURN 1', null,{params: {}});
CALL apoc.trigger.pause('trigTwo');
Cypher
metadata.uuids.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.install('Person', {uuidProperty:""alpha"",addToSetLabels:true}) YIELD label RETURN label;
CALL apoc.uuid.install('Person', {uuidProperty:""beta"",addToSetLabels:null}) YIELD label RETURN label;
Cypher
metadata.uuids.schema.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT IF NOT EXISTS ON (n:Person) ASSERT n.alpha IS UNIQUE;
CREATE CONSTRAINT IF NOT EXISTS ON (n:Person) ASSERT n.beta IS UNIQUE;
So that we can import everything in another db, with the apoc.cypher.run* procedures:
Cypher
metadata.uuids.schema.neo4j.cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchemaFile(""metadata.uuids.schema.neo4j.cypher"");
CALL apoc.cypher.runFiles([""metadata.customProcedures.neo4j.cypher"", ""metadata.dvCatalogs.neo4j.cypher"", ""metadata.triggers.neo4j.cypher"", ""metadata.uuids.neo4j.cypher""])
We can choose what we want to export with config parameter features (this is a list of strings with possible values ""customProcedures"", ""triggers"", ""uuids"", ""dvCatalogs""). For example with:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.export.metadata({features: [""triggers"", ""uuids""]})
will be exported only metadata.triggers.neo4j.cypher and metadata.uuids.neo4j.cypher files.
Therefore, we can choose the file name prefix, for example if we want to export files with names customName.triggers.neo4j.cypher, etc…, we can do:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.export.metadata({filename: ""customName""})
Was this page helpful?"
https://neo4j.com/labs/apoc/5/cypher-execution/running-cypher;"Running Cypher fragments
Contents
Procedure Overview
Example: Fast Node-Counts by Label
We can use Cypher as a safe, graph-aware, partially compiled scripting language within APOC.
Procedure Overview
The supported procedures are described in the table below:
Qualified Name Type Release
apoc.cypher.parallel
- executes fragments in parallel through a list defined in paramMap with a key keyList
Procedure
Apoc Extended
apoc.cypher.parallel2
- executes fragments in parallel batches through a list defined in paramMap with a key keyList
Procedure
Apoc Extended
apoc.cypher.mapParallel
apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
Apoc Extended
apoc.cypher.mapParallel2
apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
Apoc Extended
Example: Fast Node-Counts by Label
We can quickly compute the number of nodes for a specific label using the count function, but only if that’s the only single thing in the query. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person) RETURN count(*);
We can also combine several with UNION ALL:
Cypher
Works
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person) RETURN count(*)
UNION ALL
MATCH (:Movie) RETURN count(*);
But we can’t do the same thing using the WITH clause:
Cypher
Doesn’t work
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)
WITH count(*) as people
MATCH (:Movie) RETURN people, count(*) as movies;
This query will work out the count by iterating over all nodes, which is a very slow operation
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.get/apoc.get.rels;"apoc.get.rels
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.get.rels(rel|id|[ids]) - quickly returns all relationships with these id’s
Signature
None
Copy to Clipboard
apoc.get.rels(relationships :: ANY?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
relationships
ANY?
null
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix);
We can return the internal IDs of these nodes using the id function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r]->()
RETURN id(r) AS id;
Table 1. Results
id
0
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.get.rels([0]);
Table 2. Results
rel
[:ACTED_IN {roles: [""Neo""]}]
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.info;"apoc.redis.info
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.info(uri, {config}) | Execute the 'INFO' command
Signature
None
Copy to Clipboard
apoc.redis.info(uri :: STRING?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.info
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.htmlPlainText;"apoc.load.htmlPlainText
Contents
Signature
Input parameters
Output parameters
Usage Examples
Load from runtime generated file
Css / jQuery selectors
Html as json list
Procedure Apoc Extended
apoc.load.htmlPlainText('urlOrHtml',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Signature
None
Copy to Clipboard
apoc.load.htmlPlainText(urlOrHtml :: STRING?, query = {} :: MAP?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
urlOrHtml
STRING?
null
query
MAP?
{}
config
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
We can extract the <h1> tag and the tag with id mp-right the Wikipedia home page, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""https://en.wikipedia.org/"",{h1:""h1"", mp:""#mp-right""});
with a result like this (that is, a map of mp: ""content of tag with id mp-right"", h1: ""content of h1 tags""):
Table 1. Results
Output
{
  ""mp"": ""

In the news

Elizabeth II
 - In Nigeria, at least 40 people are killed in an attack  at a Catholic church  in Owo , Ondo State .
 - A fire and explosions  at a storage depot in Sitakunda , Bangladesh, kill at least 49 people and
injure more than 450 others.
 - The Commonwealth of Nations  celebrates the Platinum Jubilee  of Elizabeth

II (pictured) .
 - Denmark votes  to eliminate its opt-out  of the European Union 's Common Security and Defence
Policy . Ongoing :
 - COVID-19 pandemic
 - Russian invasion of Ukraine Recent deaths :
 - Paula Rego
 - Christopher Pratt
 -
Dorothy E. Smith

 - Zeta Emilianidou
 -
Ann Turner Cook

 - Barry Sussman
 - Nominate an article

On this day


June 10
Frederick Barbarossa
 - 1190  – Third Crusade : Frederick Barbarossa (pictured) , Holy Roman Emperor , drowned in the
Saleph River  in Anatolia .
 - 1692  – Bridget Bishop  became the first person to be executed for witchcraft  in the Salem witch
trials  in colonial Massachusetts .
 - 1878  – The League of Prizren  was officially founded to ""struggle in arms to defend the wholeness
of the territories of Albania"".
 - 1925  – The United Church of Canada , the country's largest Protestant  denomination, held its
inaugural service at the Mutual Street Arena  in Toronto.
 - 2008  – Sudan Airways Flight 109  crashed on landing at Khartoum International Airport , killing
30 of the 214 occupants on board.
 - Theodor Philipsen  ( b.
 1840)
 - Margarito Bautista  ( b.
 1878)
 - Margaret Abbott  ( d.
 1955)  More anniversaries:
 - June 9
 - June 10
 - June 11
 - Archive
 - By email
 - List of days of the year ""
,

  ""h1"": ""
Main Page


Welcome to Wikipedia

""
}
or we can extract and get the whole body document by running:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""https://en.wikipedia.org/"",{body:""body""})
YIELD value
RETURN value[""body""]
with a result similar to this:
Table 2. Results
body
""
Main Page
From Wikipedia, the free encyclopedia Jump to navigation Jump to search

Welcome to Wikipedia

, the free encyclopedia  that anyone can edit . 6,510,947  articles in English


From today's featured article

Life restoration  of Mosasaurus hoffmanni
Mosasaurus  is a genus  of mosasaurs , an extinct group of aquatic scaly reptiles . It lived from
about 82 to 66 million years ago during the Late Cretaceous . Its earliest fossils were found as
skulls near the River Meuse  ( Mosa  in Latin). In 1808, Georges Cuvier  concluded that the skulls
belonged to a giant marine lizard with similarities to monitors  but otherwise unlike any known
living animal, supporting the then-developing idea of extinction . Scientists continue to
debate whether its closest living relatives are monitors or snakes . Mosasaurus  had jaws
capable of swinging back and forth and was capable of powerful bites, using dozens of teeth
designed for cutting prey. Its four limbs were shaped into paddles to steer underwater.
Mosasaurus  was a predator with excellent vision but a poor sense of smell, and a high metabolic
rate suggesting it was warm-blooded . It lived in much of the Atlantic  and in a wide range of
oceanic climates including tropical, subtropical, temperate, and subpolar. ( Full
article... )
 Recently featured:
 - On the Job  (2013 film)
 - White swamphen
 - Lake Estancia
 - Archive
 - By email
 - More featured articles

Did you know ...

Bare formula shelves with purchase limit notice, January 2022
 - ... that the ongoing infant formula shortage in the United States (example pictured)  also
affects non-infant medical patients who require nasogastric feeding ?
 - ... that John Jacob Withrow  allegedly did not consult anyone before announcing a permanent
exhibition  in Toronto?
 - ... that the Hawaii Civil Liberties Committee  was designated as a Communist front  by the House
Un-American Activities Committee ?
 - ... that Mahendra Raj
's
 engineering work on the Hindustan Lever pavilion  resembled a crumpled sheet of paper?
 - ... that the clown character Mombo was created for The Dr. Max Show  after being blamed for an
off-stage noise?
 - ... that Roddie Fleming  was expecting to inherit the family business, but it was sold to Chase
Bank  instead?
 - ... that Darkness Visible: A Study of Vergil's Aeneid  was thought by one reviewer to have ""the
remarkable qualities of the oracular""?
 - ... that Sunny Low  and his sister were dubbed the ""King and Queen of Cha-Cha-Cha and Rock 'n'
Roll""?
 - Archive
 - Start a new article
 - Nominate an article

In the news

Elizabeth II
 - In Nigeria, at least 40 people are killed in an attack  at a Catholic church  in Owo , Ondo State .
 - A fire and explosions  at a storage depot in Sitakunda , Bangladesh, kill at least 49 people and
injure more than 450 others.
 - The Commonwealth of Nations  celebrates the Platinum Jubilee  of Elizabeth

II (pictured) .
 - Denmark votes  to eliminate its opt-out  of the European Union 's Common Security and Defence
Policy . Ongoing :
 - COVID-19 pandemic
 - Russian invasion of Ukraine Recent deaths :
 - Paula Rego
 - Christopher Pratt
 -
Dorothy E. Smith

 - Zeta Emilianidou
 -
Ann Turner Cook

 - Barry Sussman
 - Nominate an article

On this day


June 10
Frederick Barbarossa
 - 1190  – Third Crusade : Frederick Barbarossa (pictured) , Holy Roman Emperor , drowned in the
Saleph River  in Anatolia .
 - 1692  – Bridget Bishop  became the first person to be executed for witchcraft  in the Salem witch
trials  in colonial Massachusetts .
 - 1878  – The League of Prizren  was officially founded to ""struggle in arms to defend the wholeness
of the territories of Albania"".
 - 1925  – The United Church of Canada , the country's largest Protestant  denomination, held its
inaugural service at the Mutual Street Arena  in Toronto.
 - 2008  – Sudan Airways Flight 109  crashed on landing at Khartoum International Airport , killing
30 of the 214 occupants on board.
 - Theodor Philipsen  ( b.
 1840)
 - Margarito Bautista  ( b.
 1878)
 - Margaret Abbott  ( d.
 1955)  More anniversaries:
 - June 9
 - June 10
 - June 11
 - Archive
 - By email
 - List of days of the year


....


""
Note that the procedure returns empty results in case of tags without textual content, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""https://en.wikipedia.org/"", {meta:""meta""});
Table 3. Results
value
{ ""meta"": """" }
Load from runtime generated file
If we have a test.html file with a jQuery script like:
Html
Copy to Clipboard
<!DOCTYPE html>
<html>
    <head>
      <script src=""https://code.jquery.com/jquery-1.9.1.min.js""></script>
      <script type=""text/javascript"">
        $(() => {
            var newP = document.createElement(""strong"");
            var textNode = document.createTextNode(""This is a new text node"");
            newP.appendChild(textNode);
            document.getElementById(""appendStuff"").appendChild(newP);
        });
      </script>
    </head>
    <body>
        <div id=""appendStuff""></div>
    </body>
</html>
we can read the generated js through the browser config. Note that to use the browser config (except with ""NONE"" value), you have to install additional dependencies which can be downloaded from this link.
For example, with the above file we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""test.html"", {strong: ""strong""}, {browser: ""FIREFOX""});
Table 4. Results
Output
Json
Copy to Clipboard
{ ""body"": ""This is a new text node "" }
If we have to parse a tag from a slow async call, we can use wait config to waiting for 10 second (in this example):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""test.html"", {asyncTag: ""#asyncTag""}, {browser: ""FIREFOX"", wait: 10});
We can also pass an HTML string into the 1st parameter by putting as a config parameter htmlString: true, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText(""<!DOCTYPE html> <html> <body> <p class='firstClass'>My first paragraph.</p> </body> </html>"",{body:""body""}, {htmlString: true})
YIELD value
RETURN value[""body""] as body
Table 5. Results
body ---- "" My first paragraph. "" ----
Css / jQuery selectors
The jsoup class org.jsoup.nodes.Element provides a set of functions that can be used. Anyway, we can emulate all of them using the appropriate css/jQuery selectors in these ways (except for the last one, we can substitute the with a tag name to search into it instead of everywhere. Furthermore, by removing the selector will be returned the same result):
jsoup function css/jQuery selector description
getElementById(id)
#id
Find an element by ID, including or under this element.
getElementsByTag(tag)
tag
Finds elements, including and recursively under this element, with the specified tag name.
getElementsByClass(className)
.className
Find elements that have this class, including or under this element.
getElementsByAttribute(key)
[key]
Find elements that have a named attribute set.
getElementsByAttributeStarting(keyPrefix)
*[^keyPrefix]
Find elements that have an attribute name starting with the supplied prefix. Use data
to find elements that have HTML5 datasets.
getElementsByAttributeValue(key,value)
*[key=value]
Find elements that have an attribute with the specific value.
getElementsByAttributeValueContaining(key,match)
[key=match]
Find elements that have attributes whose value contains the match string.
getElementsByAttributeValueEnding(key,valueSuffix)
*[class$=""test""]
Find elements that have attributes that end with the value suffix.
getElementsByAttributeValueMatching(key,regex)
*[id~=content]
Find elements that have attributes whose values match the supplied regular expression.
getElementsByAttributeValueNot(key,value)
*:not([key=""value""])
Find elements that either do not have this attribute, or have it with a different value.
getElementsByAttributeValueStarting(key,valuePrefix)
*[key^=valuePrefix]
Find elements that have attributes that start with the value prefix.
getElementsByIndexEquals(index)
*:nth-child(index)
Find elements whose sibling index is equal to the supplied index.
getElementsByIndexGreaterThan(index)
*:gt(index)
Find elements whose sibling index is greater than the supplied index.
getElementsByIndexLessThan(index)
*:lt(index)
Find elements whose sibling index is less than the supplied index.
getElementsContainingOwnText(searchText)
*:containsOwn(searchText)
Find elements that directly contain the specified string.
getElementsContainingText(searchText)
*:contains('searchText')
Find elements that contain the specified string.
getElementsMatchingOwnText(regex)
*:matches(regex)
Find elements whose text matches the supplied regular expression.
getElementsMatchingText(pattern)
*:matchesOwn(pattern)
Find elements whose text matches the supplied regular expression.
getAllElements()
*
For example, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.htmlPlainText($url, {nameKey: '#idName'})
Table 6. Results
Output
Json
Copy to Clipboard
{
  ""h6"": [
    {
      ""attributes"": {
        ""id"": ""idName""
      },
      ""text"": ""test"",
      ""tagName"": ""h6""
    }
  ]
}
Html as json list
If, instead of a map of plain text representations, you want to get a map of json list results, you can use the apoc.load.html procedure, which use the same syntax, logic and config parameters as apoc.load.htmlPlainText.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.html;"apoc.load.html
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Load from runtime generated file
Css / jQuery selectors
Html plain text representation
Procedure Apoc Extended
apoc.load.html('url',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Signature
None
Copy to Clipboard
apoc.load.html(url :: STRING?, query = {} :: MAP?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
url
STRING?
null
query
MAP?
{}
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
browser
Enum [NONE, CHROME, FIREFOX]
NONE
If it is set to ""CHROME"" or ""FIREFOX"", is used Selenium Web Driver to read the dynamically generated js. In case it is ""NONE"" (default), it is not possible to read dynamic contents. Note that to use the Chrome or Firefox driver, you need to have them installed on your machine and you have to download additional jars into the plugin folder. See below
wait
long
0
If greater than 0, it waits until it finds at least one element for each of those entered in the query parameter (up to a maximum of defined seconds, otherwise it continues execution). Useful to handle elements which can be rendered after the page is loaded (i.e. slow asynchronous calls).
charset
String
""UTF-8""
the character set of the page being scraped, if http-equiv meta-tag is not set.
headless
boolean
true
Valid with browser not equal to NONE, allow to run browser in headless mode, that is without actually opening the browser UI (recommended).
acceptInsecureCerts
boolean
true
If true, allow to read html from insecure certificates
baseUri
String
""""
Base URI used to resolve relative paths
failSilently
Enum [FALSE, WITH_LOG, WITH_LIST]
FALSE
If the parse fails with one or more elements, using FALSE it throws a RuntimeException, using WITH_LOG a log.warn is created for each incorrect item and using WITH_LIST an errorList key is added to the result with the failed tags.
htmlString
boolean
true
to use a string instead of an url as 1st parameter
Output parameters
Name Type
value
MAP?
Usage Examples
We can extract the metadata and h2 heading from the Wikipedia home page, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""https://en.wikipedia.org/"",{metadata:""meta"", h2:""h2""});
Table 2. Results
Output
Json
Copy to Clipboard
{
   ""metadata"":[
      {
         ""tagName"":""meta"",
         ""attributes"":{
            ""charset"":""UTF-8""
         }
      },
      {
         ""tagName"":""meta"",
         ""attributes"":{
            ""name"":""ResourceLoaderDynamicStyles""
         }
      },
      {
         :,
         :{
            :,
            :
         }
      },
      {
         :,
         :{
            :,
            :
         }
      },
      {
         :,
         :{
            :,
            :
         }
      },
      {
         :,
         :{
            :,
            :
         }
      },
      {
         :,
         :{
            :,
            :
         }
      }
   ],
   :[
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :{
            :,
            :
         },
         :,
         :
      },
      {
         :,
         :
      }
   ]
}
View all (116 more lines)
Let’s suppose we have a test.html file like this:
Html
Copy to Clipboard
<!DOCTYPE html>
<html class=""client-nojs"" lang=""en"" dir=""ltr"">
  <h6 i d=""error"">test</h6>
  <h6 id=""correct"">test</h6>
</html>
We can handle the parse error caused by i d through failSilently configuration. So, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""test.html"",{h6:""h6""});
Table 3. Results
Failed to invoke procedure apoc.load.html: Caused by: java.lang.RuntimeException: Error during parsing element: <h6 i d=""error"">test</h6>
or with failSilently WITH_LIST:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""test.html"",{h6:""h6""}, {failSilently: 'WITH_LIST'});
Table 4. Results
Output
Json
Copy to Clipboard
{
  ""errorList"": [
    ""<h6 i d=""error"">test</h6>""
  ],
  ""h6"": [
    {
      ""attributes"": {
        ""id"": ""correct""
      },
      ""text"": ""test"",
      ""tagName"": ""h6""
    }
  ]
}
or with failSilently WITH_LOG (note that will be created a log.warn(""Error during parsing element: <h6 i d=""error"">test</h6>"") ):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""test.html"",{h6:""h6""}, {failSilently: 'WITH_LOG'});
Table 5. Results
Output
Json
Copy to Clipboard
{
  ""h6"": [
    {
      ""attributes"": {
        ""id"": ""correct""
      },
      ""text"": ""test"",
      ""tagName"": ""h6""
    }
  ]
}
Load from runtime generated file
If we have a test.html file with a jQuery script like:
Html
Copy to Clipboard
<!DOCTYPE html>
<html>
    <head>
      <script src=""https://code.jquery.com/jquery-1.9.1.min.js""></script>
      <script type=""text/javascript"">
        $(() => {
            var newP = document.createElement(""strong"");
            var textNode = document.createTextNode(""This is a new text node"");
            newP.appendChild(textNode);
            document.getElementById(""appendStuff"").appendChild(newP);
        });
      </script>
    </head>
    <body>
        <div id=""appendStuff""></div>
    </body>
</html>
we can read the generated js through the browser config. Note that to use the browser config (except with ""NONE"" value), you have to install additional dependencies which can be downloaded from this link.
For example, with the above file we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""test.html"",{strong: ""strong""}, {browser: ""FIREFOX""});
Table 6. Results
Output
Json
Copy to Clipboard
{
  ""strong"": [
    {
      ""tagName"": ""strong"",
      ""text"": ""This is a new text node""
    }
  ]
}
If we have to parse a tag from a slow async call, we can use wait config to waiting for 10 second (in this example):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""test.html"",{asyncTag: ""#asyncTag""}, {browser: ""FIREFOX"", wait: 10});
We can also pass an HTML string into the 1st parameter by putting as a config parameter htmlString: true, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""<!DOCTYPE html> <html> <body> <p class='firstClass'>My first paragraph.</p> </body> </html>"",{body:""body""}, {htmlString: true})
YIELD value
RETURN value[""body""] as body
Table 7. Results
body
Json
Copy to Clipboard
[{
  ""attributes"": {},
  ""text"": ""My first paragraph."",
  ""tagName"": ""body""
}]
Css / jQuery selectors
The jsoup class org.jsoup.nodes.Element provides a set of functions that can be used. Anyway, we can emulate all of them using the appropriate css/jQuery selectors in these ways (except for the last one, we can substitute the with a tag name to search into it instead of everywhere. Furthermore, by removing the selector will be returned the same result):
jsoup function css/jQuery selector description
getElementById(id)
#id
Find an element by ID, including or under this element.
getElementsByTag(tag)
tag
Finds elements, including and recursively under this element, with the specified tag name.
getElementsByClass(className)
.className
Find elements that have this class, including or under this element.
getElementsByAttribute(key)
[key]
Find elements that have a named attribute set.
getElementsByAttributeStarting(keyPrefix)
*[^keyPrefix]
Find elements that have an attribute name starting with the supplied prefix. Use data
to find elements that have HTML5 datasets.
getElementsByAttributeValue(key,value)
*[key=value]
Find elements that have an attribute with the specific value.
getElementsByAttributeValueContaining(key,match)
[key=match]
Find elements that have attributes whose value contains the match string.
getElementsByAttributeValueEnding(key,valueSuffix)
*[class$=""test""]
Find elements that have attributes that end with the value suffix.
getElementsByAttributeValueMatching(key,regex)
*[id~=content]
Find elements that have attributes whose values match the supplied regular expression.
getElementsByAttributeValueNot(key,value)
*:not([key=""value""])
Find elements that either do not have this attribute, or have it with a different value.
getElementsByAttributeValueStarting(key,valuePrefix)
*[key^=valuePrefix]
Find elements that have attributes that start with the value prefix.
getElementsByIndexEquals(index)
*:nth-child(index)
Find elements whose sibling index is equal to the supplied index.
getElementsByIndexGreaterThan(index)
*:gt(index)
Find elements whose sibling index is greater than the supplied index.
getElementsByIndexLessThan(index)
*:lt(index)
Find elements whose sibling index is less than the supplied index.
getElementsContainingOwnText(searchText)
*:containsOwn(searchText)
Find elements that directly contain the specified string.
getElementsContainingText(searchText)
*:contains('searchText')
Find elements that contain the specified string.
getElementsMatchingOwnText(regex)
*:matches(regex)
Find elements whose text matches the supplied regular expression.
getElementsMatchingText(pattern)
*:matchesOwn(pattern)
Find elements whose text matches the supplied regular expression.
getAllElements()
*
For example, we can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html($url, {nameKey: '#idName'})
Table 8. Results
Output
Json
Copy to Clipboard
{
  ""h6"": [
    {
      ""attributes"": {
        ""id"": ""idName""
      },
      ""text"": ""test"",
      ""tagName"": ""h6""
    }
  ]
}
Html plain text representation
If, instead of a map of json list results, you want to get a map of plain text representations, you can use the apoc.load.htmlPlainText procedure, which use the same syntax, logic and config parameters as apoc.load.html.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.static/apoc.static.list;"apoc.static.list
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.static.list(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Signature
None
Copy to Clipboard
apoc.static.list(prefix :: STRING?) :: (key :: STRING?, value :: ANY?)
Input parameters
Name Type Default
prefix
STRING?
null
Output parameters
Name Type
key
STRING?
value
ANY?
Usage Examples
The example in this section assumes that we’ve first stored values in memory using apoc.static.set:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.static.set(""twitter.user"", ""Michael"");
CALL apoc.static.set(""twitter.username"", ""mesirii"");
Cypher
The following returns all static values under the twitter prefix:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.static.list(""twitter"");
Table 1. Results
key
value
""user""
""Michael""
""username""
""mesirii""
More documentation of apoc.static.list
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate;"apoc.generate
Qualified Name Type
apoc.generate.ba
apoc.generate.ba(noNodes, edgesPerNode, label, type) - generates a random graph according to the Barabasi-Albert model
Procedure
apoc.generate.complete
apoc.generate.complete(noNodes, label, type) - generates a random complete graph
Procedure
apoc.generate.er
apoc.generate.er(noNodes, noEdges, label, type) - generates a random graph according to the Erdos-Renyi model
Procedure
apoc.generate.simple
apoc.generate.simple(degrees, label, type) - generates a simple random graph according to the given degree distribution
Procedure
apoc.generate.ws
apoc.generate.ws(noNodes, degree, beta, label, type) - generates a random graph according to the Watts-Strogatz model
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate/apoc.generate.simple;"apoc.generate.simple
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.generate.simple(degrees, label, type) - generates a simple random graph according to the given degree distribution
Signature
None
Copy to Clipboard
apoc.generate.simple(degrees :: LIST? OF INTEGER?, label :: STRING?, type :: STRING?) :: VOID
Input parameters
Name Type Default
degrees
LIST? OF INTEGER?
null
label
STRING?
null
type
STRING?
null
Usage Examples
The following creates a graph of 5 nodes, each connected to two other nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.simple([2,2,2,2,2], ""Node"", ""CONNECTED_TO"");
More documentation of apoc.generate.simple
Was this page helpful?"
https://neo4j.com/labs/apoc/5/graph-updates/graph-generators;"Generating Graphs
Generate undirected (random direction) graphs with semi-real random distributions based on theoretical models. Providing a node label will generate nodes with that label and a random uuid property. Providing a relationship type will generate relationships with that type. Providing null in place of labels and/or relationships will generate random Person nodes with a random name and FRIEND_OF relationships, respectively.
For a theoretical introduction, please take a look at the following blog posts:
Random Graph Models (Part I)
Random Graph Models (Part II)
For permitted configuration values, please look at the Javadoc of config classes of the respective generators (BarabasiAlbertConfig, ErdosRenyiConfig, WattsStrogatzConfig, and DistributionBasedConfig).
Apart from the number of nodes you would like to generate, null can be passed in for all other parameters. Sensible defaults will be used.
Example
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.ba(1000, 2, 'TestLabel', 'TEST_REL_TYPE')
CALL apoc.generate.ws(1000, null, null, null)
CALL apoc.generate.simple([2,2,2,2], null, null)
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate/apoc.generate.complete;"apoc.generate.complete
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.generate.complete(noNodes, label, type) - generates a random complete graph
Signature
None
Copy to Clipboard
apoc.generate.complete(noNodes :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID
Input parameters
Name Type Default
noNodes
INTEGER?
null
label
STRING?
null
type
STRING?
null
Usage Examples
The following creates a graph of 10 nodes where every node is connected to all other nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.complete(10, ""Node"", ""CONNECTED_TO"");
More documentation of apoc.generate.complete
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate/apoc.generate.er;"apoc.generate.er
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.generate.er(noNodes, noEdges, label, type) - generates a random graph according to the Erdos-Renyi model
Signature
None
Copy to Clipboard
apoc.generate.er(noNodes :: INTEGER?, noEdges :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID
Input parameters
Name Type Default
noNodes
INTEGER?
null
noEdges
INTEGER?
null
label
STRING?
null
type
STRING?
null
Usage Examples
The following creates a random graph of 10 nodes with 3 relationships each, using the Erdos-Renyi model:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.er(10,3,null,null);
More documentation of apoc.generate.er
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate/apoc.generate.ws;"apoc.generate.ws
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.generate.ws(noNodes, degree, beta, label, type) - generates a random graph according to the Watts-Strogatz model
Signature
None
Copy to Clipboard
apoc.generate.ws(noNodes :: INTEGER?, degree :: INTEGER?, beta :: FLOAT?, label :: STRING?, type :: STRING?) :: VOID
Input parameters
Name Type Default
noNodes
INTEGER?
null
degree
INTEGER?
null
beta
FLOAT?
null
label
STRING?
null
type
STRING?
null
Usage Examples
The following creates a random graph of 10 nodes, using the Watts-Strogatz model:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.ws(10, null, null, null, null);
More documentation of apoc.generate.ws
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.generate/apoc.generate.ba;"apoc.generate.ba
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.generate.ba(noNodes, edgesPerNode, label, type) - generates a random graph according to the Barabasi-Albert model
Signature
None
Copy to Clipboard
apoc.generate.ba(noNodes :: INTEGER?, edgesPerNode :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID
Input parameters
Name Type Default
noNodes
INTEGER?
null
edgesPerNode
INTEGER?
null
label
STRING?
null
type
STRING?
null
Usage Examples
The following creates a random graph of 10 nodes with 3 relationships each, using the Barabasi-Albert model:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.generate.ba(10,3,null,null);
More documentation of apoc.generate.ba
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.namedParamsQuery;"apoc.couchbase.namedParamsQuery
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.namedParamsQuery(hostkOrKey, bucket, statement, paramNames, paramValues, config) yield queryResult - executes a N1QL statement with named parameters.
Signature
None
Copy to Clipboard
apoc.couchbase.namedParamsQuery(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, paramNames :: LIST? OF STRING?, paramValues :: LIST? OF ANY?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
statement
STRING?
null
paramNames
LIST? OF STRING?
null
paramValues
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
queryResult
LIST? OF MAP?
More documentation of apoc.couchbase.namedParamsQuery
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/couchbase;"Couchbase
Contents
Install Dependencies
Usage
Configuration parameters
Qualified Name Type Release
apoc.couchbase.get
apoc.couchbase.get(hostOrKey, bucket, documentId) yield id, expiry, cas, mutationToken, content - retrieves a couchbase json document by its unique ID.
Procedure
Apoc Extended
apoc.couchbase.exists
apoc.couchbase.exists(hostOrKey, bucket, documentId) yield value - check whether a couchbase json document with the given ID does exist.
Procedure
Apoc Extended
apoc.couchbase.upsert
apoc.couchbase.upsert(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - insert or overwrite a couchbase json document with its unique ID.
Procedure
Apoc Extended
apoc.couchbase.append
apoc.couchbase.append(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - append a couchbase json document to an existing one.
Procedure
Apoc Extended
apoc.couchbase.prepend
apoc.couchbase.prepend(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - prepend a couchbase json document to an existing one.
Procedure
Apoc Extended
apoc.couchbase.remove
apoc.couchbase.remove(hostOrKey, bucket, documentId) yield id, expiry, cas, mutationToken, content - remove the couchbase json document identified by its unique ID.
Procedure
Apoc Extended
apoc.couchbase.replace
apoc.couchbase.replace(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - replace the content of the couchbase json document identified by its unique ID.
Procedure
Apoc Extended
apoc.couchbase.query
apoc.couchbase.query(hostOrKey, bucket, statement) yield queryResult - executes a plain un-parameterized N1QL statement.
Procedure
Apoc Extended
Install Dependencies
(Tested with CB Enterprise 5.5.3)
The Couchbase procedures have dependencies on a client library that is not included in the APOC Extended library. This dependency is included in apoc-couchbase-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you could copy into the plugins directory, from maven repository, the Couchbase Java SDK, and the Couchbase JVM Core IO
Usage
To interact with Couchbase you can define the host on which to connect to as the first parameter of the procedure (with bucket as second parameter, document_id as third parameter):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.couchbase.get('couchbase://Administrator:password@localhost', 'default', 'artist:vincent_van_gogh')
Otherwise you can use configuration properties in the same way as MongoDB. For example, you can add the following properties to the apoc.conf file:
apoc.couchbase.mykey.username=Administrator
apoc.couchbase.mykey.password=password
apoc.couchbase.mykey.uri=host1,host2,host3 // here you can define more than one hostname if you're using a cluster
apoc.couchbase.mykey.port=8091 // the bootstrapHttpDirectPort (optional)
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.couchbase.get('mykey', 'default', 'artist:vincent_van_gogh')
You can also define some CouchbaseEnvironment parameters in the apoc.conf:
apoc.couchbase.connectTimeout=<default=5000>
apoc.couchbase.kvTimeout=<default=2500>
apoc.couchbase.ioPoolSize=<default=3>
In order to get an in-depth description of these configuration params please refer to the Official Couchbase Documentation
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
collection
String
""_default""
the collection to use. See Scope and collections
scope
String
""_default""
the scope to use. See Scope and collections
compressionEnabled
boolean
true
If enabled, the client will compress documents before they are sent to Couchbase Server. See here.
compressionMinSize
Integer
32
Size in bytes. Documents smaller than this size are never compressed.
compressionMinRatio
Double
0.83
A value between 0 and 1. Specifies how ""compressible"" a document must be in order for the compressed form to be sent to the server.
mutationTokensEnabled
boolean
true
Mutation tokens allow enhanced durability requirements as well as advanced N1QL querying capabilities. Set this to false if you do not require these features and wish to avoid the associated overhead.
retryStrategy
Enum[FAILFAST, BESTEFFORT]
BESTEFFORT
The client’s default retry strategy. A retry strategy decides whether a failed operation should be retried. See here.
transcoder
Enum[DEFAULT, RAWJSON, RAWSTRING, RAWBINARY]
DEFAULT
The transcoder responsible for converting KV binary packages to and from Java objects.
connectTimeout
Long
null
The connection timeout (in milliseconds) used when a Bucket is opened. If null will be used the apoc.conf parameter apoc.couchbase.connectTimeout.
kvTimeout
Long
null
The Key/Value default timeout (in milliseconds) used on operations which are performed on a specific key. If null will be used the apoc.conf parameter apoc.couchbase.kvTimeout.
disconnectTimeout
Long
10000
The disconnect timeout (in milliseconds) is used when a Cluster is disconnected
queryTimeout
Long
75000
The Query timeout (in milliseconds) used on all N1QL query operations
analyticsTimeout
Long
75000
The Analytics timeout (in milliseconds) used on all Analytics query operations.
viewTimeout
Long
75000
The View timeout (in milliseconds) used on view operations. If there is a node failure during the request the internal cluster timeout is set to 60 seconds.
searchTimeout
Long
75000
The Search timeout is used on all FTS operations
configPollInterval
Long
2500
The interval at which the client fetches cluster topology information in order to proactively detect changes.
idleHttpConnectionTimeout
Long
4500
The length of time an HTTP connection may remain idle before it is closed and removed from the pool. Durations longer than 50 seconds are not recommended, since some services have a 1 minute server side idle timeout.
enableTcpKeepAlives
boolean
true
If enabled, the client periodically sends a TCP keepalive to the server to prevent firewalls and other network equipment from dropping idle TCP connections.
tcpKeepAliveTime
long
60000
The idle time after which a TCP keepalive gets fired. (This setting has no effect if enableTcpKeepAlives is false.) TODO
enableDnsSrv
boolean
true
Gets the bootstrap node list from a DNS SRV record. TODO
networkResolution
com.couchbase.client.core.env.NetworkResolution
null
The network resolution. See here for details.
trustCertificate
boolean
null
If not null, it is the path to a file containing a single X.509 certificate to trust as a Certificate Authority when establishing secure connections. This enable Tls, if present. See here for details.
waitUntilReady
Long
null
This method will wait until either the cluster state is ""online"" by default, or the timeout is reached.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.remove;"apoc.couchbase.remove
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.remove(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - remove the couchbase json document identified by its unique ID.
Signature
None
Copy to Clipboard
apoc.couchbase.remove(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
config
MAP?
{}
Output parameters
Name Type
content
MAP?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.remove
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.prepend;"apoc.couchbase.prepend
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.prepend(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - prepend a couchbase json document to an existing one.
Signature
None
Copy to Clipboard
apoc.couchbase.prepend(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, content :: BYTEARRAY?, config = {} :: MAP?) :: (content :: BYTEARRAY?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
content
BYTEARRAY?
null
config
MAP?
{}
Output parameters
Name Type
content
BYTEARRAY?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.prepend
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.get;"apoc.couchbase.get
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.get(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - retrieves a couchbase json document by its unique ID.
Signature
None
Copy to Clipboard
apoc.couchbase.get(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
config
MAP?
{}
Output parameters
Name Type
content
MAP?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.get
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.upsert;"apoc.couchbase.upsert
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.upsert(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - insert or overwrite a couchbase json document with its unique ID.
Signature
None
Copy to Clipboard
apoc.couchbase.upsert(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
json
STRING?
null
config
MAP?
{}
Output parameters
Name Type
content
MAP?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.upsert
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.exists;"apoc.couchbase.exists
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.exists(hostOrKey, bucket, documentId, config) yield value - check whether a couchbase json document with the given ID does exist.
Signature
None
Copy to Clipboard
apoc.couchbase.exists(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.couchbase.exists
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.append;"apoc.couchbase.append
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.append(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - append a couchbase json document to an existing one.
Signature
None
Copy to Clipboard
apoc.couchbase.append(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, content :: BYTEARRAY?, config = {} :: MAP?) :: (content :: BYTEARRAY?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
content
BYTEARRAY?
null
config
MAP?
{}
Output parameters
Name Type
content
BYTEARRAY?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.append
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.query;"apoc.couchbase.query
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.query(hostOrKey, bucket, statement, config) yield queryResult - executes a plain un-parameterized N1QL statement.
Signature
None
Copy to Clipboard
apoc.couchbase.query(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
statement
STRING?
null
config
MAP?
{}
Output parameters
Name Type
queryResult
LIST? OF MAP?
More documentation of apoc.couchbase.query
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.replace;"apoc.couchbase.replace
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.replace(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - replace the content of the couchbase json document identified by its unique ID.
Signature
None
Copy to Clipboard
apoc.couchbase.replace(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
json
STRING?
null
config
MAP?
{}
Output parameters
Name Type
content
MAP?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.replace
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load;"apoc.load
Qualified Name Type
apoc.load.csv
apoc.load.csv('urlOrBinary',{config}) YIELD lineNo, list, map - load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Procedure
apoc.load.csvParams
apoc.load.csvParams('urlOrBinary', {httpHeader: value}, payload, {config}) YIELD lineNo, list, map - load from CSV URL (e.g. web-api) while sending headers / payload to load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Procedure
apoc.load.directory
apoc.load.directory('pattern', 'urlDir', {config}) YIELD value - Loads list of all files in folder specified by urlDir or in import folder if urlDir string is empty or not specified
Procedure
apoc.load.directory.async.add
apoc.load.directory.async.add(name, cypher, pattern, urlDir, {}) YIELD name, status, pattern, cypher, urlDir, config, error - Add or replace a folder listener with a specific name, pattern and url directory that execute the specified cypher query when an event is triggered and return listener list
Procedure
apoc.load.directory.async.list
apoc.load.directory.async.list() YIELD name, status, pattern, cypher, urlDir, config, error - List of all folder listeners
Procedure
apoc.load.directory.async.remove
apoc.load.directory.async.remove(name) YIELD name, status, pattern, cypher, urlDir, config, error - Remove a folder listener by name and return remaining listeners, if any
Procedure
apoc.load.directory.async.removeAll
apoc.load.directory.async.removeAll() - Remove all folder listeners
Procedure
apoc.load.driver
apoc.load.driver('org.apache.derby.jdbc.EmbeddedDriver') register JDBC driver of source database
Procedure
apoc.load.html
apoc.load.html('url',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Procedure
apoc.load.htmlPlainText
apoc.load.htmlPlainText('urlOrHtml',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map
Procedure
apoc.load.jdbc
apoc.load.jdbc('key or url','table or statement', params, config) YIELD row - load from relational database, from a full table or a sql statement
Procedure
apoc.load.jdbcParams
deprecated - please use: apoc.load.jdbc('key or url','',[params]) YIELD row - load from relational database, from a sql statement with parameters
Procedure
apoc.load.jdbcUpdate
apoc.load.jdbcUpdate('key or url','statement',[params],config) YIELD row - update relational database, from a SQL statement with optional parameters
Procedure
apoc.load.ldap
apoc.load.ldap(""key"" or {connectionMap},{searchMap}) Load entries from an ldap source (yield entry)
Procedure
apoc.load.xls
apoc.load.xls('url','selector',{config}) YIELD lineNo, list, map - load XLS fom URL as stream of row values, config contains any of: {skip:1,limit:5,header:false,ignore:['tmp'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false, dateFormat:'iso_date', dateParse:['dd-MM-yyyy']}}
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.csv;"apoc.load.csv
Contents
Signature
Input parameters
Config parameters
Output parameters
Reading from a file
Usage Examples
Binary file
Procedure Apoc Extended
apoc.load.csv('urlOrBinary',{config}) YIELD lineNo, list, map - load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Signature
None
Copy to Clipboard
apoc.load.csv(urlOrBinary :: ANY?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, strings :: LIST? OF STRING?, map :: MAP?, stringMap :: MAP?)
Input parameters
Name Type Default
urlOrBinary
ANY?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
skip
boolean
none
skip result rows
limit
Long
none
limit result rows
header
booelan
true
indicates if file has a header
sep
String
','
separator character or 'TAB'
quoteChar
String
'""'
the char to use for quoted elements
escapeChar
String
'\'
the char to use for escape elements. Use ""NONE"" if you don’t want to use any characters
arraySep
String
';'
array separator
ignore
List<String>
[]
which columns to ignore
nullValues
List<String>
[]
which values to treat as null, e.g. ['na',false]
mapping
Map
{}
per field mapping, entry key is field name, .e.g {years:{….} see below
compression
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
Allow taking binary data, either not compressed (value: NONE) or compressed (other values) See the Binary file example
Output parameters
Name Type
lineNo
INTEGER?
list
LIST? OF ANY?
strings
LIST? OF STRING?
map
MAP?
stringMap
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
test.csv contains people and their properties:
test.csv
name,age,beverage
Selma,9,Soda
Rana,12,Tea;Milk
Selina,19,Cola
We’ll place this file into the import directory of our Neo4j instance.
We can load this file and return the contents by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv('test.csv')
YIELD lineNo, map, list
RETURN *;
Table 2. Results
lineNo list map
0
[""Selma"", ""9"", ""Soda""]
{name: ""Selma"", age: ""9"", beverage: ""Soda""}
1
[""Rana"", ""12"", ""Tea;Milk""]
{name: ""Rana"", age: ""12"", beverage: ""Tea;Milk""}
2
[""Selina"", ""19"", ""Cola""]
{name: ""Selina"", age: ""19"", beverage: ""Cola""}
Binary file
You can also import a file from a binary byte[] (not compressed) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv(`binaryGzipByteArray`, {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv(`binaryFileNotCompressed`, {compression: 'NONE'})
Table 3. Results
lineNo list map
0
[""Selma"", ""8""]
{name: ""Selma"", age: ""8""}
1
[""Rana"", ""11""]
{name: ""Rana"", age: ""11""}
2
[""Selina"", ""18""]
{name: ""Selina"", age: ""18""}
More documentation of apoc.load.csv
Was this page helpful?"
https://neo4j.com/labs/apoc/5/import/load-csv;"Load CSV
Contents
Examples for apoc.load.csv
Configuration Options
Transaction Batching
Error handling
Many existing applications and data integrations use CSV as the minimal denominator format. CSV files contain text with delimiters (most often comma, but also tab (TSV) and colon (DSV)) separating columns and newlines for rows. Fields are possibly quoted to handle stray quotes, newlines, and the use of the delimiter within a field.
In Cypher it is supported by LOAD CSV and with the neo4j-import (neo4j-admin import) tool for bulk imports. The existing LOAD CSV works ok for most uses, but has a few features missing, that apoc.load.csv and apoc.load.xls add.
provide a line number
provide both a map and a list representation of each line
automatic data conversion (including split into arrays)
option to keep the original string formatted values
ignoring fields (makes it easier to assign a full line as properties)
headerless files
replacing certain values with null
The APOC procedures also support reading compressed files.
The data conversion is useful for setting properties directly, but for computation within Cypher it’s problematic as Cypher doesn’t know the type of map values so they default to Any.
To use them correctly, you’ll have to indicate their type to Cypher by using the built-in (e.g. toInteger) conversion functions on the value.
For reading from files you’ll have to enable the config option:
apoc.import.file.enabled=true
By default file paths are global, for paths relative to the import directory set:
apoc.import.file.use_neo4j_config=true
Examples for apoc.load.csv
test.csv
name,age,beverage
Selma,9,Soda
Rana,12,Tea;Milk
Selina,19,Cola
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv('test.csv')
YIELD lineNo, map, list
RETURN *;
Table 1. Results
lineNo list map
0
[""Selma"", ""9"", ""Soda""]
{name: ""Selma"", age: ""9"", beverage: ""Soda""}
1
[""Rana"", ""12"", ""Tea;Milk""]
{name: ""Rana"", age: ""12"", beverage: ""Tea;Milk""}
2
[""Selina"", ""19"", ""Cola""]
{name: ""Selina"", age: ""19"", beverage: ""Cola""}
Configuration Options
Besides the file you can pass in a config map:
name default description
skip
none
skip result rows
limit
none
limit result rows
header
true
indicates if file has a header
sep
','
separator character or 'TAB'
quoteChar
'""'
the char to use for quoted elements
arraySep
';'
array separator
ignore
[]
which columns to ignore
nullValues
[]
which values to treat as null, e.g. ['na',false]
mapping
{}
per field mapping, entry key is field name, .e.g {years:{….} see below
failOnError
boolean
true
Table 2. mapping config for each field in the mapping entry
name default description
type
none
'int', 'string' etc.
array
false
indicates if field is an array
arraySep
';'
separator for array
name
none
rename field
ignore
false
ignore/remove this field
nullValues
[]
which values to treat as null, e.g. ['na',false]
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv('test.csv', {skip:1, limit:1, header:true, ignore:['name'],
   mapping:{
     age: {type:'int'},
     beverage: {array:true, arraySep:';', name:'drinks'}
   }
})
YIELD lineNo, map, list
RETURN *;
Table 3. Results
lineNo list map
1
[12,[""Tea"",""Milk""]]
{""age"":12,""drinks"":[""Tea"",""Milk""]}
Transaction Batching
To handle large files, CALL … IN TRANSACTIONS can be used together with LOAD CSV, you’ll have to watch out though for Eager operations which might break that behavior.
In apoc you can combine any data source with apoc.periodic.iterate to achieve the same.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate('
CALL apoc.load.csv({url}) yield map as row return row
','
CREATE (p:Person) SET p = row
', {batchSize:10000, iterateList:true, parallel:true});
Please note that the parallel operation only works well for non-conflicting updates otherwise you might run into deadlocks.
To make these data structures available to Cypher, you can use apoc.load.xml. It takes a file or http URL and parses the XML into a map data structure.
See the following usage-examples for the procedures.
Error handling
You can use failOnError configuration to handle the result in case of incorrect url or csv. For example, with the help of the apoc.when procedure, you can return nothingToList and nothingToMap as list and map result, with incorrect url:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.csv(""MY_CSV_URL"", {failOnError:false})
YIELD list, map
WITH list, map
call apoc.do.when(list = [], ""return 'nothingToList' as list, 'nothingToMap' as map"", ""return list, map"", {list: list, map: map})
YIELD value
RETURN value[""list""], value[""map""]
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.xls;"apoc.load.xls
Contents
Signature
Input parameters
Config parameters
Output parameters
Install Dependencies
Usage Examples
Procedure Apoc Extended
apoc.load.xls('url','selector',{config}) YIELD lineNo, list, map - load XLS fom URL as stream of row values, config contains any of: {skip:1,limit:5,header:false,ignore:['tmp'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false, dateFormat:'iso_date', dateParse:['dd-MM-yyyy']}}
Signature
None
Copy to Clipboard
apoc.load.xls(url :: STRING?, selector :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, map :: MAP?)
Input parameters
Name Type Default
url
STRING?
null
selector
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
skip
boolean
none
skip result rows
limit
Long
none
limit result rows
header
booelan
true
indicates if file has a header
sep
String
','
separator character or 'TAB'
quoteChar
String
'""'
the char to use for quoted elements
arraySep
String
';'
array separator
ignore
List<String>
[]
which columns to ignore
nullValues
List<String>
[]
which values to treat as null, e.g. ['na',false]
mapping
Map
{}
per field mapping, entry key is field name, .e.g {mapping:{'<sheet>':{type:'<type>', dateFormat: '<format>', dateParse: [<formats>]}}}
mapping supports the following values:
<sheet> - name of the sheet
<type> - type of the conversion requested (STRING, INTEGER, FLOAT, BOOLEAN, NULL, LIST, DATE, DATE_TIME, LOCAL_DATE, LOCAL_DATE_TIME, LOCAL_TIME, TIME)
dateFormat: <format> - convert the Date into String (only String is allowed)
dateParse: [<formats>] - convert the String into Date (Array of strings are allowed)
Output parameters
Name Type
lineNo
INTEGER?
list
LIST? OF ANY?
map
MAP?
Install Dependencies
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""https://github.com/neo4j-contrib/neo4j-apoc-procedures/raw/5.0/extended/src/test/resources/load_test.xls"",
  'Full',{ mapping: {
  Integer:{type:'int'},
  Array:{type:'int',array:true,arraySep:';'}
}});
Table 2. Results
lineNo list map
0
[""Test"", TRUE, 2, 1.5, [1, 2, 3]]
{Integer: 2, Array: [1, 2, 3], Float: 1.5, String: ""Test"", Boolean: TRUE}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""https://github.com/neo4j-contrib/neo4j-apoc-procedures/raw/5.0/extended/src/test/resources/load_test.xls"",
  'Kids'
);
Table 3. Results
lineNo list map
0
[""Selma"", 8]
{name: ""Selma"", age: 8}
1
[""Rana"", 11]
{name: ""Rana"", age: 11}
2
[""Selina"", 18]
{name: ""Selina"", age: 18}
Some examples with type/dateFormat and dateParse:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('https://github.com/neo4j-contrib/neo4j-apoc-procedures/raw/5.0/extended/src/test/resources/test_date.xlsx',
  'sheet',{ mapping:{
  Date:{type:'String'}
}});
Table 4. Results
lineNo list map
0
[""2018/05/10"", ""2018/10/05"", ""Alan""]
{Data: ""2018/10/05"", Date: ""2018/05/10"", Name: ""Alan""}
1
[""2018-09-10T00:00:00"", 2018-10-10T00:00, ""Jack""]
{Data: 2018-10-10T00:00, Date: ""2018-09-10T00:00:00"", Name: ""Jack""}
2
[""2018/05/10 12:10:10"", 2018-10-10T00:00, 2018-10-10T00:00]
{Data: 2018-10-10T00:00, Date: ""2018/05/10 12:10:10"", Name: 2018-10-10T00:00}
3
[NULL, 2018-10-10T00:00, 1899-12-31T12:01:10]
{Data: 2018-10-10T00:00, Date: NULL, Name: 1899-12-31T12:01:10}
4
[""2011-01-01T12:00:00.05381+01:00"", NULL, NULL]
{Data: NULL, Date: ""2011-01-01T12:00:00.05381+01:00"", Name: NULL}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('https://github.com/neo4j-contrib/neo4j-apoc-procedures/raw/5.0/extended/src/test/resources/test_date.xlsx',
  'sheet', { mapping: {
    Date:{type:'String',dateFormat:'iso_date'}
}});
Table 5. Results
lineNo list map
0
[""2018/05/10"", ""2018/10/05"", ""Alan""]
{Data: ""2018/10/05"", Date: ""2018/05/10"", Name: ""Alan""}
1
[""2018-09-10"", 2018-10-10T00:00, ""Jack""]
{Data: 2018-10-10T00:00, Date: ""2018-09-10"", Name: ""Jack""}
2
[""2018/05/10 12:10:10"", 2018-10-10T00:00, 2018-10-10T00:00]
{Data: 2018-10-10T00:00, Date: ""2018/05/10 12:10:10"", Name: 2018-10-10T00:00}
3
[NULL, 2018-10-10T00:00, 1899-12-31T12:01:10]
{Data: 2018-10-10T00:00, Date: NULL, Name: 1899-12-31T12:01:10}
4
[""2011-01-01T12:00:00.05381+01:00"", NULL, NULL]
{Data: NULL, Date: ""2011-01-01T12:00:00.05381+01:00"", Name: NULL}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('https://github.com/neo4j-contrib/neo4j-apoc-procedures/raw/5.0/extended/src/test/resources/test_date.xlsx',
  'sheet',{ mapping:{
  Date:{type:'String',dateParse:[""wrongPath"", ""dd-MM-yyyy"", ""dd/MM/yyyy"", ""yyyy/MM/dd"", ""yyyy/dd/MM"", ""yyyy-dd-MM'T'hh:mm:ss""]}
}});
Table 6. Results
lineNo list map
0
[""2018/05/10"", ""2018/10/05"", ""Alan""]
{Data: ""2018/10/05"", Date: ""2018/05/10"", Name: ""Alan""}
1
[""2018-09-10T00:00:00"", 2018-10-10T00:00, ""Jack""]
{Data: 2018-10-10T00:00, Date: ""2018-09-10T00:00:00"", Name: ""Jack""}
2
[""2018/05/10 12:10:10"", 2018-10-10T00:00, 2018-10-10T00:00]
{Data: 2018-10-10T00:00, Date: ""2018/05/10 12:10:10"", Name: 2018-10-10T00:00}
3
[NULL, 2018-10-10T00:00, 1899-12-31T12:01:10]
{Data: 2018-10-10T00:00, Date: NULL, Name: 1899-12-31T12:01:10}
4
[""2011-01-01T12:00:00.05381+01:00"", NULL, NULL]
{Data: NULL, Date: ""2011-01-01T12:00:00.05381+01:00"", Name: NULL}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.jdbcUpdate;"apoc.load.jdbcUpdate
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.load.jdbcUpdate('key or url','statement',[params],config) YIELD row - update relational database, from a SQL statement with optional parameters
Signature
None
Copy to Clipboard
apoc.load.jdbcUpdate(jdbc :: STRING?, query :: STRING?, params = [] :: LIST? OF ANY?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
jdbc
STRING?
null
query
STRING?
null
params
LIST? OF ANY?
[]
config
MAP?
{}
Output parameters
Name Type
row
MAP?
More documentation of apoc.load.jdbcUpdate
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/load-jdbc;"Load JDBC (RDBMS)
Contents
MySQL Example
MySQL Northwind Data
Load JDBC Examples
Load data in transactional batches
Cassandra Example
Support for Hive with Kerberos Auth
LOAD JDBC - Resources
LOAD JDBC - UPDATE
Load JDBC format date
Config
Data Integration is an important topic. Reading data from relational databases to create and augment data models is a very helpful exercise.
With apoc.load.jdbc you can access any database that provides a JDBC driver, and execute queries whose results are turned into streams of rows. Those rows can then be used to update or create graph structures.
To simplify the JDBC URL syntax and protect credentials, you can configure aliases in conf/apoc.conf:
apoc.jdbc.myDB.url=jdbc:derby:derbyDB
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('jdbc:derby:derbyDB','PERSON')
becomes
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('myDB','PERSON')
The 3rd value in the apoc.jdbc.<alias>.url= effectively defines an alias to be used in apoc.load.jdbc('<alias>',….
MySQL Example
Northwind is a common example set for relational databases, which is also covered in our import guides, e.g. :play northwind graph in the Neo4j browser.
MySQL Northwind Data
Sql
Copy to Clipboard
select count(*) from products;
Table 1. Results
count(*)
77
Sql
Copy to Clipboard
describe products;
Table 2. Results
Field Type Null Key Default Extra
ProductID
int(11)
NO
PRI
NULL
auto_increment
ProductName
varchar(40)
NO
MUL
NULL
SupplierID
int(11)
YES
MUL
NULL
CategoryID
int(11)
YES
MUL
NULL
QuantityPerUnit
varchar(20)
YES
NULL
UnitPrice
decimal(10,4)
YES
0.0000
UnitsInStock
smallint(2)
YES
0
UnitsOnOrder
smallint(2)
YES
0
ReorderLevel
smallint(2)
YES
0
Discontinued
bit(1)
NO
b'0'
Load JDBC Examples
Cypher
Load the JDBC driver
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.driver(""com.mysql.jdbc.Driver"");
Cypher
Count rows in products table
Copy to Clipboard
Run in Neo4j Browser
WITH ""jdbc:mysql://localhost:3306/northwind?user=root"" as url
CALL apoc.load.jdbc(url,""products"") YIELD row
RETURN count(*);
Table 3. Results
count(*)
77
Cypher
Return row from products table
Copy to Clipboard
Run in Neo4j Browser
WITH ""jdbc:mysql://localhost:3306/northwind?user=root"" as url
CALL apoc.load.jdbc(url,""products"") YIELD row
RETURN row limit 1;
Table 4. Results
row
{UnitPrice → 18.0000, UnitsOnOrder → 0, CategoryID → 1, UnitsInStock → 39}
Load data in transactional batches
You can load data from jdbc and create/update the graph using the query results in batches (and in parallel).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(
  'CALL apoc.load.jdbc(""jdbc:mysql://localhost:3306/northwind?user=root"",""company"")',
  'CREATE (p:Person) SET p += value',
  { batchSize:10000, parallel:true})
YIELD batches, total
Cassandra Example
Setup Song database as initial dataset
curl -OL https://raw.githubusercontent.com/neo4j-contrib/neo4j-cassandra-connector/master/db_gen/playlist.cql
curl -OL https://raw.githubusercontent.com/neo4j-contrib/neo4j-cassandra-connector/master/db_gen/artists.csv
curl -OL https://raw.githubusercontent.com/neo4j-contrib/neo4j-cassandra-connector/master/db_gen/songs.csv
$CASSANDRA_HOME/bin/cassandra
$CASSANDRA_HOME/bin/cqlsh -f playlist.cql
Download the Cassandra JDBC Wrapper, and put it into your $NEO4J_HOME/plugins directory. Add this config option to $NEO4J_HOME/conf/apoc.conf to make it easier to interact with the cassandra instance.
Add to conf/apoc.conf
apoc.jdbc.cassandra_songs.url=jdbc:cassandra://localhost:9042/playlist
Restart the server.
Now you can inspect the data in Cassandra with.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','artists_by_first_letter')
YIELD row
RETURN count(*);
Table 5. Results
count(*)
3605
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','artists_by_first_letter')
YIELD row
RETURN row LIMIT 5;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','artists_by_first_letter')
YIELD row
RETURN row.first_letter, row.artist
LIMIT 5;
Table 6. Results
row.first_letter row.artist
C
C.W. Stoneking
C
CH2K
C
CHARLIE HUNTER WITH LEON PARKER
C
Calvin Harris
C
Camané
Let’s create some graph data, we have a look at the track_by_artist table, which contains about 60k records.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','track_by_artist')
YIELD row
RETURN count(*);
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','track_by_artist')
YIELD row
RETURN row
LIMIT 5;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','track_by_artist')
YIELD row
RETURN row.track_id, row.track_length_in_seconds, row.track, row.music_file, row.genre, row.artist, row.starred
LIMIT 2;
Table 7. Results
row.track_id length row.track row.music_file row.genre row.artist row.starred
c0693b1e-0eaa-4e81-b23f-b083db303842
219
1913 Massacre
TRYKHMD128F934154C
folk
Woody Guthrie & Jack Elliott
false
7d114937-0bc7-41c7-8e0c-94b5654ac77f
178
Alabammy Bound
TRMQLPV128F934152B
folk
Woody Guthrie & Jack Elliott
false
Let’s create some indexes and constraints, note that other indexes and constraints will be dropped by this.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.schema.assert(
  {Track:['title','length']},
  {Artist:['name'],Track:['id'],Genre:['name']});
Table 8. Results
label key unique action
Track
title
false
CREATED
Track
length
false
CREATED
Artist
name
true
CREATED
Genre
name
true
CREATED
Track
id
true
CREATED
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('cassandra_songs','track_by_artist')
YIELD row
MERGE (a:Artist {name:row.artist})
MERGE (g:Genre {name:row.genre})
CREATE (t:Track {id:toString(row.track_id), title:row.track, length:row.track_length_in_seconds})
CREATE (a)-[:PERFORMED]->(t)
CREATE (t)-[:GENRE]->(g);
Added 63213 labels, created 63213 nodes, set 182413 properties, created 119200 relationships, statement executed in 40076 ms.
Support for Hive with Kerberos Auth
Support for Hive especially with Kerberos is more involved.
First of all the required configuration is more detailed, make sure to get this information:
kerberos user / password
kerberos realm / kdc
hive hostname + port (10000)
Create this login.conf file at a known location:
login.conf
KerberosClient {
  com.sun.security.auth.module.Krb5LoginModule required
  debug=true debugNative=true;
};
Add these options to your conf/apoc.conf
apoc.conf
dbms.jvm.additional=-Djava.security.auth.login.config=/path/to/login.conf
dbms.jvm.additional=-Djava.security.auth.login.config.client=KerberosClient
dbms.jvm.additional=-Djava.security.krb5.realm=KRB.REALM.COM
dbms.jvm.additional=-Djava.security.krb5.kdc=krb-kdc.host.com
Unlike other JDBC drivers, Hive comes with a bunch of dependencies, you can download these from the Hadoop providers
Cloudera Hive Drivers
Hortonworks Hive Drivers
Apache Hive Driver
or grab them from maven central.
The versions might vary, use what comes with your Hive driver.
hadoop-common-2.7.3.2.6.1.0-129.jar
hive-exec-1.2.1000.2.6.1.0-129.jar
hive-jdbc-1.2.1000.2.6.1.0-129.jar
hive-metastore-1.2.1000.2.6.1.0-129.jar
hive-service-1.2.1000.2.6.1.0-129.jar
httpclient-4.4.jar
httpcore-4.4.jar
libfb303-0.9.2.jar
libthrift-0.9.3.jar
Now you can use a JDBC URL like this from APOC.
This has no newlines, it’s just wrapped because it is too long.
jdbc:hive2://username%40krb-realm:password@hive-hostname:10000/default;principal=hive/hostname@krb-realm;auth=kerberos;kerberosAuthType=fromSubject
And then call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH 'jdbc:hive2://username%40krb-realm:password@hive-hostname:10000/default;principal=hive/hostname@krb-realm;auth=kerberos;kerberosAuthType=fromSubject' AS url
CALL apoc.load.jdbc(url,'PRODUCTS')
YIELD row
RETURN row.name, row.price;
You can also set it in your conf/apoc.conf as a key:
apoc.conf
apoc.jdbc.my-hive.url=jdbc:hive2://username%40krb-realm:password@hive-hostname:10000/default;principal=hive/hostname@krb-realm;auth=kerberos;kerberosAuthType=fromSubject
And then use the more compact call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('my-hive','SELECT * PRODUCTS');
LOAD JDBC - Resources
To use other JDBC drivers use these download links and JDBC URL. Put the JDBC driver into the $NEO4J_HOME/plugins directory and configure the JDBC-URL in $NEO4J_HOME/conf/apoc.conf with apoc.jdbc.<alias>.url=<jdbc-url>
Credentials can be passed in two ways:
into url
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('jdbc:derby:derbyDB;user=apoc;password=Ap0c!#Db;create=true', 'PERSON')
by config parameter.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('jdbc:derby:derbyDB', 'PERSON',[],{credentials:{user:'apoc',password:'Ap0c!#Db'}})
Google BigQuery using Simba drivers requires an additional parameter 'autoCommit' to be used e.g.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('BigQuery', 'SELECT action_type FROM `patents-public-data.ebi_chembl.action_type` LIMIT 10', [], {autoCommit:true})
Database JDBC-URL Driver Source
MySQL
jdbc:mysql://<hostname>:<port/3306>/<database>?user=<user>&password=<pass>
MySQL Driver
Postgres
jdbc:postgresql://<hostname>/<database>?user=<user>&password=<pass>
PostgresSQL JDBC Driver
Oracle
jdbc:oracle:thin:<user>/<pass>@<host>:<port>/<service_name>
Oracle JDBC Driver
MS SQLServer
jdbc:sqlserver://;servername=<servername>;databaseName=<database>;user=<user>;password=<pass>
SQLServer Driver
IBM DB2
jdbc:db2://<host>:<port/5021>/<database>:user=<user>;password=<pass>;
DB2 Driver
Derby
jdbc:derby:derbyDB
Included in JDK6-8
Cassandra
jdbc:cassandra://<host>:<port/9042>/<database>
Cassandra JDBC Wrapper
SAP Hana
jdbc:sap://<host>:<port/39015>/?user=<user>&password=<pass>
SAP Hana ngdbc Driver
Apache Hive (w/ Kerberos)
jdbc:hive2://username%40krb-realm:password@hostname:10000/default;principal=hive/hostname@krb-realm;auth=kerberos;kerberosAuthType=fromSubject
Apache Hive Driver (Cloudera) (Hortonworks) There are several jars (hadoop-common-xxx.jar hive-exec-xxx.jar hive-jdbc-xxx.jar hive-metastore-xxx.jar hive-service-xxx.jar httpclient-4.4.jar httpcore-4.4.jar libfb303-0.9.2.jar libthrift-0.9.3.jar)
Google BigQuery
jdbc:bigquery://https://www.googleapis.com/bigquery/v2:443;ProjectId=<Project ID>;OAuthType=0;OAuthServiceAcctEmail=<Service Account ID>;OAuthPvtKeyPath=/path/to/<Private Key>.json
Simba Drivers for BigQuery There are several jars
There are a number of blog posts / examples that details usage of apoc.load.jdbc
Explore your browser history in Neo4j
Neo4j With Scala : Migrate Data From Other Database to Neo4j
APOC: Database Integration, Import and Export with Awesome Procedures On Cypher
Importing Google Analytics to Neo4j via BigQuery using APOC & JDBC
LOAD JDBC - UPDATE
The jdbcUpdate is use for update relational database, from a SQL statement with optional parameters
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbcUpdate(jdbc-url,statement, params, config)
With this set of data you can call the procedure in two different mode:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (u:User)-[:BOUGHT]->(p:Product)<-[:BOUGHT]-(o:User)-[:BOUGHT]->(reco)
WHERE u <> o AND NOT (u)-[:BOUGHT]->(reco)
WITH u, reco, count(*) as score
WHERE score > 1000
You can call the procedure with param:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbcUpdate('jdbc:mysql:....','INSERT INTO RECOMMENDATIONS values(?,?,?)',[user.id, reco.id, score]);
You can call the procedure without param:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbcUpdate('jdbc:mysql:....','INSERT INTO RECOMMENDATIONS values(user.id, reco.id, score)');
Load JDBC format date
Starting from Neo4j 3.4 there is the support for Temporal Values
If the returning JdbcType, from the load operation, is TIMESTAMP or TIMESTAMP_WITH_TIMEZONE you could provide the configuration parameter timezone with type java.time.ZoneId
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('key or url','table or statement', config);
Config
Config param is optional, the default value is an empty map.
timezone
default value: null
credentials
default value: {}
Example:
Cypher
with timezone
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc(
  'jdbc:derby:derbyDB',
  'SELECT * FROM PERSON WHERE NAME = ?',['John'],
  {timezone: ""Asia/Tokyo""})
2018-10-31T01:32:25.012+09:00[Asia/Tokyo]
Cypher
with credentials
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbcUpdate('jdbc:derby:derbyDB','UPDATE PERSON SET NAME = ? WHERE NAME = ?',['John','John'],{credentials:{user:'apoc',password:'Ap0c!#Db'}})
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('jdbc:derby:derbyDB', 'PERSON',[],{credentials:{user:'apoc',password:'Ap0c!#Db'}})
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.directory.async.list;"apoc.load.directory.async.list
Contents
Signature
Output parameters
Usage Examples
Examples of interoperability with other procedures
Error handling
Procedure enabling
Procedure Apoc Extended
apoc.load.directory.async.list() YIELD name, status, pattern, cypher, urlDir, config, error - List of all folder listeners
Signature
None
Copy to Clipboard
apoc.load.directory.async.list() :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)
Output parameters
Name Type
name
STRING?
status
STRING?
pattern
STRING?
cypher
STRING?
urlDir
STRING?
config
MAP?
error
STRING?
Usage Examples
The first parameter is the name of our custom watch listener. If we use an already existing listener name, that listener will be overwritten. The second parameter is the cypher query that will be executed. The query can have the following parameters:
$fileName: the name of the file which triggered the event
$filePath: the absolute path of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$fileDirectory: the absolute path directory of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$listenEventType: the triggered event (""CREATE"", ""DELETE"" or ""MODIFY""). The event ""CREATE"" happens when a file is inserted in the folder, ""DELETE"" when a file is removed from the folder and ""MODIFY"" when a file in the folder is changed. Please note that if a file is renamed, will be triggered 2 event, that is first ""DELETE"" and then""CREATE""
The third parameter is the pattern of file to search for. By default is '*', that is, search all files. The fourth is the search path of directory. By default is an empty string, that is, search file in import directory.
Examples of interoperability with other procedures
We can use another load procedure as query parameter, like apoc.load.csv.
Here is an example.
We can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('csvImport',
""CALL apoc.load.csv($filePath) yield list WITH list CREATE (n:CsvToNode {content: list, fileName: $fileName, fileDirectory: $fileDirectory, listenEventType: $listenEventType})"",
""*.csv"", ""csvFolder"" ,{listenEventType: [""CREATE"", ""MODIFY""]})
where $fileName is the file created/modified, $filePath is the relative path of the file, that is $IMPORT_DIR/csvFolder/[FILENAME.csv], $fileDirectory is the relative path of the directory, that is $IMPORT_DIR/csvFolder and $listenEventType is the triggered event, that is CREATE or MODIFY.
If we upload the following file in $IMPORT_DIR/csvFolder folder:
Csv
test.csv
Copy to Clipboard
name,age
Selma,8
Rana,11
Selina,18
and then, executing MATCH (n:CsvToNode) RETURN properties(n) as props:
Table 1. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""8"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""11"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""18"" ] }
If we modify the test.csv as follow:
Csv
test.csv
Copy to Clipboard
name,age
Selma,80
Rana,110
Selina,180
we obtain 3 new nodes with these props:
Table 2. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""80"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""110"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""180"" ] }
Error handling
When for some reason, the listener fails, its status field change from RUNNING to ERROR, and the associated error is output. If we execute call apoc.load.directory.async.list, we obtain, for example:
name status pattern cypher urlDir config error
listenerName
ERROR
*.csv
'create (n:Node)'
'path'
{}
""org.neo4j.graphdb.QueryExecutionException: Failed to invoke procedure apoc.load.csv: Caused by: java.io.FileNotFoundException ….
Procedure enabling
Please note that to use the apoc.load.directory.async.* procedures, we’ll have to enable the following config option:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.directory.async.removeAll;"apoc.load.directory.async.removeAll
Contents
Signature
Output parameters
Usage Examples
Examples of interoperability with other procedures
Error handling
Procedure enabling
Procedure Apoc Extended
apoc.load.directory.async.removeAll() - Remove all folder listeners
Signature
None
Copy to Clipboard
apoc.load.directory.async.removeAll() :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)
Output parameters
Name Type
name
STRING?
status
STRING?
pattern
STRING?
cypher
STRING?
urlDir
STRING?
config
MAP?
error
STRING?
Usage Examples
The first parameter is the name of our custom watch listener. If we use an already existing listener name, that listener will be overwritten. The second parameter is the cypher query that will be executed. The query can have the following parameters:
$fileName: the name of the file which triggered the event
$filePath: the absolute path of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$fileDirectory: the absolute path directory of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$listenEventType: the triggered event (""CREATE"", ""DELETE"" or ""MODIFY""). The event ""CREATE"" happens when a file is inserted in the folder, ""DELETE"" when a file is removed from the folder and ""MODIFY"" when a file in the folder is changed. Please note that if a file is renamed, will be triggered 2 event, that is first ""DELETE"" and then""CREATE""
The third parameter is the pattern of file to search for. By default is '*', that is, search all files. The fourth is the search path of directory. By default is an empty string, that is, search file in import directory.
Examples of interoperability with other procedures
We can use another load procedure as query parameter, like apoc.load.csv.
Here is an example.
We can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('csvImport',
""CALL apoc.load.csv($filePath) yield list WITH list CREATE (n:CsvToNode {content: list, fileName: $fileName, fileDirectory: $fileDirectory, listenEventType: $listenEventType})"",
""*.csv"", ""csvFolder"" ,{listenEventType: [""CREATE"", ""MODIFY""]})
where $fileName is the file created/modified, $filePath is the relative path of the file, that is $IMPORT_DIR/csvFolder/[FILENAME.csv], $fileDirectory is the relative path of the directory, that is $IMPORT_DIR/csvFolder and $listenEventType is the triggered event, that is CREATE or MODIFY.
If we upload the following file in $IMPORT_DIR/csvFolder folder:
Csv
test.csv
Copy to Clipboard
name,age
Selma,8
Rana,11
Selina,18
and then, executing MATCH (n:CsvToNode) RETURN properties(n) as props:
Table 1. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""8"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""11"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""18"" ] }
If we modify the test.csv as follow:
Csv
test.csv
Copy to Clipboard
name,age
Selma,80
Rana,110
Selina,180
we obtain 3 new nodes with these props:
Table 2. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""80"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""110"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""180"" ] }
Error handling
When for some reason, the listener fails, its status field change from RUNNING to ERROR, and the associated error is output. If we execute call apoc.load.directory.async.list, we obtain, for example:
name status pattern cypher urlDir config error
listenerName
ERROR
*.csv
'create (n:Node)'
'path'
{}
""org.neo4j.graphdb.QueryExecutionException: Failed to invoke procedure apoc.load.csv: Caused by: java.io.FileNotFoundException ….
Procedure enabling
Please note that to use the apoc.load.directory.async.* procedures, we’ll have to enable the following config option:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.jdbc;"apoc.load.jdbc
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.load.jdbc('key or url','table or statement', params, config) YIELD row - load from relational database, from a full table or a sql statement
Signature
None
Copy to Clipboard
apoc.load.jdbc(jdbc :: STRING?, tableOrSql :: STRING?, params = [] :: LIST? OF ANY?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
jdbc
STRING?
null
tableOrSql
STRING?
null
params
LIST? OF ANY?
[]
config
MAP?
{}
Output parameters
Name Type
row
MAP?
Usage Examples
The following examples assume that the MySQL driver has been loaded using apoc.load.driver.
The following count rows in the products table of the Northwind dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""jdbc:mysql://localhost:3306/northwind?user=root"" as url
CALL apoc.load.jdbc(url,""products"") YIELD row
RETURN count(*);
Table 1. Results
count(*)
77
The following returns the first row in the products table of the Northwind dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""jdbc:mysql://localhost:3306/northwind?user=root"" as url
CALL apoc.load.jdbc(url,""products"")
YIELD row
RETURN row
LIMIT 1;
Table 2. Results
row
{UnitPrice → 18.0000, UnitsOnOrder → 0, CategoryID → 1, UnitsInStock → 39}
More documentation of apoc.load.jdbc
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.driver;"apoc.load.driver
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.load.driver('org.apache.derby.jdbc.EmbeddedDriver') register JDBC driver of source database
Signature
None
Copy to Clipboard
apoc.load.driver(driverClass :: STRING?) :: VOID
Input parameters
Name Type Default
driverClass
STRING?
null
Usage Examples
The following loads the JDBC driver:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.driver(""com.mysql.jdbc.Driver"");
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.directory.async.remove;"apoc.load.directory.async.remove
Contents
Signature
Input parameters
Output parameters
Usage Examples
Examples of interoperability with other procedures
Error handling
Procedure enabling
Procedure Apoc Extended
apoc.load.directory.async.remove(name) YIELD name, status, pattern, cypher, urlDir, config, error - Remove a folder listener by name and return remaining listeners, if any
Signature
None
Copy to Clipboard
apoc.load.directory.async.remove(name :: STRING?) :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
status
STRING?
pattern
STRING?
cypher
STRING?
urlDir
STRING?
config
MAP?
error
STRING?
Usage Examples
The first parameter is the name of our custom watch listener. If we use an already existing listener name, that listener will be overwritten. The second parameter is the cypher query that will be executed. The query can have the following parameters:
$fileName: the name of the file which triggered the event
$filePath: the absolute path of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$fileDirectory: the absolute path directory of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$listenEventType: the triggered event (""CREATE"", ""DELETE"" or ""MODIFY""). The event ""CREATE"" happens when a file is inserted in the folder, ""DELETE"" when a file is removed from the folder and ""MODIFY"" when a file in the folder is changed. Please note that if a file is renamed, will be triggered 2 event, that is first ""DELETE"" and then""CREATE""
The third parameter is the pattern of file to search for. By default is '*', that is, search all files. The fourth is the search path of directory. By default is an empty string, that is, search file in import directory.
Examples of interoperability with other procedures
We can use another load procedure as query parameter, like apoc.load.csv.
Here is an example.
We can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('csvImport',
""CALL apoc.load.csv($filePath) yield list WITH list CREATE (n:CsvToNode {content: list, fileName: $fileName, fileDirectory: $fileDirectory, listenEventType: $listenEventType})"",
""*.csv"", ""csvFolder"" ,{listenEventType: [""CREATE"", ""MODIFY""]})
where $fileName is the file created/modified, $filePath is the relative path of the file, that is $IMPORT_DIR/csvFolder/[FILENAME.csv], $fileDirectory is the relative path of the directory, that is $IMPORT_DIR/csvFolder and $listenEventType is the triggered event, that is CREATE or MODIFY.
If we upload the following file in $IMPORT_DIR/csvFolder folder:
Csv
test.csv
Copy to Clipboard
name,age
Selma,8
Rana,11
Selina,18
and then, executing MATCH (n:CsvToNode) RETURN properties(n) as props:
Table 1. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""8"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""11"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""18"" ] }
If we modify the test.csv as follow:
Csv
test.csv
Copy to Clipboard
name,age
Selma,80
Rana,110
Selina,180
we obtain 3 new nodes with these props:
Table 2. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""80"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""110"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""180"" ] }
Error handling
When for some reason, the listener fails, its status field change from RUNNING to ERROR, and the associated error is output. If we execute call apoc.load.directory.async.list, we obtain, for example:
name status pattern cypher urlDir config error
listenerName
ERROR
*.csv
'create (n:Node)'
'path'
{}
""org.neo4j.graphdb.QueryExecutionException: Failed to invoke procedure apoc.load.csv: Caused by: java.io.FileNotFoundException ….
Procedure enabling
Please note that to use the apoc.load.directory.async.* procedures, we’ll have to enable the following config option:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.ldap;"apoc.load.ldap
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.load.ldap(""key"" or {connectionMap},{searchMap}) Load entries from an ldap source (yield entry)
Signature
None
Copy to Clipboard
apoc.load.ldap(connection :: ANY?, search :: MAP?) :: (entry :: MAP?)
Input parameters
Name Type Default
connection
ANY?
null
search
MAP?
null
Output parameters
Name Type
entry
MAP?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.directory.async.add;"apoc.load.directory.async.add
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Examples of interoperability with other procedures
Error handling
Procedure enabling
Configuration Examples
Procedure Apoc Extended
apoc.load.directory.async.add(name, cypher, pattern, urlDir, {}) YIELD name, status, pattern, cypher, urlDir, config, error - Add or replace a folder listener with a specific name, pattern and url directory that execute the specified cypher query when an event is triggered and return listener list
Signature
None
Copy to Clipboard
apoc.load.directory.async.add(name :: STRING?, cypher :: STRING?, pattern = * :: STRING?, urlDir =  :: STRING?, config = {} :: MAP?) :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)
Input parameters
Name Type Default
name
STRING?
null
cypher
STRING?
null
pattern
STRING?
*
urlDir
STRING?
config
MAP?
{}
Config parameters
The procedure supports the following config parameters:
Table 1. Config parameters
name type default description
interval
Integer
1000
Time interval in ms after re-watch for directory changes
listenEventType
List<Enum>
List.of(""CREATE"", ""DELETE"", ""MODIFY"")
Types of event that execute the cypher query, that is creation (CREATE), deletion (DELETE) or editing (MODIFY) of a file in specified folder
Output parameters
Name Type
name
STRING?
status
STRING?
pattern
STRING?
cypher
STRING?
urlDir
STRING?
config
MAP?
error
STRING?
Usage Examples
The first parameter is the name of our custom watch listener. If we use an already existing listener name, that listener will be overwritten. The second parameter is the cypher query that will be executed. The query can have the following parameters:
$fileName: the name of the file which triggered the event
$filePath: the absolute path of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$fileDirectory: the absolute path directory of the file which triggered the event if apoc.import.file.use_neo4j_config=false, otherwise the relative path starting from $IMPORT_DIR
$listenEventType: the triggered event (""CREATE"", ""DELETE"" or ""MODIFY""). The event ""CREATE"" happens when a file is inserted in the folder, ""DELETE"" when a file is removed from the folder and ""MODIFY"" when a file in the folder is changed. Please note that if a file is renamed, will be triggered 2 event, that is first ""DELETE"" and then""CREATE""
The third parameter is the pattern of file to search for. By default, is '*', that is, search all files. The fourth is the search path of directory. By default, is an empty string, that is, search file in import directory.
Examples of interoperability with other procedures
We can use another load procedure as query parameter, like apoc.load.csv.
Here is an example.
We can execute:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('csvImport',
""CALL apoc.load.csv($filePath) yield list WITH list CREATE (n:CsvToNode {content: list, fileName: $fileName, fileDirectory: $fileDirectory, listenEventType: $listenEventType})"",
""*.csv"", ""csvFolder"" ,{listenEventType: [""CREATE"", ""MODIFY""]})
where $fileName is the file created/modified, $filePath is the relative path of the file, that is $IMPORT_DIR/csvFolder/[FILENAME.csv], $fileDirectory is the relative path of the directory, that is $IMPORT_DIR/csvFolder and $listenEventType is the triggered event, that is CREATE or MODIFY.
If we upload the following file in $IMPORT_DIR/csvFolder folder:
Csv
test.csv
Copy to Clipboard
name,age
Selma,8
Rana,11
Selina,18
and then, executing MATCH (n:CsvToNode) RETURN properties(n) as props:
Table 2. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""8"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""11"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""CREATE"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""18"" ] }
If we modify the test.csv as follow:
Csv
test.csv
Copy to Clipboard
name,age
Selma,80
Rana,110
Selina,180
we obtain 3 new nodes with these props:
Table 3. Results
props
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selma"", ""80"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Rana"", ""110"" ] }
{ ""fileName"": ""test.csv"", ""listenEventType"": ""MODIFY"", ""fileDirectory"": ""csvFolder"", ""content"": [ ""Selina"", ""180"" ] }
Error handling
When for some reason, the listener fails, its status field change from RUNNING to ERROR, and the associated error is output. If we execute call apoc.load.directory.async.list, we obtain, for example:
name status pattern cypher urlDir config error
listenerName
ERROR
*.csv
'create (n:Node)'
'path'
{}
""org.neo4j.graphdb.QueryExecutionException: Failed to invoke procedure apoc.load.csv: Caused by: java.io.FileNotFoundException ….
Procedure enabling
Please note that to use the apoc.load.directory.async.* procedures, we’ll have to enable the following config option:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
Configuration Examples
Let’s suppose we have set the config option:
apoc.import.file.use_neo4j_config=true
We can do the following procedure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('test', 'CREATE (n:Test)');
so every time, in import folder, a file is created/deleted/updated will be executed the query CREATE (n:Test).
We can listen only for specified event kinds, for example for file creation, and create an import report:
CALL apoc.load.directory.async.add('test', 'CREATE (n:Import {fileName: $fileName})', '*', '', {listenEventType: ['ENTRY_CREATE']});
to listen only for file creation. So, if we import two file ""foo.csv"" and ""bar.csv"", will be created 2 nodes: (n:Import {fileName: 'foo.csv'}) and (n:Import {fileName: 'bar.csv'}).
Moreover, we can set a specific file pattern, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory.async.add('test', 'CREATE (n:Test)', '*.csv');
in this case, every time in import folder, a file .csv is created/deleted/updated will be executed the query CREATE (n:Test).
Furthermore, we can also set a path, like:
CALL apoc.load.directory.async.add('test', 'CREATE (n:Test)', '*.csv', 'subfolderImport');
to listen in a subfolder called subfolderImport in import folder.
Instead, if we set apoc.import.file.use_neo4j_config=false, we can search with an absolute path:
CALL apoc.load.directory.async.add('test', 'CREATE (n:Test)', '*.csv', 'file:///Users/username/Downloads');
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.directory;"apoc.load.directory
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.load.directory('pattern', 'urlDir', {config}) YIELD value - Loads list of all files in folder specified by urlDir or in import folder if urlDir string is empty or not specified
Signature
None
Copy to Clipboard
apoc.load.directory(pattern = * :: STRING?, urlDir =  :: STRING?, config = {} :: MAP?) :: (value :: STRING?)
Input parameters
Name Type Default
pattern
STRING?
*
urlDir
STRING?
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
recursive
boolean
true
find all files in current folder and subfolders
Output parameters
Name Type
value
STRING?
Usage Examples
The first parameter is the pattern of file to search for. By default is '*', that is, search all files. The second is the search path of directory. By default is an empty string, that is, search file in import directory.
Let’s suppose we have set the config option:
apoc.import.file.use_neo4j_config=true
and in the import directory the following files:
Table 2. Files
fileName path
db.json
/
1.csv
/
3.csv
/
4.csv
/
8.xls
/
11.txt
/
5.csv
subfolder1
6.xls
subfolder1
7.xls
subfolder1
20.xls
subfolder1/foo
2.csv
subfolder2
9.xls
subfolder2
10.txt
subfolder2
We can do the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory();
Table 3. Results
value
""4.csv""
""1.csv""
""db.json""
""3.csv""
""subfolder2/10.txt""
""subfolder2/2.csv""
""subfolder2/9.xls""
""11.txt""
""8.xls""
""subfolder1/5.csv""
""subfolder1/.DS_Store""
""subfolder1/7.xls""
""subfolder1/foo/20.xls""
""subfolder1/6.xls""
We can set a file pattern, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory(""*.csv"");
Table 4. Results
value
""4.csv""
""1.csv""
""3.csv""
""subfolder2/2.csv""
""subfolder1/5.csv""
Furthermore we can also set a path, like:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory(""*.csv"", ""subfolder1"");
Table 5. Results
value
""subfolder1/5.csv""
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory(""*"", ""subfolder1"");
Table 6. Results
value
""subfolder1/5.csv""
""subfolder1/.DS_Store""
""subfolder1/7.xls""
""subfolder1/foo/20.xls""
""subfolder1/6.xls""
And we can search only in current folder:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory(""*"", ""subfolder2"", {recursive: false});
Table 7. Results
value
""subfolder2/10.txt""
""subfolder2/2.csv""
""subfolder2/9.xls""
Instead, if we set apoc.import.file.use_neo4j_config=false, we can search with an absolute path:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory('*', 'file:///Users/username/Downloads', {recursive: false});
We can concatenate this procedure with other procedures, for example with apoc.load.csv to obtain an aggregation of multiple results. Let’s suppose we have these 2 files:
beta.csv
name,age
Selma,8
Rana,11
Selina,18
and
alpha.csv
name,beverage
Selma,Soda
Rana,Tea|Milk
Selina,Cola
so we can execute this query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.directory('*.csv', 'path/to/directory')
YIELD value WITH value as url ORDER BY url DESC
CALL apoc.load.csv(url, {results:['map']}) YIELD map RETURN map
with these results:
Table 8. Results
map
{ ""name"": ""Selma"", ""age"": ""8"" }
{ ""name"": ""Rana"", ""age"": ""11"" }
{ ""name"": ""Selina"", ""age"": ""18"" }
{ ""name"": ""Selma"", ""beverage"": ""Soda"" }
{ ""name"": ""Rana"", ""beverage"": ""Tea|Milk"" }
{ ""name"": ""Selina"", ""beverage"": ""Cola"" }
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.load/apoc.load.csvParams;"apoc.load.csvParams
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.load.csvParams('urlOrBinary', {httpHeader: value}, payload, {config}) YIELD lineNo, list, map - load from CSV URL (e.g. web-api) while sending headers / payload to load CSV from URL as stream of values, config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}
Signature
None
Copy to Clipboard
apoc.load.csvParams(urlOrBinary :: ANY?, httpHeaders :: MAP?, payload :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, strings :: LIST? OF STRING?, map :: MAP?, stringMap :: MAP?)
Input parameters
Name Type Default
urlOrBinary
ANY?
null
httpHeaders
MAP?
null
payload
STRING?
null
config
MAP?
{}
Output parameters
Name Type
lineNo
INTEGER?
list
LIST? OF ANY?
strings
LIST? OF STRING?
map
MAP?
stringMap
MAP?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.zrangebyscore;"apoc.redis.zrangebyscore
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.zrangebyscore(uri, key, min, max, {config}) | Execute the 'ZRANGEBYSCORE key min max' command
Signature
None
Copy to Clipboard
apoc.redis.zrangebyscore(uri :: STRING?, key :: ANY?, min :: INTEGER?, max :: INTEGER?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
min
INTEGER?
null
max
INTEGER?
null
config
MAP?
{}
Output parameters
Name Type
value
LIST? OF ANY?
More documentation of apoc.redis.zrangebyscore
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.postRaw;"apoc.es.postRaw
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.postRaw(host-or-port,path,payload-or-null) yield value - perform a raw POST operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.postRaw(host :: STRING?, path :: STRING?, payload :: ANY?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
path
STRING?
null
payload
ANY?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can create a document with a name property of John Doe in the customers index, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.postRaw(""localhost"",""customers/_doc"", {
  name: ""John Doe""
});
Table 1. Results
value
{result: ""created"", _shards: {total: 2, failed: 0, successful: 1}, _seq_no: 8, _index: ""customers"", _type: ""_doc"", _id: ""JG43_3UBi9jUSsIzOYJL"", _version: 1, _primary_term: 1}
More documentation of apoc.es.postRaw
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/elasticsearch;"ElasticSearch
Contents
Interacting with Elastic Search
Example
Pagination
General Structure and Parameters
host or port parameter
index parameter
type parameter
id parameter
query parameter
payload parameter
Results
Interacting with Elastic Search
Qualified Name Type Release
apoc.es.stats
apoc.es.stats(host-url-Key) - elastic search statistics
Procedure
Apoc Extended
apoc.es.get
apoc.es.get(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a GET operation on elastic search
Procedure
Apoc Extended
apoc.es.query
apoc.es.query(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a SEARCH operation on elastic search
Procedure
Apoc Extended
apoc.es.getRaw
apoc.es.getRaw(host-or-port,path,payload-or-null) yield value - perform a raw GET operation on elastic search
Procedure
Apoc Extended
apoc.es.postRaw
apoc.es.postRaw(host-or-port,path,payload-or-null) yield value - perform a raw POST operation on elastic search
Procedure
Apoc Extended
apoc.es.post
apoc.es.post(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a POST operation on elastic search
Procedure
Apoc Extended
apoc.es.put
apoc.es.put(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a PUT operation on elastic search
Procedure
Apoc Extended
Example
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.es.post(""localhost"",""tweets"",""users"",null,{name:""Chris""})
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.es.put(""localhost"",""tweets"",""users"",""1"",null,{name:""Chris""})
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.es.get(""localhost"",""tweets"",""users"",""1"",null,null)
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.es.stats(""localhost"")
Pagination
To use the pagination feature of Elasticsearch you have to follow these steps:
Call apoc.es.query to get the first chunk of data and obtain also the scroll_id (in order to enable the pagination).
Do your merge/create etc. operations with the first N hits
Use the range(start,end,step) function to repeat a second call to get all the other chunks until the end. For example, if you have 1000 documents and you want to retrieve 10 documents for each request, you cand do range(11,1000,10). You start from 11 because the first 10 documents are already processed. If you don’t know the exact upper bound (the total size of your documents) you can set a number that is bigger than the real total size.
The second call to repeat is apoc.es.get. Remember to set the scroll_id as a parameter.
Then process the result of each chunk of data as the first one.
Here an example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// It's important to create an index to improve performance
CREATE INDEX FOR (n:Document) ON (n.id)
// First query: get first chunk of data + the scroll_id for pagination
CALL apoc.es.query('localhost','test-index','test-type','name:Neo4j&size=1&scroll=5m',null) yield value with value._scroll_id as scrollId, value.hits.hits as hits
// Do something with hits
UNWIND hits as hit
// Here we simply create a document and a relation to a company
MERGE (doc:Document {id: hit._id, description: hit._source.description, name: hit._source.name})
MERGE (company:Company {name: hit._source.company})
MERGE (doc)-[:IS_FROM]->(company)
// Then call for the other docs and use the scrollId value from previous query
// Use a range to count our chunk of data (i.e. i want to get chunks from 2 to 10)
WITH range(2,10,1) as list, scrollId
UNWIND list as count
CALL apoc.es.get(""localhost"",""_search"",""scroll"",null,{scroll:""5m"",scroll_id:scrollId},null) yield value with value._scoll_id as scrollId, value.hits.hits as nextHits

 nextHits  hit
 (doc: {id: hit._id, description: hit._source.description, name: hit._source.name})
 (company: {name: hit._source.company})
 (doc)-[:]->(company)  scrollId, doc, company
View all (5 more lines)
This example was tested on a Mac Book Pro with 16GB of RAM. Loading 20000 documents from ES to Neo4j (100 documents for each request) took 1 minute.
General Structure and Parameters
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.es.post(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value

// GET/PUT/POST url/index/type/id?query -d payload
host or port parameter
The parameter can be a direct host or url, or an entry to be lookup up in apoc.conf
host
host:port
http://host:port
lookup via key to apoc.es.<key>.url
lookup via key apoc.es.<key>.host
lookup apoc.es.url
lookup apoc.es.host
index parameter
Main ES index, will be sent directly, if null then ""_all"" multiple indexes can be separated by comma in the string.
type parameter
Document type, will be sent directly, if null then ""_all"" multiple types can be separated by comma in the string.
id parameter
Document id, will be left off when null.
query parameter
Query can be a map which is turned into a query string, a direct string or null then it is left off.
payload parameter
Payload can be a map which will be turned into a json payload or a string which will be sent directly or null.
Results
Results are stream of map in value.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.stats;"apoc.es.stats
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.stats(host-url-Key) - elastic search statistics
Signature
None
Copy to Clipboard
apoc.es.stats(host :: STRING?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.stats(""localhost"");
Table 1. Results
value
{_shards: {total: 4, failed: 0, successful: 2}, indices: {bank: {primaries: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 200, delete_current: 0, index_total: 1000, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 55, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 55, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 152, total: 5, listeners: 0, total_time_in_millis: 151, external_total: 4}, store: {size_in_bytes: 388421, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 3, total_time_in_millis: 0}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 512, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 1, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 4948, terms_memory_in_bytes: 3872, doc_values_memory_in_bytes: 76, stored_fields_memory_in_bytes: 488}, search: {scroll_total: 0, suggest_total: 0, query_total: 10, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 25, fetch_total: 10, open_contexts: 0, query_time_in_millis: 24}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1000, deleted: 0}, flush: {total: 1, total_time_in_millis: 16, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 3, current: 0, missing_total: 0, exists_time_in_millis: 2, missing_time_in_millis: 0, time_in_millis: 2, exists_total: 3}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 20971520, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}, total: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 200, delete_current: 0, index_total: 1000, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 55, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 55, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 152, total: 5, listeners: 0, total_time_in_millis: 151, external_total: 4}, store: {size_in_bytes: 388421, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 3, total_time_in_millis: 0}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 512, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 1, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 4948, terms_memory_in_bytes: 3872, doc_values_memory_in_bytes: 76, stored_fields_memory_in_bytes: 488}, search: {scroll_total: 0, suggest_total: 0, query_total: 10, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 25, fetch_total: 10, open_contexts: 0, query_time_in_millis: 24}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1000, deleted: 0}, flush: {total: 1, total_time_in_millis: 16, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 3, current: 0, missing_total: 0, exists_time_in_millis: 2, missing_time_in_millis: 0, time_in_millis: 2, exists_total: 3}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 20971520, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}, uuid: ""n30zldteSaW6mhIfeLEg1A""}, customer: {primaries: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 0, delete_current: 0, index_total: 0, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 55, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 55, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 1, total: 2, listeners: 0, total_time_in_millis: 0, external_total: 2}, store: {size_in_bytes: 3930, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 1, total_time_in_millis: 1}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 64, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 1, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 1364, terms_memory_in_bytes: 736, doc_values_memory_in_bytes: 76, stored_fields_memory_in_bytes: 488}, search: {scroll_total: 0, suggest_total: 0, query_total: 0, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 0, fetch_total: 0, open_contexts: 0, query_time_in_millis: 0}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1, deleted: 0}, flush: {total: 1, total_time_in_millis: 0, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 2, current: 0, missing_total: 0, exists_time_in_millis: 3, missing_time_in_millis: 0, time_in_millis: 3, exists_total: 2}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 20971520, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}, total: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 0, delete_current: 0, index_total: 0, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 55, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 55, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 1, total: 2, listeners: 0, total_time_in_millis: 0, external_total: 2}, store: {size_in_bytes: 3930, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 1, total_time_in_millis: 1}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 64, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 1, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 1364, terms_memory_in_bytes: 736, doc_values_memory_in_bytes: 76, stored_fields_memory_in_bytes: 488}, search: {scroll_total: 0, suggest_total: 0, query_total: 0, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 0, fetch_total: 0, open_contexts: 0, query_time_in_millis: 0}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1, deleted: 0}, flush: {total: 1, total_time_in_millis: 0, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 2, current: 0, missing_total: 0, exists_time_in_millis: 3, missing_time_in_millis: 0, time_in_millis: 3, exists_total: 2}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 20971520, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}, uuid: ""qsJolIubSKuQW7COg02k1Q""}}, _all: {primaries: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 200, delete_current: 0, index_total: 1000, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 110, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 110, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 153, total: 7, listeners: 0, total_time_in_millis: 151, external_total: 6}, store: {size_in_bytes: 392351, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 4, total_time_in_millis: 1}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 576, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 2, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 6312, terms_memory_in_bytes: 4608, doc_values_memory_in_bytes: 152, stored_fields_memory_in_bytes: 976}, search: {scroll_total: 0, suggest_total: 0, query_total: 10, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 25, fetch_total: 10, open_contexts: 0, query_time_in_millis: 24}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1001, deleted: 0}, flush: {total: 2, total_time_in_millis: 16, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 5, current: 0, missing_total: 0, exists_time_in_millis: 5, missing_time_in_millis: 0, time_in_millis: 5, exists_total: 5}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 41943040, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}, total: {completion: {size_in_bytes: 0}, indexing: {delete_time_in_millis: 0, throttle_time_in_millis: 0, index_time_in_millis: 200, delete_current: 0, index_total: 1000, is_throttled: FALSE, delete_total: 0, index_current: 0, noop_update_total: 0, index_failed: 0}, translog: {size_in_bytes: 110, uncommitted_operations: 0, operations: 0, uncommitted_size_in_bytes: 110, earliest_last_modified_age: 0}, refresh: {external_total_time_in_millis: 153, total: 7, listeners: 0, total_time_in_millis: 151, external_total: 6}, store: {size_in_bytes: 392351, reserved_in_bytes: 0}, recovery: {current_as_source: 0, current_as_target: 0, throttle_time_in_millis: 0}, warmer: {current: 0, total: 4, total_time_in_millis: 1}, segments: {version_map_memory_in_bytes: 0, norms_memory_in_bytes: 576, file_sizes: {}, max_unsafe_auto_id_timestamp: -1, count: 2, fixed_bit_set_memory_in_bytes: 0, term_vectors_memory_in_bytes: 0, points_memory_in_bytes: 0, index_writer_memory_in_bytes: 0, memory_in_bytes: 6312, terms_memory_in_bytes: 4608, doc_values_memory_in_bytes: 152, stored_fields_memory_in_bytes: 976}, search: {scroll_total: 0, suggest_total: 0, query_total: 10, scroll_time_in_millis: 0, suggest_time_in_millis: 0, query_current: 0, suggest_current: 0, fetch_current: 0, scroll_current: 0, fetch_time_in_millis: 25, fetch_total: 10, open_contexts: 0, query_time_in_millis: 24}, query_cache: {miss_count: 0, memory_size_in_bytes: 0, cache_size: 0, total_count: 0, evictions: 0, hit_count: 0, cache_count: 0}, docs: {count: 1001, deleted: 0}, flush: {total: 2, total_time_in_millis: 16, periodic: 0}, fielddata: {evictions: 0, memory_size_in_bytes: 0}, get: {total: 5, current: 0, missing_total: 0, exists_time_in_millis: 5, missing_time_in_millis: 0, time_in_millis: 5, exists_total: 5}, request_cache: {evictions: 0, miss_count: 0, hit_count: 0, memory_size_in_bytes: 0}, merges: {current: 0, total: 0, total_time_in_millis: 0, current_docs: 0, total_auto_throttle_in_bytes: 41943040, total_docs: 0, total_size_in_bytes: 0, current_size_in_bytes: 0, total_stopped_time_in_millis: 0, total_throttled_time_in_millis: 0}}}}
More documentation of apoc.es.stats
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.getRaw;"apoc.es.getRaw
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.getRaw(host-or-port,path,payload-or-null) yield value - perform a raw GET operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.getRaw(host :: STRING?, path :: STRING?, payload :: ANY?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
path
STRING?
null
payload
ANY?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can find the document with id 1, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.getRaw(""localhost"",""bank/_doc/1"",null);
Table 1. Results
value
{_seq_no: 0, found: TRUE, _index: ""bank"", _type: ""_doc"", _source: {account_number: 1, firstname: ""Amber"", address: ""880 Holmes Lane"", balance: 39225, gender: ""M"", city: ""Brogan"", employer: ""Pyrami"", state: ""IL"", age: 32, email: ""amberduke@pyrami.com"", lastname: ""Duke""}, _id: ""1"", _version: 1, _primary_term: 1}
We can find the documents that have an address of mill lane, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.getRaw(""localhost"",""bank/_search"",{
  query: { match_phrase: { address: ""mill lane"" } }
});
Table 2. Results
value
{_shards: {total: 1, failed: 0, successful: 1, skipped: 0}, hits: {hits: [{_type: ""_doc"", _source: {account_number: 136, firstname: ""Winnie"", address: ""198 Mill Lane"", balance: 45801, gender: ""M"", city: ""Urie"", employer: ""Neteria"", state: ""IL"", age: 38, email: ""winnieholland@neteria.com"", lastname: ""Holland""}, _id: ""136"", _index: ""bank"", _score: 9.507477}], total: {value: 1, relation: ""eq""}, max_score: 9.507477}, took: 2, timed_out: FALSE}
More documentation of apoc.es.getRaw
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.post;"apoc.es.post
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.post(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a POST operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.post(host :: STRING?, index :: STRING?, type :: STRING?, query :: ANY?, payload = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
index
STRING?
null
type
STRING?
null
query
ANY?
null
payload
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can create a document with a name property of John Doe in the customers index, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.post(""localhost"",""customers"",""_doc"", null, {
  name: ""John Doe""
});
Table 1. Results
value
{result: ""created"", _shards: {total: 2, failed: 0, successful: 1}, _seq_no: 4, _index: ""customers"", _type: ""_doc"", _id: ""Im4w_3UBi9jUSsIzV4Js"", _version: 1, _primary_term: 1}
Elastic will generate an _id value for us when we use apoc.es.post. If we want to provide an id, or update an existing document, see apoc.es.put.
More documentation of apoc.es.post
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.put;"apoc.es.put
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.put(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a PUT operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.put(host :: STRING?, index :: STRING?, type :: STRING?, id :: STRING?, query :: ANY?, payload = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
index
STRING?
null
type
STRING?
null
id
STRING?
null
query
ANY?
null
payload
MAP?
{}
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can create a document with a name property of John Doe and document id of 2, in the customers index, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.put(""localhost"",""customers"",""_doc"", ""2"", null, {
  name: ""John Doe""
});
Table 1. Results
value
{result: ""created"", _shards: {total: 2, failed: 0, successful: 1}, _seq_no: 2, _index: ""customers"", _type: ""_doc"", _id: ""2"", _version: 1, _primary_term: 1}
We can update this document to add an address, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.put(""localhost"",""customers"",""_doc"", ""2"", null, {
  name: ""John Doe"",
  address: ""Buckingham Palace""
});
Table 2. Results
value
{result: ""updated"", _shards: {total: 2, failed: 0, successful: 1}, _seq_no: 5, _index: ""customers"", _type: ""_doc"", _id: ""2"", _version: 2, _primary_term: 1}
More documentation of apoc.es.put
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.query;"apoc.es.query
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.query(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a SEARCH operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.query(host :: STRING?, index :: STRING?, type :: STRING?, query :: ANY?, payload :: ANY?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
index
STRING?
null
type
STRING?
null
query
ANY?
null
payload
ANY?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can find the first 10 documents sorted by account_number, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.query(""localhost"",""bank"",""_doc"",null,{
  query: { match_all: {} },
  sort: [
    { account_number: ""asc"" }
  ]
})
YIELD value
UNWIND value.hits.hits AS hit
RETURN hit;
Table 1. Results
hit
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 0, firstname: ""Bradshaw"", address: ""244 Columbus Place"", balance: 16623, gender: ""F"", city: ""Hobucken"", employer: ""Euron"", state: ""CO"", age: 29, email: ""bradshawmckenzie@euron.com"", lastname: ""Mckenzie""}, _id: ""0"", sort: [0], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 1, firstname: ""Amber"", address: ""880 Holmes Lane"", balance: 39225, gender: ""M"", city: ""Brogan"", employer: ""Pyrami"", state: ""IL"", age: 32, email: ""amberduke@pyrami.com"", lastname: ""Duke""}, _id: ""1"", sort: [1], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 2, firstname: ""Roberta"", address: ""560 Kingsway Place"", balance: 28838, gender: ""F"", city: ""Bennett"", employer: ""Chillium"", state: ""LA"", age: 22, email: ""robertabender@chillium.com"", lastname: ""Bender""}, _id: ""2"", sort: [2], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 3, firstname: ""Levine"", address: ""328 Wilson Avenue"", balance: 44947, gender: ""F"", city: ""Cochranville"", employer: ""Amtap"", state: ""HI"", age: 26, email: ""levineburks@amtap.com"", lastname: ""Burks""}, _id: ""3"", sort: [3], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 4, firstname: ""Rodriquez"", address: ""986 Wyckoff Avenue"", balance: 27658, gender: ""F"", city: ""Eastvale"", employer: ""Tourmania"", state: ""HI"", age: 31, email: ""rodriquezflores@tourmania.com"", lastname: ""Flores""}, _id: ""4"", sort: [4], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 5, firstname: ""Leola"", address: ""311 Elm Place"", balance: 29342, gender: ""F"", city: ""Fairview"", employer: ""Diginetic"", state: ""NJ"", age: 30, email: ""leolastewart@diginetic.com"", lastname: ""Stewart""}, _id: ""5"", sort: [5], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 6, firstname: ""Hattie"", address: ""671 Bristol Street"", balance: 5686, gender: ""M"", city: ""Dante"", employer: ""Netagy"", state: ""TN"", age: 36, email: ""hattiebond@netagy.com"", lastname: ""Bond""}, _id: ""6"", sort: [6], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 7, firstname: ""Levy"", address: ""820 Logan Street"", balance: 39121, gender: ""M"", city: ""Shrewsbury"", employer: ""Teraprene"", state: ""MO"", age: 22, email: ""levyrichard@teraprene.com"", lastname: ""Richard""}, _id: ""7"", sort: [7], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 8, firstname: ""Jan"", address: ""699 Visitation Place"", balance: 48868, gender: ""M"", city: ""Wakulla"", employer: ""Glasstep"", state: ""AZ"", age: 35, email: ""janburns@glasstep.com"", lastname: ""Burns""}, _id: ""8"", sort: [8], _score: NULL}
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 9, firstname: ""Opal"", address: ""963 Neptune Avenue"", balance: 24776, gender: ""M"", city: ""Olney"", employer: ""Cedward"", state: ""OH"", age: 39, email: ""opalmeadows@cedward.com"", lastname: ""Meadows""}, _id: ""9"", sort: [9], _score: NULL}
We can find documents with an account number of 7, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.query(""localhost"",""bank"",""_doc"",null,{
  query: { match: {account_number: 7} }
})
YIELD value
UNWIND value.hits.hits AS hit
RETURN hit;
Table 2. Results
hit
{_index: ""bank"", _type: ""_doc"", _source: {account_number: 7, firstname: ""Levy"", address: ""820 Logan Street"", balance: 39121, gender: ""M"", city: ""Shrewsbury"", employer: ""Teraprene"", state: ""MO"", age: 22, email: ""levyrichard@teraprene.com"", lastname: ""Richard""}, _id: ""7"", sort: [7], _score: NULL}
We can find documents that belong to customers who are 40 years old, but excluding anyone who lives in Idaho (ID), by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.query(""localhost"",""bank"",""_doc"",null,{
  query: {
    bool: {
      must: [ { match: { age: ""40"" } }],
      must_not: [{ match: { state: ""ID"" } }]
    }
  }
})
YIELD value
UNWIND value.hits.hits AS hit
RETURN hit;
Table 3. Results
hit
{_type: ""_doc"", _source: {account_number: 474, firstname: ""Obrien"", address: ""192 Ide Court"", balance: 35896, gender: ""F"", city: ""Crucible"", employer: ""Suremax"", state: ""UT"", age: 40, email: ""obrienwalton@suremax.com"", lastname: ""Walton""}, _id: ""474"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 479, firstname: ""Cameron"", address: ""904 Bouck Court"", balance: 31865, gender: ""M"", city: ""Nord"", employer: ""Telpod"", state: ""MO"", age: 40, email: ""cameronross@telpod.com"", lastname: ""Ross""}, _id: ""479"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 549, firstname: ""Jacqueline"", address: ""444 Schenck Place"", balance: 1932, gender: ""M"", city: ""Oretta"", employer: ""Fuelworks"", state: ""OR"", age: 40, email: ""jacquelinemaxwell@fuelworks.com"", lastname: ""Maxwell""}, _id: ""549"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 878, firstname: ""Battle"", address: ""234 Hendrix Street"", balance: 49159, gender: ""F"", city: ""Wanamie"", employer: ""Zilphur"", state: ""PA"", age: 40, email: ""battleblackburn@zilphur.com"", lastname: ""Blackburn""}, _id: ""878"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 885, firstname: ""Valdez"", address: ""227 Scholes Street"", balance: 31661, gender: ""F"", city: ""Chilton"", employer: ""Delphide"", state: ""MT"", age: 40, email: ""valdezroberson@delphide.com"", lastname: ""Roberson""}, _id: ""885"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 948, firstname: ""Sargent"", address: ""532 Fiske Place"", balance: 37074, gender: ""M"", city: ""Umapine"", employer: ""Accuprint"", state: ""AK"", age: 40, email: ""sargentpowers@accuprint.com"", lastname: ""Powers""}, _id: ""948"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 998, firstname: ""Letha"", address: ""206 Llama Court"", balance: 16869, gender: ""F"", city: ""Dunlo"", employer: ""Dognosis"", state: ""WV"", age: 40, email: ""lethabaker@dognosis.com"", lastname: ""Baker""}, _id: ""998"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 40, firstname: ""Pace"", address: ""263 Ovington Court"", balance: 33882, gender: ""M"", city: ""Silkworth"", employer: ""Cytrak"", state: ""OR"", age: 40, email: ""pacemolina@cytrak.com"", lastname: ""Molina""}, _id: ""40"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 165, firstname: ""Sims"", address: ""205 Jackson Street"", balance: 18956, gender: ""F"", city: ""Tilden"", employer: ""Comtour"", state: ""DC"", age: 40, email: ""simsmckay@comtour.com"", lastname: ""Mckay""}, _id: ""165"", _index: ""bank"", _score: 1.0}
{_type: ""_doc"", _source: {account_number: 177, firstname: ""Harris"", address: ""468 Suydam Street"", balance: 48972, gender: ""F"", city: ""Yettem"", employer: ""Kidstock"", state: ""KY"", age: 40, email: ""harrisgross@kidstock.com"", lastname: ""Gross""}, _id: ""177"", _index: ""bank"", _score: 1.0}
More documentation of apoc.es.query
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es/apoc.es.get;"apoc.es.get
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.es.get(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a GET operation on elastic search
Signature
None
Copy to Clipboard
apoc.es.get(host :: STRING?, index :: STRING?, type :: STRING?, id :: STRING?, query :: ANY?, payload :: ANY?) :: (value :: MAP?)
Input parameters
Name Type Default
host
STRING?
null
index
STRING?
null
type
STRING?
null
id
STRING?
null
query
ANY?
null
payload
ANY?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on an Elastic instance populated with the accounts.json sample dataset from the Getting Started with Elasticsearch guide. You can find instructions for setting this up at github.com/neo4j-examples/elastic-example.
We can find the document with id 1, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.es.get(""localhost"",""bank"",""_doc"",""1"",null,null);
Table 1. Results
value
{_seq_no: 0, found: TRUE, _index: ""bank"", _type: ""_doc"", _source: {account_number: 1, firstname: ""Amber"", address: ""880 Holmes Lane"", balance: 39225, gender: ""M"", city: ""Brogan"", employer: ""Pyrami"", state: ""IL"", age: 32, email: ""amberduke@pyrami.com"", lastname: ""Duke""}, _id: ""1"", _version: 1, _primary_term: 1}
More documentation of apoc.es.get
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.pop;"apoc.redis.pop
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.pop(uri, key, {config}) | Execute the 'LPOP key' command, or the 'RPOP' if config right=true (default)
Signature
None
Copy to Clipboard
apoc.redis.pop(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.pop
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.zadd;"apoc.redis.zadd
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.zadd(uri, keys, scoresAndMembers, {config}) | Execute the 'ZADD key scoresAndMembers' command, where scoresAndMembers is a list of score,member,score,member,…
Signature
None
Copy to Clipboard
apoc.redis.zadd(uri :: STRING?, key :: ANY?, value :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
value
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.zadd
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis;"apoc.redis
Qualified Name Type
apoc.redis.append
apoc.redis.append(uri, key, value, {config}) | Execute the 'APPEND key value' command
Procedure
apoc.redis.configGet
apoc.redis.configGet(uri, parameter, {config}) | Execute the 'CONFIG GET parameter' command
Procedure
apoc.redis.configSet
apoc.redis.configSet(uri, parameter, {config}) | Execute the 'CONFIG SET parameter value' command
Procedure
apoc.redis.copy
apoc.redis.copy(uri, source, destination, {config}) | Execute the 'COPY source destination' command and returns true if source was copied and false otherwise
Procedure
apoc.redis.eval
apoc.redis.eval(uri, script, outputType, keys, values, {config}) | Execute the 'EVAL script' command. In the parameters provided to the procedure, keys are bound to the KEYS[n] like special array of the Lua script and values are bound to the ARGV[n] like special array of the Lua script.
Procedure
apoc.redis.exists
apoc.redis.exists(uri, keys, {config}) | Execute the 'EXISTS keys' command
Procedure
apoc.redis.get
apoc.redis.get(uri, key, {config}) | Execute the 'GET key' command
Procedure
apoc.redis.hdel
apoc.redis.hdel(uri, key, fields, {config}) | Execute the 'HDEL key fields' command
Procedure
apoc.redis.hexists
apoc.redis.hexists(uri, key, field, {config}) | Execute the 'HEXISTS key field' command
Procedure
apoc.redis.hget
apoc.redis.hget(uri, key, field, {config}) | Execute the 'HGET key field' command
Procedure
apoc.redis.hgetall
apoc.redis.hgetall(uri, key, {config}) | Execute the 'HGETALL key' command
Procedure
apoc.redis.hincrby
apoc.redis.hincrby(uri, key, field, amount, {config}) | Execute the 'HINCRBY key field amount' command
Procedure
apoc.redis.hset
apoc.redis.hset(uri, key, field, value, {config}) | Execute the 'HSET key field value' command and returns true if it is a new field in the hash or false if the field already exists
Procedure
apoc.redis.incrby
apoc.redis.incrby(uri, key, amount, {config}) | Execute the 'INCRBY key increment' command
Procedure
apoc.redis.info
apoc.redis.info(uri, {config}) | Execute the 'INFO' command
Procedure
apoc.redis.lrange
apoc.redis.lrange(uri, key, start, stop, {config}) | Execute the 'LRANGE key start stop' command
Procedure
apoc.redis.persist
apoc.redis.persist(uri, key, {config}) | Execute the 'PERSIST key' command
Procedure
apoc.redis.pexpire
apoc.redis.pexpire(uri, key, time, isExpireAt {config}) | Execute the 'PEXPIRE key time' command, or the 'PEPXPIREAT' if isExpireAt=true
Procedure
apoc.redis.pop
apoc.redis.pop(uri, key, {config}) | Execute the 'LPOP key' command, or the 'RPOP' if config right=true (default)
Procedure
apoc.redis.pttl
apoc.redis.pttl(uri, key, {config}) | Execute the 'PTTL key' command
Procedure
apoc.redis.push
apoc.redis.push(uri, key, values, {config}) | Execute the 'LPUSH key field values' command, or the 'RPUSH' if config right=true (default)
Procedure
apoc.redis.sadd
apoc.redis.sadd(uri, key, members, {config}) | Execute the 'SADD key members' command
Procedure
apoc.redis.scard
apoc.redis.scard(uri, key, {config}) | Execute the 'SCARD key' command
Procedure
apoc.redis.getSet
apoc.redis.getSet(uri, key, value, {config}) | Execute the 'SET key value' command and return old value stored (or null if did not exists)
Procedure
apoc.redis.smembers
apoc.redis.smembers(uri, key, {config}) | Execute the 'SMEMBERS key' command
Procedure
apoc.redis.spop
apoc.redis.spop(uri, key, {config}) | Execute the 'SPOP key' command
Procedure
apoc.redis.sunion
apoc.redis.sunion(uri, keys, {config}) | Execute the 'SUNION keys' command
Procedure
apoc.redis.zadd
apoc.redis.zadd(uri, keys, scoresAndMembers, {config}) | Execute the 'ZADD key scoresAndMembers' command, where scoresAndMembers is a list of score,member,score,member,…
Procedure
apoc.redis.zcard
apoc.redis.zcard(uri, key, {config}) | Execute the 'ZCARD key' command
Procedure
apoc.redis.zrangebyscore
apoc.redis.zrangebyscore(uri, key, min, max, {config}) | Execute the 'ZRANGEBYSCORE key min max' command
Procedure
apoc.redis.zrem
apoc.redis.zrem(uri, key, members, {config}) | Execute the 'ZREM key members' command
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.configSet;"apoc.redis.configSet
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.configSet(uri, parameter, {config}) | Execute the 'CONFIG SET parameter value' command
Signature
None
Copy to Clipboard
apoc.redis.configSet(uri :: STRING?, parameter :: STRING?, value :: STRING?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
parameter
STRING?
null
value
STRING?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.configSet
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.append;"apoc.redis.append
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.append(uri, key, value, {config}) | Execute the 'APPEND key value' command
Signature
None
Copy to Clipboard
apoc.redis.append(uri :: STRING?, key :: ANY?, value :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
value
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.append
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hgetall;"apoc.redis.hgetall
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hgetall(uri, key, {config}) | Execute the 'HGETALL key' command
Signature
None
Copy to Clipboard
apoc.redis.hgetall(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
MAP?
More documentation of apoc.redis.hgetall
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hincrby;"apoc.redis.hincrby
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hincrby(uri, key, field, amount, {config}) | Execute the 'HINCRBY key field amount' command
Signature
None
Copy to Clipboard
apoc.redis.hincrby(uri :: STRING?, key :: ANY?, field :: ANY?, amount :: INTEGER?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
field
ANY?
null
amount
INTEGER?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.hincrby
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.eval;"apoc.redis.eval
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.redis.eval(uri, script, outputType, keys, values, {config}) | Execute the 'EVAL script' command. In the parameters provided to the procedure, keys are bound to the KEYS[n] like special array of the Lua script and values are bound to the ARGV[n] like special array of the Lua script.
Signature
None
Copy to Clipboard
apoc.redis.eval(uri :: STRING?, script :: STRING?, outputType :: STRING?, keys :: LIST? OF ANY?, values :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
script
STRING?
null
outputType
STRING?
null
keys
LIST? OF ANY?
null
values
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
Usage Examples
We can do through the apoc.redis.eval procedure, any Lua script executable with the EVAL command
In this procedure, the third parameter in the procedure, in this case VALUE is the ScriptOutputType, that is, the return type of Lua script that can be a BOOLEAN, INTEGER, STATUS, VALUE or MULTI.
The fourth and fifth params, are bound respectively to the KEYS[n] and to the ARGV[n] like special array of the Lua script.
So, if we have a record with key testEval and value valueEval, we can execute the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.eval($uri, 'return redis.call(""set"", KEYS[1], ARGV[1])', 'VALUE', ['testEval'], ['key:name'], {})
that is equivalent to a redis-cli command eval ""return redis.call('set', KEYS[1], ARGV[1])"" 1 testEval key:name and returns
Table 1. Results
value
""OK""
Or also, we can execute (without ARGV[n]):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.redis.eval($uri, 'return redis.call(""get"", KEYS[1])', 'VALUE', ['testEval'], [], {})
Table 2. Results
value
key:name
that is equivalent to a redis-cli command eval ""return redis.call('get', KEYS[1])"" 1 testEval.
More documentation of apoc.redis.eval
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.exists;"apoc.redis.exists
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.exists(uri, keys, {config}) | Execute the 'EXISTS keys' command
Signature
None
Copy to Clipboard
apoc.redis.exists(uri :: STRING?, keys :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
keys
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.exists
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.getSet;"apoc.redis.getSet
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.getSet(uri, key, value, {config}) | Execute the 'SET key value' command and return old value stored (or null if did not exists)
Signature
None
Copy to Clipboard
apoc.redis.getSet(uri :: STRING?, key :: ANY?, value :: ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
value
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.getSet
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.push;"apoc.redis.push
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.push(uri, key, values, {config}) | Execute the 'LPUSH key field values' command, or the 'RPUSH' if config right=true (default)
Signature
None
Copy to Clipboard
apoc.redis.push(uri :: STRING?, key :: ANY?, value :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
value
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.push
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hget;"apoc.redis.hget
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hget(uri, key, field, {config}) | Execute the 'HGET key field' command
Signature
None
Copy to Clipboard
apoc.redis.hget(uri :: STRING?, key :: ANY?, field :: ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
field
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.hget
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.smembers;"apoc.redis.smembers
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.smembers(uri, key, {config}) | Execute the 'SMEMBERS key' command
Signature
None
Copy to Clipboard
apoc.redis.smembers(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
LIST? OF ANY?
More documentation of apoc.redis.smembers
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.zrem;"apoc.redis.zrem
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.zrem(uri, key, members, {config}) | Execute the 'ZREM key members' command
Signature
None
Copy to Clipboard
apoc.redis.zrem(uri :: STRING?, key :: ANY?, members :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
members
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.zrem
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.sadd;"apoc.redis.sadd
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.sadd(uri, key, members, {config}) | Execute the 'SADD key members' command
Signature
None
Copy to Clipboard
apoc.redis.sadd(uri :: STRING?, key :: ANY?, members :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
members
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.sadd
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hexists;"apoc.redis.hexists
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hexists(uri, key, field, {config}) | Execute the 'HEXISTS key field' command
Signature
None
Copy to Clipboard
apoc.redis.hexists(uri :: STRING?, key :: ANY?, field :: ANY?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
field
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.redis.hexists
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.sunion;"apoc.redis.sunion
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.sunion(uri, keys, {config}) | Execute the 'SUNION keys' command
Signature
None
Copy to Clipboard
apoc.redis.sunion(uri :: STRING?, keys :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
uri
STRING?
null
keys
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
LIST? OF ANY?
More documentation of apoc.redis.sunion
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.spop;"apoc.redis.spop
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.spop(uri, key, {config}) | Execute the 'SPOP key' command
Signature
None
Copy to Clipboard
apoc.redis.spop(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
ANY?
More documentation of apoc.redis.spop
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hdel;"apoc.redis.hdel
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hdel(uri, key, fields, {config}) | Execute the 'HDEL key fields' command
Signature
None
Copy to Clipboard
apoc.redis.hdel(uri :: STRING?, key :: ANY?, fields :: LIST? OF ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
fields
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.hdel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.persist;"apoc.redis.persist
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.persist(uri, key, {config}) | Execute the 'PERSIST key' command
Signature
None
Copy to Clipboard
apoc.redis.persist(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.redis.persist
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.incrby;"apoc.redis.incrby
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.incrby(uri, key, amount, {config}) | Execute the 'INCRBY key increment' command
Signature
None
Copy to Clipboard
apoc.redis.incrby(uri :: STRING?, key :: ANY?, amount :: INTEGER?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
amount
INTEGER?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.incrby
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.hset;"apoc.redis.hset
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.hset(uri, key, field, value, {config}) | Execute the 'HSET key field value' command and returns true if it is a new field in the hash or false if the field already exists
Signature
None
Copy to Clipboard
apoc.redis.hset(uri :: STRING?, key :: ANY?, field :: ANY?, value :: ANY?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
field
ANY?
null
value
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.redis.hset
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.pexpire;"apoc.redis.pexpire
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.pexpire(uri, key, time, isExpireAt {config}) | Execute the 'PEXPIRE key time' command, or the 'PEPXPIREAT' if isExpireAt=true
Signature
None
Copy to Clipboard
apoc.redis.pexpire(uri :: STRING?, key :: ANY?, time :: INTEGER?, isExpireAt :: BOOLEAN?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
time
INTEGER?
null
isExpireAt
BOOLEAN?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.redis.pexpire
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.configGet;"apoc.redis.configGet
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.configGet(uri, parameter, {config}) | Execute the 'CONFIG GET parameter' command
Signature
None
Copy to Clipboard
apoc.redis.configGet(uri :: STRING?, parameter :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
uri
STRING?
null
parameter
STRING?
null
config
MAP?
{}
Output parameters
Name Type
value
MAP?
More documentation of apoc.redis.configGet
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.copy;"apoc.redis.copy
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.copy(uri, source, destination, {config}) | Execute the 'COPY source destination' command and returns true if source was copied and false otherwise
Signature
None
Copy to Clipboard
apoc.redis.copy(uri :: STRING?, source :: ANY?, destination :: ANY?, config = {} :: MAP?) :: (value :: BOOLEAN?)
Input parameters
Name Type Default
uri
STRING?
null
source
ANY?
null
destination
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
BOOLEAN?
More documentation of apoc.redis.copy
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.lrange;"apoc.redis.lrange
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.lrange(uri, key, start, stop, {config}) | Execute the 'LRANGE key start stop' command
Signature
None
Copy to Clipboard
apoc.redis.lrange(uri :: STRING?, key :: ANY?, start :: INTEGER?, stop :: INTEGER?, config = {} :: MAP?) :: (value :: LIST? OF ANY?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
start
INTEGER?
null
stop
INTEGER?
null
config
MAP?
{}
Output parameters
Name Type
value
LIST? OF ANY?
More documentation of apoc.redis.lrange
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.zcard;"apoc.redis.zcard
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.zcard(uri, key, {config}) | Execute the 'ZCARD key' command
Signature
None
Copy to Clipboard
apoc.redis.zcard(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.zcard
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.scard;"apoc.redis.scard
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.scard(uri, key, {config}) | Execute the 'SCARD key' command
Signature
None
Copy to Clipboard
apoc.redis.scard(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.scard
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.redis/apoc.redis.pttl;"apoc.redis.pttl
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.redis.pttl(uri, key, {config}) | Execute the 'PTTL key' command
Signature
None
Copy to Clipboard
apoc.redis.pttl(uri :: STRING?, key :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
key
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.redis.pttl
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.get;"apoc.get
Qualified Name Type
apoc.get.nodes
apoc.get.nodes(node|id|[ids]) - quickly returns all nodes with these id’s
Procedure
apoc.get.rels
apoc.get.rels(rel|id|[ids]) - quickly returns all relationships with these id’s
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.get/apoc.get.nodes;"apoc.get.nodes
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.get.nodes(node|id|[ids]) - quickly returns all nodes with these id’s
Signature
None
Copy to Clipboard
apoc.get.nodes(nodes :: ANY?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Student {name: 'Alice', score: 71});
CREATE (:Student {name: 'Mark', score: 95});
CREATE (:Student {name: 'Andrea', score: 86});
We can return the internal IDs of these nodes using the id function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
RETURN id(s) AS id;
Table 1. Results
id
3975
3976
3977
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.get.nodes([3975, 3976, 3977]);
Table 2. Results
node
(:Student {name: ""Alice"", score: 71})
(:Student {name: ""Mark"", score: 95})
(:Student {name: ""Andrea"", score: 86})
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.insert;"apoc.mongo.insert
Contents
Signature
Input parameters
Procedure Apoc Extended
apoc.mongo.insert(uri, documents, $config) yield value - inserts the given documents into the mongodb collection
Signature
None
Copy to Clipboard
apoc.mongo.insert(uri :: STRING?, documents :: LIST? OF ANY?, config = {} :: MAP?) :: VOID
Input parameters
Name Type Default
uri
STRING?
null
documents
LIST? OF ANY?
null
config
MAP?
{}
More documentation of apoc.mongo.insert
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/mongo;"MongoDB
Contents
Available Procedures
Install Dependencies
Field description
Configuration parameters
Examples
apoc.mongo.aggregate
apoc.mongo.count
apoc.mongo.find
apoc.mongo.update
apoc.mongo.delete
apoc.mongo.insert
Available Procedures
signature
apoc.mongo.aggregate(uri, pipeline, $config) yield value - perform an aggregate operation on mongodb collection
apoc.mongo.count(uri, query, $config) yield value - perform a count operation on mongodb collection
apoc.mongo.find(uri, query, $config) yield value - perform a find operation on mongodb collection
apoc.mongo.delete(uri, query, $config) - delete the given documents from the mongodb collection and returns the number of affected documents
apoc.mongo.insert(uri, documents, $config) yield value - inserts the given documents into the mongodb collection
apoc.mongo.update(uri, query, update, $config) - updates the given documents from the mongodb collection and returns the number of affected documents
Install Dependencies
The Mongo procedures have dependencies on a client library that is not included in the APOC Extended library.
This dependency is included in apoc-mongodb-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you could copy these jars into the plugins directory:
bson-3.4.2.jar
mongo-java-driver-3.4.2.jar,
mongodb-driver-3.4.2.jar
mongodb-driver-core-3.4.2.jar
You should be able to get them from the following links:
mongo-java-driver
mongodb-driver
mongodb-driver-core
BSON
Field description
uri: The connection String URI, with scheme mongodb://[username:password@]host1[:port1][,host2[:port2],…[,hostN[:portN]]]/databaseName.collectionName[?options]. Note that this uri must necessarily have the database name and (if the collection config parameter is not explicit) the collection name (for example mongodb://user:pass@localhost:27017/myDb.myCollection?authSource=admin)
query: query parameter map (can be a map or a json string)
update: update parameter map (only for apoc.mongo.update)
documents: the documents to insert (only for apoc.mongo.insert)
config: see below
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
extractReferences
Boolean
false
If true and a field contains an ObjectId it will include the related document instead of the ObjectId
objectIdAsMap
Boolean
true
If true extract the ObjectId as map
project
Map<K,V> OR String
empty
The projection parameters (can be a map or a json string)
sort
Map<K,V> OR String
empty
The sort parameters (can be a map or a json string)
skip
Long
0
The number of documents to skip
limit
Long
0
The max number of documents to show
collection
String
empty
The collection name (takes precedence over the collection passed with uri parameter
Examples
Given the following collections:
None
Copy to Clipboard
// Product
...
{""_id"": ObjectId(""product1""), ""name"": ""Product 1"", ""price"": 100}
{""_id"": ObjectId(""product3""), ""name"": ""Product 2"", ""price"": 200}
{""_id"": ObjectId(""product3""), ""name"": ""Product 3"", ""price"": 300}
...
None
Copy to Clipboard
// Person
...
{""_id"": ObjectId(""personAl""), ""name"": ""Al"", expr: BsonRegularExpression(""foo*""), ""bought"": [ObjectId(""product1""), ObjectId(""product3"")]}
{""_id"": ObjectId(""personJohn""), ""name"": ""John"", ""age"": 40, ""foo"", ""bar""}
{""_id"": ObjectId(""personJack""), ""name"": ""Jack"", ""age"": 50, ""foo"", ""bar"", expr: BsonRegularExpression(""bar*""), ""bought"": [ObjectId(""product1""), ObjectId(""product2"")]}
...
we can run the following procedures.
apoc.mongo.aggregate
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.aggregate('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', [{`$match`: {foo: 'bar'}}, {`$set`: {aggrField: 'Y'} }])
Table 2. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""John"", ""foo"": ""bar"", ""age"": 40L, ""aggrField"": ""Y"", }
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Jack"", ""age"": 50L, ""foo"": ""bar"", ""expr"": ""bar*"", ""bought"": [""product1"", ""product2""], ""aggrField"": ""Y"", }
apoc.mongo.count
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.count('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin')
Table 3. Results
value
3
We can also pass the collection name through the config parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.count('mongodb://user:pass@localhost:27017/myDb?authSource=admin', {collection: 'Person'})
Table 4. Results
value
3
apoc.mongo.find
If we want to extract the all `Person`s with default parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.find('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin')
Table 5. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Al"", ""expr"": ""foo*"", ""bought"": [""product1"", ""product3""] }
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""John"", ""foo"": ""bar"", ""age"": 40L }
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Jack"", ""age"": 50L, ""foo"": ""bar"", ""expr"": ""bar*"", ""bought"": [""product1"", ""product2""] }
In addition, we can pass the query param like:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.first('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', {expr: {`$regex`: 'bar*', `$options`: ''}})
Table 6. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Jack"", ""foo"": ""bar"", ""expr"": ""bar*"", ""bought"": [""product1"", ""product2""] }
If we want to extract bought references, through config parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.first('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', {expr: {`$regex`: 'foo*', `$options`: ''}}, {extractReferences: true})
Table 7. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Al"", ""expr"": ""foo*"", ""bought"": [ { ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Product 1"", ""price"": 100 }, { ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""name"": ""Product 3"", ""price"": 300 }, ] }
Moreover, we can retrieve the ObjectId s with theirs HexString representation through objectIdAsMap config:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.first('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', {expr: {`$regex`: 'foo*', `$options`: ''}}, {objectIdAsMap: false, extractReferences: true})
Table 8. Results
value
{ ""_id"": ""personAl"", ""name"": ""Al"", ""expr"": ""foo*"", ""bought"": [ {""_id"": ""product1"", ""name"": ""Product 1"", ""price"": 100}, {""_id"": ""product3"", ""name"": ""Product 3"", ""price"": 300} ] }
Furthermore, we can skip n values and pass a project parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.first('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', null, {skip: 2, project: {age: 1}})
Table 9. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""age"": 50L, }
We can pass query, skip and sort parameter as stringified values, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.first('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', '{foo: ""bar""}', {sort: '{name: -1}', project: '{age: 1}'})
Table 10. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""age"": 40L, }
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""age"": 50L, }
Furthermore, we can use the limit parameter, for example:
CALL apoc.mongo.find('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', null, {skip: 1, limit: 1, project: {age: 1}})
Table 11. Results
value
{ ""_id"": { ""timestamp"": <…>, ""machineIdentifier"": <…>, ""processIdentifier"": <…>, ""counter"": <…>, }, ""age"": 40, }
Furthermore, we can pass a sort parameter, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.find('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', null, {sort: {name: -1}, objectIdAsMap: false, project: {name: 1}})
Table 12. Results
value
`` { ""_id"": ""personJohn"", ""name"": ""John"", }
`` { ""_id"": ""personJack"", ""name"": ""Jack"", }
{ ""_id"": ""personAl"", ""name"": ""Al"", }
apoc.mongo.update
To update the age property of the John document:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.update('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', {name: ""John""}, {`$set`: {age:99}})
with the number of row affected as result:
Table 13. Results
value
1
apoc.mongo.delete
To delete the John document:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.update('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', {name: ""John""})
with the number of row affected as result:
Table 14. Results
value
1
apoc.mongo.insert
To insert 2 document {""secondId"": ObjectId(""507f191e811c19729de860ea""), ""baz"": 1} and {""secondId"": ObjectId(""507f191e821c19729de860ef""), ""baz"": 1} in a Person collection (in this case the procedure return void):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.mongo.insert('mongodb://user:pass@localhost:27017/myDb.Person?authSource=admin', [{secondId: {`$oid`: '507f191e811c19729de860ea'}, baz: 1}, {secondId: {`$oid`: '507f191e821c19729de860ef'}, baz: 1}])
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.export/apoc.export.xls.graph;"apoc.export.xls.graph
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Usage Examples
Procedure Apoc Extended
apoc.export.xls.graph(graph,file,config) - exports given graph object as xls to the provided file
Signature
None
Copy to Clipboard
apoc.export.xls.graph(graph :: MAP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
graph
MAP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Install Dependencies
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Movies Graph Visualization
The apoc.export.xls.graph procedure exports a virtual graph to a CSV file or as a stream.
The examples in this section are based on a virtual graph that contains all PRODUCED relationships and the nodes either side of that relationship. We can then export that virtual graph to movies-producers.xls:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[produced:PRODUCED]->(:Movie)
WITH collect(path) AS paths
CALL apoc.graph.fromPaths(paths, ""producers"", {})
YIELD graph AS g
CALL apoc.export.xls.graph(g, ""movies-producers.xls"", {})
YIELD file, nodes, relationships, properties
RETURN file, nodes, relationships, properties;
Table 1. Results
file nodes relationships properties
""movies-producers.xls""
2
1
5
movies-producers.xls contains individual sheets for each node label and relationship type. In this case it contains the following sheets:
Movie
Person
PRODUCED
We can query the contents of those sheets using apoc.load.xls. Let’s have a look at a couple of the sheets:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies-producers.xls"", ""Person"");
Table 2. Results
lineNo list map
0
[7, 1952, ""Joel Silver""]
{name: ""Joel Silver"", <nodeId>: 7, born: 1952}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies-producers.xls"", ""PRODUCED"");
Table 3. Results
lineNo list map
0
[6, 7, 0]
{<startNodeId>: 7, <endNodeId>: 0, <relationshipId>: 6}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.trigger;"apoc.trigger
Qualified Name Type
apoc.trigger.nodesByLabel
Function
apoc.trigger.propertiesByKey
Function
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.trigger/apoc.trigger.nodesByLabel;"apoc.trigger.nodesByLabel
Contents
Signature
Input parameters
Usage Examples
Function Apoc Extended
Signature
None
Copy to Clipboard
apoc.trigger.nodesByLabel(labelEntries :: ANY?, label :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
labelEntries
ANY?
null
label
STRING?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
create constraint for (p:Person)
require p.id is unique;
This function is used inside an apoc.trigger.add Cypher statement.
We can use it to conditionally run Cypher statements when labels are added or removed or when properties are added or removed. For example, we add an id property to all Person nodes that is the lower case value of the name property of that node, by defining the following trigger:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add(
  'lowercase',
  'UNWIND apoc.trigger.nodesByLabel($assignedLabels,""Person"") AS n
   SET n.id = toLower(n.name)',
  {}
);
Let’s now create a Person node:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Person {name:'John Doe'});
And now let’s find all Person nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Person)
RETURN f.id, f.name;
Table 1. Results
f.id f.name
""john doe""
""John Doe""
But if we create an Animal node instead:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Animal {name: ""Cow""});
An id property will not be added to that node. We can see that it hasn’t been added, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
RETURN n;
Table 2. Results
n
(:Person {name: ""John Doe"", id: ""john doe""})
(:Animal {name: ""Cow""})
More documentation of apoc.trigger.nodesByLabel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.trigger/apoc.trigger.propertiesByKey;"apoc.trigger.propertiesByKey
Contents
Signature
Input parameters
Usage Examples
Function Apoc Extended
Signature
None
Copy to Clipboard
apoc.trigger.propertiesByKey(propertyEntries :: MAP?, key :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
propertyEntries
MAP?
null
key
STRING?
null
Usage Examples
This function is used inside an apoc.trigger.add.adoc Cypher statement.
We can use it to conditionally run Cypher statements when properties are added or removed. For example, we can connect nodes with a genre property to a Genre node, with the following trigger:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add(
  'triggerTest',
  'UNWIND apoc.trigger.propertiesByKey($assignedNodeProperties, ""genre"") as prop
   WITH prop.node as n
   MERGE (g:Genre {name: n.genre})
   MERGE (n)-[:HAS_GENRE]->(g)
   ',
  {}
);
Let’s now create a Movie node with a genre property:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Movie {title: ""The White Tiger"", genre: ""Crime""});
And now let’s find all HAS_GENRE relationships:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH path = ()-[:HAS_GENRE]->()
RETURN path;
Table 1. Results
path
(:Movie {genre: ""Crime"", title: ""The White Tiger""})-[:HAS_GENRE]→(:Genre {name: ""Crime""})
More documentation of apoc.trigger.propertiesByKey
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.config;"apoc.config
Qualified Name Type
apoc.config.list
apoc.config.list | Lists the Neo4j configuration as key,value table
Procedure
apoc.config.map
apoc.config.map | Lists the Neo4j configuration as map
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.config/apoc.config.list;"apoc.config.list
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.config.list | Lists the Neo4j configuration as key,value table
Signature
None
Copy to Clipboard
apoc.config.list() :: (key :: STRING?, value :: ANY?)
Output parameters
Name Type
key
STRING?
value
ANY?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.config.list()
YIELD key, value
WHERE key CONTAINS ""apoc""
RETURN key, value;
Table 1. Results
key value
""apoc_ttl_enabled""
""true""
""apoc.export.file.enabled""
""false""
""apoc.ttl.enabled""
""true""
""apoc.ttl.schedule""
""PT1M""
""apoc.ttl.limit""
""1000""
""apoc.import.file.enabled""
""false""
""apoc.import.file.use_neo4j_config""
""true""
""apoc.import.file.allow_read_from_filesystem""
""true""
""apoc.trigger.enabled""
""false""
""apoc.uuid.enabled""
""false""
More documentation of apoc.config.list
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-introspection/config;"Config
Qualified Name Type Release
apoc.config.list
apoc.config.list | Lists the Neo4j configuration as key,value table
Procedure
Apoc Extended
apoc.config.map
apoc.config.map | Lists the Neo4j configuration as map
Procedure
Apoc Extended
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.config/apoc.config.map;"apoc.config.map
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.config.map | Lists the Neo4j configuration as map
Signature
None
Copy to Clipboard
apoc.config.map() :: (value :: MAP?)
Output parameters
Name Type
value
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.config.map()
YIELD value
WITH [key in keys(value) WHERE not(key STARTS WITH ""apoc"")] AS keys, value
RETURN apoc.map.clean(value, keys, []) AS value;
Table 1. Results
value
{apoc.uuid.enabled: ""false"", apoc.import.file.allow_read_from_filesystem: ""true"", apoc.ttl.enabled: ""true"", apoc.trigger.enabled: ""false"", apoc.ttl.limit: ""1000"", apoc.import.file.enabled: ""false"", apoc.ttl.schedule: ""PT1M"", apoc.export.file.enabled: ""false"", apoc_ttl_enabled: ""true"", apoc.import.file.use_neo4j_config: ""true""}
More documentation of apoc.config.map
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom/apoc.custom.removeProcedure;"apoc.custom.removeProcedure
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.custom.removeProcedure(name) - remove the targeted custom procedure
Signature
None
Copy to Clipboard
apoc.custom.removeProcedure(name :: STRING?) :: VOID
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
name
STRING?
null
Usage Examples
We can remove a custom procedure named powers, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.removeProcedure(""powers"");
More documentation of apoc.custom.removeProcedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.static;"apoc.static
Qualified Name Type
apoc.static.list
apoc.static.list(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Procedure
apoc.static.set
apoc.static.set(name, value) - stores value under key for server lifetime storage, returns previously stored or configured value
Procedure
apoc.static.get
apoc.static.get(name) - returns statically stored value from config (apoc.static.<key>) or server lifetime storage
Function
apoc.static.getAll
apoc.static.getAll(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage
Function
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.systemdb/apoc.systemdb.graph;"apoc.systemdb.graph
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
Signature
None
Copy to Clipboard
apoc.systemdb.graph() :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.graph();
Figure 1. apoc.systemdb.graph Neo4j Browser Visualization
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.gephi/apoc.gephi.add;"apoc.gephi.add
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.gephi.add(url-or-key, workspace, data, weightproperty, ['exportproperty']) | streams passed in data to Gephi
Signature
None
Copy to Clipboard
apoc.gephi.add(urlOrKey :: STRING?, workspace :: STRING?, data :: ANY?, weightproperty = null :: STRING?, exportproperties = [] :: LIST? OF STRING?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
urlOrKey
STRING?
null
workspace
STRING?
null
data
ANY?
null
weightproperty
STRING?
null
exportproperties
LIST? OF STRING?
[]
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
More documentation of apoc.gephi.add
Was this page helpful?"
https://neo4j.com/labs/apoc/5/export/gephi;"Export to Gephi
Contents
Installing the plugin
Available Procedure
Export Format
Examples
Gephi has a streaming plugin, that can provide and accept JSON-graph-data in a streaming fashion. The export to Gephi procedure sends data to this end point.
Installing the plugin
Make sure to install the plugin first and activate it for your workspace (there is a new ""Streaming""-tab besides ""Layout""), right-click ""Master""→""start"" to start the server.
You can provide your workspace name (you might want to rename it before you start thes streaming), otherwise it defaults to workspace0
The default Gephi-URL is http://localhost:8080, resulting in http://localhost:8080/workspace0?operation=updateGraph
It can also be configured by adding the following to apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.gephi.url=url
or
Properties
apoc.conf
Copy to Clipboard
apoc.gephi.<key>.url=url
Available Procedure
The table below describes the available procedure:
Qualified Name Type Release
apoc.gephi.add
apoc.gephi.add(url-or-key, workspace, data, weightproperty, ['exportproperty']) | streams passed in data to Gephi
Procedure
Apoc Extended
Export Format
All nodes and relationships of the passed in data are converted into individual Gephi-Streaming JSON fragements, separated by \r\n. \r\n.
JavaScript
Example of exported JSON
Copy to Clipboard
{""an"":{""123"":{""TYPE"":""Person:Actor"",""label"":""Tom Hanks"",                           x:333,y:222,r:0.1,g:0.3,b:0.5}}}\r\n
{""an"":{""345"":{""TYPE"":""Movie"",""label"":""Forrest Gump"",                               x:234,y:122,r:0.2,g:0.2,b:0.7}}}\r\n
{""ae"":{""3344"":{""TYPE"":""ACTED_IN"",""label"":""Tom Hanks"",source:""123"",target:""345"",""directed"":true,""weight"":1.0,r:0.1,g:0.3,b:0.5}}}
Gephi doesn’t render the graph data unless you also provide x,y coordinates in the payload, so the procedures send random ones within a 1000x1000 grid.
Colors are generated per label combination and relationship-type, both of which are also transferred as TYPE property.
Weight properties are stored as a number (integer,float) or a string. If the weight property is invalid or null, a default value of 1.0 will be used.
Examples
You can export your graph as an unweighted network.
Cypher
The following exports ACTED_IN paths
Copy to Clipboard
Run in Neo4j Browser
match path = (:Person)-[:ACTED_IN]->(:Movie)
WITH path LIMIT 1000
with collect(path) as paths
call apoc.gephi.add(null,'workspace0', paths) yield nodes, relationships, time
return nodes, relationships, time
You can export your graph as a weighted network, by specifying the property of a relationship, that holds the weight value.
Cypher
The following exports ACTED_IN paths where the weightproperty property exists on the relationship type
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[r:ACTED_IN]->(:Movie)
WHERE r.weightproperty IS NOT NULL
WITH path LIMIT 1000
with collect(path) as paths
call apoc.gephi.add(null,'workspace0', paths, 'weightproperty') yield nodes, relationships, time
return nodes, relationships, time
You can also export with your graph other properties of your nodes and/or relationship by adding an optional array with the property names you want to export.
Cypher
The following exports ACTED_IN paths, but only includes the birthYear and role properties
Copy to Clipboard
Run in Neo4j Browser
MATCH path = (:Person)-[r:ACTED_IN]->(:Movie)
WHERE r.weightproperty IS NOT NULL
WITH path LIMIT 1000
with collect(path) as paths
call apoc.gephi.add(null,'workspace0', paths, 'weightproperty',['birthYear', 'role']) yield nodes, relationships, time
return nodes, relationships, time
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.model/apoc.model.jdbc;"apoc.model.jdbc
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.model.jdbc('key or url', {schema:'<schema>', write: <true/false>, filters: { tables:[], views: [], columns: []}) YIELD nodes, relationships - load schema from relational database
Signature
None
Copy to Clipboard
apoc.model.jdbc(jdbc :: STRING?, config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)
Input parameters
Name Type Default
jdbc
STRING?
null
config
MAP?
{}
Output parameters
Name Type
nodes
LIST? OF NODE?
relationships
LIST? OF RELATIONSHIP?
More documentation of apoc.model.jdbc
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/database-modeling;"Database Modeling
Contents
apoc.model.jdbc
Configuration
Filters
Example
This new package provides a set of function in order to extract metadata information from different data sources such as RDBMS, JSON file etc
Qualified Name Type Release
apoc.model.jdbc
apoc.model.jdbc('key or url', {schema:'<schema>', write: <true/false>, filters: { tables:[], views: [], columns: []}) YIELD nodes, relationships - load schema from relational database
Procedure
Apoc Extended
apoc.model.jdbc
The procedure allows to extract metadata information by any JDBC compatible db.
Configuration
Config Type Description
schema
String. Default empty
The schema name.
write
boolean. Default false
If you want persist the data on Neo4j
filters
map<String, Array<String>>. Default empty
A set of filters for each object type tables, views, columns
Filters
Config Type Description
tables
Array<String>
A set of regex patterns that, if matched, exclude the tables
views
Array<String>
A set of regex patterns that, if matched, exclude the views
columns
Array<String>
A set of regex patterns that, if matched, exclude the columns
Example
Starting from the following schema:
Sql
Copy to Clipboard
 CREATE TABLE ""country"" (
   ""Code"" CHAR(3) NOT NULL DEFAULT '',
   ""Name"" CHAR(52) NOT NULL DEFAULT '',
   ""Continent"" enum('Asia','Europe','North America','Africa','Oceania','Antarctica','South America') NOT NULL DEFAULT 'Asia',
   ""Region"" CHAR(26) NOT NULL DEFAULT '',
   ""SurfaceArea"" FLOAT(10,2) NOT NULL DEFAULT '0.00',
   ""IndepYear"" SMALLINT(6) DEFAULT NULL,
   ""Population"" INT(11) NOT NULL DEFAULT '0',
   ""LifeExpectancy"" FLOAT(3,1) DEFAULT NULL,
   ""GNP"" FLOAT(10,2) DEFAULT NULL,
   ""GNPOld"" FLOAT(10,2) DEFAULT NULL,
   ""LocalName"" CHAR(45) NOT NULL DEFAULT '',
   ""GovernmentForm"" CHAR(45) NOT NULL DEFAULT '',
   ""HeadOfState"" CHAR(60) DEFAULT NULL,
   ""Capital"" INT(11) DEFAULT NULL,
    ()    ,
   PRIMARY  ()
 ) =  =latin1;

    (
    ()   AUTO_INCREMENT,
    ()    ,
    ()    ,
    ()    ,
    ()    ,
   PRIMARY  (),
     (),
       ()   ()
 ) = AUTO_INCREMENT=  =latin1;

    (
    ()    ,
    ()    ,
    enum(,)    ,
    (,)    ,
   PRIMARY  (,),
     (),
       ()   (""Code"")
 ) =  =latin1;
View all (24 more lines)
By doing this procedure call:
call apoc.model.jdbc('jdbc:mysql://mysql:3306', {schema: 'test', credentials: {user: 'root', password: 'andrea'}})
You’ll get the following result:
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.uuid/apoc.uuid.removeAll;"apoc.uuid.removeAll
Contents
Signature
Output parameters
Enable automatic UUIDs
Usage Examples
Procedure Apoc Extended
CALL apoc.uuid.removeAll() yield label, installed, properties | it removes all previously added uuid handlers and returns uuids information. All the existing uuid properties are left as-is
Signature
None
Copy to Clipboard
apoc.uuid.removeAll() :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Output parameters
Name Type
label
STRING?
installed
BOOLEAN?
properties
MAP?
Enable automatic UUIDs
This procedure is part of a set of procedures that handle automatic adding of UUID properties, via the UUID Handler Lifecycle. The UUID handler is a transaction event handler that automatically adds the UUID property to a provided label and for the provided property name.
By default automatic adding of UUIDs is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.uuid.enabled=true
Usage Examples
We can remove all UUID handler (installed by apoc.uuid.install), by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.removeAll();
Table 1. Results
label installed properties
""Person""
FALSE
{uuidProperty: ""myUUID""}
If we try to remove UUID handlers when non are installed, the output will indicate that no handlers were removed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.removeAll();
Table 2. Results
label installed properties
More documentation of apoc.uuid.removeAll
Was this page helpful?"
https://neo4j.com/labs/apoc/5/graph-updates/uuid;"UUIDs
Contents
Automatic UUIDs
Config
UUID Examples
Export metadata
The library supports manual and automation generation of UUIDs, which can be stored as properties on nodes.
UUIDs are generated using the java randomUUID utility method, which generates a v4UUID.
UUID may be encoded into String with well-known hexadecimal presentation (32 characters, e.g. 1051af4f-b81d-4a76-8605-ecfb8ef703d5) or Base64 (22 characters, e.g. vX8dM5XoSe2ldoc/QzMEyw)
Automatic UUIDs
There are also procedures that handle automatic adding of UUID properties, via the UUID Handler Lifecycle. The UUID handler is a transaction event handler that automatically adds the UUID property to a provided label and for the provided property name. Please check the following documentation to an in-depth description.
Enable apoc.uuid.enabled=true or apoc.uuid.enabled.[DATABASE_NAME]=true in $NEO4J_HOME/config/apoc.conf first.
Configuration value apoc.uuid.format let you choose between different UUID encoding methods: hex (default option) or base64.
Qualified Name Type Release
apoc.uuid.install
CALL apoc.uuid.install(label, {addToExistingNodes: true/false, uuidProperty: 'uuid'}) yield label, installed, properties, batchComputationResult | it will add the uuid transaction handler for the provided `label and uuidProperty, in case the UUID handler is already present it will be replaced by the new one`
Procedure
Apoc Extended
apoc.uuid.remove
CALL apoc.uuid.remove(label) yield label, installed, properties | remove previously added uuid handler and returns uuid information. All the existing uuid properties are left as-is
Procedure
Apoc Extended
apoc.uuid.removeAll
CALL apoc.uuid.removeAll() yield label, installed, properties | it removes all previously added uuid handlers and returns uuids information. All the existing uuid properties are left as-is
Procedure
Apoc Extended
apoc.uuid.list
CALL apoc.uuid.list() yield label, installed, properties | provides a list of all the uuid handlers installed with the related configuration
Procedure
Apoc Extended
Config
config
type
description
addToExistingNodes
Boolean (default: true)
when installed, for the label provided, adds the UUID to the nodes already existing in your graph
uuidProperty
String (default: uuid)
the name of the UUID field
UUID Examples
First create a Constraint for the Label and the Property, if you try to add a uuid an error occured.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT FOR (person:Person)
REQUIRE person.uuid IS UNIQUE
Add the uuid:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.install('Person')
YIELD label, installed, properties
RETURN label, installed, properties
The result is:
label installed properties batchComputationResult
""Person""
true
{uuidProperty → ""uuid"", addToExistingNodes → true}
{wasTerminated → false, count → 10, batches → 1, successes → 1, failedOps → 0, timeTaken → 0, operationErrors → {}, failedBatches → 0}
The result is Node Person that has 2 properties:
Get all the uuid installed, call the procedure as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.list()
YIELD label, installed, properties
RETURN label, installed, properties
The result is:
label installed properties
""Person""
true
{uuidProperty → ""uuid"", addToExistingNodes → true}
Remove the uuid installed call the procedure as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.remove('Person')
YIELD label, installed, properties
RETURN label, installed, properties
The result is:
label installed properties
""Person""
false
{uuidProperty → ""uuid"", addToExistingNodes → true}
You can also remove all the uuid installed call the procedure as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.removeAll()
YIELD label, installed, properties
RETURN label, installed, properties
The result is:
label installed properties
""Person""
false
{uuidProperty → ""uuid"", addToExistingNodes → true}
Export metadata
To import uuids in another database (for example after a ./neo4j-admin backup and /neo4j-admin restore), please see the apoc.systemdb.export.metadata procedure.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.uuid/apoc.uuid.remove;"apoc.uuid.remove
Contents
Signature
Input parameters
Output parameters
Enable automatic UUIDs
Usage Examples
Procedure Apoc Extended
CALL apoc.uuid.remove(label) yield label, installed, properties | remove previously added uuid handler and returns uuid information. All the existing uuid properties are left as-is
Signature
None
Copy to Clipboard
apoc.uuid.remove(label :: STRING?) :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
label
STRING?
null
Output parameters
Name Type
label
STRING?
installed
BOOLEAN?
properties
MAP?
Enable automatic UUIDs
This procedure is part of a set of procedures that handle automatic adding of UUID properties, via the UUID Handler Lifecycle. The UUID handler is a transaction event handler that automatically adds the UUID property to a provided label and for the provided property name.
By default automatic adding of UUIDs is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.uuid.enabled=true
Usage Examples
We can remove a UUID handler (installed by apoc.uuid.install), by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.remove(""Person"");
Table 1. Results
label installed properties
""Person""
FALSE
{uuidProperty: ""myUUID""}
If we try to remove a non existent UUID handler, the output will indicate that no such handler is installed:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.remove(""Foo"");
Table 2. Results
label installed properties
NULL
FALSE
{}
More documentation of apoc.uuid.remove
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.uuid/apoc.uuid.install;"apoc.uuid.install
Contents
Signature
Input parameters
Config parameters
Output parameters
Enable automatic UUIDs
Usage Examples
Procedure Apoc Extended
CALL apoc.uuid.install(label, {addToExistingNodes: true/false, uuidProperty: 'uuid'}) yield label, installed, properties, batchComputationResult | it will add the uuid transaction handler for the provided label and uuidProperty, in case the UUID handler is already present it will be replaced by the new one
Signature
None
Copy to Clipboard
apoc.uuid.install(label :: STRING?, config = {} :: MAP?) :: (batchComputationResult :: MAP?, label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
label
STRING?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
addToExistingNodes
Boolean
true
adds UUID values to existing nodes. Will override an existing value.
addToSetLabels
Boolean
false
adds UUID values even when there is a set label. For example: MATCH (p:OtherLabel) SET p:LabelWithUuid.
uuidProperty
String
""uuid""
the property key for the UUID value
Output parameters
Name Type
batchComputationResult
MAP?
label
STRING?
installed
BOOLEAN?
properties
MAP?
Enable automatic UUIDs
This procedure is part of a set of procedures that handle automatic adding of UUID properties, via the UUID Handler Lifecycle. The UUID handler is a transaction event handler that automatically adds the UUID property to a provided label and for the provided property name.
By default automatic adding of UUIDs is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.uuid.enabled=true
Usage Examples
We need to create a unique constraint for the label and property on which we want to add UUIDs.
If we try to setup UUID creation on nodes with the Person label without adding a constraint, we’ll get an exception as shown below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.install(""Person"");
Table 2. Results
Failed to invoke procedure apoc.uuid.install: Caused by: java.lang.RuntimeException: No constraint found for label: Person, please add the constraint with the following : CREATE CONSTRAINT FOR (person:Person) REQUIRE person.uuid IS UNIQUE
We can create a constraint on the (Person, uuid) label/property pair by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT FOR (person:Person)
REQUIRE person.uuid IS UNIQUE;
And now we can automatically add UUIDs to all new nodes, as well as existing nodes, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.install(""Person"");
By default, UUID values will be added to existing nodes and will override existing values. We can pass the config addToExistingNodes: false to only have UUIDs added to new nodes.
Table 3. Results
batchComputationResult
label
installed
properties
{failedParams: {}, committedOperations: 3, batch: {total: 1, committed: 1, failed: 0, errors: {}}, wasTerminated: FALSE, batches: 1, timeTaken: 0, retries: 0, errorMessages: {}, total: 3, operations: {total: 3, committed: 3, failed: 0, errors: {}}, failedOperations: 0, failedBatches: 0}
""Person""
TRUE
{uuidProperty: ""uuid""}
Now let’s create a new Person node;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {name: ""Tom Hanks""});
And if we look for all Person nodes, we’ll see it has a uuid property:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
RETURN p;
Table 4. Results
p
(:Person {name: ""Tom Hanks"", uuid: ""cec34337-9709-46af-bbb7-9e0742d8aaa7""})
The uuid property will be created also with a label SET when the addToSetLabels configuration is set to true. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:AnotherLabel {name: ""Tom Hanks""});
// ...
MATCH (n:AnotherLabel) SET n:Person;
If we want to use a different property key for our UUID value, we can pass in the uuidProperty key, not forgetting to first setup a constraint:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT FOR (person:Person)
REQUIRE person.myUUID IS UNIQUE;
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.install(""Person"", {uuidProperty: ""myUUID""});
Table 5. Results
batchComputationResult
label
installed
properties
{failedParams: {}, committedOperations: 1, batch: {total: 1, committed: 1, failed: 0, errors: {}}, wasTerminated: FALSE, batches: 1, timeTaken: 0, retries: 0, errorMessages: {}, total: 1, operations: {total: 1, committed: 1, failed: 0, errors: {}}, failedOperations: 0, failedBatches: 0}
""Person""
TRUE
{uuidProperty: ""myUUID""}
And now let’s find those Person nodes again:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
RETURN p;
Table 6. Results
p
(:Person {name: ""Tom Hanks"", uuid: ""cec34337-9709-46af-bbb7-9e0742d8aaa7"", myUUID: ""d09f177b-ff91-4eb9-aac0-73e7a850c9ba""})
More documentation of apoc.uuid.install
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.uuid/apoc.uuid.list;"apoc.uuid.list
Contents
Signature
Output parameters
Enable automatic UUIDs
Usage Examples
Procedure Apoc Extended
CALL apoc.uuid.list() yield label, installed, properties | provides a list of all the uuid handlers installed with the related configuration
Signature
None
Copy to Clipboard
apoc.uuid.list() :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)
Output parameters
Name Type
label
STRING?
installed
BOOLEAN?
properties
MAP?
Enable automatic UUIDs
This procedure is part of a set of procedures that handle automatic adding of UUID properties, via the UUID Handler Lifecycle. The UUID handler is a transaction event handler that automatically adds the UUID property to a provided label and for the provided property name.
By default automatic adding of UUIDs is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.uuid.enabled=true
Usage Examples
We can list all the UUID handlers (installed by apoc.uuid.install), by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.uuid.list();
Table 1. Results
label installed properties
""Person""
TRUE
{uuidProperty: ""myUUID""}
More documentation of apoc.uuid.list
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo;"apoc.mongo
Qualified Name Type
apoc.mongo.aggregate
apoc.mongo.aggregate(uri, pipeline, $config) yield value - perform an aggregate operation on mongodb collection
Procedure
apoc.mongo.count
apoc.mongo.count(uri, query, $config) yield value - perform a count operation on mongodb collection
Procedure
apoc.mongo.delete
apoc.mongo.delete(uri, query, $config) - delete the given documents from the mongodb collection and returns the number of affected documents
Procedure
apoc.mongo.find
apoc.mongo.find(uri, query, $config) yield value - perform a find operation on mongodb collection
Procedure
apoc.mongo.insert
apoc.mongo.insert(uri, documents, $config) yield value - inserts the given documents into the mongodb collection
Procedure
apoc.mongo.update
apoc.mongo.update(uri, query, update, $config) - updates the given documents from the mongodb collection and returns the number of affected documents
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.find;"apoc.mongo.find
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.mongo.find(uri, query, $config) yield value - perform a find operation on mongodb collection
Signature
None
Copy to Clipboard
apoc.mongo.find(uri :: STRING?, query = null :: ANY?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
uri
STRING?
null
query
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
MAP?
More documentation of apoc.mongo.find
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.delete;"apoc.mongo.delete
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.mongo.delete(uri, query, $config) - delete the given documents from the mongodb collection and returns the number of affected documents
Signature
None
Copy to Clipboard
apoc.mongo.delete(uri :: STRING?, query :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
query
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.mongo.delete
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.update;"apoc.mongo.update
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.mongo.update(uri, query, update, $config) - updates the given documents from the mongodb collection and returns the number of affected documents
Signature
None
Copy to Clipboard
apoc.mongo.update(uri :: STRING?, query :: ANY?, update :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
query
ANY?
null
update
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.mongo.update
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.count;"apoc.mongo.count
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.mongo.count(uri, query, $config) yield value - perform a count operation on mongodb collection
Signature
None
Copy to Clipboard
apoc.mongo.count(uri :: STRING?, query :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)
Input parameters
Name Type Default
uri
STRING?
null
query
ANY?
null
config
MAP?
{}
Output parameters
Name Type
value
INTEGER?
More documentation of apoc.mongo.count
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongo/apoc.mongo.aggregate;"apoc.mongo.aggregate
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.mongo.aggregate(uri, pipeline, $config) yield value - perform an aggregate operation on mongodb collection
Signature
None
Copy to Clipboard
apoc.mongo.aggregate(uri :: STRING?, pipeline :: LIST? OF MAP?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
uri
STRING?
null
pipeline
LIST? OF MAP?
null
config
MAP?
{}
Output parameters
Name Type
value
MAP?
More documentation of apoc.mongo.aggregate
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv;"apoc.dv
Qualified Name Type
apoc.dv.catalog.add
Add a virtualized resource configuration
Procedure
apoc.dv.catalog.list
List all virtualized resource configuration
Procedure
apoc.dv.catalog.remove
Remove a virtualized resource config by name
Procedure
apoc.dv.query
Query a virtualized resource by name and return virtual nodes
Procedure
apoc.dv.queryAndLink
Query a virtualized resource by name and return virtual nodes linked using virtual rels to the node passed as first param
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv/apoc.dv.query;"apoc.dv.query
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
Query a virtualized resource by name and return virtual nodes
Signature
None
Copy to Clipboard
apoc.dv.query(name :: STRING?, params = {} :: ANY?, config = {} :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
name
STRING?
null
params
ANY?
{}
config
MAP?
{}
Output parameters
Name Type
node
NODE?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv/apoc.dv.catalog.add;"apoc.dv.catalog.add
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
Add a virtualized resource configuration
Signature
None
Copy to Clipboard
apoc.dv.catalog.add(name :: STRING?, config = {} :: MAP?) :: (name :: STRING?, type :: STRING?, url :: STRING?, desc :: STRING?, labels :: LIST? OF STRING?, query :: STRING?, params :: LIST? OF STRING?)
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
name
STRING?
null
config
MAP?
{}
Output parameters
Name Type
name
STRING?
type
STRING?
url
STRING?
desc
STRING?
labels
LIST? OF STRING?
query
STRING?
params
LIST? OF STRING?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv/apoc.dv.catalog.remove;"apoc.dv.catalog.remove
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
Remove a virtualized resource config by name
Signature
None
Copy to Clipboard
apoc.dv.catalog.remove(name :: STRING?) :: (name :: STRING?, type :: STRING?, url :: STRING?, desc :: STRING?, labels :: LIST? OF STRING?, query :: STRING?, params :: LIST? OF STRING?)
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
type
STRING?
url
STRING?
desc
STRING?
labels
LIST? OF STRING?
query
STRING?
params
LIST? OF STRING?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv/apoc.dv.queryAndLink;"apoc.dv.queryAndLink
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
Query a virtualized resource by name and return virtual nodes linked using virtual rels to the node passed as first param
Signature
None
Copy to Clipboard
apoc.dv.queryAndLink(node :: NODE?, relName :: STRING?, name :: STRING?, params = {} :: ANY?, config = {} :: MAP?) :: (path :: PATH?)
Input parameters
Name Type Default
node
NODE?
null
relName
STRING?
null
name
STRING?
null
params
ANY?
{}
config
MAP?
{}
Output parameters
Name Type
path
PATH?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.dv/apoc.dv.catalog.list;"apoc.dv.catalog.list
Contents
Signature
Output parameters
Procedure Apoc Extended
List all virtualized resource configuration
Signature
None
Copy to Clipboard
apoc.dv.catalog.list() :: (name :: STRING?, type :: STRING?, url :: STRING?, desc :: STRING?, labels :: LIST? OF STRING?, query :: STRING?, params :: LIST? OF STRING?)
Output parameters
Name Type
name
STRING?
type
STRING?
url
STRING?
desc
STRING?
labels
LIST? OF STRING?
query
STRING?
params
LIST? OF STRING?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.monitor/apoc.monitor.tx;"apoc.monitor.tx
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.monitor.tx() returns informations about the neo4j transaction manager
Signature
None
Copy to Clipboard
apoc.monitor.tx() :: (rolledBackTx :: INTEGER?, peakTx :: INTEGER?, lastTxId :: INTEGER?, currentOpenedTx :: INTEGER?, totalOpenedTx :: INTEGER?, totalTx :: INTEGER?)
Output parameters
Name Type
rolledBackTx
INTEGER?
peakTx
INTEGER?
lastTxId
INTEGER?
currentOpenedTx
INTEGER?
totalOpenedTx
INTEGER?
totalTx
INTEGER?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.tx();
Table 1. Results
rolledBackTx peakTx lastTxId currentOpenedTx totalOpenedTx totalTx
21
1
710
1
49
27
More documentation of apoc.monitor.tx
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-introspection/monitoring;"Monitoring
Qualified Name Type Release
apoc.monitor.ids
apoc.monitor.ids() returns the object ids in use for this neo4j instance
Procedure
Apoc Extended
apoc.monitor.kernel
apoc.monitor.kernel() returns informations about the neo4j kernel
Procedure
Apoc Extended
apoc.monitor.store
apoc.monitor.store() returns informations about the sizes of the different parts of the neo4j graph store
Procedure
Apoc Extended
apoc.monitor.tx
apoc.monitor.tx() returns informations about the neo4j transaction manager
Procedure
Apoc Extended
Cypher
The following returns ID usage:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.ids();
Table 1. Results
nodeIds relIds propIds relTypeIds
400
3560
4000
7
Cypher
The following returns store information:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.kernel();
Table 2. Results
readOnly kernelVersion storeId kernelStartTime databaseName storeLogVersion storeCreationDate
FALSE
""neo4j-kernel, version: 3.5.6,73866e84158298d5f4a7325b6466c0189ad21d11""
""7f450cfe1e4fefb5""
""2019-06-24 12:01:01""
""graph.db""
0
""2019-06-24 11:59:28""
Cypher
The following returns store size information:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.store();
Table 3. Results
logSize stringStoreSize arrayStoreSize relStoreSize propStoreSize totalStoreSize nodeStoreSize
691264
8192
8192
122400
171339
1207741
8190
Cypher
The following returns transaction information:
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.tx();
Table 4. Results
rolledBackTx peakTx lastTxId currentOpenedTx totalOpenedTx totalTx
2213
6
16
1
9170
6956
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.monitor/apoc.monitor.kernel;"apoc.monitor.kernel
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.monitor.kernel() returns informations about the neo4j kernel
Signature
None
Copy to Clipboard
apoc.monitor.kernel() :: (readOnly :: BOOLEAN?, kernelVersion :: STRING?, storeId :: STRING?, kernelStartTime :: STRING?, databaseName :: STRING?, storeLogVersion :: INTEGER?, storeCreationDate :: STRING?)
Output parameters
Name Type
readOnly
BOOLEAN?
kernelVersion
STRING?
storeId
STRING?
kernelStartTime
STRING?
databaseName
STRING?
storeLogVersion
INTEGER?
storeCreationDate
STRING?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.kernel();
Table 1. Results
readOnly kernelVersion storeId kernelStartTime databaseName storeLogVersion storeCreationDate
FALSE
""4.1.3""
""StoreId{creationTime=1605519819278, randomId=4311716801557479419, storeVersion=3471765337752883975, upgradeTime=1605519819278, upgradeTxId=1}""
""2020-11-18 14:25:46""
""apoc""
3471765337752883975
""2020-11-16 09:43:39""
More documentation of apoc.monitor.kernel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.monitor/apoc.monitor.store;"apoc.monitor.store
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.monitor.store() returns informations about the sizes of the different parts of the neo4j graph store
Signature
None
Copy to Clipboard
apoc.monitor.store() :: (logSize :: INTEGER?, stringStoreSize :: INTEGER?, arrayStoreSize :: INTEGER?, relStoreSize :: INTEGER?, propStoreSize :: INTEGER?, totalStoreSize :: INTEGER?, nodeStoreSize :: INTEGER?)
Output parameters
Name Type
logSize
INTEGER?
stringStoreSize
INTEGER?
arrayStoreSize
INTEGER?
relStoreSize
INTEGER?
propStoreSize
INTEGER?
totalStoreSize
INTEGER?
nodeStoreSize
INTEGER?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.store();
Table 1. Results
logSize stringStoreSize arrayStoreSize relStoreSize propStoreSize totalStoreSize nodeStoreSize
262144000
8192
8192
16964640
416109
19256826
155610
More documentation of apoc.monitor.store
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.monitor/apoc.monitor.ids;"apoc.monitor.ids
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.monitor.ids() returns the object ids in use for this neo4j instance
Signature
None
Copy to Clipboard
apoc.monitor.ids() :: (nodeIds :: INTEGER?, relIds :: INTEGER?, propIds :: INTEGER?, relTypeIds :: INTEGER?)
Output parameters
Name Type
nodeIds
INTEGER?
relIds
INTEGER?
propIds
INTEGER?
relTypeIds
INTEGER?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.monitor.ids();
Table 1. Results
nodeIds relIds propIds relTypeIds
10040
498773
10040
15
More documentation of apoc.monitor.ids
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.metrics/apoc.metrics.get;"apoc.metrics.get
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.metrics.get(metricName, {}) - retrieve a system metric by its metric name. Additional configuration options may be passed matching the options available for apoc.load.csv.
Signature
None
Copy to Clipboard
apoc.metrics.get(metricName :: STRING?, config = {} :: MAP?) :: (timestamp :: INTEGER?, metric :: STRING?, map :: MAP?)
Input parameters
Name Type Default
metricName
STRING?
null
config
MAP?
{}
Output parameters
Name Type
timestamp
INTEGER?
metric
STRING?
map
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.metrics.get(""neo4j.neo4j.transaction.started"")
YIELD metric, map, timestamp
RETURN metric, map, datetime({epochSeconds: timestamp}) AS timestamp
LIMIT 5;
Table 1. Results
metric map timestamp
""neo4j.neo4j.transaction.started""
{mean_rate: 0.0, t: ""1605189172"", count: ""0"", rate_unit: ""events/second"", m15_rate: 0.0, m1_rate: 0.0, m5_rate: 0.0}
2020-11-12T13:52:52Z
""neo4j.neo4j.transaction.started""
{mean_rate: 0.943493, t: ""1605189175"", count: ""6"", rate_unit: ""events/second"", m15_rate: 0.0, m1_rate: 0.0, m5_rate: 0.0}
2020-11-12T13:52:55Z
""neo4j.neo4j.transaction.started""
{mean_rate: 0.64233, t: ""1605189178"", count: ""6"", rate_unit: ""events/second"", m15_rate: 0.0, m1_rate: 0.0, m5_rate: 0.0}
2020-11-12T13:52:58Z
""neo4j.neo4j.transaction.started""
{mean_rate: 0.485832, t: ""1605189181"", count: ""6"", rate_unit: ""events/second"", m15_rate: 0.0, m1_rate: 0.0, m5_rate: 0.0}
2020-11-12T13:53:01Z
""neo4j.neo4j.transaction.started""
{mean_rate: 0.456092, t: ""1605189184"", count: ""7"", rate_unit: ""events/second"", m15_rate: 0.0, m1_rate: 0.0, m5_rate: 0.0}
2020-11-12T13:53:04Z
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.cypher;"apoc.cypher
Qualified Name Type
apoc.cypher.mapParallel
apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
apoc.cypher.mapParallel2
apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _
Procedure
apoc.cypher.parallel
apoc.cypher.parallel(fragment, paramMap, keyList) yield value - executes fragments in parallel through a list defined in paramMap with a key keyList
Procedure
apoc.cypher.parallel2
apoc.cypher.parallel2(fragment, paramMap, keyList) yield value - executes fragments in parallel batches through a list defined in paramMap with a key keyList
Procedure
apoc.cypher.runFile
apoc.cypher.runFile(file or url,[{statistics:true,timeout:10,parameters:{}}]) - runs each statement in the file, all semicolon separated - currently no schema operations
Procedure
apoc.cypher.runFiles
apoc.cypher.runFiles([files or urls],[{statistics:true,timeout:10,parameters:{}}])) - runs each statement in the files, all semicolon separated
Procedure
apoc.cypher.runSchemaFile
apoc.cypher.runSchemaFile(file or url,[{statistics:true,timeout:10}]) - allows only schema operations, runs each schema statement in the file, all semicolon separated
Procedure
apoc.cypher.runSchemaFiles
apoc.cypher.runSchemaFiles([files or urls],{statistics:true,timeout:10}) - allows only schema operations, runs each schema statement in the files, all semicolon separated
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.systemdb;"apoc.systemdb
Qualified Name Type
apoc.systemdb.execute
Procedure
apoc.systemdb.export.metadata
Procedure
apoc.systemdb.graph
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.systemdb/apoc.systemdb.execute;"apoc.systemdb.execute
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure Apoc Extended
Signature
None
Copy to Clipboard
apoc.systemdb.execute(DDL commands, either a string or a list of strings :: ANY?, params = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
DDL commands, either a string or a list of strings
ANY?
null
params
MAP?
{}
Output parameters
Name Type
row
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.execute(""SHOW DATABASES"");
Table 1. Results
row
{default: TRUE, address: ""localhost:7687"", role: ""standalone"", currentStatus: ""online"", name: ""neo4j"", error: """", requestedStatus: ""online""}
{default: FALSE, address: ""localhost:7687"", role: ""standalone"", currentStatus: ""online"", name: ""system"", error: """", requestedStatus: ""online""}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.export/apoc.export.xls.data;"apoc.export.xls.data
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Usage Examples
Procedure Apoc Extended
apoc.export.xls.data(nodes,rels,file,config) - exports given nodes and relationships as xls to the provided file
Signature
None
Copy to Clipboard
apoc.export.xls.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Install Dependencies
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.xls.data procedure exports the specified nodes and relationships to a XLS file.
The following query exports all nodes with the :Person label with a name property that starts with L to the file movies-l.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.name STARTS WITH ""L""
WITH collect(person) AS people
CALL apoc.export.xls.data(people, [], ""movies-l.xls"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-l.xls""
""data: nodes(3), rels(0)""
""xls""
3
0
6
10
3
20000
1
TRUE
NULL
movies-l.xls contains individual sheets for each node label and relationship type. In this case it contains a Person sheet.
We can query the contents of those sheets using apoc.load.xls. Let’s have a look at the Person sheet:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies-l.xls"", ""Person"");
Table 2. Results
lineNo list map
0
[3, 1961, ""Laurence Fishburne""]
{name: ""Laurence Fishburne"", <nodeId>: 3, born: 1961}
1
[5, 1967, ""Lilly Wachowski""]
{name: ""Lilly Wachowski"", <nodeId>: 5, born: 1967}
2
[6, 1965, ""Lana Wachowski""]
{name: ""Lana Wachowski"", <nodeId>: 6, born: 1965}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom/apoc.custom.declareFunction;"apoc.custom.declareFunction
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.custom.declareFunction(signature, statement, forceSingle, description) - register a custom cypher function
Signature
None
Copy to Clipboard
apoc.custom.declareFunction(signature :: STRING?, statement :: STRING?, forceSingle = false :: BOOLEAN?, description =  :: STRING?) :: VOID
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
signature
STRING?
null
statement
STRING?
null
forceSingle
BOOLEAN?
false
description
STRING?
Usage Examples
We can create the function custom.double, that doubles the provided value, by running the following function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareFunction(
  'double(input::INT) :: INT',
  'RETURN $input*2 as answer'
);
Function, input and output names must have at least 2 characters.
We can use this function, as shown in the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN custom.double(83) AS value;
Table 1. Results
value
166
More documentation of apoc.custom.declareFunction
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.data/apoc.data.email;"apoc.data.email
Contents
Signature
Input parameters
Install Dependencies
Usage Examples
Function Apoc Extended
apoc.data.email('email_address') as {personal,user,domain} - extract the personal name, user and domain as a map
Signature
None
Copy to Clipboard
apoc.data.email(email_address :: STRING?) :: (MAP?)
Input parameters
Name Type Default
email_address
STRING?
null
Install Dependencies
This procedure has a dependency on an email library that is not included in the APOC Extended library.
The dependency is included in apoc-email-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.data.email(""michael@neo4j.com"") AS output;
Table 1. Results
output
{personal: NULL, user: ""michael"", domain: ""neo4j.com""
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase;"apoc.couchbase
Qualified Name Type
apoc.couchbase.append
apoc.couchbase.append(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - append a couchbase json document to an existing one.
Procedure
apoc.couchbase.exists
apoc.couchbase.exists(hostOrKey, bucket, documentId, config) yield value - check whether a couchbase json document with the given ID does exist.
Procedure
apoc.couchbase.get
apoc.couchbase.get(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - retrieves a couchbase json document by its unique ID.
Procedure
apoc.couchbase.insert
apoc.couchbase.insert(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - insert a couchbase json document with its unique ID.
Procedure
apoc.couchbase.namedParamsQuery
apoc.couchbase.namedParamsQuery(hostkOrKey, bucket, statement, paramNames, paramValues, config) yield queryResult - executes a N1QL statement with named parameters.
Procedure
apoc.couchbase.posParamsQuery
apoc.couchbase.posParamsQuery(hostOrKey, bucket, statement, params, config) yield queryResult - executes a N1QL statement with positional parameters.
Procedure
apoc.couchbase.prepend
apoc.couchbase.prepend(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - prepend a couchbase json document to an existing one.
Procedure
apoc.couchbase.query
apoc.couchbase.query(hostOrKey, bucket, statement, config) yield queryResult - executes a plain un-parameterized N1QL statement.
Procedure
apoc.couchbase.remove
apoc.couchbase.remove(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - remove the couchbase json document identified by its unique ID.
Procedure
apoc.couchbase.replace
apoc.couchbase.replace(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - replace the content of the couchbase json document identified by its unique ID.
Procedure
apoc.couchbase.upsert
apoc.couchbase.upsert(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - insert or overwrite a couchbase json document with its unique ID.
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.insert;"apoc.couchbase.insert
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.insert(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - insert a couchbase json document with its unique ID.
Signature
None
Copy to Clipboard
apoc.couchbase.insert(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
documentId
STRING?
null
json
STRING?
null
config
MAP?
{}
Output parameters
Name Type
content
MAP?
id
STRING?
expiry
INTEGER?
cas
INTEGER?
mutationToken
MAP?
More documentation of apoc.couchbase.insert
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.couchbase/apoc.couchbase.posParamsQuery;"apoc.couchbase.posParamsQuery
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.couchbase.posParamsQuery(hostOrKey, bucket, statement, params, config) yield queryResult - executes a N1QL statement with positional parameters.
Signature
None
Copy to Clipboard
apoc.couchbase.posParamsQuery(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, params :: LIST? OF ANY?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)
Input parameters
Name Type Default
hostOrKey
STRING?
null
bucket
STRING?
null
statement
STRING?
null
params
LIST? OF ANY?
null
config
MAP?
{}
Output parameters
Name Type
queryResult
LIST? OF MAP?
More documentation of apoc.couchbase.posParamsQuery
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.metrics/apoc.metrics.list;"apoc.metrics.list
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.metrics.list() - get a list of available metrics
Signature
None
Copy to Clipboard
apoc.metrics.list() :: (name :: STRING?, lastUpdated :: INTEGER?)
Output parameters
Name Type
name
STRING?
lastUpdated
INTEGER?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.metrics.list()
YIELD name, lastUpdated
WHERE name STARTS WITH ""neo4j.neo4j""
RETURN name, datetime({epochMillis: lastUpdated}) AS lastUpdated
LIMIT 5;
Table 1. Results
name lastUpdated
""neo4j.neo4j.transaction.started""
2020-11-16T12:04:13.224Z
""neo4j.neo4j.transaction.peak_concurrent""
2020-11-16T12:04:13.224Z
""neo4j.neo4j.transaction.active_write""
2020-11-16T12:04:13.220Z
""neo4j.neo4j.transaction.rollbacks""
2020-11-16T12:04:13.224Z
""neo4j.neo4j.transaction.last_committed_tx_id""
2020-11-16T12:04:13.224Z
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom/apoc.custom.declareProcedure;"apoc.custom.declareProcedure
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.custom.declareProcedure(signature, statement, mode, description) - register a custom cypher procedure
Signature
None
Copy to Clipboard
apoc.custom.declareProcedure(signature :: STRING?, statement :: STRING?, mode = read :: STRING?, description =  :: STRING?) :: VOID
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
signature
STRING?
null
statement
STRING?
null
mode
STRING?
read
description
STRING?
Usage Examples
We can create the function custom.powers that returns a stream of the powers of the first parameter, up to and including the power provided by the second parameter:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.declareProcedure(
  'powers(input::INT, power::INT) :: (answer::INT)',
  'UNWIND range(0, $power) AS power
   RETURN $input ^ power AS answer'
);
Procedure, input and output names must have at least 2 characters.
We can use this function, to return 4°, 4¹, 4², and 4³, as shown in the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call custom.powers(4,3);
Table 1. Results
answer
1.0
4.0
16.0
64.0
More documentation of apoc.custom.declareProcedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.bolt/apoc.bolt.load;"apoc.bolt.load
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.bolt.load(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for read
Signature
None
Copy to Clipboard
apoc.bolt.load(url :: STRING?, kernelTransaction :: STRING?, params = {} :: MAP?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
url
STRING?
null
kernelTransaction
STRING?
null
params
MAP?
{}
config
MAP?
{}
Output parameters
Name Type
row
MAP?
More documentation of apoc.bolt.load
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/bolt-neo4j;"Bolt
Contents
Install Dependencies
Driver configuration
Bolt Examples
Bolt procedures allows to accessing other databases via bolt protocol.
Qualified Name Type Release
apoc.bolt.execute
apoc.bolt.execute(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for reads and writes
Procedure
Apoc Extended
apoc.bolt.load
apoc.bolt.load(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for read
Procedure
Apoc Extended
apoc.bolt.load.fromLocal
Procedure
Apoc Extended
urlOrKey param allows users to decide if send url by apoc or if put it into apoc.conf file.
apoc : write the complete url in his right position on the apoc.
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load(""bolt://user:password@localhost:7687"",""match(p:Person {name: $name}) return p"", {name:'Michael'})
apoc.conf : here the are two choices:
1) complete url: write the complete url with the param apoc.bolt.url;
Cypher
apoc
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load("""",""match(p:Person {name: $name}) return p"", {name:'Michael'})
Txt
neo4jConf
Copy to Clipboard
//simple url
apoc.bolt.url=bolt://user:password@localhost:7687
2) by key: set the url with a personal key apoc.bolt.yourKey.url; in this case in the apoc on the url param user has to insert the key.
Cypher
apoc
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load(""test"",""match(p:Person {name: $name}) return p"", {name:'Michael'})
Txt
neo4jConf
Copy to Clipboard
//with key
apoc.bolt.test.url=bolt://user:password@localhost:7687
apoc.bolt.production.url=bolt://password:test@localhost:7688
Config available are:
statistics: possible values are true/false, the default value is false. This config print the execution statistics;
virtual: possible values are true/false, the default value is false. This config return result in virtual format and not in map format, in apoc.bolt.load.
databaseName: the database instance name on the remote Neo4j instance. The default value is 'neo4j'. Put null to connect through protocol which not support database name (for neo4j before 4.x).
In addition, the apoc.bolt.load.fromLocal can have: * streamStatements: if true and used in combination with the cypher export procedures it streams the statement from local to remote database. * readOnly: default false. To execute or not, read-only statements. * localParams: to put optional parameters to local cypher statement
Install Dependencies
The Bolt procedures have dependencies on a client library that is not included in the APOC Extended library.
You can download it from mvnrepository or apoc repository. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Driver configuration
To set the configuration of the Driver, you can add the parameter driverConfig in the config. It’s a map of values, the values that we don’t pass to the config, are set to the default value.
Cypher
Copy to Clipboard
Run in Neo4j Browser
{logging='INFO', encryption=true, logLeakedSessions:true, maxIdleConnectionPoolSize:10, idleTimeBeforeConnectionTest:-1, trustStrategy:'TRUST_ALL_CERTIFICATES',
 routingFailureLimit: 1, routingRetryDelayMillis:5000, connectionTimeoutMillis:5000, maxRetryTimeMs:30000 }
param description possible values/ types
logging
logging provider to use
INFO, WARNING, OFF, SEVERE, CONFIG, FINE, FINER
encryption
Disable or enabled encryption
true, false
logLeakedSessions
Disable or enable logging of leaked sessions
true, false
maxIdleConnectionPoolSize
Max number of connections
number
idleTimeBeforeConnectionTest
Pooled connections that have been idle in the pool for longer than this timeout
Milliseconds
trustStrategy
Specify how to determine the authenticity of an encryption certificate provided by the Neo4j instance we are connecting to
TRUST_ALL_CERTIFICATES, TRUST_SYSTEM_CA_SIGNED_CERTIFICATES, or directly a custom certificate
routingFailureLimit
the number of times to retry each server in the list of routing servers
number
routingRetryDelayMillis
Specify how long to wait before retrying to connect to a routing server
Milliseconds
connectionTimeoutMillis
Specify socket connection timeout
Milliseconds
maxRetryTimeMs
Specify the maximum time transactions are allowed to retry
Milliseconds
You can find all the values in the documentation Config.ConfigBuilder
Bolt Examples
Return node in map format
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.execute(""bolt://user:password@localhost:7687"",
""match(p:Person {name: $name}) set p.surname = $surname return p"",
{name:'Michael', surname: 'Jordan'})
Return node in virtual Node format
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load(""bolt://user:password@localhost:7687"",
""match(p:Person {name: $name}) return p"", {name:'Michael'}, {virtual:true})
Create node and return statistic
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.execute(""bolt://user:password@localhost:7687"",
""create(n:Node {name: $name})"", {name:'Node1'}, {statistics:true})
Return more scalar values
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.execute(""bolt://user:password@localhost:7687"",
""match (n:Person {name: $name}) set n.foo = 'bar' return n.age as age, n.name as name, n.surname as surname, n.foo as foo"", {name:'Michael'})
Return relationship in a map format
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load(""bolt://user:password@localhost:7687"",
""MATCH (n:Person{name: $name})-[r:KNOWS]->(p) return r as rel"", {name:'Anne'})
Return virtual path
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.load(""bolt://user:password@localhost:7687"",
""MATCH (n) WHERE id(n) = $idNode MATCH path= (n)-[r:REL_TYPE*..3]->(o) return path"", {idNode:200}, {virtual:true})
Create a Node with params in input
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.bolt.execute(""bolt://user:password@localhost:7687"",
""CREATE (n:Car{brand: $brand, model: $model, year: $year}) return n"", {brand:'Ferrari',model:'California',year:2016})
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.bolt/apoc.bolt.execute;"apoc.bolt.execute
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.bolt.execute(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for reads and writes
Signature
None
Copy to Clipboard
apoc.bolt.execute(url :: STRING?, kernelTransaction :: STRING?, params = {} :: MAP?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
url
STRING?
null
kernelTransaction
STRING?
null
params
MAP?
{}
config
MAP?
{}
Output parameters
Name Type
row
MAP?
More documentation of apoc.bolt.execute
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.bolt/apoc.bolt.load.fromLocal;"apoc.bolt.load.fromLocal
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
Signature
None
Copy to Clipboard
apoc.bolt.load.fromLocal(url :: STRING?, localStatement :: STRING?, remoteStatement :: STRING?, config = {} :: MAP?) :: (row :: MAP?)
Input parameters
Name Type Default
url
STRING?
null
localStatement
STRING?
null
remoteStatement
STRING?
null
config
MAP?
{}
Output parameters
Name Type
row
MAP?
More documentation of apoc.bolt.load.fromLocal
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom/apoc.custom.removeFunction;"apoc.custom.removeFunction
Contents
Signature
Input parameters
Usage Examples
Procedure Apoc Extended
apoc.custom.removeFunction(name, type) - remove the targeted custom function
Signature
None
Copy to Clipboard
apoc.custom.removeFunction(name :: STRING?) :: VOID
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Input parameters
Name Type Default
name
STRING?
null
Usage Examples
We can remove a custom function named double, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.removeFunction(""double"");
More documentation of apoc.custom.removeFunction
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.es;"apoc.es
Qualified Name Type
apoc.es.get
apoc.es.get(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a GET operation on elastic search
Procedure
apoc.es.getRaw
apoc.es.getRaw(host-or-port,path,payload-or-null) yield value - perform a raw GET operation on elastic search
Procedure
apoc.es.post
apoc.es.post(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a POST operation on elastic search
Procedure
apoc.es.postRaw
apoc.es.postRaw(host-or-port,path,payload-or-null) yield value - perform a raw POST operation on elastic search
Procedure
apoc.es.put
apoc.es.put(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a PUT operation on elastic search
Procedure
apoc.es.query
apoc.es.query(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a SEARCH operation on elastic search
Procedure
apoc.es.stats
apoc.es.stats(host-url-Key) - elastic search statistics
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom/apoc.custom.list;"apoc.custom.list
Contents
Signature
Output parameters
Usage Examples
Procedure Apoc Extended
apoc.custom.list() - provide a list of custom procedures/function registered
Signature
None
Copy to Clipboard
apoc.custom.list() :: (type :: STRING?, name :: STRING?, description :: STRING?, mode :: STRING?, statement :: STRING?, inputs :: LIST? OF LIST? OF STRING?, outputs :: ANY?, forceSingle :: BOOLEAN?)
Output parameters
Name Type
type
STRING?
name
STRING?
description
STRING?
mode
STRING?
statement
STRING?
inputs
LIST? OF LIST? OF STRING?
outputs
ANY?
forceSingle
BOOLEAN?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.custom.list();
Table 1. Results
type name description mode statement inputs outputs forceSingle
""function""
""double""
""""
NULL
""RETURN $input*2 as answer""
[[""input"", ""number""]]
""integer""
FALSE
More documentation of apoc.custom.list
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.relationshipWithStats.eager;"apoc.merge.relationshipWithStats.eager
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.merge.relationshipWithStats.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly. Provides queryStatistics in the result.
Signature
None
Copy to Clipboard
apoc.merge.relationshipWithStats.eager(startNode :: NODE?, relationshipType :: STRING?, identProps :: MAP?, props :: MAP?, endNode :: NODE?, onMatchProps = {} :: MAP?) :: (stats :: MAP?, rel :: RELATIONSHIP?)
Input parameters
Name Type Default
startNode
NODE?
null
relationshipType
STRING?
null
identProps
MAP?
null
props
MAP?
null
endNode
NODE?
null
onMatchProps
MAP?
{}
Output parameters
Name Type
stats
MAP?
rel
RELATIONSHIP?
More documentation of apoc.merge.relationshipWithStats.eager
apoc.merge.relationshipWithStats
apoc.meta
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.relationshipWithStats;"apoc.merge.relationshipWithStats
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.merge.relationshipWithStats(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties. Provides queryStatistics in the result.
Signature
None
Copy to Clipboard
apoc.merge.relationshipWithStats(startNode :: NODE?, relationshipType :: STRING?, identProps :: MAP?, props :: MAP?, endNode :: NODE?, onMatchProps = {} :: MAP?) :: (stats :: MAP?, rel :: RELATIONSHIP?)
Input parameters
Name Type Default
startNode
NODE?
null
relationshipType
STRING?
null
identProps
MAP?
null
props
MAP?
null
endNode
NODE?
null
onMatchProps
MAP?
{}
Output parameters
Name Type
stats
MAP?
rel
RELATIONSHIP?
More documentation of apoc.merge.relationshipWithStats
apoc.merge.relationship.eager
apoc.merge.relationshipWithStats.eager
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.relationship.eager;"apoc.merge.relationship.eager
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.merge.relationship.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly.
Signature
None
Copy to Clipboard
apoc.merge.relationship.eager(startNode :: NODE?, relationshipType :: STRING?, identProps :: MAP?, props :: MAP?, endNode :: NODE?, onMatchProps = {} :: MAP?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
startNode
NODE?
null
relationshipType
STRING?
null
identProps
MAP?
null
props
MAP?
null
endNode
NODE?
null
onMatchProps
MAP?
{}
Output parameters
Name Type
rel
RELATIONSHIP?
More documentation of apoc.merge.relationship.eager
apoc.merge.relationship
apoc.merge.relationshipWithStats
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.relationship;"apoc.merge.relationship
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.merge.relationship(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties.
Signature
None
Copy to Clipboard
apoc.merge.relationship(startNode :: NODE?, relationshipType :: STRING?, identProps :: MAP?, props :: MAP?, endNode :: NODE?, onMatchProps = {} :: MAP?) :: (rel :: RELATIONSHIP?)
Input parameters
Name Type Default
startNode
NODE?
null
relationshipType
STRING?
null
identProps
MAP?
null
props
MAP?
null
endNode
NODE?
null
onMatchProps
MAP?
{}
Output parameters
Name Type
rel
RELATIONSHIP?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Person {name: ""Tom Hanks""})
CREATE (m:Movie {title:""You've Got Mail""});
This procedure provides a more flexible way of merging relationships than Cypher’s MERGE clause.
The example below shows equivalent ways of merging an ACTED_IN relationship between the Tom Hanks and You’ve Got Mail nodes:
apoc.merge.relationship
MERGE clause
Cypher
apoc.merge.relationship
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
MATCH (m:Movie {title:""You've Got Mail""})
CALL apoc.merge.relationship(p, ""ACTED_IN"",
  {roles:['Joe Fox']},
  {created: datetime()},
  m,
  {lastSeen: datetime()}
)
YIELD rel
RETURN rel;
If we run these queries a few times, we’ll see output as shown below:
Table 1. Results
rel
[:ACTED_IN {lastSeen: 2020-11-03T11:02:00.261Z, created: 2020-11-03T11:00:56.849Z, roles: [""Joe Fox""]}]
But this procedure is mostly useful for merging relationships that have a dynamic relationship type or dynamic properties. For example, we might want to merge a relationship with a relationship type or properties passed in as parameters.
The following creates relationshipType and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param relType =>  (""ACTED_IN"");
:param properties => ({roles: [""Joe Fox""]});
The following merges a relationship with a relationship type and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Tom Hanks""})
MATCH (m:Movie {title:""You've Got Mail""})
CALL apoc.merge.relationship(p, $relType, $properties, {}, m, {})
YIELD rel
RETURN rel;
Table 2. Results
rel
[:ACTED_IN {roles: [""Joe Fox""]}]
More documentation of apoc.merge.relationship
apoc.merge.nodeWithStats.eager
apoc.merge.relationship.eager
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.nodeWithStats.eager;"apoc.merge.nodeWithStats.eager
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.merge.nodeWithStats.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly. Provides queryStatistics in the result.
Signature
None
Copy to Clipboard
apoc.merge.nodeWithStats.eager(labels :: LIST? OF STRING?, identProps :: MAP?, props = {} :: MAP?, onMatchProps = {} :: MAP?) :: (stats :: MAP?, node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
identProps
MAP?
null
props
MAP?
{}
onMatchProps
MAP?
{}
Output parameters
Name Type
stats
MAP?
node
NODE?
More documentation of apoc.merge.nodeWithStats.eager
apoc.merge.nodeWithStats
apoc.merge.relationship
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.nodeWithStats;"apoc.merge.nodeWithStats
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.merge.nodeWithStats(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels. Provides queryStatistics in the result.
Signature
None
Copy to Clipboard
apoc.merge.nodeWithStats(labels :: LIST? OF STRING?, identProps :: MAP?, props = {} :: MAP?, onMatchProps = {} :: MAP?) :: (stats :: MAP?, node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
identProps
MAP?
null
props
MAP?
{}
onMatchProps
MAP?
{}
Output parameters
Name Type
stats
MAP?
node
NODE?
More documentation of apoc.merge.nodeWithStats
apoc.merge.node.eager
apoc.merge.nodeWithStats.eager
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.node.eager;"apoc.merge.node.eager
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.merge.node.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly.
Signature
None
Copy to Clipboard
apoc.merge.node.eager(labels :: LIST? OF STRING?, identProps :: MAP?, props = {} :: MAP?, onMatchProps = {} :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
identProps
MAP?
null
props
MAP?
{}
onMatchProps
MAP?
{}
Output parameters
Name Type
node
NODE?
Usage Examples
This procedure provides a more flexible way of merging nodes than Cypher’s MERGE clause.
The example below shows equivalent ways of merging a node with the Person and Actor labels, with a name property of ""Tom Hanks"":
apoc.create.node
CREATE clause
Cypher
apoc.create.node
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.merge.node.eager(
  [""Person"", ""Actor""],
  {name: ""Tom Hanks""},
  {created: datetime()},
  {lastSeen: datetime()}
);
Table 1. Results
node
(:Person:Actor {name: ""Tom Hanks"", created: 2020-11-24T11:33:39.319Z})
But this procedure is mostly useful for merging nodes that have dynamic labels or properties. For example, we might want to create a node with labels or properties passed in as parameters.
The following creates labels and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param labels =>  ([""Human"", ""MovieStar""]);
:param identityProperties => ({name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""});
The following creates a node with labels and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.merge.node.eager($labels, $identityProperties);
Table 2. Results
node
(:Human:MovieStar {name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""})
More documentation of apoc.merge.node.eager
apoc.merge.node
apoc.merge.nodeWithStats
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge/apoc.merge.node;"apoc.merge.node
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.merge.node(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels.
Signature
None
Copy to Clipboard
apoc.merge.node(labels :: LIST? OF STRING?, identProps :: MAP?, props = {} :: MAP?, onMatchProps = {} :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
labels
LIST? OF STRING?
null
identProps
MAP?
null
props
MAP?
{}
onMatchProps
MAP?
{}
Output parameters
Name Type
node
NODE?
Usage Examples
This procedure provides a more flexible way of merging nodes than Cypher’s MERGE clause.
The example below shows equivalent ways of merging a node with the Person and Actor labels, with a name property of ""Tom Hanks"":
apoc.create.node
CREATE clause
Cypher
apoc.create.node
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.merge.node(
  [""Person"", ""Actor""],
  {name: ""Tom Hanks""},
  {created: datetime()},
  {lastSeen: datetime()}
);
Table 1. Results
node
(:Person:Actor {name: ""Tom Hanks"", created: 2020-11-24T11:33:39.319Z})
But this procedure is mostly useful for merging nodes that have dynamic labels or properties. For example, we might want to create a node with labels or properties passed in as parameters.
The following creates labels and properties parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param labels =>  ([""Human"", ""MovieStar""]);
:param identityProperties => ({name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""});
The following creates a node with labels and properties based on the previously defined parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.merge.node($labels, $identityProperties);
Table 2. Results
node
(:Human:MovieStar {name: ""Tom Cruise"", placeOfBirth: ""Syracuse, New York, United States""})
More documentation of apoc.merge.node
apoc.merge
apoc.merge.node.eager
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.merge;"apoc.merge
Qualified Name Type
apoc.merge.node
apoc.merge.node(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels.
Procedure
apoc.merge.node.eager
apoc.merge.node.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly.
Procedure
apoc.merge.nodeWithStats
apoc.merge.nodeWithStats(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels. Provides queryStatistics in the result.
Procedure
apoc.merge.nodeWithStats.eager
apoc.merge.nodeWithStats.eager(labels [String], identProps Map<String, Any>, props Map<String, Any>, onMatchProps Map<String, Any>) - merges the given node(s) with the given dynamic labels eagerly. Provides queryStatistics in the result.
Procedure
apoc.merge.relationship
apoc.merge.relationship(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties.
Procedure
apoc.merge.relationship.eager
apoc.merge.relationship.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly.
Procedure
apoc.merge.relationshipWithStats
apoc.merge.relationshipWithStats(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties. Provides queryStatistics in the result.
Procedure
apoc.merge.relationshipWithStats.eager
apoc.merge.relationshipWithStats.eager(startNode Node, relType String, identProps Map<String, Any>, props Map<String, Any>, endNode Node, onMatchProps Map<String, Any>) - merges the given relationship(s) with the given dynamic types/properties eagerly. Provides queryStatistics in the result.
Procedure
apoc.math.tanh
apoc.merge.node
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.math/apoc.math.tanh;"apoc.math.tanh
Contents
Signature
Input parameters
Function
apoc.math.tanh(value Float) - returns the hyperbolic tangent of the given value.
Signature
None
Copy to Clipboard
apoc.math.tanh(value :: FLOAT?) :: (FLOAT?)
Input parameters
Name Type Default
value
FLOAT?
null
More documentation of apoc.math.cosh
apoc.math.sinh
apoc.merge
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.remove;"apoc.trigger.remove
Contents
Signature
Input parameters
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.remove(name String) - removes the given trigger.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.remove(name :: STRING?) :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
If we want to remove the trigger created by the example in apoc.trigger.add, we can run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.remove(""count-removals"");
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
FALSE
FALSE
More documentation of apoc.trigger.remove
apoc.trigger.pause
apoc.trigger.removeAll
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.pause;"apoc.trigger.pause
Contents
Signature
Input parameters
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.pause(name String) - pauses the given trigger.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.pause(name :: STRING?) :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
If we want to pause the trigger created by the example in apoc.trigger.add, we can run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.pause(""count-removals"");
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
TRUE
TRUE
More documentation of apoc.trigger.pause
apoc.trigger.list
apoc.trigger.remove
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.add;"apoc.trigger.add
Contents
Signature
Input parameters
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.add(name String, statement String, selector Map<String, Any>, config Map<String, Any>) - adds a trigger to the given Cypher statement. The selector for this procedure is {phase:'before/after/rollback/afterAsync'}.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.add(name :: STRING?, kernelTransaction :: STRING?, selector :: MAP?, config = {} :: MAP?) :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Input parameters
Name Type Default
name
STRING?
null
kernelTransaction
STRING?
null
selector
MAP?
null
config
MAP?
{}
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Counter {count:0})
CREATE (f:Foo);
Let’s create a trigger that keeps a count of the number of nodes that have been deleted:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.add(
  'count-removals',
  'MATCH (c:Counter)
   SET c.count = c.count + size([f IN $deletedNodes WHERE id(f) > 0])',
  {}
);
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
TRUE
FALSE
We’ll now delete the Foo node:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (f:Foo)
DELETE f;
Text
Results
Copy to Clipboard
0 rows available after 20 ms, consumed after another 0 ms
Deleted 1 nodes
And finally, let’s check that the count property on our Counter node has been incremented:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (c:Counter)
RETURN c.count as count;
Table 3. Results
count
1
More documentation of apoc.trigger.add
apoc.trigger
apoc.trigger.list
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.trigger/apoc.trigger.list;"apoc.trigger.list
Contents
Signature
Output parameters
Enable Triggers
Usage Examples
Procedure
apoc.trigger.list() - lists all installed triggers.
This procedure is not intended to be used in a cluster environment, and may act unpredictably.
Signature
None
Copy to Clipboard
apoc.trigger.list() :: (name :: STRING?, query :: STRING?, selector :: MAP?, params :: MAP?, installed :: BOOLEAN?, paused :: BOOLEAN?)
Output parameters
Name Type
name
STRING?
query
STRING?
selector
MAP?
params
MAP?
installed
BOOLEAN?
paused
BOOLEAN?
Enable Triggers
By default triggers are disabled. We can enable them by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.trigger.enabled=true
apoc.trigger.refresh=60000
Table 1. Description
Option Key Value Description
apoc.trigger.enabled
true/false, default false
Enable/Disable the feature
apoc.trigger.refresh
number, default 60000
Interval in ms after which a replication check is triggered across all cluster nodes
Usage Examples
This example assumes that we’ve first added the trigger described in apoc.trigger.add:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.trigger.list();
Table 2. Results
name query selector params installed paused
""count-removals""
MATCH (c:Counter) SET c.count = c.count + size([f IN $deletedNodes WHERE id(f)  0])
{}
{}
TRUE
FALSE
More documentation of apoc.trigger.list
apoc.trigger.add
apoc.trigger.pause
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runManyReadOnly;"apoc.cypher.runManyReadOnly
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.cypher.runManyReadOnly(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated read-only statement and returns a summary of the statement outcomes.
Signature
None
Copy to Clipboard
apoc.cypher.runManyReadOnly(cypher :: STRING?, params :: MAP?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
More documentation of apoc.cypher.runManyReadOnly
apoc.cypher.runMany
apoc.cypher.runSchema
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runSchema;"apoc.cypher.runSchema
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.cypher.runSchema(statement String, params Map<String, Any>) - runs the given query schema statement with the given parameters.
Signature
None
Copy to Clipboard
apoc.cypher.runSchema(cypher :: STRING?, params :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Output parameters
Name Type
value
MAP?
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchema('CREATE INDEX test FOR (w:Test) ON (w.$name)',{})
or
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runSchema('CREATE CONSTRAINT $name FOR (w:Test) REQUIRE w.baz IS UNIQUE',{})
More documentation of apoc.cypher.runSchema
apoc.cypher.runManyReadOnly
apoc.cypher.runTimeboxed
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runTimeboxed;"apoc.cypher.runTimeboxed
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.cypher.runTimeboxed(statement String, params Map<String, Any>, timeout Integer) - terminates a Cypher statement if it has not finished before the set timeout (ms).
Signature
None
Copy to Clipboard
apoc.cypher.runTimeboxed(cypher :: STRING?, params :: MAP?, timeout :: INTEGER?) :: (value :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
timeout
INTEGER?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on a sample graph with 10000 nodes, each with 50 relationships with the label ""Node"" and Type ""CONNECTED_TO"".
The query below calculates the cross product of shortest paths for every pair of nodes.
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Node), (m:Node)
WHERE n <> m
match path = shortestpath((n)-[:CONNECTED_TO*]-(m))
RETURN n, m, length(path) AS path;
This query returns 999,000 rows, but it takes a while to return all of those rows.
We can use the apoc.cypher.runTimeboxed procedure to return the paths computed within a threshold defined in ms. We can return the results computed within 100ms, by running the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.cypher.runTimeboxed(""match (n:Node), (m:Node)
WHERE n <> m
match path = shortestpath((n)-[:CONNECTED_TO*]-(m))
RETURN n, m, length(path) AS path"", {}, 100)
YIELD value
RETURN value.n.uuid, value.m.uuid, value.path;
Table 1. Results
value.n.uuid value.m.uuid value.path
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""62b0578a-cae5-4d45-8a47-5553692a6f22""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""9d910497-1aca-48e8-a14c-cd04528675ab""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""dde31015-73a9-4d22-bf57-ee13a8f7eeb0""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""6040453e-c705-4755-95f3-3b673d10ae54""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""bb2a9b42-71ab-4219-beae-a1e99353921f""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""856a4b54-d027-4438-bbee-fd34d9a6990d""
1
""67dd7a13-dc8d-4d82-9ab3-383d66c54fe4""
""d3e325b4-7691-400a-a819-787c065d537c""
1
….
1022 rows available after 9 ms, consumed after another 1 ms
More documentation of apoc.cypher.runTimeboxed
apoc.cypher.runSchema
apoc.cypher.runWrite
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runWrite;"apoc.cypher.runWrite
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.cypher.runWrite(statement String, params Map<String, Any>) - alias for apoc.cypher.doIt.
Signature
None
Copy to Clipboard
apoc.cypher.runWrite(cypher :: STRING?, params :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Output parameters
Name Type
value
MAP?
More documentation of apoc.cypher.runWrite
apoc.cypher.runTimeboxed
apoc.cypher.runFirstColumnMany
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runFirstColumnMany;"apoc.cypher.runFirstColumnMany
Contents
Signature
Input parameters
Usage Examples
Function
apoc.cypher.runFirstColumnMany(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first column collected into a list.
Signature
None
Copy to Clipboard
apoc.cypher.runFirstColumnMany(cypher :: STRING?, params :: MAP?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (TomT:Person {name:'Tom Tykwer', born:1965})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)
 (TomT)-[:]->(CloudAtlas);
View all (11 more lines)
This function is useful for executing Cypher statements that have a dynamic node label or relationship type and return multiple rows of one column. For example, we can return a stream of all the labels and the distinct sets of property keys used by node with those labels:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label
RETURN label,
       apoc.cypher.runFirstColumnMany(
          ""MATCH (n:`"" + label + ""`)
           WITH DISTINCT keys(n) AS keys
           RETURN DISTINCT apoc.coll.sort(keys)"",
          {}) AS keys;
Table 1. Results
label keys
""Person""
[[""born"", ""name""]]
""Movie""
[[""released"", ""tagline"", ""title""], [""released"", ""title""]]
More documentation of apoc.cypher.runFirstColumnMany
apoc.cypher.runWrite
apoc.cypher.runFirstColumnSingle
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.runMany;"apoc.cypher.runMany
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.cypher.runMany(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated statement and returns a summary of the statement outcomes.
Signature
None
Copy to Clipboard
apoc.cypher.runMany(cypher :: STRING?, params :: MAP?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
config
MAP?
{}
Output parameters
Name Type
row
INTEGER?
result
MAP?
Usage Examples
This procedure is useful for executing multiple Cypher statements. We can create a node in one statement and create a relationship to itself in another statement, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runMany(
  'CREATE (n:Node {name:$name});
   MATCH (n {name:$name})
   CREATE (n)-[:X {name:$name2}]->(n);',
  {name:""John"", name2:""Doe""}
);
Table 1. Results
row result
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 1, rows: 0, propertiesSet: 1, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 1, relationshipsCreated: 0, time: 0}
-1
{constraintsRemoved: 0, indexesRemoved: 0, nodesCreated: 0, rows: 0, propertiesSet: 1, labelsRemoved: 0, relationshipsDeleted: 0, constraintsAdded: 0, nodesDeleted: 0, indexesAdded: 0, labelsAdded: 0, relationshipsCreated: 1, time: 0}
If we don’t want to see statistics for each Cypher statement, we can set statistics: false:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runMany(
  'CREATE (n:Node {name:$name});
   MATCH (n {name:$name})
   CREATE (n)-[:X {name:$name2}]->(n);',
  {name:""John"", name2:""Doe""},
  {statistics: false}
);
Table 2. Results
row result
More documentation of apoc.cypher.runMany
apoc.cypher.run
apoc.cypher.runManyReadOnly
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.run;"apoc.cypher.run
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.cypher.run(statement String, params Map<String, Any>) - runs a dynamically constructed read-only string with the given parameters.
Signature
None
Copy to Clipboard
apoc.cypher.run(cypher :: STRING?, params :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (TomH:Person {name:'Tom Hanks', born:1956})
CREATE (TomT:Person {name:'Tom Tykwer', born:1965})

CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (TheMatrixReloaded:Movie {title:'The Matrix Reloaded', released:2003, tagline:'Free your mind'})
CREATE (TheMatrixRevolutions:Movie {title:'The Matrix Revolutions', released:2003, tagline:'Everything that has a beginning has an end'})
CREATE (SomethingsGottaGive:Movie {title:""Something's Gotta Give"", released:2003})
CREATE (TheDevilsAdvocate:Movie {title:""The Devil's Advocate"", released:1997, tagline:'Evil has its winning ways'})

CREATE (YouveGotMail:Movie {title:""You've Got Mail"", released:1998, tagline:'At odds in life... in love on-line.'})
CREATE (SleeplessInSeattle:Movie {title:'Sleepless in Seattle', released:1993, tagline:'What if someone you never met, someone you never saw, someone you never knew was the only someone for you?'})
CREATE (ThatThingYouDo:Movie {title:'That Thing You Do', released:1996, tagline:'In every life there comes a time when that thing you dream becomes that thing you do'})
CREATE (CloudAtlas:Movie {title:'Cloud Atlas', released:2012, tagline:'Everything is connected'})

 (Keanu)-[: {roles:[]}]->(TheMatrix)
 (Keanu)-[: {roles:[]}]->(TheMatrixReloaded)
 (Keanu)-[: {roles:[]}]->(TheMatrixRevolutions)
 (Keanu)-[: {roles:[]}]->(SomethingsGottaGive)
 (Keanu)-[: {roles:[]}]->(TheDevilsAdvocate)

 (TomH)-[: {roles:[]}]->(YouveGotMail)
 (TomH)-[: {roles:[]}]->(SleeplessInSeattle)
 (TomH)-[: {roles:[]}]->(ThatThingYouDo)
 (TomH)-[: {roles:[, , , ]}]->(CloudAtlas)
 (TomT)-[:]->(CloudAtlas);
View all (11 more lines)
This procedure is useful for executing Cypher statements that have a dynamic node label or relationship type. For example, we can return a stream of all the labels and their counts by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label
CALL apoc.cypher.run(""MATCH (:"" + label + "") RETURN count(*) AS count"", {})
YIELD value
RETURN label, value.count AS count;
Table 1. Results
label count
""Person""
3
""Movie""
9
And we can return a stream of all relationship types and their counts, by running the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.relationshipTypes()
YIELD relationshipType
CALL apoc.cypher.run(""MATCH ()-[:"" + relationshipType + ""]->() RETURN count(*) AS count"", {})
YIELD value
RETURN relationshipType, value.count AS count;
Table 2. Results
relationshipType count
""ACTED_IN""
9
""DIRECTED""
1
If the query that we’re running only returns a single column, we could also apoc.cypher.runFirstColumnMany or apoc.cypher.runFirstColumnSingle.
More documentation of apoc.cypher.run
apoc.cypher.doIt
apoc.cypher.runMany
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher/apoc.cypher.doIt;"apoc.cypher.doIt
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.cypher.doIt(statement String, params Map<String, Any>) - runs a dynamically constructed string with the given parameters. This procedure allows for both read and write statements.
Signature
None
Copy to Clipboard
apoc.cypher.doIt(cypher :: STRING?, params :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
cypher
STRING?
null
params
MAP?
null
Output parameters
Name Type
value
MAP?
Usage Examples
The examples in this section are based on a graph where we’ve accidentally created node labels in all capitals, as shown below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:PERSON)
CREATE (:EVENT)
CREATE (:TAG)
CREATE (:LOCATION);
We want to update all these labels to have only the first letter capitalized. We can use the toLower and apoc.text.capitalize functions to transform the label names, as shown in the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels()
YIELD label
RETURN apoc.text.capitalize(toLower(label)) AS value;
Table 1. Results
value
""Event""
""Person""
""Tag""
""Location""
Now we want to set our new labels and remove the old ones. Unfortunately the SET and REMOVE clauses don’t support dynamically created values, but we can use the apoc.cypher.doIt command instead, as shown in the query below:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (node)
WITH node, labels(node)[0] AS label
CALL apoc.cypher.doIt(
  ""WITH $node AS node
   REMOVE node:"" + label + ""\n"" +
  ""SET node:"" + apoc.text.capitalize(toLower(label)) + ""\n"" +
  ""RETURN node"",
  {node: node})
YIELD value
RETURN value;
Table 2. Results
value
{node: (:Person)}
{node: (:Event)}
{node: (:Tag)}
{node: (:Location)}
Please note that if you want to use schema operation, you have to use apoc.cypher.runSchema procedure
More documentation of apoc.cypher.doIt
apoc.cypher
apoc.cypher.run
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.cypher;"apoc.cypher
Qualified Name Type
apoc.cypher.doIt
apoc.cypher.doIt(statement String, params Map<String, Any>) - runs a dynamically constructed string with the given parameters. This procedure allows for both read and write statements.
Procedure
apoc.cypher.run
apoc.cypher.run(statement String, params Map<String, Any>) - runs a dynamically constructed read-only string with the given parameters.
Procedure
apoc.cypher.runMany
apoc.cypher.runMany(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated statement and returns a summary of the statement outcomes.
Procedure
apoc.cypher.runManyReadOnly
apoc.cypher.runManyReadOnly(statement String, params Map<String, Any>, config Map<String, Any>) - runs each semicolon separated read-only statement and returns a summary of the statement outcomes.
Procedure
apoc.cypher.runSchema
apoc.cypher.runSchema(statement String, params Map<String, Any>) - runs the given query schema statement with the given parameters.
Procedure
apoc.cypher.runTimeboxed
apoc.cypher.runTimeboxed(statement String, params Map<String, Any>, timeout Integer) - terminates a Cypher statement if it has not finished before the set timeout (ms).
Procedure
apoc.cypher.runWrite
apoc.cypher.runWrite(statement String, params Map<String, Any>) - alias for apoc.cypher.doIt.
Procedure
apoc.cypher.runFirstColumnMany
apoc.cypher.runFirstColumnMany(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first column collected into a list.
Function
apoc.cypher.runFirstColumnSingle
apoc.cypher.runFirstColumnSingle(statement String, params Map<String, Any>) - runs the given statement with the given parameters and returns the first element of the first column.
Function
apoc.create.virtual.fromNode
apoc.cypher.doIt
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.virtual.fromNode;"apoc.create.virtual.fromNode
Contents
Signature
Input parameters
Usage Examples
Function
apoc.create.virtual.fromNode(node Node, propertyNames [String]) - returns a virtual node from the given existing node. The virtual node only contains the requested properties.
Signature
None
Copy to Clipboard
apoc.create.virtual.fromNode(node :: NODE?, propertyNames :: LIST? OF STRING?) :: (NODE?)
Input parameters
Name Type Default
node
NODE?
null
propertyNames
LIST? OF STRING?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (a:Account {type: 'checking', ownerName: 'Maria Perez', ownerId: '123456789', accountNumber: 101010101, routingNumber: 10101010, amount: 1000.00, bank: 'Best Bank'});
CREATE (p:Person {name: 'Jane Doe', birthdate: date('1990-01-13'), favoriteColor: 'green', favoriteDessert: 'ice cream', favoriteMusic: 'classical', favoriteBand: 'The Beatles', favoriteVacation: 'beach', favoriteAnimal: 'horse', favoriteBeverage: 'coffee', favoriteFlower: 'lily'});
The apoc.create.virtual.fromNode procedure provides a way to only visualize or return data that is needed, hiding any unnecessary or sensitive pieces.
The example below shows how we can use the procedure to return only the non-sensitive properties from the node above:
Cypher
apoc.create.virtual.fromNode
Copy to Clipboard
Run in Neo4j Browser
MATCH (a:Account {accountNumber: 101010101})
RETURN apoc.create.virtual.fromNode(a, ['type','bank']);
Table 1. Results
account
{""type"":""checking"",""bank"":""Best Bank""}
The apoc.create.virtual.fromNode procedure can also be used to simplify nodes with many properties by only displaying ones that are important to the query.
The example below shows an example of this use:
Cypher
apoc.create.virtual.fromNode
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: 'Jane Doe'})
RETURN apoc.create.virtual.fromNode(p, ['favoriteColor','favoriteAnimal','favoriteMusic']);
Table 2. Results
favorites
{""favoriteAnimal"":""horse"",""favoriteMusic"":""classical"",""favoriteColor"":│
""green""}
More documentation of apoc.create.virtual.fromNode
apoc.create.vRelationship
apoc.cypher
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.arrow.stream;"apoc.load.arrow.stream
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.load.arrow.stream(source ByteArray, config Map<String, Any>) - imports nodes and relationships from the provided arrow byte array.
Signature
None
Copy to Clipboard
apoc.load.arrow.stream(source :: BYTEARRAY?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
source
BYTEARRAY?
null
config
MAP?
null
Output parameters
Name Type
value
MAP?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.all;"apoc.export.arrow.all
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.all(file String, config Map<String, Any>) - exports the full database as an arrow file.
Signature
None
Copy to Clipboard
apoc.export.arrow.all(file :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: ANY?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.jsonParams;"apoc.load.jsonParams
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Procedure
apoc.load.jsonParams(urlOrKeyOrBinary Any, headers Map<String, Any>, payload String, path String, config Map<String, Any>) - loads parameters from a JSON URL (e.g. web-API) as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead.
Signature
None
Copy to Clipboard
apoc.load.jsonParams(urlOrKeyOrBinary :: ANY?, headers :: MAP?, payload :: STRING?, path =  :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
urlOrKeyOrBinary
ANY?
null
headers
MAP?
null
payload
STRING?
null
path
STRING?
config
MAP?
{}
Output parameters
Name Type
value
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
We can perform a POST request to a JSON endpoint by setting the config parameter method to POST. We’ll also use apoc.convert.toJson to construct a JSON payload from a Cypher map.
The following makes a POST request to Neo4j’s search API:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jsonParams(
  ""https://neo4j.com/docs/search/"",
  {method: ""POST""},
  apoc.convert.toJson({query: ""subquery"", version: ""4.0""})
);
Table 1. Results
value
{description: ""The CALL {} clause evaluates a subquery that returns some values."", weight: 0.6460227966308594, title: ""3.16. CALL {} (subquery) - Chapter 3. Clauses"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/call-subquery/""}
{description: ""This section provides examples of queries and Cypher commands that can be used with Neo4j Fabric."", weight: 0.05099273845553398, title: ""7.3. Queries - Chapter 7. Fabric"", uri: ""https://neo4j.com/docs/operations-manual/4.0/fabric/queries/""}
{description: ""WHERE adds constraints to the patterns in a MATCH or OPTIONAL MATCH clause or filters the results of a WITH clause."", weight: 0.03291567042469978, title: ""3.6. WHERE - Chapter 3. Clauses"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/where/""}
{description: ""This appendix contains the recommended style when writing Cypher queries."", weight: 0.031550146639347076, title: ""Appendix A. Cypher styleguide - The Neo4j Cypher Manual v4.0"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/styleguide/""}
{description: ""This section contains information on all the clauses in the Cypher query language."", weight: 0.02944066934287548, title: ""Chapter 3. Clauses - The Neo4j Cypher Manual v4.0"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/""}
{description: """", weight: 0.01821548491716385, title: ""2.3. Expressions - Chapter 2. Syntax"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/syntax/expressions/""}
More documentation of apoc.load.jsonParams
apoc.load.jsonArray
apoc.load.xml
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.jsonArray;"apoc.load.jsonArray
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.load.jsonArray(url String, path String, config Map<String, Any>) - loads array from a JSON URL (e.g. web-API) to then import the given JSON file as a stream of values.
Signature
None
Copy to Clipboard
apoc.load.jsonArray(url :: STRING?, path =  :: STRING?, config = {} :: MAP?) :: (value :: ANY?)
Input parameters
Name Type Default
url
STRING?
null
path
STRING?
config
MAP?
{}
Output parameters
Name Type
value
ANY?
Usage Examples
map.json contains a JSON document representing a person and their children.
Json
map.json
Copy to Clipboard
{
  ""foo"":[1,2,3]
}
We’ll place this file into the import directory of our Neo4j instance. Let’s now write a query using the apoc.load.jsonArray procedure to explore this file.
The following query processes map.json and returns the content as Cypher data structures
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jsonArray(""file:///map.json"", ""$.foo"");
Table 1. Results
value
[1, 2, 3]
Moreover, we can customize the Json path options, adding the config {pathOptions: LIST OF STRINGS}, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So with the following json:
Json
Copy to Clipboard
{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}
we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jsonArray($url, '$..columns');
Table 2. Results
value
[ {""col2"": { ""_id"": ""772col2"" }}, null, null ]
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jsonArray($url, '$..columns', ['ALWAYS_RETURN_LIST']);
Table 3. Results
value
[ {""col2"": { ""_id"": ""772col2"" }} ]
More documentation of apoc.load.jsonArray
apoc.load.json
apoc.load.jsonParams
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import/load-json;"Load JSON
Contents
Procedure Overview
apoc.load.json
apoc.load.jsonParams
apoc.load.jsonArray
apoc.import.json
Importing from a file
JSON-Path
Examples
Import from local file
Import from StackOverflow API
Use JSON Path and Import from StackOverflow API
Import JSON file created by Export JSON procedures
POST a query to the neo4j.com search API
Web APIs are a huge opportunity to access and integrate data from any sources with your graph. Most of them provide the data in JSON format.
The Load JSON procedures retrieve data from URLs or maps and turn it into map value(s) for Cypher to consume. Cypher has support for deconstructing nested documents with dot syntax, slices, UNWIND etc. so it is easy to turn nested data into graphs.
Sources with multiple JSON objects (JSONL,JSON Lines) in a stream, like the streaming Twitter format or the Yelp Kaggle dataset, are also supported,
Procedure Overview
The table below describes the available procedures:
Qualified Name Type
apoc.load.json
apoc.load.json('url',path, config) YIELD value - import JSON as stream of values if the JSON was an array or a single value if it was a map
Procedure
apoc.load.jsonParams
apoc.load.jsonParams('url',{header:value},payload, config) YIELD value - load from JSON URL (e.g. web-api) while sending headers / payload to import JSON as stream of values if the JSON was an array or a single value if it was a map
Procedure
apoc.load.jsonArray
apoc.load.jsonArray('url') YIELD value - load array from JSON URL (e.g. web-api) to import JSON as stream of values
Procedure
apoc.import.json
apoc.import.json(file,config) - imports the json list to the provided file
Procedure
apoc.load.json
This procedure takes a file or HTTP URL and parses the JSON into a map data structure.
signature
apoc.load.json(urlOrKeyOrBinary :: ANY?, path = :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
It supports the following config parameter:
Table 1. Config
name type default description
failOnError
boolean
true
fail if error encountered while parsing JSON
binary
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
If not null, allow to take binary data instead of a file name/url as first parameter. Similar to Binary file example
charset
java.nio.charset.Charset
UTF_8
The optional charset, with binary config not null and with string as file
apoc.load.jsonParams
This procedure takes a file or HTTP URL and parses the JSON into a map data structure. It is a more configurable version of apoc.load.json that enables processing of endpoints that require HTTP headers or JSON payloads.
signature
apoc.load.jsonParams(urlOrKeyOrBinary :: ANY?, headers :: MAP?, payload :: STRING?, path = :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
It supports the following config parameter:
Table 2. Config
name type default description
failOnError
boolean
true
fail if error encountered while parsing JSON
apoc.load.jsonArray
This procedure takes a file or HTTP URL containing a JSON array, and parses it into a stream of maps.
signature
apoc.load.jsonArray(url :: STRING?, path = :: STRING?, config = {} :: MAP?) :: (value :: ANY?)
apoc.import.json
This procedure can be used to import JSON files created by the Export JSON procedures, exported using the config parameter jsonFormat: 'JSON_LINES' (default config).
signature
apoc.import.json(urlOrBinaryFile :: ANY?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
It supports the following config parameters:
Table 3. Config parameters
name type default description
unwindBatchSize
Long
5000
the batch size of the unwind
txBatchSize
Long
5000
the batch size of the transacttion
importIdName
String
neo4jImportId
the name of the property to be populated with the ""id"" field present into the json. For example a row {""type"":""node"", ""labels"":[""Language""], ""id"":""10""}, with importIdName:`foo`, will create a node (:User {foo: ""10""})
nodePropertyMappings
Map
{}
The mapping label/property name/property type for Custom Neo4j types (point date).
i.e. { User: { born: 'Point', dateOfBirth: 'Datetime' } }
relPropertyMappings
Map
{}
The mapping rel type/property name/property type for Custom Neo4j types (point date).
i.e. { KNOWS: { since: 'Datetime' } }
nodePropertyMappings and relPropertyMappings support the following Neo4j types:
Point, Localdate, Localtime, Localdatetime, Duration, offsettime, and Zoneddatetime.
Importing from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
JSON-Path
Using JSON paths gives you a condensed way to read and process sub-documents and sub-values from nested JSON structures. This is especially helpful if you need to skip over unwinding higher-level parent objects in order to access more nested data, or if you need to manipulate values in those substructures.
Rather than passing in a large JSON file and using Cypher to unwind each object and access what you need, you can pass in the file and provide the JSON path to the substructures you need, resulting in shorter statements for nested JSON. The JSON path format follows the Java implementation by Jayway of Stefan Gössner’s JSONPath, providing a consistent syntax for the paths.
Many of the apoc.convert.Json procedures and functions, as well as the apoc.load.json procedure, now accept a json path as last argument. Note that these functions are meant to stream arrays (of values or objects) and maps, not a single value. If a single item containing a single value is specified as the path, the function must try to wrap it and will not return expected results.
There is also the apoc.json.path(json,path) function that takes a JSON string (not map or list) and retrieves values from the json path provided as the second argument. Note: if the JSON is not already in string format, you can use the apoc.convert.toJson function to convert it.
More examples can be found at the links provided above, but let us look at an example of the syntax for JSON paths. The syntax shown below pulls the items array from the StackOverflow API of Neo4j questions and retrieves the array of tags from the first object in the item list.
$.items[0].tags
All of the operators and options for specifying JSON paths are included in the next table.
Table 4. Operators
Operator Description Example
$
The root element to query. This starts all path expressions.
$ - retrieve all data in parent object
@
The current node being processed by a filter predicate.
$.items[?(@.answer_count > 0)] - retrieve the item if it has an answer_count greater than 0
*
Wildcard. Available anywhere a name or numeric are required.
$.items[\*] - retrieve all items in array
..
Deep scan. Available anywhere a name is required.
$..tags[\*] - find substructure named tags and pull all the values
.<name>
Dot-notated child
$.items[0:1].owner.user_id - retrieve user_id for the first item (in the owner object)
[<number> (,<number>)]
Array index or indexes
$.items[0,-1] - retrieve first and last item in array
[start:end]
Array slice operator
$.items[0:5] - retrieve the first through fifth items in the array
[?(<expression>)]
Filter expression. Expression must evaluate to a boolean value.
$.items[?(@.is_answered == true)] - retrieve items where the is_answered field is true
Moreover, we can customize the Json path options, adding the config {pathOptions: LIST OF STRINGS}, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So with the following json:
Json
Copy to Clipboard
{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}
we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json($url, '$..columns');
Table 5. Results
value
[ {""col2"": { ""_id"": ""772col2"" }}, null, null ]
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json($url, '$..columns', ['ALWAYS_RETURN_LIST']);
Table 6. Results
Output
[ {""col2"": { ""_id"": ""772col2"" }} ]
Examples
The following section contains examples showing how to import data from various JSON sources.
Import from local file
person.json contains a JSON document representing a person and their children.
Json
person.json
Copy to Clipboard
{
 ""name"":""Michael"",
 ""age"": 41,
 ""children"": [""Selina"",""Rana"",""Selma""]
}
We’ll place this file into the import directory of our Neo4j instance. Let’s now write a query using the apoc.load.json procedure to explore this file.
Cypher
The following query processes person.json and returns the content as Cypher data structures
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(""file:///person.json"")
YIELD value
RETURN value;
Table 7. Results
value
{name: ""Michael"", children: [""Selina"", ""Rana"", ""Selma""], age: 41}
We get back a map that looks almost the same as the JSON document. We can now extend that query to create a graph based on this JSON file. We’ll create a Person node for Michael and each of his children, and a CHILD_OF relationship from each child to the Michael node.
Cypher
The following creates a graph based on person.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(""file:///person.json"")
YIELD value
MERGE (p:Person {name: value.name})
SET p.age = value.age
WITH p, value
UNWIND value.children AS child
MERGE (c:Person {name: child})
MERGE (c)-[:CHILD_OF]->(p);
The Neo4j Browser visualization below shows the imported graph:
You can use failOnError configuration to handle the result in case of incorrect url or json. For example, with the help of the apoc.when procedure, you can return nothingToDo as result with incorrect url:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(""MY_JSON_URL"", null, {failOnError:false})
YIELD value
WITH collect(value) as values
call apoc.do.when(values = [], ""return 'nothingToDo' as result"", ""return values as result"", {values: values})
YIELD value
UNWIND value[""result""] as result
RETURN result
Import from StackOverflow API
apoc.load.json enables loading JSON data from any file or URL. If the result is a JSON object, it is returned as a singular map. If the result is an array, it is turned into a stream of maps.
StackOverflow provides several APIs, including one for retrieving recent questions and answers. The URL for retrieving the last questions and answers for the neo4j tag is:
Text
Copy to Clipboard
https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf
Since this is a rather long URL string, we can simplify the syntax by configuring aliases in conf/apoc.conf:
Text
apoc.conf
Copy to Clipboard
apoc.json.myJson.url=https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf
The third value in the apoc.json.<alias>.url= effectively defines the variable to be used in apoc.load.json('<alias>',….. With this, the massive JSON url string below can be aliased to a shorter string.
Cypher
Original call with full json url string
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json('https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf')
Cypher
New call with aliased string with full string in apoc.conf
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json('myJson')
Let’s introspect the data that is returned from this end point.
Cypher
The following finds the 5 most recent questions with the neo4j tag on StackOverflow
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf"" AS url
CALL apoc.load.json(url) YIELD value
UNWIND value.items AS item
RETURN item.title, item.owner, item.creation_date, keys(item)
LIMIT 5;
Table 8. Results
item.title item.owner item.creation_date keys(item)
""Cypher patten for getting self related nodes""
{profile_image: ""https://lh3.googleusercontent.com/-1FWbhuaEBiQ/AAAAAAAAAAI/AAAAAAAAAIA/tLM_mEb-8MY/photo.jpg?sz=128"", user_type: ""registered"", user_id: 5730203, link: ""https://stackoverflow.com/users/5730203/asif-ali"", reputation: 1148, display_name: ""Asif Ali"", accept_rate: 90}
1586944991
[""owner"", ""comment_count"", ""link"", ""last_activity_date"", ""creation_date"", ""answer_count"", ""title"", ""question_id"", ""tags"", ""share_link"", ""score"", ""down_vote_count"", ""body_markdown"", ""favorite_count"", ""is_answered"", ""delete_vote_count"", ""close_vote_count"", ""view_count"", ""up_vote_count""]
""Problem connecting .NET Client to Neo4j Desktop version 4""
{profile_image: ""https://www.gravatar.com/avatar/a3fac35d600d1d462d8fc12f3926074c?s=128&d=identicon&r=PG&f=1"", user_type: ""registered"", user_id: 2853912, link: ""https://stackoverflow.com/users/2853912/user2853912"", reputation: 21, display_name: ""user2853912""}
1586938954
[""owner"", ""comment_count"", ""link"", ""last_activity_date"", ""creation_date"", ""answer_count"", ""title"", ""question_id"", ""tags"", ""share_link"", ""score"", ""down_vote_count"", ""body_markdown"", ""favorite_count"", ""is_answered"", ""delete_vote_count"", ""close_vote_count"", ""view_count"", ""up_vote_count""]
""What kind of graph algorithm does Neo4j use?""
{profile_image: ""https://www.gravatar.com/avatar/736024b862a229111d4b3119875753b0?s=128&d=identicon&r=PG&f=1"", user_type: ""registered"", user_id: 4402081, link: ""https://stackoverflow.com/users/4402081/mariappan"", reputation: 7, display_name: ""Mariappan""}
1586901300
[""owner"", ""comment_count"", ""answers"", ""link"", ""last_activity_date"", ""creation_date"", ""answer_count"", ""title"", ""question_id"", ""tags"", ""share_link"", ""score"", ""down_vote_count"", ""body_markdown"", ""favorite_count"", ""is_answered"", ""delete_vote_count"", ""close_vote_count"", ""view_count"", ""up_vote_count""]
""Import json file to Neo4j""
{profile_image: ""https://lh3.googleusercontent.com/-PWDC85Kp2ig/AAAAAAAAAAI/AAAAAAAAAAA/AB6qoq3nhmVZl-_0VDKESOG5MsyHvXnw_A/mo/photo.jpg?sz=128"", user_type: ""registered"", user_id: 9964138, link: ""https://stackoverflow.com/users/9964138/jo%c3%a3o-costa"", reputation: 23, display_name: ""João Costa""}
1586897574
[""owner"", ""comment_count"", ""answers"", ""link"", ""last_activity_date"", ""creation_date"", ""answer_count"", ""title"", ""question_id"", ""tags"", ""share_link"", ""score"", ""down_vote_count"", ""body_markdown"", ""favorite_count"", ""is_answered"", ""delete_vote_count"", ""close_vote_count"", ""view_count"", ""up_vote_count""]
""Difference between Neo4j Graph Algorithms and Graph Data Science""
{profile_image: ""https://i.stack.imgur.com/2rLPZ.jpg?s=128&g=1"", user_type: ""registered"", user_id: 3297954, link: ""https://stackoverflow.com/users/3297954/rotten"", reputation: 1295, display_name: ""rotten"", accept_rate: 75}
1586872077
[""owner"", ""comment_count"", ""answers"", ""link"", ""last_activity_date"", ""creation_date"", ""answer_count"", ""title"", ""question_id"", ""tags"", ""share_link"", ""score"", ""down_vote_count"", ""body_markdown"", ""favorite_count"", ""is_answered"", ""delete_vote_count"", ""close_vote_count"", ""view_count"", ""up_vote_count""]
Let’s now create a Neo4j graph based on those entities.
Cypher
The following creates a graph based on data from the StackOverflow API
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf"" AS url
CALL apoc.load.json(url) YIELD value
UNWIND value.items AS q
MERGE (question:Question {id:q.question_id})
ON CREATE SET question.title = q.title,
              question.share_link = q.share_link,
              question.favorite_count = q.favorite_count

FOREACH (tagName IN q.tags | MERGE (tag:Tag {name:tagName}) MERGE (question)-[:TAGGED]->(tag))
FOREACH (a IN q.answers |
   MERGE (question)<-[:ANSWERS]-(answer:Answer {id:a.answer_id})
   MERGE (answerer:User {id:a.owner.user_id}) ON CREATE SET answerer.display_name = a.owner.display_name
   MERGE (answer)<-[:PROVIDED]-(answerer)
)

 *  NOT q.owner.user_id  
 (owner: {id:q.owner.user_id})    owner.display_name = q.owner.display_name
 (owner)-[:]->(question)
View all (3 more lines)
The Neo4j Browser visualization below shows the imported graph:
Use JSON Path and Import from StackOverflow API
We can narrow down the data that we sift through and import using the JSON path syntax. This will allow us to specify substructures to import and ignore the rest of the data. For this example, we only want to import answers and the members posting those answers.
Cypher
Find StackOverflow answers using JSON path (only retrieve sample of 5)
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf"" AS url
CALL apoc.load.json(url,'$.items[?(@.answer_count>0)].answers[*]') YIELD value
RETURN value LIMIT 5;
Notice that we are only looking at StackOverflow questions that have an answer count greater than 0. That means we are only passing along the question JSON objects that have answers, as the rest do not pertain to our use case. With this in mind, let us import those with this statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://api.stackexchange.com/2.2/questions?pagesize=100&order=desc&sort=creation&tagged=neo4j&site=stackoverflow&filter=!5-i6Zw8Y)4W7vpy91PMYsKM-k9yzEsSC1_Uxlf"" AS url
CALL apoc.load.json(url,'$.items[?(@.answer_count>0)].answers[*]') YIELD value
MERGE (a:Answer {id: value.answer_id})
  ON CREATE SET a.accepted = value.is_accepted,
                a.shareLink = value.share_link,
                a.lastActivityDate = value.last_activity_date,
                a.creationDate = value.creation_date,
                a.title = value.title,
                a.score = value.score
MERGE (q:Question {id: value.question_id})
MERGE (a)-[rel:POSTED_TO]->(q)
WITH a as answer, value.owner as value
MERGE (u:User {userId: value.user_id})
  ON CREATE SET u.displayName = value.display_name,
                u.userType = value.user_type,
                u.reputation = value.reputation,
                u.userLink = value.link
 (u)-[rel2:]->(answer)
View all (4 more lines)
This imports around 78 answers to our graph. We can then explore this graph to find out which users submitted the most answers, have the highest ratings, and more.
Import JSON file created by Export JSON procedures
The apoc.import.json procedure can be used to import JSON files created by the apoc.export.json.* procedures, exported using the config parameter jsonFormat: 'JSON_LINES' (default config).
This procedure supports the following config parameters:
Table 9. Config parameters
name default description
unwindBatchSize
5000
the batch size of the unwind
txBatchSize
5000
the batch size of the transacttion
importIdName
String
neo4jImportId
the name of the property to be populated with the ""id"" field present into the json. For example a row {""type"":""node"", ""labels"":[""Language""], ""id"":""10""}, with importIdName:`foo`, will create a node (:User {foo: ""10""})
nodePropertyMappings
{}
The mapping label/property name/property type for Custom Neo4j types (point date). I.e. { User: { born: 'Point', dateOfBirth: 'Datetime' } }
relPropertyMappings
{}
nodePropertyMappings and relPropertyMappings support the following Neo4j types:
Point
Localdate
Localtime
Localdatetime
Duration
offsettime
Zoneddatetime
all.json contains a subset of Neo4j’s movies graph, and was generated by the Export JSON procedure.
Json
all.json
Copy to Clipboard
{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}
{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}
{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}
{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
We can import this file using apoc.import.json.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.json(""file:///all.json"")
Table 10. Results
file source format nodes relationships properties time rows batchSize batches done data
""file:///all.json""
""file""
""json""
3
1
15
105
4
-1
0
TRUE
NULL
POST a query to the neo4j.com search API
We can perform a POST request to a JSON endpoint by setting the config parameter method to POST. We’ll also use the apoc.convert.toJson function to construct a JSON payload from a Cypher map.
Cypher
The following makes a POST request to neo4j’s search API
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jsonParams(
  ""https://neo4j.com/docs/search/"",
  {method: ""POST""},
  apoc.convert.toJson({query: ""subquery"", version: ""4.0""})
)
Table 11. Results
value
{description: ""The CALL {} clause evaluates a subquery that returns some values."", weight: 0.6460227966308594, title: ""3.16. CALL {} (subquery) - Chapter 3. Clauses"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/call-subquery/""}
{description: ""This section provides examples of queries and Cypher commands that can be used with Neo4j Fabric."", weight: 0.05099273845553398, title: ""7.3. Queries - Chapter 7. Fabric"", uri: ""https://neo4j.com/docs/operations-manual/4.0/fabric/queries/""}
{description: ""WHERE adds constraints to the patterns in a MATCH or OPTIONAL MATCH clause or filters the results of a WITH clause."", weight: 0.03291567042469978, title: ""3.6. WHERE - Chapter 3. Clauses"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/where/""}
{description: ""This appendix contains the recommended style when writing Cypher queries."", weight: 0.031550146639347076, title: ""Appendix A. Cypher styleguide - The Neo4j Cypher Manual v4.0"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/styleguide/""}
{description: ""This section contains information on all the clauses in the Cypher query language."", weight: 0.02944066934287548, title: ""Chapter 3. Clauses - The Neo4j Cypher Manual v4.0"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/clauses/""}
{description: """", weight: 0.01821548491716385, title: ""2.3. Expressions - Chapter 2. Syntax"", uri: ""https://neo4j.com/docs/cypher-manual/4.0/syntax/expressions/""}
Loading Data from Web-APIs
Import CSV
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import/web-apis;"Loading Data from Web-APIs
Contents
Load Single File From Compressed File (zip/tar/tar.gz/tgz)
Using S3 protocol
Using hdfs protocol
Using Google Cloud Storage
failOnError
Supported protocols are file, http, https, s3, gs, hdfs with redirect allowed.
If no procedure is provided, this procedure will try to check whether the URL is actually a file.
As apoc.import.file.use_neo4j_config is enabled, the procedures check whether file system access is allowed and possibly constrained to a specific directory by reading the two configuration parameters dbms.security.allow_csv_import_from_file_urls and server.directories.import respectively. If you want to remove these constraints please set apoc.import.file.use_neo4j_config=false
CALL apoc.load.json('http://example.com/map.json', [path], [config]) YIELD value as person CREATE (p:Person) SET p = person
load from JSON URL (e.g. web-api) to import JSON as stream of values if the JSON was an array or a single value if it was a map
CALL apoc.load.xml('http://example.com/test.xml', ['xPath'], [config]) YIELD value as doc CREATE (p:Person) SET p.name = doc.name
load from XML URL (e.g. web-api) to import XML as single nested map with attributes and _type, _text and _children fields.
Load Single File From Compressed File (zip/tar/tar.gz/tgz)
When loading data from compressed files, we need to put the ! character before the file name or path in the compressed file. For example:
Loading a compressed JSON file
apoc.load.json(""https://github.com/neo4j/apoc/tree/3.4/src/test/resources/testload.tgz?raw=true!person.json"");
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Using hdfs protocol
To use the hdfs protocol we need to download and copy the additional jars not included in the APOC Library. We can download it from this link or locally downloading the apoc repository:
git clone https://github.com/neo4j/apoc
cd neo4j-apoc-procedures/extra-dependencies
./gradlew shadow
and a jar named apoc-hadoop-dependencies-5.0.0-rc01.jar will be created into the neo4j-apoc-procedures/extra-dependencies/hadoop/build/lib folder.
Once that file is downloaded/created, it should be placed in the plugins directory and the Neo4j Server restarted.
Using Google Cloud Storage
In order to use Google Cloud Storage, you need to add the following Google Cloud dependencies in the plugins directory:
api-common-1.8.1.jar
failureaccess-1.0.1.jar
gax-1.48.1.jar
gax-httpjson-0.65.1.jar
google-api-client-1.30.2.jar
google-api-services-storage-v1-rev20190624-1.30.1.jar
google-auth-library-credentials-0.17.1.jar
google-auth-library-oauth2-http-0.17.1.jar
google-cloud-core-1.90.0.jar
google-cloud-core-http-1.90.0.jar
google-cloud-storage-1.90.0.jar
google-http-client-1.31.0.jar
google-http-client-appengine-1.31.0.jar
google-http-client-jackson2-1.31.0.jar
google-oauth-client-1.30.1.jar
grpc-context-1.19.0.jar
guava-28.0-android.jar
opencensus-api-0.21.0.jar
opencensus-contrib-http-util-0.21.0.jar
proto-google-common-protos-1.16.0.jar
proto-google-iam-v1-0.12.0.jar
protobuf-java-3.9.1.jar
protobuf-java-util-3.9.1.jar
threetenbp-1.3.3.jar
We’ve prepared an uber-jar that contains the above dependencies in a single file in order simplify the process. You can download it from here and copy it to your plugins directory.
You can use Google Cloud storage via the following url format:
gs://<bucket_name>/<file_path>
Moreover, you can also specify the authorization type via an additional authenticationType query parameter:
NONE: for public buckets (this is the default behavior if the parameter is not specified)
GCP_ENVIRONMENT: for passive authentication as a service account when Neo4j is running in the Google Cloud
PRIVATE_KEY: for using private keys generated for service accounts (requires setting GOOGLE_APPLICATION_CREDENTIALS environment variable pointing to a private key json file as described here: https://cloud.google.com/docs/authentication#strategies)
Example:
gs://andrea-bucket-1/test-privato.csv?authenticationType=GCP_ENVIRONMENT
failOnError
Adding the config parameter failOnError:false (by default true), will mean that in the case of an error the procedure will not fail, but just return zero rows.
Import
Load JSON
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import;"Import
The APOC library adds support for importing data from various data formats, including JSON, XML, and XLS.
For more information on these procedures, see:
Loading Data from Web-APIs
Load JSON
Import CSV
Load XML
Import GraphML
Configuration Options
Loading Data from Web-APIs
Was this page helpful?"
https://neo4j.com/docs/apoc/5/config;"Configuration Options
Contents
Location of config options
Reference of config options
Location of config options
Configuration options for APOC can be set using:
Option Description
Environment variables
Set via either export key=val or --env settings when used for Docker.
conf/apoc.conf
Located in the same folder as neo4j.conf.
The order of the above table matches the config option precedence. For example, any environment variable setting will override options set in apoc.conf.
APOC internally relies on Apache commons-config for resolving config settings. The meta-configuration is located in src/main/resources/apoc-config.xml.
Reference of config options
Set these config options in $NEO4J_HOME/conf/apoc.conf, or by using environment variables.
All boolean options default to false. This means that they are disabled, unless mentioned otherwise.
Property Description
apoc.export.file.enabled=false/true
Enables writing local files to disk.
apoc.http.timeout.connect=<number> (default 10000)
Sets a specified timeout value, in milliseconds, to be used when communicating with a URI. If the timeout expires before the connection can be established, a Neo.ClientError.Procedure.ProcedureCallFailed exception is raised. A timeout of zero is interpreted as an infinite timeout.
apoc.http.timeout.read=<number> (default 60000)
Sets the read timeout to a specified timeout, in milliseconds. A non-zero value specifies the timeout when reading from a connection established to a resource. If the timeout expires before there is data available for read, a Neo.ClientError.Procedure.ProcedureCallFailed exception is raised. A timeout of zero is interpreted as an infinite timeout.
apoc.import.file.enabled=false/true
Enables reading local files from disk.
apoc.import.file.use_neo4j_config=true/false (default true)
This procedure checks whether file system access is allowed and possibly constrained to a specific directory by reading the two configuration parameters dbms.security.allow_csv_import_from_file_urls and server.directories.import respectively.
apoc.jobs.scheduled.num_threads=number-of-threads (default: number of CPU cores / 4)
Many periodic procedures rely on a scheduled executor that has a pool of threads with a default fixed size. The pool size can be configured using this configuration property.
apoc.jobs.pool.num_threads=number-of-threads (default: number of CPU cores * 2)
Number of threads in the default APOC thread pool used for background executions.
apoc.jobs.queue.size=size of the queue (default: value of apoc.jobs.pool.num_threads * 5)
Size of the ThreadPoolExecutor working queue.
apoc.spatial.geocode.provider=<providername> apoc.spatial.geocode.<providerName>.<key>=<value>
configuration for geocoding providers, keys and values are provider specific, see [spatial].
apoc.trigger.enabled=false/true
Enables triggers.
apoc.xml.parse
Import
Was this page helpful?"
https://neo4j.com/docs/apoc/5/import/import-csv;"Import CSV
Contents
Usage
Examples for apoc.import.csv
Loading nodes
Loading nodes and relationships
CSV files that comply with the Neo4j import tool’s header format can be imported using the apoc.import.csv procedure. This procedure can be used to load small- to medium-sized data sets in an online database. For importing larger data sets, it is recommended to perform a batch import using the import tool, which loads data in bulk to an offline (initially empty) database.
Usage
The parameters of the apoc.import.csv(<nodes>, <relationships>, <config>) procedure are as follows.
The <nodes> parameter is a list, where each element is a map defining a source file (fileName) to be loaded with a set of labels (labels):
name description example
fileName
filename
'file:/students.csv'
labels
set of labels
['Person', 'Student']
The <relationships> parameter is also a list, where each element is a map defining a source file (fileName) to be loaded with a given relationship type (type):
name description example
fileName
filename
'file:/works_at.csv'
type
relationship type
'WORKS_AT'
The <config> parameter is a map containing optional configurations.
The procedure support the following config parameters:
Table 1. Config parameters
name type default description import tool counterpart
delimiter
String
,
delimiter character between columns
--delimiter=,
arrayDelimiter
String
;
delimiter character in arrays
--array-delimiter=;
ignoreDuplicateNodes
Boolean
false
for duplicate nodes, only load the first one and skip the rest (true) or fail the import (false)
--ignore-duplicate-nodes=false
quotationCharacter
String
""
quotation character
--quote='""'
stringIds
Boolean
true
treat ids as strings
--id-type=STRING
skipLines
Integer
1
lines to skip (incl. header)
N/A
ignoreBlankString
Boolean
false
if true ignore properties with a blank string
N/A
ignoreEmptyCellArray
Boolean
false
if true ignore array properties containing a single empty string, like the import tool
N/A
compression
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
Allow taking binary data, either not compressed (value: NONE) or compressed (other values) .
N/A
Examples for apoc.import.csv
Loading nodes
Given the following CSV file and procedure call, the database loads two Person nodes with their name properties set:
persons.csv
name:STRING
John
Jane
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv([{fileName: 'file:/persons.csv', labels: ['Person']}], [], {})
Loading nodes and relationships
Given the following CSV files and procedure call, the database loads two Person nodes and a KNOWS relationship between them (with the value of the since property set). Note that both the field terminators and the array delimiters are changed from the default value, and the CSVs use numeric ids.
persons.csv
:ID|name:STRING|speaks:STRING[]
1|John|en,fr
2|Jane|en,de
knows.csv
:START_ID|:END_ID|since:INT
1|2|2016
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.csv(
  [{fileName: 'file:/persons.csv', labels: ['Person']}],
  [{fileName: 'file:/knows.csv', type: 'KNOWS'}],
  {delimiter: '|', arrayDelimiter: ',', stringIds: false}
)
The loader supports advanced features of the import tool:
ID spaces are supported, using the import tool’s syntax.
Node labels can be specified with the :LABEL field.
Relationship types can be specified with the :TYPE field.
Load JSON
Load XML
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.import/apoc.import.json;"apoc.import.json
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Binary file
Procedure
apoc.import.json(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided JSON file.
Signature
None
Copy to Clipboard
apoc.import.json(urlOrBinaryFile :: ANY?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
urlOrBinaryFile
ANY?
null
config
MAP?
{}
Config parameters
This procedure supports the following config parameters:
Table 1. Config parameters
name type default description
unwindBatchSize
Integer
5000
the batch size of the unwind
txBatchSize
Integer
5000
the batch size of the transacttion
importIdName
String
neo4jImportId
the name of the property to be populated with the ""id"" field present into the json. For example a row {""type"":""node"", ""labels"":[""Language""], ""id"":""10""}, with importIdName:`foo`, will create a node (:User {foo: ""10""})
nodePropertyMappings
Map
{}
The mapping label/property name/property type for Custom Neo4j types (point date). I.e. { User: { born: 'Point', dateOfBirth: 'Datetime' } }
relPropertyMappings
Map
{}
The mapping rel type/property name/property type for Custom Neo4j types (point date). I.e. { KNOWS: { since: 'Datetime' } }
compression
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
Allow taking binary data, either not compressed (value: NONE) or compressed (other values)
cleanup
boolean
false
To remove the ""id"" field present into the json, if present. Note that in this way we cannot import relationship, because we leverage on ""id"" field to connect the nodes.
nodePropFilter
Map<String, List<String>>
{}
A map with the labels as keys, and the list of property keys to filter during the import as values. For example { User: ['name', 'surname'], Another: ['foo']} will skip the properties 'name' and 'surname' of nodes with label 'User' and the property 'foo' of (:Another) nodes.
Note that if a node has multiple labels, in this example (:User:Another {}), all properties of both labels will be filtered, that is 'name', 'surname', and 'foo'.
We can also pass a key _all to filter properties of all nodes, for example {_all: ['myProp']}
relPropFilter
Map<String, List<String>>
{}
A map with the relationship types as keys, and the list of property keys to filter during the import as values. For example { MY_REL: ['foo', 'baz'] } will skip the properties 'foo' and 'baz' of '[:MY_REL]' relationship.
We can also pass a key _all to filter properties of all relationships, for example {_all: ['myProp']}
nodePropertyMappings and relPropertyMappings support the following Neo4j types:
Point
Localdate
Localtime
Localdatetime
Duration
offsettime
Zoneddatetime
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The apoc.import.json procedure can be used to import JSON files created by the apoc.export.json.* procedures, exported using the config parameter jsonFormat: 'JSON_LINES' (default config).
all.json contains a subset of Neo4j’s movies graph, and was generated by apoc.export.json.all.
Json
all.json
Copy to Clipboard
{""type"":""node"",""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}}
{""type"":""node"",""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}
{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}
{""id"":""0"",""type"":""relationship"",""label"":""KNOWS"",""properties"":{""bffSince"":""P5M1DT12H"",""since"":1993},""start"":{""id"":""0"",""labels"":[""User""],""properties"":{""born"":""2015-07-04T19:32:24"",""name"":""Adam"",""place"":{""crs"":""wgs-84"",""latitude"":13.1,""longitude"":33.46789,""height"":null},""age"":42,""male"":true,""kids"":[""Sam"",""Anna"",""Grace""]}},""end"":{""id"":""1"",""labels"":[""User""],""properties"":{""name"":""Jim"",""age"":42}}}
We can import this file using apoc.import.json.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.json(""file:///all.json"")
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""file:///all.json""
""file""
""json""
3
1
15
105
4
-1
0
TRUE
NULL
Binary file
You can also import a file from a binary byte[] not compressed (default value, with config {compression: NONE}) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY). That is:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.json(`binaryFileNotCompressed`, {compression: 'NONE'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.json(`binaryGzipByteArray`, {compression: 'GZIP'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress('{""type"":""node"",""id"":""2"",""labels"":[""User""],""properties"":{""age"":12}}', {compression: 'DEFLATE'}) AS jsonCompressed
CALL apoc.import.json(jsonCompressed, {compression: 'DEFLATE'})
YIELD source, format, nodes, relationships, properties
RETURN source, format, nodes, relationships, properties
Table 3. Results
source format nodes relationships properties
""binary""
""json""
1
0
2
More documentation of apoc.import.json
apoc.import.graphml
apoc.import.xml
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.import/apoc.import.graphml;"apoc.import.graphml
Contents
Signature
Input parameters
Config parameters
source / target config
Output parameters
Reading from a file
Usage Examples
Import simple GraphML file
Import GraphML file created by Export GraphML procedures
Binary file
Round trip separated GraphML files
With custom property key
Procedure
apoc.import.graphml(urlOrBinaryFile Any, config Map<String, Any>) - imports a graph from the provided GraphML file.
Signature
None
Copy to Clipboard
apoc.import.graphml(urlOrBinaryFile :: ANY?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
urlOrBinaryFile
ANY?
null
config
MAP?
null
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
readLabels
Boolean
false
Creates node labels based on the value in the labels property of node elements
defaultRelationshipType
String
RELATED
The default relationship type to use if none is specified in the GraphML file
storeNodeIds
Boolean
false
store the id property of node elements
batchSize
Integer
20000
The number of elements to process per transaction
compression
Enum[NONE, BYTES, GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY]
null
Allow taking binary data, either not compressed (value: NONE) or compressed (other values)
source
Map<String,String>
Empty map
See below
target
Map<String,String>
Empty map
See below
source / target config
Allows the import of relations in case the source and / or target nodes are not present in the file, searching for nodes via a custom label and property. To do this, we can insert into the config map source: {label: '<MY_SOURCE_LABEL>', id: ’<MY_SOURCE_ID>'}` and/or source: {label: '<MY_TARGET_LABEL>', id: ’<MY_TARGET_ID>'}` In this way, we can search start and end nodes via the source and end attribute of edge tag.
For example, with a config map {source: {id: 'myId', label: 'Foo'}, target: {id: 'other', label: 'Bar'}} with a edge row like <edge id=""e0"" source=""n0"" target=""n1"" label=""KNOWS""><data key=""label"">KNOWS</data></edge> we search a source node (:Foo {myId: 'n0'}) and an end node (:Bar {other: 'n1'}). The id key is optional (the default is 'id').
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
Import simple GraphML file
The simple.graphml file contains a graph representation from the GraphML primer.
Xml
simple.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns
     http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
  <graph id=""G"" edgedefault=""undirected"">
    <node id=""n0""/>
    <node id=""n1""/>
    <node id=""n2""/>
    <node id=""n3""/>
    <node id=""n4""/>
    <node id=""n5""/>
    <node id=""n6""/>
    <node id=""n7""/>
    <node id=""n8""/>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  
View all (16 more lines)
Cypher
The following imports a graph based on simple.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""http://graphml.graphdrawing.org/primer/simple.graphml"", {})
If we run this query, we’ll see the following output:
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""http://graphml.graphdrawing.org/primer/simple.graphml""
""file""
""graphml""
11
12
0
618
0
-1
0
TRUE
NULL
We could also copy simple.graphml into Neo4j’s import directory, and import the file from there.
We can then run the import procedure in the following way:
Cypher
The following imports a graph based on simple.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""file://simple.graphml"", {})
The Neo4j Browser visualization below shows the imported graph:
Figure 1. Simple Graph Visualization
Import GraphML file created by Export GraphML procedures
movies.graphml contains a subset of Neo4j’s movies graph, and was generated by the Export GraphML procedure.
Xml
movies.graphml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born""/>
<key id=""name"" for=""node"" attr.name=""name""/>
<key id=""tagline"" for=""node"" attr.name=""tagline""/>
<key id=""label"" for=""node"" attr.name=""label""/>
<key id=""title"" for=""node"" attr.name=""title""/>
<key id=""released"" for=""node"" attr.name=""released""/>
<key id=""roles"" for=""edge"" attr.name=""roles""/>
<key id=""label"" for=""edge"" attr.name=""label""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n188"" labels="":Movie""><data key=""labels"">:Movie</data><data key=""title"">The Matrix</data><data key=""tagline"">Welcome to the Real World</data><data key=""released"">1999</data></node>
<node id=""n189"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1964</data><data key=""name"">Keanu Reeves</data></node>
<node id=""n190"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1967</data><data key=""name"">Carrie-Anne Moss</data></node>
<node id=""n191"" labels="":Person""><data key=""labels"">:Person</data><data key=""born"">1961</data><data key=""name"">Laurence Fishburne</data></node>
:Person1960</data><data key=""name"">Hugo Weaving</data></node>
:Person1967</data><data key=""name"">Lilly Wachowski</data></node>
:Person1965</data><data key=""name"">Lana Wachowski</data></node>
:Person1952</data><data key=""name"">Joel Silver</data></node>
ACTED_IN</data><data key=""roles"">[""Neo""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Trinity""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Morpheus""]</data></edge>
ACTED_IN</data><data key=""roles"">[""Agent Smith""]</data></edge>
DIRECTED</data></edge>
DIRECTED</data></edge>
PRODUCED</data></edge>
View all (14 more lines)
Cypher
The following imports a graph based on movies.graphml
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""movies.graphml"", {})
If we run this query, we’ll see the following output:
Table 3. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""file""
""graphml""
8
7
36
23
0
-1
0
TRUE
NULL
We can run the following query to see the imported graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=()-->()
RETURN p
Table 4. Results
p
({name: ""Laurence Fishburne"", born: ""1961"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Morpheus\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Carrie-Anne Moss"", born: ""1967"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Trinity\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", la bels: "":Movie""})
({name: ""Lana Wachowski"", born: ""1965"", labels: "":Person""})-[:DIRECTED {label: ""DIRECTED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Joel Silver"", born: ""1952"", labels: "":Person""})-[:PRODUCED {label: ""PRODUCED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Lilly Wachowski"", born: ""1967"", labels: "":Person""})-[:DIRECTED {label: ""DIRECTED""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "":Movie""})
({name: ""Keanu Reeves"", born: ""1964"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Neo\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", labels: "": Movie""})
({name: ""Hugo Weaving"", born: ""1960"", labels: "":Person""})-[:ACTED_IN {roles: ""[\""Agent Smith\""]"", label: ""ACTED_IN""}]→({tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999"", la bels: "":Movie""})
The labels defined in the GraphML file have been added to the labels property on each node, rather than being added as a node label. We can set the config property readLabels: true to import native labels:
Cypher
The following imports a graph based on movies.graphml and stores node labels
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(""movies.graphml"", {readLabels: true})
Table 5. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.graphml""
""file""
""graphml""
8
7
21
23
0
-1
0
TRUE
NULL
And now let’s re-run the query to see the imported graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=()-->()
RETURN;
Table 6. Results
p
(:Person {name: ""Lilly Wachowski"", born: ""1967""})-[:DIRECTED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Carrie-Anne Moss"", born: ""1967""})-[:ACTED_IN {roles: ""[\""Trinity\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Hugo Weaving"", born: ""1960""})-[:ACTED_IN {roles: ""[\""Agent Smith\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Laurence Fishburne"", born: ""1961""})-[:ACTED_IN {roles: ""[\""Morpheus\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Keanu Reeves"", born: ""1964""})-[:ACTED_IN {roles: ""[\""Neo\""]""}]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Joel Silver"", born: ""1952""})-[:PRODUCED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
(:Person {name: ""Lana Wachowski"", born: ""1965""})-[:DIRECTED]→(:Movie {tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: ""1999""})
Binary file
You can also import a file from a binary byte[] (not compressed) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(`binaryGzipByteArray`,  {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml(`binaryFileNotCompressed`,  {compression: 'NONE'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress('<?xml version=""1.0"" encoding=""UTF-8""?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<graph id=""G"" edgedefault=""directed"">
<node id=""n0""> <data key=""labels"">:FOO</data><data key=""name"">foo</data> </node>
<node id=""n1""> <data key=""labels"">:BAR</data><data key=""name"">bar</data> <data key=""kids"">[a,b,c]</data> </node>
<edge id=""e0"" source=""n0"" target=""n1""> <data key=""label"">:EDGE_LABEL</data> <data key=""name"">foo</data> </edge>
</graph>
</graphml>', {compression: 'DEFLATE'}) as xmlCompressed
CALL apoc.import.graphml(xmlCompressed,  {compression: 'DEFLATE'})
YIELD source, format, nodes, relationships, properties
RETURN source, format, nodes, relationships, properties
Table 7. Results
source format nodes relationships properties
""binary""
""graphml""
2
1
7
Round trip separated GraphML files
With this dataset:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (f:Foo:Foo2:Foo0 {name:'foo', born:Date('2018-10-10'), place:point({ longitude: 56.7, latitude: 12.78, height: 100 })})-[:KNOWS]->(b:Bar {name:'bar',age:42, place:point({ longitude: 56.7, latitude: 12.78})});
CREATE (:Foo {name: 'zzz'})-[:KNOWS]->(:Bar {age: 0});
CREATE (:Foo {name: 'aaa'})-[:KNOWS {id: 1}]->(:Bar {age: 666});
we can execute these 3 export queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// Foo nodes
call apoc.export.graphml.query('MATCH (start:Foo)-[:KNOWS]->(:Bar) RETURN start', 'queryNodesFoo.graphml', {useTypes: true});

// Bar nodes
call apoc.export.graphml.query('MATCH (:Foo)-[:KNOWS]->(end:Bar) RETURN end', 'queryNodesBar.graphml', {useTypes: true});

// KNOWS rels
MATCH (:Foo)-[rel:KNOWS]->(:Bar)
WITH collect(rel) as rels
call apoc.export.graphml.data([], rels, 'queryRelationship.graphml', {useTypes: true})
YIELD nodes, relationships RETURN nodes, relationships;
In this case we will have these 3 files: .queryNodesFoo.graphml
Xml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""born"" for=""node"" attr.name=""born"" attr.type=""string""/>
<key id=""name"" for=""node"" attr.name=""name"" attr.type=""string""/>
<key id=""place"" for=""node"" attr.name=""place"" attr.type=""string""/>
<key id=""labels"" for=""node"" attr.name=""labels"" attr.type=""string""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n0"" labels="":Foo:Foo0:Foo2""><data key=""labels"">:Foo:Foo0:Foo2</data><data key=""born"">2018-10-10</data><data key=""name"">foo</data><data key=""place"">{""crs"":""wgs-84-3d"",""latitude"":12.78,""longitude"":56.7,""height"":100.0}</data></node>
<node id=""n3"" labels="":Foo""><data key=""labels"">:Foo</data><data key=""name"">zzz</data></node>
<node id=""n5"" labels="":Foo""><data key=""labels"">:Foo</data><data key=""name"">aaa</data></node>
</graph>
</graphml>
Xml
queryNodesBar.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""name"" for=""node"" attr.name=""name"" attr.type=""string""/>
<key id=""place"" for=""node"" attr.name=""place"" attr.type=""string""/>
<key id=""age"" for=""node"" attr.name=""age"" attr.type=""long""/>
<key id=""labels"" for=""node"" attr.name=""labels"" attr.type=""string""/>
<graph id=""G"" edgedefault=""directed"">
<node id=""n1"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""name"">bar</data><data key=""age"">42</data><data key=""place"">{""crs"":""wgs-84"",""latitude"":12.78,""longitude"":56.7,""height"":null}</data></node>
<node id=""n4"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""age"">0</data></node>
<node id=""n6"" labels="":Bar""><data key=""labels"">:Bar</data><data key=""age"">666</data></node>
</graph>
</graphml>
Xml
queryRelationship.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""label"" for=""edge"" attr.name=""label"" attr.type=""string""/>
<key id=""id"" for=""edge"" attr.name=""id"" attr.type=""long""/>
<graph id=""G"" edgedefault=""directed"">
<edge id=""e0"" source=""n0"" target=""n1"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e1"" source=""n3"" target=""n4"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e2"" source=""n5"" target=""n6"" label=""KNOWS""><data key=""label"">KNOWS</data><data key=""id"">1</data></edge>
</graph>
</graphml>
So we can import, in another db, in this way, to recreate the original dataset, using these queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml('queryNodesFoo.graphml', {readLabels: true, storeNodeIds: true});
CALL apoc.import.graphml('queryNodesBar.graphml', {readLabels: true, storeNodeIds: true});
CALL apoc.import.graphml('queryRelationship.graphml', {readLabels: true, source: {label: 'Foo'}, target: {label: 'Bar'}});
Note that we have to execute the import of nodes before, and we used the useTypes: true to import the attribute id of node tags as a property and readLabels to populate nodes with labels.
With custom property key
Otherwise, we can leverage a custom property and avoid importing the id attribute (via useTypes:true) in this way (same dataset and nodes export query as before):
Cypher
Copy to Clipboard
Run in Neo4j Browser
// KNOWS rels
MATCH (:Foo)-[rel:KNOWS]->(:Bar)
WITH collect(rel) as rels
call apoc.export.graphml.data([], rels, 'queryRelationship.graphml',
  {useTypes: true, source: {id: 'name'}, label: {id: 'age'}})
YIELD nodes, relationships RETURN nodes, relationships;
Is strongly recommended using an unique constraint to ensure uniqueness, so in this case for label Foo and property name and for label Bar and property age
The above query generate this rel file:
Xml
queryRelationship.graphml
Copy to Clipboard
<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns=""http://graphml.graphdrawing.org/xmlns"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"">
<key id=""label"" for=""edge"" attr.name=""label"" attr.type=""string""/>
<key id=""id"" for=""edge"" attr.name=""id"" attr.type=""long""/>
<graph id=""G"" edgedefault=""directed"">
<edge id=""e0"" source=""foo"" sourceType=""string"" target=""42"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e1"" source=""zzz"" sourceType=""string"" target=""0"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data></edge>
<edge id=""e2"" source=""aaa"" sourceType=""string"" target=""666"" targetType=""long"" label=""KNOWS""><data key=""label"">KNOWS</data><data key=""id"">1</data></edge>
</graph>
</graphml>
Finally, we can import the files using the same id (name and age) as above:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.graphml('queryNodesFoo.graphml', {readLabels: true});
CALL apoc.import.graphml('queryNodesBar.graphml', {readLabels: true});
CALL apoc.import.graphml('queryRelationship.graphml',
  {readLabels: true, source: {label: 'Foo', id: 'name'}, target: {label: 'Bar', id: 'age'}});
apoc.import.csv
apoc.import.json
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.import/apoc.import.xml;"apoc.import.xml
Contents
Signature
Input parameters
Output parameters
Reading from a file
Usage Examples
Binary file
Procedure
apoc.import.xml(urlOrBinary Any, config Map<String, Any>) - imports a graph from the provided XML file.
Signature
None
Copy to Clipboard
apoc.import.xml(urlOrBinary :: ANY?, config = {} :: MAP?) :: (node :: NODE?)
Input parameters
Name Type Default
urlOrBinary
ANY?
null
config
MAP?
{}
Output parameters
Name Type
node
NODE?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
The examples in this section are based on the Microsoft book.xml file.
Xml
book.xml
Copy to Clipboard
<?xml version=""1.0""?>
<catalog>
   <book id=""bk101"">
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications
      with XML.</description>
   </book>
   <book id=""bk102"">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      <genre>Fantasy</genre>
      5.95
      2000-12-16
      A former architect battles corporate zombies,
...
View all (4 more lines)
This file can be downloaded from GitHub.
We can write the following query to create a graph structure of the Microsoft books XML file.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.xml(
  ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml"",
  {relType:'NEXT_WORD', label:'XmlWord'}
)
YIELD node
RETURN node;
node
(:XmlDocument {_xmlVersion: ""1.0"", _xmlEncoding: ""UTF-8"", url: ""https://raw.githubusercontent.com/neo4j/apoc/5.0/src/test/resources/xml/books.xml""})
The Neo4j Browser visualization below shows the imported graph:
Binary file
You can also import a file from a binary byte[] (not compressed) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.xml(`binaryGzipByteArray`,  {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.import.xml(`binaryFileNotCompressed`,  {compression: 'NONE'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress('<?xml version=""1.0"" encoding=""UTF-8""?>
<parent name=""databases"">
    <child name=""Neo4j"">
        Neo4j is a graph database
    </child>
    <child name=""relational"">
        <grandchild name=""MySQL""><![CDATA[
            MySQL is a database & relational
            ]]>
        </grandchild>
        <grandchild name=""Postgres"">
            Postgres is a relational database
        </grandchild>
    </child>
</parent>', {compression: 'DEFLATE'}) as xmlCompressed
CALL apoc.import.xml(xmlCompressed,  {compression: 'DEFLATE'})
YIELD node
RETURN node
Table 1. Results
node
[source,json] ---- { ""identity"": 11, ""labels"": [ ""XmlDocument"" ], ""properties"": { ""_xmlEncoding"": ""UTF-8"", ""_xmlVersion"": ""1.0"" } } ----
apoc.import.json
apoc.json
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.json;"apoc.json
Qualified Name Type
apoc.json.path
apoc.json.path(json String, path String, pathOptions [String]) - returns the given JSON path.
Function
apoc.import.xml
apoc.json.path
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.json/apoc.json.path;"apoc.json.path
Contents
Signature
Input parameters
Usage Examples
Function
apoc.json.path(json String, path String, pathOptions [String]) - returns the given JSON path.
Signature
None
Copy to Clipboard
apoc.json.path(json :: STRING?, path = $ :: STRING?, pathOptions = null :: LIST? OF STRING?) :: (ANY?)
Input parameters
Name Type Default
json
STRING?
null
path
STRING?
$
pathOptions
LIST? OF STRING?
[]
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Person {json:'{a:[1,2,3]}'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN apoc.json.path(p.json, ""$.a"") AS output;
Table 1. Results
Output
[1, 2, 3]
Moreover, we can customize the Json path options, adding as third parameter (pathOptions) a list of strings, where the strings are based on Enum<Option>. The default value is [""SUPPRESS_EXCEPTIONS"", ""DEFAULT_PATH_LEAF_TO_NULL""]. Note that we can also insert [], that is ""without options"". So we can execute (with default pathOptions):
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.json.path('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$..columns') AS output;
Table 2. Results
Output
[ {""col2"": { ""_id"": ""772col2"" }}, null, null ]
or, with custom path options:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.json.path('{ ""columns"": {
      ""col2"": {
        ""_id"": ""772col2""
      }
    }
}', '$..columns', ['ALWAYS_RETURN_LIST']) AS output;
Table 3. Results
Output
[ {""col2"": { ""_id"": ""772col2"" }} ]
apoc.json
apoc.label
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.label;"apoc.label
Qualified Name Type
apoc.label.exists
apoc.label.exists(node Any, label String) - returns true or false depending on whether or not the given label exists.
Function
apoc.json.path
apoc.label.exists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.label/apoc.label.exists;"apoc.label.exists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.label.exists(node Any, label String) - returns true or false depending on whether or not the given label exists.
Signature
None
Copy to Clipboard
apoc.label.exists(node :: ANY?, label :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
node
ANY?
null
label
STRING?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s1:Student {name: 'Priya'});
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student {name: 'Priya'})
RETURN apoc.label.exists(s1, ""Student"") AS output;
Table 1. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s1:Student {name: 'Priya'})
RETURN apoc.label.exists(s1, ""Teacher"") AS output;
Table 2. Results
output
FALSE
More documentation of apoc.label.exists
apoc.label
apoc.load
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load;"apoc.load
Qualified Name Type
apoc.load.arrow
apoc.load.arrow(file String, config Map<String, Any>) - imports nodes and relationships from the provided arrow file.
Procedure
apoc.load.arrow.stream
apoc.load.arrow.stream(source ByteArray, config Map<String, Any>) - imports nodes and relationships from the provided arrow byte array.
Procedure
apoc.load.json
apoc.load.json(urlOrKeyOrBinary Any, path String, config Map<String, Any>) - imports JSON file as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead.
Procedure
apoc.load.jsonArray
apoc.load.jsonArray(url String, path String, config Map<String, Any>) - loads array from a JSON URL (e.g. web-API) to then import the given JSON file as a stream of values.
Procedure
apoc.load.jsonParams
apoc.load.jsonParams(urlOrKeyOrBinary Any, headers Map<String, Any>, payload String, path String, config Map<String, Any>) - loads parameters from a JSON URL (e.g. web-API) as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead.
Procedure
apoc.load.xml
apoc.load.xml(urlOrBinary Any, path String, config Map<String, Any>, simple Boolean) - loads a single nested map from an XML URL (e.g. web-API).
Procedure
apoc.label.exists
apoc.load.json
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.arrow;"apoc.load.arrow
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.load.arrow(file String, config Map<String, Any>) - imports nodes and relationships from the provided arrow file.
Signature
None
Copy to Clipboard
apoc.load.arrow(file :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
value
MAP?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.load/apoc.load.json;"apoc.load.json
Contents
Input parameters
Output parameters
Reading from a file
Usage Examples
Binary file
Procedure
apoc.load.json(urlOrKeyOrBinary Any, path String, config Map<String, Any>) - imports JSON file as a stream of values if the given JSON file is an array. If the given JSON file is a map, this procedure imports a single value instead. == Signature
None
Copy to Clipboard
apoc.load.json(urlOrKeyOrBinary :: ANY?, path =  :: STRING?, config = {} :: MAP?) :: (value :: MAP?)
Input parameters
Name Type Default
urlOrKeyOrBinary
ANY?
null
path
STRING?
config
MAP?
{}
Output parameters
Name Type
value
MAP?
Reading from a file
By default importing from the file system is disabled. We can enable it by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.enabled=true
If we try to use any of the import procedures without having first set this property, we’ll get the following error message:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your apoc.conf
Import files are read from the import directory, which is defined by the server.directories.import property. This means that any file path that we provide is relative to this directory. If we try to read from an absolute path, such as /tmp/filename, we’ll get an error message similar to the following one:
Failed to invoke procedure: Caused by: java.lang.RuntimeException: Can’t read url or key file:/path/to/neo4j/import/tmp/filename as json: /path/to/neo4j//import/tmp/filename (No such file or directory)
We can enable reading files from anywhere on the file system by setting the following property in apoc.conf:
Properties
apoc.conf
Copy to Clipboard
apoc.import.file.use_neo4j_config=false
Neo4j will now be able to read from anywhere on the file system, so be sure that this is your intention before setting this property.
Usage Examples
person.json contains a JSON document representing a person and their children.
Json
person.json
Copy to Clipboard
{
 ""name"":""Michael"",
 ""age"": 41,
 ""children"": [""Selina"",""Rana"",""Selma""]
}
We’ll place this file into the import directory of our Neo4j instance. Let’s now write a query using the apoc.load.json procedure to explore this file.
The following query processes person.json and returns the content as Cypher data structures
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(""file:///person.json"")
YIELD value
RETURN value;
Table 1. Results
value
{name: ""Michael"", children: [""Selina"", ""Rana"", ""Selma""], age: 41}
We get back a map that looks almost the same as the JSON document. We can now extend that query to create a graph based on this JSON file. We’ll create a Person node for Michael and each of his children, and a CHILD_OF relationship from each child to the Michael node.
Cypher
The following creates a graph based on person.json
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(""file:///person.json"")
YIELD value
MERGE (p:Person {name: value.name})
SET p.age = value.age
WITH p, value
UNWIND value.children AS child
MERGE (c:Person {name: child})
MERGE (c)-[:CHILD_OF]->(p);
The Neo4j Browser visualization below shows the imported graph:
Binary file
You can also import a file from a binary byte[] (not compressed) or a compressed file (allowed compression algos are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY).
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(`binaryGzipByteArray`, '', {compression: 'GZIP'})
or:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.json(`binaryFileNotCompressed`, '', {compression: 'NONE'})
For example, this one works well with apoc.util.compress function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress('{""foo"":[1,2,3]}', {compression: 'DEFLATE'}) as jsonCompressed
CALL apoc.load.json(jsonCompressed, '', {compression: 'DEFLATE'})
YIELD value
RETURN value
Table 2. Results
value
{""foo"": [1, 2, 3] }
More documentation of apoc.load.json
apoc.load
apoc.load.jsonArray
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.delete;"apoc.nodes.delete
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.nodes.delete(nodes Any, batchSize Integer) - deletes all nodes with the given ids.
Signature
None
Copy to Clipboard
apoc.nodes.delete(nodes :: ANY?, batchSize :: INTEGER?) :: (value :: INTEGER?)
Input parameters
Name Type Default
nodes
ANY?
null
batchSize
INTEGER?
null
Output parameters
Name Type
value
INTEGER?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Student {name: 'Alice', score: 71});
CREATE (:Student {name: 'Mark', score: 95});
CREATE (:Student {name: 'Andrea', score: 86});
We can return the internal IDs of these nodes using the id function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
RETURN id(s) AS id;
Table 1. Results
id
3975
3976
3977
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.delete([3975, 3976, 3977], 2);
Table 2. Results
value
3
More documentation of apoc.nodes.delete
apoc.nodes.cycles
apoc.nodes.get
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.get;"apoc.nodes.get
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.nodes.get(nodes Any) - returns all nodes with the given ids.
Signature
None
Copy to Clipboard
apoc.nodes.get(nodes :: ANY?) :: (node :: NODE?)
Input parameters
Name Type Default
nodes
ANY?
null
Output parameters
Name Type
node
NODE?
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Student {name: 'Alice', score: 71});
CREATE (:Student {name: 'Mark', score: 95});
CREATE (:Student {name: 'Andrea', score: 86});
We can return the internal IDs of these nodes using the id function:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
RETURN id(s) AS id;
Table 1. Results
id
3975
3976
3977
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.nodes.get([3975, 3976, 3977]);
Table 2. Results
node
(:Student {name: ""Alice"", score: 71})
(:Student {name: ""Mark"", score: 95})
(:Student {name: ""Andrea"", score: 86})
More documentation of apoc.nodes.get
apoc.nodes.delete
apoc.nodes.group
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.cycles;"apoc.nodes.cycles
Contents
Signature
Input parameters
Config parameters
Output parameters
Usage Examples
Procedure
apoc.nodes.cycles(nodes [Node], config Map<String, Any>) - detects all path cycles in the given node list. This procedure can be limited on relationships as well.
Signature
None
Copy to Clipboard
apoc.nodes.cycles(nodes :: LIST? OF NODE?, config = {} :: MAP?) :: (path :: PATH?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
config
MAP?
{}
Config parameters
Table 1. Config parameters
name type default description
maxDepth
long
Integer.MAX_VALUE
The max number of hops (relationships) to search for cycles.
relTypes
List<String>
[]
The relationship types to detect cycles. By default, all types will be considered.
Output parameters
Name Type
path
PATH?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (m1:Start {bar: 'alpha'}) with m1 CREATE (m1)-[:DEPENDS_ON {id: 0}]->(m2:Module {bar: 'one'})-[:DEPENDS_ON {id: 1}]->(m3:Module {bar: 'two'})-[:DEPENDS_ON {id: 2}]->(m1)  WITH m1, m2, m3 CREATE (m1)-[:DEPENDS_ON {id: 3}]->(m2), (m2)-[:ANOTHER {id: 4}]->(m3), (m2)-[:DEPENDS_ON {id: 5}]->(m3) CREATE (m1)-[:DEPENDS_ON {id: 6}]->(:Module {bar: 'seven'})-[:DEPENDS_ON {id: 7}]->(:Module {bar: 'eight'})-[:DEPENDS_ON {id: 8}]->(m1);
CREATE (m1:Start {bar: 'beta'}) with m1 CREATE (m1)-[:MY_REL {id: 9}]->(m2:Module {bar: 'three'})-[:MY_REL  {id: 10}]->(m3:Module {bar: 'four'})-[:MY_REL {id: 11}]->(m1);
CREATE (m1:Start {bar: 'gamma'}) with m1 CREATE (m1)-[:DEPENDS_ON {id: 12}]->(m2:Module {bar: 'five'})-[:DEPENDS_ON {id: 13}]->(m3:Module {bar: 'six'});
CREATE (m1:Start {bar: 'delta'}) with m1 CREATE (m1)-[:DEPENDS_ON {id: 20}]->(m1);
CREATE (m1:Start {bar: 'epsilon'}) with m1 CREATE (m1)-[:DEPTH_ONE {id: 30}]->(:Module {bar: 'seven'})-[:DEPTH_ONE {id: 31}]->(m1);
The data set above consists in a node alpha with 2 cycles, a node beta with 1 cycles, a gamma node without cycles, a node delta with 1 cycle (with only 1 intermediate node), and a epsilon node with a self-relationship:
We can execute the following query which looks for all the cycles starting from the Start nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m1:Start) WITH collect(m1) as nodes CALL apoc.nodes.cycles(nodes) YIELD path RETURN path
Note that, in case of nodes with double-rels (in this example, between (:Start {bar: 'alpha'}) and (:Module {bar: 'one'}) and between (:Module {bar: 'one'}) and (:Module {bar: 'two'})), only the first cycle found will be considered.
We can also specify a list of relationship types to detect cycles. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m1:Start) WITH collect(m1) as nodes CALL apoc.nodes.cycles(nodes, {relTypes: [""DEPENDS_ON"", ""MY_REL"", ""NOT_EXISTENT""]}) YIELD path RETURN path
Furthermore, we can specify a maxDepth to consider cycles with only n intermediate nodes. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m1:Start) WITH collect(m1) as nodes CALL apoc.nodes.cycles(nodes, {maxDepth: 1}) YIELD path RETURN path
Note that is allowed also a maxDepth: 0, returning only nodes with one or more self relationships:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m1:Start) WITH collect(m1) as nodes CALL apoc.nodes.cycles(nodes, {relTypes: ['DEPENDS_ON'], maxDepth: 0}) YIELD path RETURN path
More documentation of apoc.nodes.cycles
apoc.nodes.collapse
apoc.nodes.delete
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes/apoc.nodes.collapse;"apoc.nodes.collapse
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.nodes.collapse(nodes [Node], config Map<String, Any>) - merges nodes together in the given list. The nodes are then combined to become one node, with all labels of the previous nodes attached to it, and all relationships pointing to it.
Signature
None
Copy to Clipboard
apoc.nodes.collapse(nodes :: LIST? OF NODE?, config = {} :: MAP?) :: (from :: NODE?, rel :: RELATIONSHIP?, to :: NODE?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
config
MAP?
{}
Output parameters
Name Type
from
NODE?
rel
RELATIONSHIP?
to
NODE?
More documentation of apoc.nodes.collapse
apoc.nodes
apoc.nodes.cycles
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.nodes;"apoc.nodes
Qualified Name Type
apoc.nodes.collapse
apoc.nodes.collapse(nodes [Node], config Map<String, Any>) - merges nodes together in the given list. The nodes are then combined to become one node, with all labels of the previous nodes attached to it, and all relationships pointing to it.
Procedure
apoc.nodes.cycles
apoc.nodes.cycles(nodes [Node], config Map<String, Any>) - detects all path cycles in the given node list. This procedure can be limited on relationships as well.
Procedure
apoc.nodes.delete
apoc.nodes.delete(nodes Any, batchSize Integer) - deletes all nodes with the given ids.
Procedure
apoc.nodes.get
apoc.nodes.get(nodes Any) - returns all nodes with the given ids.
Procedure
apoc.nodes.group
apoc.nodes.group(labels [String], groupByProperties [String], aggregations [Map<String, Any>], config Map<String, Any>) - allows for the aggregation of nodes based on the given properties. This procedure returns virtual nodes.
Procedure
apoc.nodes.link
apoc.nodes.link(nodes [Node], type String, config Map<String, Any>) - creates a linked list of the given nodes connected by the given relationship type.
Procedure
apoc.nodes.rels
apoc.nodes.rels(rels Any) - returns all relationships with the given ids.
Procedure
apoc.nodes.connected
apoc.nodes.connected(startNode Node, endNode Node, types String) - returns true when a given node is directly connected to another given node. This function is optimized for dense nodes.
Function
apoc.nodes.isDense
apoc.nodes.isDense(node Node) - returns true if the given node is a dense node.
Function
apoc.nodes.relationship.types
apoc.nodes.relationship.types(nodes Any, types String) - returns a list of distinct relationship types from the given list of nodes.
Function
apoc.nodes.relationships.exist
apoc.nodes.relationships.exist(nodes Any, types String) - returns a boolean based on whether or not the given nodes have the given relationships.
Function
apoc.node.relationships.exist
apoc.nodes.collapse
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.relationships.exist;"apoc.node.relationships.exist
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.relationships.exist(node Node, relTypes String) - returns a boolean based on whether the given node has relationships (or whether the given nodes has relationships of the given type and direction).
Signature
None
Copy to Clipboard
apoc.node.relationships.exist(node :: NODE?, types =  :: STRING?) :: (MAP?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Person60""})
RETURN apoc.node.relationships.exist(p1, ""KNOWS|FOLLOWS"") AS output;
Table 2. Results
output
{KNOWS: TRUE, FOLLOWS: FALSE}
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
RETURN apoc.node.relationships.exist(p1, ""KNOWS>|<FOLLOWS"") AS output;
Table 3. Results
output
{KNOWS>: TRUE, <FOLLOWS: FALSE}
More documentation of apoc.node.relationships.exist
apoc.node.relationship.types
apoc.nodes
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.relationship.types;"apoc.node.relationship.types
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.relationship.types(node Node, relTypes String) - returns a list of distinct relationship types for the given node.
Signature
None
Copy to Clipboard
apoc.node.relationship.types(node :: NODE?, types =  :: STRING?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Person30""})
RETURN apoc.node.relationship.types(p1) AS output;
Table 2. Results
output
[""KNOWS"", ""FOLLOWS""]
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Person30""})
RETURN apoc.node.relationship.types(p1, ""FOLLOWS"") AS output;
Table 3. Results
output
[""FOLLOWS""]
More documentation of apoc.node.relationship.types
apoc.node.relationship.exists
apoc.node.relationships.exist
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.relationship.exists;"apoc.node.relationship.exists
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.relationship.exists(node Node, relTypes String) - returns a boolean based on whether the given node has a relationship (or whether the given node has a relationship of the given type and direction).
Signature
None
Copy to Clipboard
apoc.node.relationship.exists(node :: NODE?, types =  :: STRING?) :: (BOOLEAN?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Michael""})
RETURN apoc.node.relationship.exists(p1) AS output;
Table 2. Results
output
TRUE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Person40""})
RETURN apoc.node.relationship.exists(p1, ""FOLLOWS>"") AS output;
Table 3. Results
output
FALSE
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p1:Person {name: ""Person40""})
RETURN apoc.node.relationship.exists(p1, ""<FOLLOWS"") AS output;
Table 4. Results
output
TRUE
More documentation of apoc.node.relationship.exists
apoc.node.labels
apoc.node.relationship.types
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.labels;"apoc.node.labels
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.labels(node Node) - returns the labels for the given virtual node.
Signature
None
Copy to Clipboard
apoc.node.labels(node :: NODE?) :: (LIST? OF ANY?)
Input parameters
Name Type Default
node
NODE?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Alice', score: 71});
CREATE (s:Student {name: 'Mark', score: 95});
CREATE (s:Student {name: 'Andrea', score: 86});
CREATE (s:Student {name: 'Rajesh', score: 89});
CREATE (s:Student {name: 'Jennifer', score: 96});
CREATE (s:Student {name: 'Katarina', score: 80});
If we create virtual nodes containing students scores, we can use apoc.node.labels to return the labels of those virtual nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.create.vNode(['Score'],{value: s.score})
YIELD node
RETURN node, apoc.node.labels(node) AS labels;
Table 1. Results
node labels
(:Score {value: 71})
[""Score""]
(:Score {value: 95})
[""Score""]
(:Score {value: 86})
[""Score""]
(:Score {value: 89})
[""Score""]
(:Score {value: 96})
[""Score""]
(:Score {value: 80})
[""Score""]
More documentation of apoc.node.labels
apoc.node.id
apoc.node.relationship.exists
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.id;"apoc.node.id
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.id(node Node) - returns the id for the given virtual node.
Signature
None
Copy to Clipboard
apoc.node.id(node :: NODE?) :: (INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
Usage Examples
The examples in this section are based on the following graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student {name: 'Alice', score: 71});
CREATE (s:Student {name: 'Mark', score: 95});
CREATE (s:Student {name: 'Andrea', score: 86});
CREATE (s:Student {name: 'Rajesh', score: 89});
CREATE (s:Student {name: 'Jennifer', score: 96});
CREATE (s:Student {name: 'Katarina', score: 80});
If we create virtual nodes containing students scores, we can use apoc.node.id to return the node id of those virtual nodes:
Cypher
apoc.create.vNode Procedure
Copy to Clipboard
Run in Neo4j Browser
MATCH (s:Student)
CALL apoc.create.vNode(['Score'],{value: s.score})
YIELD node
RETURN node, apoc.node.id(node) AS nodeId;
Table 1. Results
node nodeId
(:Score {value: 71})
-13
(:Score {value: 95})
-14
(:Score {value: 86})
-15
(:Score {value: 89})
-16
(:Score {value: 96})
-17
(:Score {value: 80})
-18
More documentation of apoc.node.id
apoc.node.degree.out
apoc.node.labels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.degree.out;"apoc.node.degree.out
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.degree.out(node Node, relTypes String) - returns the total number of outgoing relationships from the given node.
Signature
None
Copy to Clipboard
apoc.node.degree.out(node :: NODE?, types =  :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Person1""})
RETURN apoc.node.degree.out(p) AS output;
Table 2. Results
output
0
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree.out(p) AS output;
Table 3. Results
output
152
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree.out(p, ""KNOWS"") AS output;
Table 4. Results
output
101
More documentation of apoc.node.degree.out
apoc.node.degree.in
apoc.node.id
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.degree.in;"apoc.node.degree.in
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.degree.in(node Node, relTypes String) - returns the total number of incoming relationships to the given node.
Signature
None
Copy to Clipboard
apoc.node.degree.in(node :: NODE?, types =  :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree.in(p) AS output;
Table 2. Results
output
0
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Person1""})
RETURN apoc.node.degree.in(p) AS output;
Table 3. Results
output
2
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Person1""})
RETURN apoc.node.degree.in(p, ""KNOWS"") AS output;
Table 4. Results
output
1
More documentation of apoc.node.degree.in
apoc.node.degree
apoc.node.degree.out
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node/apoc.node.degree;"apoc.node.degree
Contents
Signature
Input parameters
Usage Examples
Function
apoc.node.degree(node Node, relTypes String) - returns the total degrees for the given node.
Signature
None
Copy to Clipboard
apoc.node.degree(node :: NODE?, types =  :: STRING?) :: (INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (michael:Person {name: ""Michael""})
WITH michael
CALL {
    WITH michael
    UNWIND range(0, 100) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:KNOWS]-(p)
    RETURN count(*) AS friends
}

CALL {
    WITH michael
    UNWIND range(0, 50) AS id
    MERGE (p:Person {name: ""Person"" + id})
    MERGE (michael)-[:FOLLOWS]-(p)
      follows
}

 friends, follows;
View all (4 more lines)
Table 1. Results
friends follows
101
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree(p) AS output;
Table 2. Results
output
152
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree(p, ""FOLLOWS>"") AS output;
Table 3. Results
output
51
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Michael""})
RETURN apoc.node.degree(p, ""<KNOWS"") AS output;
Table 4. Results
output
0
More documentation of apoc.node.degree
apoc.node
apoc.node.degree.in
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.node;"apoc.node
Qualified Name Type
apoc.node.degree
apoc.node.degree(node Node, relTypes String) - returns the total degrees for the given node.
Function
apoc.node.degree.in
apoc.node.degree.in(node Node, relTypes String) - returns the total number of incoming relationships to the given node.
Function
apoc.node.degree.out
apoc.node.degree.out(node Node, relTypes String) - returns the total number of outgoing relationships from the given node.
Function
apoc.node.id
apoc.node.id(node Node) - returns the id for the given virtual node.
Function
apoc.node.labels
apoc.node.label(node Node) - returns the labels for the given virtual node.
Function
apoc.node.relationship.exists
apoc.node.relationship.exists(node Node, relTypes String) - returns a boolean based on whether the given node has a relationship (or whether the given node has a relationship of the given type and direction).
Function
apoc.node.relationship.types
apoc.node.relationship.types(node Node, relTypes String) - returns a list of distinct relationship types for the given node.
Function
apoc.node.relationships.exist
apoc.node.relationships.exist(node Node, relTypes String) - returns a boolean based on whether the given node has relationships (or whether the given nodes has relationships of the given type and direction).
Function
apoc.neighbors.tohop.count
apoc.node.degree
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.neighbors/apoc.neighbors.tohop.count;"apoc.neighbors.tohop.count
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.neighbors.tohop.count(node Node, relTypes String, distance Integer) - returns the count of all nodes connected by the given relationships in the pattern within the specified distance.
Signature
None
Copy to Clipboard
apoc.neighbors.tohop.count(node :: NODE?, types =  :: STRING?, distance = 1 :: INTEGER?) :: (value :: INTEGER?)
Input parameters
Name Type Default
node
NODE?
null
types
STRING?
distance
INTEGER?
1
Output parameters
Name Type
value
INTEGER?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person {name: ""Mark""})
MERGE (praveena:Person {name: ""Praveena""})
MERGE (joe:Person {name: ""Joe""})
MERGE (lju:Person {name: ""Lju""})
MERGE (michael:Person {name: ""Michael""})
MERGE (emil:Person {name: ""Emil""})
MERGE (ryan:Person {name: ""Ryan""})

MERGE (ryan)-[:FOLLOWS]->(joe)
MERGE (joe)-[:FOLLOWS]->(mark)
MERGE (mark)-[:FOLLOWS]->(emil)
MERGE (michael)-[:KNOWS]-(emil)
MERGE (michael)-[:KNOWS]-(lju)
MERGE (michael)-[:KNOWS]-(praveena)
MERGE (emil)-[:FOLLOWS]->(joe)
MERGE (praveena)-[:FOLLOWS]->(joe)
This procedure computes a node’s neighborhood up to a specified hop count.
The following returns the number of people that Praveena FOLLOWS up to 2 hops:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.neighbors.tohop.count(p, ""FOLLOWS>"", 2)
YIELD value
RETURN value
Table 1. Results
value
2
If we also want to know which nodes are in our neighborhood, we can do that as well. See apoc.neighbors.tohop.
More documentation of apoc.neighbors.tohop.count
apoc.neighbors.tohop
apoc.node
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.md5;"apoc.util.md5
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.md5(values [Any]) - returns the MD5 checksum of the concatenation of all string values in the given list. MD5 is a weak hashing algorithm which is unsuitable for cryptographic use-cases.
Signature
None
Copy to Clipboard
apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.md5([""Michael""]) AS output;
Table 1. Results
output
""3e06fa3927cbdf4e9d93ba4541acce86""
More documentation of apoc.util.md5
apoc.util.decompress
apoc.util.sha1
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.decompress;"apoc.util.decompress
Contents
Signature
Input parameters
Config parameters
Usage Examples
Function
apoc.util.decompress(data ByteArray, config Map<String, Any>) - unzips the given byte array.
Signature
None
Copy to Clipboard
apoc.util.decompress(data :: BYTEARRAY?, config = {} :: MAP?) :: (STRING?)
Input parameters
Name Type Default
data
BYTEARRAY?
null
config
MAP?
{}
Config parameters
The procedure support the following config parameters:
Table 1. Config parameters
name type default description
compression
enum
GZIP
The compression algorithm used to decompress the byte[]
Accepted values are: GZIP, BZIP2, DEFLATE, BLOCK_LZ4, FRAMED_SNAPPY, NONE (that is conversion to string without compression)
charset
enum
UTF-8
The charset used to decompress the byte[]
Accepted values are: UTF-8, UTF-16, UTF-16BE, UTF-16LE, UTF-32, US-ASCII, ISO-8859-1
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress(""Mätrix II 哈哈😄123"", {charset: 'UTF-32'}) as compressed
RETURN apoc.util.decompress(compressed, {charset: 'UTF-32'}) AS value
Table 2. Results
value
""Mätrix II 哈哈😄123""
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress(""Mätrix II 哈哈😄123"", {compression: 'DEFLATE'}) as compressed
RETURN apoc.util.decompress(compressed, {compression: 'DEFLATE'}) AS value
Table 3. Results
value
""Mätrix II 哈哈😄123""
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.util.compress(""Example"", {charset: 'UTF-16'}) as compressed
RETURN apoc.util.decompress(compressed, {charset: 'UTF-16'}) AS value
Table 4. Results
value
""Example""
apoc.util.compress
apoc.util.md5
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.sha1;"apoc.util.sha1
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.sha1(values [Any]) - returns the SHA1 of the concatenation of all string values in the given list.
Signature
None
Copy to Clipboard
apoc.util.sha1(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha1([""Michael""]) AS output;
Table 1. Results
output
""f8c38b2167c0ab6d7c720e47c2139428d77d8b6a""
More documentation of apoc.util.sha1
apoc.util.md5
apoc.util.sha256
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.sha256;"apoc.util.sha256
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.sha256(values [Any]) - returns the SHA256 of the concatenation of all string values in the given list.
Signature
None
Copy to Clipboard
apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha256([""Michael""]) AS output;
Table 1. Results
output
""f089eaef57aba315bc0e1455985c0c8e40c247f073ce1f4c5a1f8ffde8773176""
apoc.util.sha1
apoc.util.sha384
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.sha384;"apoc.util.sha384
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.sha384(values [Any]) - returns the SHA384 of the concatenation of all string values in the given list.
Signature
None
Copy to Clipboard
apoc.util.sha384(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha384([""Michael""]) AS output;
Table 1. Results
output
""906f4540978fe52137d82a4b1061fc8a281a8393881b2a47403fdaf559c9f7f16838784825ff326f6243e518066daee8""
apoc.util.sha256
apoc.util.sha512
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.util/apoc.util.sha512;"apoc.util.sha512
Contents
Signature
Input parameters
Usage Examples
Function
apoc.util.sha512(values [Any]) - returns the SHA512 of the concatenation of all string values in the list.
Signature
None
Copy to Clipboard
apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha512([""Michael""]) AS output;
Table 1. Results
output
""e70bdf701bd91b2357ec83bd6fb74d602f2883beb6934de21c9bffa0fc0717a9ee6ef9327387ac2b3735a3be9796754a03941059405955999e2302b0ae7efeb6""
apoc.util.sha384
apoc.util.validatePredicate
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.uuidHexToBase64;"apoc.create.uuidHexToBase64
Contents
Signature
Input parameters
Usage Examples
Function
apoc.create.uuidHexToBase64(uuid String) - takes the given UUID represented as a hexadecimal string and returns it encoded with base64.
Signature
None
Copy to Clipboard
apoc.create.uuidHexToBase64(uuidHex :: STRING?) :: (STRING?)
Input parameters
Name Type Default
uuidHex
STRING?
null
Usage Examples
The following converts a UUID encoded with Base64 to HEX representation:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.create.uuidHexToBase64(""bd7f1d33-95e8-49ed-a576-873f433304cb"") as output;
Table 1. Results
Output
""vX8dM5XoSe2ldoc/QzMEyw""
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock/apoc.lock.rels;"apoc.lock.rels
Contents
Signature
Input parameters
Procedure
apoc.lock.rels(rels [Rels]) - acquires a write lock on the given relationships.
Signature
None
Copy to Clipboard
apoc.lock.rels(rels :: LIST? OF RELATIONSHIP?) :: VOID
Input parameters
Name Type Default
rels
LIST? OF RELATIONSHIP?
null
More documentation of apoc.lock.rels
apoc.lock.read.rels
apoc.log
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock/apoc.lock.read.rels;"apoc.lock.read.rels
Contents
Signature
Input parameters
Procedure
apoc.lock.read.rels(rels [Rel]) - acquires a read lock on the given relationships.
Signature
None
Copy to Clipboard
apoc.lock.read.rels(rels :: LIST? OF RELATIONSHIP?) :: VOID
Input parameters
Name Type Default
rels
LIST? OF RELATIONSHIP?
null
More documentation of apoc.lock.read.rels
apoc.lock.read.nodes
apoc.lock.rels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.lock/apoc.lock.read.nodes;"apoc.lock.read.nodes
Contents
Signature
Input parameters
Procedure
apoc.lock.read.nodes(nodes [Node]) - acquires a read lock on the given nodes.
Signature
None
Copy to Clipboard
apoc.lock.read.nodes(nodes :: LIST? OF NODE?) :: VOID
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
More documentation of apoc.lock.read.nodes
apoc.lock.nodes
apoc.lock.read.rels
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.log;"apoc.log
Qualified Name Type
apoc.log.stream
apoc.log.stream(path String, config Map<String, Any>) - returns the file contents from the given log, optionally returning only the last n lines. This procedure requires users to have an admin role.
Procedure
apoc.lock.rels
apoc.log.stream
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.log/apoc.log.stream;"apoc.log.stream
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.log.stream(path String, config Map<String, Any>) - returns the file contents from the given log, optionally returning only the last n lines. This procedure requires users to have an admin role.
Signature
None
Copy to Clipboard
apoc.log.stream(path :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, line :: STRING?, path :: STRING?)
Input parameters
Name Type Default
path
STRING?
null
config
MAP?
{}
Output parameters
Name Type
lineNo
INTEGER?
line
STRING?
path
STRING?
Usage Examples
To use the apoc.log.stream procedure the user must have the admin role, otherwise the procedure throws with an error permission has not been granted for user 'xxx', to make sure that only the Administrator can access the logs, which could provide sensitive data.
The following returns the last 10 lines in neo4j.log:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.log.stream(""neo4j.log"", {last: 10});
Table 1. Results
lineNo line path
12827
""2020-11-16 11:12:10.197+0000 WARN The client is unauthorized due to authentication failure.""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12826
""2020-11-16 11:12:09.967+0000 WARN The client is unauthorized due to authentication failure.""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12825
""2020-11-16 09:43:39.332+0000 INFO Called db.clearQueryCaches(): Query cache already empty.""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12824
""2020-11-12 16:18:44.392+0000 INFO LabelPropagationStreamProc: overall memory usage 27 KiB""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12823
""2020-11-12 16:18:44.391+0000 INFO [neo4j.BoltWorker-5 [bolt] [/127.0.0.1:51704] ] LabelPropagation :: Finished""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12822
""2020-11-12 16:18:44.391+0000 INFO [gds-3] LabelPropagation 99%""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12821
""2020-11-12 16:18:44.391+0000 INFO [gds-3] LabelPropagation 98%""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12820
""2020-11-12 16:18:44.391+0000 INFO [gds-3] LabelPropagation 97%""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12819
""2020-11-12 16:18:44.391+0000 INFO [gds-3] LabelPropagation 96%""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
12818
""2020-11-12 16:18:44.391+0000 INFO [gds-3] LabelPropagation 95%""
""/home/markhneedham/.local/share/neo4j-relate/dbmss/dbms-8c3607ed-fe8d-42de-9be9-075d86babcfe/logs/neo4j.log""
apoc.log
apoc.map
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.stream.query;"apoc.export.arrow.stream.query
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.stream.query(query Any, config Map<String, Any>) - exports the given Cypher query as an arrow byte array.
Signature
None
Copy to Clipboard
apoc.export.arrow.stream.query(query :: ANY?, config = {} :: MAP?) :: (value :: BYTEARRAY?)
Input parameters
Name Type Default
query
ANY?
null
config
MAP?
null
Output parameters
Name Type
value
BYTEARRAY?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.stream.all;"apoc.export.arrow.stream.all
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.stream.all(config Map<String, Any>) - exports the full database as an arrow byte array.
Signature
None
Copy to Clipboard
apoc.export.arrow.stream.all(config = {} :: MAP?) :: (value :: BYTEARRAY?)
Input parameters
Name Type Default
config
MAP?
null
Output parameters
Name Type
value
BYTEARRAY?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.query;"apoc.export.arrow.query
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.query(file String, query String, config Map<String, Any>) - exports the results from the given Cypher query as an arrow file.
Signature
None
Copy to Clipboard
apoc.export.arrow.query(file :: STRING?, query :: STRING?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: ANY?)
Input parameters
Name Type Default
file
STRING?
null
query
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.csv.data;"apoc.export.csv.data
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.csv.data(nodes [Node], rels [Rel], file String, config Map<String, Any>) - exports the given nodes and relationships to the provided CSV file.
Signature
None
Copy to Clipboard
apoc.export.csv.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
nodes
LIST? OF NODE?
null
rels
LIST? OF RELATIONSHIP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.csv.data procedure exports the specified nodes and relationships to a CSV file or as a stream.
The following query exports all nodes with the :Person label with a name property that starts with L to the file movies-l.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.name STARTS WITH ""L""
WITH collect(person) AS people
CALL apoc.export.csv.data(people, [], ""movies-l.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-l.csv""
""data: nodes(3), rels(0)""
""csv""
3
0
6
2
3
20000
1
TRUE
NULL
The contents of movies-l.csv are shown below:
Csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""_start"",""_end"",""_type""
""191"","":Person"",""1961"",""Laurence Fishburne"",,,
""193"","":Person"",""1967"",""Lilly Wachowski"",,,
""194"","":Person"",""1965"",""Lana Wachowski"",,,
The following query exports all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-actedIn.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.csv.data(people + movies, actedInRels, ""movies-actedIn.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
Table 2. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-actedIn.csv""
""data: nodes(5), rels(4)""
""csv""
5
4
15
2
9
20000
1
TRUE
NULL
The contents of movies-actedIn.csv are shown below:
Csv
Copy to Clipboard
""_id"",""_labels"",""born"",""name"",""released"",""tagline"",""title"",""_start"",""_end"",""_type"",""roles""
""189"","":Person"",""1964"",""Keanu Reeves"","""","""","""",,,,
""190"","":Person"",""1967"",""Carrie-Anne Moss"","""","""","""",,,,
""191"","":Person"",""1961"",""Laurence Fishburne"","""","""","""",,,,
""192"","":Person"",""1960"",""Hugo Weaving"","""","""","""",,,,
""188"","":Movie"","""","""",""1999"",""Welcome to the Real World"",""The Matrix"",,,,
,,,,,,,""189"",""188"",""ACTED_IN"",""[""""Neo""""]""
,,,,,,,""190"",""188"",""ACTED_IN"",""[""""Trinity""""]""
,,,,,,,""191"",""188"",""ACTED_IN"",""[""""Morpheus""""]""
,,,,,,,""192"",""188"",""ACTED_IN"",""[""""Agent Smith""""]""
The following query returns a stream of all ACTED_IN relationships and the nodes with Person and Movie labels on either side of that relationship in the data column:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[actedIn:ACTED_IN]->(movie:Movie)
WITH collect(DISTINCT person) AS people, collect(DISTINCT movie) AS movies, collect(actedIn) AS actedInRels
CALL apoc.export.csv.data(people + movies, actedInRels, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data
Table 3. Results
file nodes relationships properties data
NULL
5
4
15
""\""_id\"",\""_labels\"",\""born\"",\""name\"",\""released\"",\""tagline\"",\""title\"",\""_start\"",\""_end\"",\""_type\"",\""roles\"" \""190\"",\"":Person\"",\""1967\"",\""Carrie-Anne Moss\"",\""\"",\""\"",\""\"",,,, \""189\"",\"":Person\"",\""1964\"",\""Keanu Reeves\"",\""\"",\""\"",\""\"",,,, \""191\"",\"":Person\"",\""1961\"",\""Laurence Fishburne\"",\""\"",\""\"",\""\"",,,, \""192\"",\"":Person\"",\""1960\"",\""Hugo Weaving\"",\""\"",\""\"",\""\"",,,, \""188\"",\"":Movie\"",\""\"",\""\"",\""1999\"",\""Welcome to the Real World\"",\""The Matrix\"",,,, ,,,,,,,\""189\"",\""188\"",\""ACTED_IN\"",\""[\""\""Neo\""\""]\"" ,,,,,,,\""190\"",\""188\"",\""ACTED_IN\"",\""[\""\""Trinity\""\""]\"" ,,,,,,,\""191\"",\""188\"",\""ACTED_IN\"",\""[\""\""Morpheus\""\""]\"" ,,,,,,,\""192\"",\""188\"",\""ACTED_IN\"",\""[\""\""Agent Smith\""\""]\"" ""
More documentation of apoc.export.csv.data
apoc.export.csv.all
apoc.export.csv.graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.csv.graph;"apoc.export.csv.graph
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.csv.graph(graph Map<String, Any>, file String, config Map<String, Any>) - exports the given graph to the provided CSV file.
Signature
None
Copy to Clipboard
apoc.export.csv.graph(graph :: MAP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
graph
MAP?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
See here for more documentation of apoc.export.csv.graph.
apoc.export.csv.data
apoc.export.csv.query
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.csv.query;"apoc.export.csv.query
Contents
Signature
Input parameters
Output parameters
Usage Examples
Procedure
apoc.export.csv.query(query String, file String, config Map<String, Any>) - exports the results from running the given Cypher query to the provided CSV file.
Signature
None
Copy to Clipboard
apoc.export.csv.query(query :: STRING?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
query
STRING?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.csv.query procedure exports the results of a Cypher query to a CSV file or as a stream.
The following query exports all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-directed.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[:DIRECTED]->(movie)
      RETURN person.name AS name, person.born AS born,
             movie.title AS title, movie.tagline AS tagline, movie.released AS released"" AS query
CALL apoc.export.csv.query(query, ""movies-directed.csv"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-directed.csv""
""statement: cols(5)""
""csv""
0
0
10
3
2
20000
1
TRUE
NULL
The contents of movies-directed.csv are shown below:
Csv
Copy to Clipboard
""name"",""born"",""role"",""title"",""tagline"",""released""
""Lilly Wachowski"",""1967"","""",""The Matrix"",""Welcome to the Real World"",""1999""
""Lana Wachowski"",""1965"","""",""The Matrix"",""Welcome to the Real World"",""1999""
The following query returns a stream of all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[:DIRECTED]->(movie)
      RETURN person.name AS name, person.born AS born,
             movie.title AS title, movie.tagline AS tagline, movie.released AS released"" AS query
CALL apoc.export.csv.query(query, null, {stream: true})
YIELD file, nodes, relationships, properties, data
RETURN file, nodes, relationships, properties, data;
Table 2. Results
file nodes relationships properties data
NULL
0
0
10
""\""name\"",\""born\"",\""title\"",\""tagline\"",\""released\"" \""Lilly Wachowski\"",\""1967\"",\""The Matrix\"",\""Welcome to the Real World\"",\""1999\"" \""Lana Wachowski\"",\""1965\"",\""The Matrix\"",\""Welcome to the Real World\"",\""1999\"" ""
More documentation of apoc.export.csv.query
apoc.export.csv.graph
apoc.export.cypher.all
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.clonePathToVirtual;"apoc.create.clonePathToVirtual
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.create.clonePathToVirtual(path Path) - takes the given path and returns a virtual representation of it.
Signature
None
Copy to Clipboard
apoc.create.clonePathToVirtual(path :: PATH?) :: (path :: PATH?)
Input parameters
Name Type Default
path
PATH?
null
Output parameters
Name Type
path
PATH?
More documentation of apoc.create.clonePathToVirtual
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.warmup;"apoc.warmup
Qualified Name Type
apoc.warmup.run
apoc.warmup.run(loadProperties Boolean, loadDynamicProperties Boolean, loadIndexes Boolean) - loads all nodes and relationships in the database into memory.
Procedure
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.graph;"apoc.export.arrow.graph
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.graph(file String, graph Any, config Map<String, Any>) - exports the given graph as an arrow file.
Signature
None
Copy to Clipboard
apoc.export.arrow.graph(file :: STRING?, graph :: ANY?, config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: ANY?)
Input parameters
Name Type Default
file
STRING?
null
graph
ANY?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.clonePathsToVirtual;"apoc.create.clonePathsToVirtual
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.create.clonePathsToVirtual(paths [Path]) - takes the given paths and returns a virtual representation of them.
Signature
None
Copy to Clipboard
apoc.create.clonePathsToVirtual(paths :: LIST? OF PATH?) :: (path :: PATH?)
Input parameters
Name Type Default
paths
LIST? OF PATH?
null
Output parameters
Name Type
path
PATH?
More documentation of apoc.create.clonePathsToVirtual
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.create/apoc.create.uuidBase64;"apoc.create.uuidBase64
Contents
Signature
Usage Examples
Function
apoc.create.uuidBase64() - returns a UUID encoded with base64.
Signature
None
Copy to Clipboard
apoc.create.uuidBase64() :: (STRING?)
Usage Examples
The following generates a new UUID encoded with Base64:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.create.uuidBase64() as output;
Table 1. Results
Output
""vX8dM5XoSe2ldoc/QzMEyw""
Was this page helpful?"
https://neo4j.com/docs/apoc/5/overview/apoc.export/apoc.export.arrow.stream.graph;"apoc.export.arrow.stream.graph
Contents
Signature
Input parameters
Output parameters
Procedure
apoc.export.arrow.stream.graph(graph Any, config Map<String, Any>) - exports the given graph as an arrow byte array.
Signature
None
Copy to Clipboard
apoc.export.arrow.stream.graph(graph :: ANY?, config = {} :: MAP?) :: (value :: BYTEARRAY?)
Input parameters
Name Type Default
graph
ANY?
null
config
MAP?
null
Output parameters
Name Type
value
BYTEARRAY?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.metrics/apoc.metrics.storage;"apoc.metrics.storage
Contents
Signature
Input parameters
Output parameters
Procedure Apoc Extended
apoc.metrics.storage(directorySetting) - retrieve storage metrics about the devices Neo4j uses for data storage. directorySetting may be any valid neo4j directory setting name, such as 'server.directories.data'. If null is provided as a directorySetting, you will get back all available directory settings. For a list of available directory settings, see the Neo4j operations manual reference on configuration settings. Directory settings are not paths, they are a neo4j.conf setting key name
Signature
None
Copy to Clipboard
apoc.metrics.storage(directorySetting :: STRING?) :: (setting :: STRING?, freeSpaceBytes :: INTEGER?, totalSpaceBytes :: INTEGER?, usableSpaceBytes :: INTEGER?, percentFree :: FLOAT?)
Input parameters
Name Type Default
directorySetting
STRING?
null
Output parameters
Name Type
setting
STRING?
freeSpaceBytes
INTEGER?
totalSpaceBytes
INTEGER?
usableSpaceBytes
INTEGER?
percentFree
FLOAT?
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.export/apoc.export.xls.all;"apoc.export.xls.all
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Usage Examples
Procedure Apoc Extended
apoc.export.xls.all(file,config) - exports whole database as xls to the provided file
Signature
None
Copy to Clipboard
apoc.export.xls.all(file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Install Dependencies
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.xls.all procedure exports the whole database to an XLS file.
The following query exports the whole database to the file movies.xls:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.export.xls.all(""movies.xls"", {});
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies.xls""
""database: nodes(8), rels(7)""
""xls""
8
7
21
102
15
20000
1
TRUE
NULL
movies.xls contains individual sheets for each node label and relationship type. In this case, it contains the following sheets:
Movie
Person
ACTED_IN
DIRECTED
PRODUCED
We can query the contents of those sheets using apoc.load.xls. Let’s have a look at a couple of the sheets:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies.xls"", ""Movie"");
Table 2. Results
lineNo list map
0
[0, 1999, ""Welcome to the Real World"", ""The Matrix""]
{tagline: ""Welcome to the Real World"", <nodeId>: 0, title: ""The Matrix"", released: 1999}
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies.xls"", ""ACTED_IN"");
Table 3. Results
lineNo list map
0
[0, 1, 0, ""Neo""]
{<startNodeId>: 1, <endNodeId>: 0, <relationshipId>: 0, roles: ""Neo""}
1
[1, 2, 0, ""Trinity""]
{<startNodeId>: 2, <endNodeId>: 0, <relationshipId>: 1, roles: ""Trinity""}
2
[2, 3, 0, ""Morpheus""]
{<startNodeId>: 3, <endNodeId>: 0, <relationshipId>: 2, roles: ""Morpheus""}
3
[3, 4, 0, ""Agent Smith""]
{<startNodeId>: 4, <endNodeId>: 0, <relationshipId>: 3, roles: ""Agent Smith""}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.gephi;"apoc.gephi
Qualified Name Type
apoc.gephi.add
apoc.gephi.add(url-or-key, workspace, data, weightproperty, ['exportproperty']) | streams passed in data to Gephi
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.mongodb;"apoc.mongodb
Qualified Name Type
apoc.mongodb.get.byObjectId
apoc.mongodb.get.byObjectId(hostOrKey, db, collection, objectIdValue, config(default:{})) - get the document by Object id value
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.custom;"apoc.custom
Qualified Name Type
apoc.custom.declareFunction
apoc.custom.declareFunction(signature, statement, forceSingle, description) - register a custom cypher function
Procedure
apoc.custom.declareProcedure
apoc.custom.declareProcedure(signature, statement, mode, description) - register a custom cypher procedure
Procedure
apoc.custom.list
apoc.custom.list() - provide a list of custom procedures/function registered
Procedure
apoc.custom.removeFunction
apoc.custom.removeFunction(name, type) - remove the targeted custom function
Procedure
apoc.custom.removeProcedure
apoc.custom.removeProcedure(name) - remove the targeted custom procedure
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.uuid;"apoc.uuid
Qualified Name Type
apoc.uuid.install
CALL apoc.uuid.install(label, {addToExistingNodes: true/false, uuidProperty: 'uuid'}) yield label, installed, properties, batchComputationResult | it will add the uuid transaction handler for the provided label and uuidProperty, in case the UUID handler is already present it will be replaced by the new one
Procedure
apoc.uuid.list
CALL apoc.uuid.list() yield label, installed, properties | provides a list of all the uuid handlers installed with the related configuration
Procedure
apoc.uuid.remove
CALL apoc.uuid.remove(label) yield label, installed, properties | remove previously added uuid handler and returns uuid information. All the existing uuid properties are left as-is
Procedure
apoc.uuid.removeAll
CALL apoc.uuid.removeAll() yield label, installed, properties | it removes all previously added uuid handlers and returns uuids information. All the existing uuid properties are left as-is
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.bolt;"apoc.bolt
Qualified Name Type
apoc.bolt.execute
apoc.bolt.execute(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for reads and writes
Procedure
apoc.bolt.load
apoc.bolt.load(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for read
Procedure
apoc.bolt.load.fromLocal
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.export;"apoc.export
Qualified Name Type
apoc.export.xls.all
apoc.export.xls.all(file,config) - exports whole database as xls to the provided file
Procedure
apoc.export.xls.data
apoc.export.xls.data(nodes,rels,file,config) - exports given nodes and relationships as xls to the provided file
Procedure
apoc.export.xls.graph
apoc.export.xls.graph(graph,file,config) - exports given graph object as xls to the provided file
Procedure
apoc.export.xls.query
apoc.export.xls.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as xls to the provided file
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.export/apoc.export.xls.query;"apoc.export.xls.query
Contents
Signature
Input parameters
Output parameters
Install Dependencies
Usage Examples
Procedure Apoc Extended
apoc.export.xls.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as xls to the provided file
Signature
None
Copy to Clipboard
apoc.export.xls.query(query :: STRING?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)
Input parameters
Name Type Default
query
STRING?
null
file
STRING?
null
config
MAP?
null
Output parameters
Name Type
file
STRING?
source
STRING?
format
STRING?
nodes
INTEGER?
relationships
INTEGER?
properties
INTEGER?
time
INTEGER?
rows
INTEGER?
batchSize
INTEGER?
batches
INTEGER?
done
BOOLEAN?
data
STRING?
Install Dependencies
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
CREATE
(Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),
(Carrie)-[:ACTED_IN {roles:['Trinity']}]->(TheMatrix),
(Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix),
(Hugo)-[:ACTED_IN {roles:['Agent Smith']}]->(TheMatrix),
(LillyW)-[:DIRECTED]->(TheMatrix),
(LanaW)-[:DIRECTED]->(TheMatrix),
(JoelS)-[:PRODUCED]->(TheMatrix);
The Neo4j Browser visualization below shows the imported graph:
The apoc.export.xls.query procedure exports the results of a Cypher query to a XLS file.
The following query exports all DIRECTED relationships and the nodes with Person and Movie labels on either side of that relationship to the file movies-directed.csv:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""MATCH path = (person:Person)-[:DIRECTED]->(movie)
      RETURN person.name AS name, person.born AS born,
             movie.title AS title, movie.tagline AS tagline, movie.released AS released"" AS query
CALL apoc.export.xls.query(query, ""movies-directed.xls"", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;
Table 1. Results
file source format nodes relationships properties time rows batchSize batches done data
""movies-directed.xls""
""statement: cols(5)""
""xls""
0
0
0
12
0
20000
1
TRUE
NULL
movies-directed.xls contains one sheet with the name Sheet0.
We can query the contents of this sheet using apoc.load.xls. Let’s have a look at a couple of the sheets:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls(""file://movies-directed.xls"", ""Sheet0"");
Table 2. Results
lineNo list map
0
[""Lilly Wachowski"", 1967, ""The Matrix"", ""Welcome to the Real World"", 1999]
{name: ""Lilly Wachowski"", tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999, born: 1967}
1
[""Lana Wachowski"", 1965, ""The Matrix"", ""Welcome to the Real World"", 1999]
{name: ""Lana Wachowski"", tagline: ""Welcome to the Real World"", title: ""The Matrix"", released: 1999, born: 1965}
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.metrics;"apoc.metrics
Qualified Name Type
apoc.metrics.get
apoc.metrics.get(metricName, {}) - retrieve a system metric by its metric name. Additional configuration options may be passed matching the options available for apoc.load.csv.
Procedure
apoc.metrics.list
apoc.metrics.list() - get a list of available metrics
Procedure
apoc.metrics.storage
apoc.metrics.storage(directorySetting) - retrieve storage metrics about the devices Neo4j uses for data storage. directorySetting may be any valid neo4j directory setting name, such as 'server.directories.data'. If null is provided as a directorySetting, you will get back all available directory settings. For a list of available directory settings, see the Neo4j operations manual reference on configuration settings. Directory settings are not paths, they are a neo4j.conf setting key name
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.model;"apoc.model
Qualified Name Type
apoc.model.jdbc
apoc.model.jdbc('key or url', {schema:'<schema>', write: <true/false>, filters: { tables:[], views: [], columns: []}) YIELD nodes, relationships - load schema from relational database
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.nlp;"apoc.nlp
Qualified Name Type
apoc.nlp.aws.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
apoc.nlp.aws.entities.stream
Returns a stream of entities for provided text
Procedure
apoc.nlp.aws.keyPhrases.graph
Creates a (virtual) key phrases graph for provided text
Procedure
apoc.nlp.aws.keyPhrases.stream
Returns a stream of key phrases for provided text
Procedure
apoc.nlp.aws.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
apoc.nlp.aws.sentiment.stream
Returns stream of sentiment for items in provided text
Procedure
apoc.nlp.azure.entities.stream
Provides a entity analysis for provided text
Procedure
apoc.nlp.azure.keyPhrases.graph
Creates a (virtual) key phrase graph for provided text
Procedure
apoc.nlp.azure.keyPhrases.stream
Provides a entity analysis for provided text
Procedure
apoc.nlp.azure.sentiment.graph
Creates a (virtual) sentiment graph for provided text
Procedure
apoc.nlp.azure.sentiment.stream
Provides a sentiment analysis for provided text
Procedure
apoc.nlp.gcp.classify.graph
Classifies a document into categories.
Procedure
apoc.nlp.gcp.classify.stream
Classifies a document into categories.
Procedure
apoc.nlp.gcp.entities.graph
Creates a (virtual) entity graph for provided text
Procedure
apoc.nlp.gcp.entities.stream
Returns a stream of entities for provided text
Procedure
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.data;"apoc.data
Qualified Name Type
apoc.data.email
apoc.data.email('email_address') as {personal,user,domain} - extract the personal name, user and domain as a map
Function
Was this page helpful?"
https://neo4j.com/labs/apoc/5/overview/apoc.monitor;"apoc.monitor
Qualified Name Type
apoc.monitor.ids
apoc.monitor.ids() returns the object ids in use for this neo4j instance
Procedure
apoc.monitor.kernel
apoc.monitor.kernel() returns informations about the neo4j kernel
Procedure
apoc.monitor.store
apoc.monitor.store() returns informations about the sizes of the different parts of the neo4j graph store
Procedure
apoc.monitor.tx
apoc.monitor.tx() returns informations about the neo4j transaction manager
Procedure
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying;"Advanced Graph Querying
The procedures in this chapter enable the querying of graph data when pure Cypher isn’t enough. For more information on how to use these procedures, see:
Path Expander Overview
Expand paths
Expand paths with config
Expand to nodes in a subgraph
Expand to subgraph
Expand a spanning tree
Neighbor Functions
Path Manipulation
Relationship Querying
Node Querying
Parallel Node Search
Sigmoid & Hyperbolic Operations
Path Expander Overview
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/expand-spanning-tree;"Expand a spanning tree
Contents
Procedure Overview
Configuration parameters
Relationship Filters
Label Filters
Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Sequences of relationship types
Expands a spanning tree reachable from start node following relationships to max-level adhering to the label filters. The paths returned collectively form a spanning tree.
This procedure has the same behaviour as Expand paths with config with the config uniqueness: ""NODE_GLOBAL"".
Procedure Overview
The procedure is described below:
Qualified Name Type
apoc.path.spanningTree
apoc.path.spanningTree(startNode <id>|Node|list, {maxLevel,relationshipFilter,labelFilter,bfs:true, filterStartNode:false, limit:-1, optional:false, endNodes:[], terminatorNodes:[], sequence, beginSequenceAtStart:true}) yield path - expand a spanning tree reachable from start node following relationships to max-level adhering to the label filters
Procedure
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal. Must be 0 or 1 if specified
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given. If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
It also has the following fixed parameter:
Table 2. Config parameters
name type default description
uniqueness
String
NODE_GLOBAL
the strategy to use when expanding relationships in a traversal. NODE_GLOBAL means that a node cannot be traversed more than once. This is what the legacy traversal framework does.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the spanning tree starting from Praveena and traversing the KNOWS relationship type for 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Praveena.
Figure 2. Spanning tree from Praveena
The spanning tree contains 4 nodes apart from Praveena. Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re also included in the spanning tree.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns the spanning tree starting from Praveena and traversing the KNOWS relationship type for 1 to 2 hops, only includin Engineering nodes
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Praveena to engineering nodes.
Figure 3. Spanning tree from Praveena to engineering nodes
We lose Lju and Stefan from the spanning tree because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia.
Figure 4. Spanning tree from Alicia
This query returns paths to 11 of the 12 people in the graph, which indicates that Alicia is very well connected.
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia terminating at Engineering nodes.
Figure 5. Spanning tree from Alicia terminating at Engineering nodes
Our spanning tree has been reduced to only 3 other nodes apart from Alicia. But this query doesn’t capture the complete spanning tree from Alicia containing nodes with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns the spanning tree starting from Alicia and traversing the FOLLOWS or KNOWS relationship type for 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia to Engineering nodes.
Figure 6. Spanning tree from Alicia to Engineering nodes
The spanning tree now also reaches Martin, via a relationship from Zhen.
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want the returned spanning tree to stop as soon as the Mark, Joe, Zhen, or Praveena nodes are reached. We can do that by passing those nodes to the terminatorNodes parameter.
Cypher
The following returns the spanning tree of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (terminator:Person)
WHERE terminator.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(terminator) AS terminatorNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: terminatorNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the spanning tree in Spanning tree from Alicia, terminating at Mark, Joe, Zhen, or Rik.
Figure 7. Spanning tree from Alicia, terminating at Mark, Joe, Zhen, or Rik
Mark and Joe are included in the spanning tree, but Rik and Zhen can’t be reached. This could be because there is no path to Zhen and Rik that doesn’t go through Mark and Joe, or it could mean that there’s no path based on the other traversal criteria.
We can find out whether Mark, Joe, Zhen, or Rik are reachable by passing these nodes to the endNodes parameter.
Cypher
The following returns the spanning tree of people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, ending as soon as Mark, Joe, Zhen, or Rik nodes are reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (end:Person)
WHERE end.name IN [""Mark"", ""Joe"", ""Zhen"", ""Rik""]
WITH p, collect(end) AS endNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: endNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Alicia, ending at Mark, Joe, Zhen, or Rik.
Figure 8. Spanning tree from Alicia, ending at Mark, Joe, Zhen, or Rik
Our spanning tree now includes Joe, Mark, and Zhen, but Rik is still unreachable.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns the spanning tree reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes must only include Mark, Jonny, or Zhen
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Jonny"", ""Mark"", ""Zhen""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning Tree from Alicia where paths to nodes include Mark, Jonny, or Zhen.
Figure 9. Spanning Tree from Alicia where paths to nodes include Mark, Jonny, or Zhen
Only Jonny can be reached. We can therefore infer that Mark and Zhen are only reachable via another node that wasn’t include in the whitelist.
A blacklist is used to exclude nodes from the paths that lead to reachable nodes. If we want to return nodes that are reachable without going through Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns the spanning tree reachable by the FOLLOWS or KNOWS relationship types at 1 to 3 hops from Alicia, where the paths to those nodes do not go through Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.spanningTree(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Alicia where paths to nodes can’t go via Joe.
Figure 10. Spanning tree from Alicia where paths to nodes can’t go via Joe
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the reachable nodes by following the FOLLOWS and KNOWS relationship types alternately from Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.spanningTree(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path;
We can see a Neo4j Browser visualization of the returned spanning tree in Spanning tree from Joe via alternate FOLLOWS and KNOWS relationship types.
Figure 11. Spanning tree from Joe via alternate FOLLOWS and KNOWS relationship types
Expand to subgraph
Neighbor Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/graph-querying/expand-paths-config;"Expand paths with config
Contents
Procedure Overview
Configuration parameters
Relationship Filters
Label Filters
Uniqueness
Specifying Sequences of node labels and relationship types
Examples
Relationship Type and Node Label filters
Terminator Nodes and End Nodes
Whitelist Nodes and Blacklist Nodes
Breadth First Search and Depth First Search
Uniqueness
Sequences of relationship types
Sequences of node labels
The expand paths with config procedure enables powerful variable length path traversals with fine grained control over the traversals. For a more basic version of the algorithm where fine grained control over traversals isn’t required, see Expand paths.
Procedure Overview
The procedure is described below:
Qualified Name Type
apoc.path.expandConfig
apoc.path.expandConfig(startNode <id>|Node|list, {minLevel,maxLevel,uniqueness,relationshipFilter,labelFilter,uniqueness:'RELATIONSHIP_PATH',bfs:true, filterStartNode:false, limit:-1, optional:false, endNodes:[], terminatorNodes:[], sequence, beginSequenceAtStart:true}) yield path - expand from start node following the given relationships from min to max-level adhering to the label filters.
Procedure
Configuration parameters
The procedures support the following config parameters:
Table 1. Config parameters
name type default description
minLevel
Long
-1
the minimum number of hops in the traversal
maxLevel
Long
-1
the maximum number of hops in the traversal
relationshipFilter
String
null
the relationship types and directions to traverse.
See Relationship Filters.
labelFilter
String
null
the node labels to traverse.
See Label Filters.
sequence
String
null
comma-separated alternating label and relationship filters, for each step in a repeating sequence. If present, labelFilter, and relationshipFilter are ignored, as this takes priority.
See Specifying Sequences of node labels and relationship types.
beginSequenceAtStart
Boolean
true
starts matching sequences of node labels and/or relationship types (defined in relationshipFilter, labelFilter, or sequences) one node away from the start node.
uniqueness
String
RELATIONSHIP_PATH
the strategy to use when expanding relationships in a traversal.
See Uniqueness.
bfs
Boolean
true
use Breadth First Search when traversing. Uses Depth First Search if set to false
filterStartNode
Boolean
false
whether the labelFilter and sequence apply to the start node of the expansion.
limit
Long
-1
limit the number of paths returned. When using bfs:true, this has the effect of returning paths to the n nearest nodes with labels in the termination or end node filter, where n is the limit given.
optional
Boolean
false
is path expansion optional? If set to true, a null value is yielded whenever the expansion would normally eliminate rows due to no results.
endNodes
List<Node>
null
only these nodes can end returned paths, and expansion will continue past these nodes, if possible.
terminatorNodes
List<Node>
null
Only these nodes can end returned paths, and expansion won’t continue past these nodes.
whitelistNodes
List<Node>
null
Only these nodes are allowed in the expansion (though endNodes and terminatorNodes will also be allowed, if present).
blacklistNodes
List<Node>
null
None of the paths returned will include these nodes.
Relationship Filters
The syntax for relationship filters is described below:
Syntax: [<]RELATIONSHIP_TYPE1[>]|[<]RELATIONSHIP_TYPE2[>]|…
input type direction
LIKES>
LIKES
OUTGOING
<FOLLOWS
FOLLOWS
INCOMING
KNOWS
KNOWS
BOTH
>
any type
OUTGOING
<
any type
INCOMING
Label Filters
The syntax for label filters is described below:
Syntax: [+-/>]LABEL1|LABEL2|*|…
input result
-Foe
blacklist filter - No node in the path will have a label in the blacklist.
+Friend
whitelist filter - All nodes in the path must have a label in the whitelist (exempting termination and end nodes, if using those filters). If no whitelist operator is present, all labels are considered whitelisted.
/Friend
termination filter - Only return paths up to a node of the given labels, and stop further expansion beyond it. Termination nodes do not have to respect the whitelist. Termination filtering takes precedence over end node filtering.
>Friend
end node filter - Only return paths up to a node of the given labels, but continue expansion to match on end nodes beyond it. End nodes do not have to respect the whitelist to be returned, but expansion beyond them is only allowed if the node has a label in the whitelist.
Label filter operator precedence and behavior
Multiple label filter operators are allowed at the same time. Take the following example:
labelFilter:'+Person|Movie|-SciFi|>Western|/Romance'
If we work through this label filter, we can see that:
:Person and :Movie labels are whitelisted
:SciFi is blacklisted
:Western is an end node label
:Romance is as a termination label.
The precedence of operator evaluation isn’t dependent upon their location in the labelFilter but is fixed:
Blacklist filter -, termination filter /, end node filter >, whitelist filter +.
This means:
No blacklisted label - will ever be present in the nodes of paths returned, even if the same label (or another label of a node with a blacklisted label) is included in another filter list.
If the termination filter / or end node filter > is used, then only paths up to nodes with those labels will be returned as results. These end nodes are exempt from the whitelist filter.
If a node is a termination node /, no further expansion beyond the node will occur.
The whitelist only applies to nodes up to but not including end nodes from the termination or end node filters. If no end node or termination node operators are present, then the whitelist applies to all nodes of the path.
If no whitelist operators are present in the labelFilter, this is treated as if all labels are whitelisted.
Uniqueness
Uniqueness of nodes and relationships guides the expansion and the returned results. The table below describes the available values:
value description
RELATIONSHIP_PATH
For each returned node there’s a (relationship wise) unique path from the start node to it. This is Cypher’s default expansion mode.
NODE_GLOBAL
A node cannot be traversed more than once. This is what the legacy traversal framework does.
NODE_LEVEL
Entities on the same level are guaranteed to be unique.
NODE_PATH
For each returned node there’s a unique path from the start node to it.
NODE_RECENT
This is like NODE_GLOBAL, but only guarantees uniqueness among the most recent visited nodes, with a configurable count. Traversing a huge graph is quite memory intensive in that it keeps track of all the nodes it has visited. For huge graphs a traverser can hog all the memory in the JVM, causing OutOfMemoryError. Together with this Uniqueness you can supply a count, which is the number of most recent visited nodes. This can cause a node to be visited more than once, but scales infinitely.
RELATIONSHIP_GLOBAL
A relationship cannot be traversed more than once, whereas nodes can.
RELATIONSHIP_LEVEL
Entities on the same level are guaranteed to be unique.
RELATIONSHIP_RECENT
Same as for NODE_RECENT, but for relationships.
NONE
No restriction (the user will have to manage it)
Specifying Sequences of node labels and relationship types
Path expander procedures can expand on repeating sequences of labels, relationship types, or both. Sequences can be defined as follows:
If only using label sequences, use the labelFilter, but use commas to separate the filtering for each step in the repeating sequence.
If only using relationship sequences, use the relationshipFilter, but use commas to separate the filtering for each step of the repeating sequence.
If using sequences of both relationships and labels, use the sequence parameter.
Usage config param description syntax explanation
label sequences only
labelFilter
Same syntax and filters, but uses commas (,) to separate the filters for each step in the sequence.
labelFilter:'Post|-Blocked,Reply,>Admin'
Start node must be a :Post node that isn’t :Blocked, next node must be a :Reply, and the next must be an :Admin, then repeat if able. Only paths ending with the :Admin node in that position of the sequence will be returned.
relationship sequences only
relationshipFilter
Same syntax, but uses commas (,) to separate the filters for each relationship traversal in the sequence.
relationshipFilter:'NEXT>,<FROM,POSTED>|REPLIED>'
Expansion will first expand NEXT> from the start node, then <FROM, then either POSTED> or REPLIED>, then repeat if able.
sequences of both labels and relationships
sequence
A string of comma-separated alternating label and relationship filters, for each step in a repeating sequence. The sequence should begin with a label filter, and end with a relationship filter. If present, labelFilter, and relationshipFilter are ignored, as this takes priority.
sequence:'Post|-Blocked, NEXT>, Reply, <FROM, >Admin, POSTED>|REPLIED>'
Combines the behaviors above.
There are some uses cases where the sequence does not begin at the start node, but at one node distant.
The config parameter beginSequenceAtStart toggles this behavior. Its default value is true. If set to false, this changes the expected values for labelFilter, relationshipFilter, and sequence as noted below:
sequence altered behavior example explanation
labelFilter
The start node is not considered part of the sequence. The sequence begins one node off from the start node.
beginSequenceAtStart:false, labelFilter:'Post|-Blocked,Reply,>Admin'
The next node(s) out from the start node begins the sequence (and must be a :Post node that isn’t :Blocked), and only paths ending with Admin nodes returned.
relationshipFilter
The first relationship filter in the sequence string will not be considered part of the repeating sequence, and will only be used for the first relationship from the start node to the node that will be the actual start of the sequence.
beginSequenceAtStart:false, relationshipFilter:'FIRST>,NEXT>,<FROM,POSTED>|REPLIED>'
FIRST> will be traversed just from the start node to the node that will be the start of the repeating NEXT>,<FROM,POSTED>|REPLIED> sequence.
sequence
Combines the above two behaviors.
beginSequenceAtStart:false, sequence:'FIRST>, Post|-Blocked, NEXT>, Reply, <FROM, >Admin, POSTED>|REPLIED>'
Combines the behaviors above.
Sequence tips
Label filtering in sequences work together with the endNodes+terminatorNodes, though inclusion of a node must be unanimous.
If you need to limit the number of times a sequence repeats, this can be done with the maxLevel config param (multiply the number of iterations with the size of the nodes in the sequence).
Examples
The examples in this section are based on the following sample graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (mark:Person:DevRel {name: ""Mark""})
MERGE (lju:Person:DevRel {name: ""Lju""})
MERGE (praveena:Person:Engineering {name: ""Praveena""})
MERGE (zhen:Person:Engineering {name: ""Zhen""})
MERGE (martin:Person:Engineering {name: ""Martin""})
MERGE (joe:Person:Field {name: ""Joe""})
MERGE (stefan:Person:Field {name: ""Stefan""})
MERGE (alicia:Person:Product {name: ""Alicia""})
MERGE (jake:Person:Product {name: ""Jake""})
MERGE (john:Person:Product {name: ""John""})
MERGE (jonny:Person:Sales {name: ""Jonny""})
MERGE (anthony:Person:Sales {name: ""Anthony""})
MERGE (rik:Person:Sales {name: ""Rik""})

MERGE (zhen)-[:KNOWS]-(stefan)
 (zhen)-[:]-(lju)
 (zhen)-[:]-(praveena)
 (zhen)-[:]-(martin)
 (mark)-[:]-(jake)
 (alicia)-[:]-(jake)
 (jonny)-[:]-(anthony)
 (john)-[:]-(rik)

 (alicia)-[:]->(joe)
 (joe)-[:]->(mark)
 (joe)-[:]->(praveena)
 (joe)-[:]->(zhen)
 (mark)-[:]->(stefan)
 (stefan)-[:]->(joe)
 (praveena)-[:]->(joe)
 (lju)-[:]->(jake)
 (alicia)-[:]->(jonny)
 (zhen)-[:]->(john)
 (anthony)-[:]->(joe)
View all (20 more lines)
The Neo4j Browser visualization below shows the sample graph:
Figure 1. Sample Graph
The KNOWS relationship type is considered to be bidirectional, where if Zhen knows Stefan, we can imply that Stefan knows Zhen. When using the KNOWS relationship we will ignore the direction.
The FOLLOWS relationship has a direction, so we will specify a direction when we use it.
Relationship Type and Node Label filters
Let’s start by expanding paths from the Praveena node. We only want to consider the KNOWS relationship type, so we’ll specify that as the relationshipFilter parameter.
Cypher
The following returns the paths to people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 2. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
Praveena only has a direct KNOWS relationship to Zhen, but Zhen has KNOWS relationships to 3 other people, which means they’re 2 hops away from Praveena.
We can also provide a node label filter to restrict the nodes that are returned. If we want to only return paths where every node has the Engineering label, we’ll provide the value +Engineering to the labelFilter parameter.
Cypher
The following returns paths containing only Engineering people that Praveena KNOWS from 1 to 2 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS"",
 labelFilter: ""+Engineering"",
    minLevel: 1,
    maxLevel: 2
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 3. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
1
(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
We lose the paths that ended with Lju and Stefan because neither of those nodes had the Engineering label.
We can specify multiple relationship types. The following query starts from the Alicia node, and then expands the FOLLOWS and KNOWS relationships:
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 4. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This query returns 19 paths, Alicia is very well connected!
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia.
Figure 2. Paths from Alicia
We can also specify traversal termination criteria using label filters. If we wanted to terminate a traversal as soon as the traversal encounters a node containing the Engineering label, we can use the /Engineering node filter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as a node with the Engineering label is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: ""/Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 5. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
We’re now down to only two paths. But this query doesn’t capture all of the paths from Alicia that end in a node with the Engineering label. We can use the >Engineering node filter to define a traversal that:
only returns paths that terminate at nodes with the Engineering label
continues expansion to end nodes after that, looking for more paths that end with the Engineering label
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end with a node with the Engineering label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    labelFilter: "">Engineering"",
    minLevel: 1,
    maxLevel: 3
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 6. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Our query now also returns paths going through Praveena and Zhen, one going to Martin, and other others going back to Zhen and Praveena!
Terminator Nodes and End Nodes
As well as specifying terminator and end labels for traversals, we can also specify terminator and end nodes.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to stop as soon as the Joe node is encountered, which we can do by passing the Joe node to the terminatorNodes parameter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, terminating as soon as Joe is reached
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    terminatorNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 7. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
Alicia FOLLOWS Joe, but there’s also another path that goes via Jonny and Anthony.
The terminator nodes approach doesn’t necessarily find all the paths that exist between Alicia and Joe. There might be other paths that go through the Joe node twice. We can find these paths by passing the Joe node to the endNodes parameter. If we use this parameter, all returned paths will end at the Joe node, but expansion will continue past this node to try and find other paths that end at Joe.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, where paths end when they reach Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    endNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 8. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
We’ve got the two paths we got with the terminator nodes approach, from Alicia to Joe, and from Alicia to Jonny to Jonny to Joe. But we’ve also got an extra path that goes from Alicia to Joe to Praveena to Joe.
Whitelist Nodes and Blacklist Nodes
Whitelist and blacklist nodes can also be specified.
Let’s build on the previous query that found people that Alicia KNOWS or FOLLOWS. We want any returned paths to only include the nodes Mark, Joe, Zhen, and Praveena, which we can do by passing these nodes to the parameter whitelistNodes.
Cypher
The following returns paths from Alicia following the FOLLOWS or KNOWS relationship types from 1 to 3 hops, only including paths that contain Mark, Joe, Zhen, and Praveena
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (whitelist:Person)
WHERE whitelist.name IN [""Mark"", ""Joe"", ""Zhen"", ""Praveena""]
WITH p, collect(whitelist) AS whitelistNodes
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    whitelistNodes: whitelistNodes
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 9. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Out of the white list, the only person with a direct connection to Alicia is Joe, so all paths go through him. We then go from Joe to the others, and then between each other for the paths of 3 hops.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia to Mark, Joe, Zhen, and Praveena.
Figure 3. Paths from Alicia to Mark, Joe, Zhen, and Praveena
A blacklist is used to exclude nodes from the returned paths. If we want to exclude paths that contain Joe, we can do this by passing the Joe node to the blacklistNodes parameter.
Cypher
The following returns paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, excluding paths that include Joe
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    blacklistNodes: [joe]
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 10. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
This returns a very small set of paths since Joe was a very pivotal node in connecting Alicia to the rest of the graph.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia that don’t include Joe.
Figure 4. Paths from Alicia that don’t include Joe
Breadth First Search and Depth First Search
We can control whether the traversal uses the Breadth First Search (BFS), by specifying bfs: true, or Depth First Search algorithm (DFS), by specifying bfs: false. This is often combined with the limit parameter to find the nearest nodes based on the chosen algorithm.
Cypher
The following returns 10 paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, using BFS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 5,
    bfs: true,
    limit: 10
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 11. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})
1
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
2
(:Person:Product {name: ""Alicia""})-[:KNOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
From these results we can see that paths are completely expanded at each level before going onto the next one. For example, we first expand from:
Alicia → Joe
Alicia → Jonny
Alicia → Jake
Before then following relationships from those nodes. And once it’s expanded everything at level 2, it will then explore level 3.
Figure 5. Paths from Alicia using Breadth First Search
If we use the Depth First Search algorithm, the traversal will go as far as it can (up to the maxLevel of hops) down a particular path, before going back up and exploring other ones.
Cypher
The following returns 10 paths containing people that Alicia FOLLOWS or KNOWS from 1 to 3 hops, using DFS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Alicia""})
MATCH (joe:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>|KNOWS"",
    minLevel: 1,
    maxLevel: 3,
    bfs: false,
    limit: 10
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 12. Results
path hops
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
Now we have a different set of paths returned. We don’t even see the paths from Alicia to Jonny or Alicia to Jake because our limit of 10 paths is completely taken up with paths going through Joe.
We can see a Neo4j Browser visualization of the returned paths in Paths from Alicia using Depth First Search.
Figure 6. Paths from Alicia using Depth First Search
Uniqueness
We can specify the uniqueness strategy to be used by the traversal through the uniqueness parameter. See Uniqueness for a list of valid strategies. The default value is RELATIONSHIP_PATH.
In this section we’re going to write queries that start from Joe and traverse the FOLLOWS relationship.
Cypher
The following returns the nodes in paths starting from Joe and traversing the FOLLOWS relationship type from 1 to 3 hops
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>"",
    minLevel: 1,
    maxLevel: 3,
    uniqueness: ""RELATIONSHIP_PATH"" // default
})
YIELD path
RETURN [node in nodes(path) | node.name] AS nodes, length(path) AS hops
ORDER BY hops;
Table 13. Results
nodes hops
[""Joe"", ""Zhen""]
1
[""Joe"", ""Praveena""]
1
[""Joe"", ""Mark""]
1
[""Joe"", ""Zhen"", ""John""]
2
[""Joe"", ""Praveena"", ""Joe""]
2
[""Joe"", ""Mark"", ""Stefan""]
2
[""Joe"", ""Praveena"", ""Joe"", ""Zhen""]
3
[""Joe"", ""Praveena"", ""Joe"", ""Mark""]
3
[""Joe"", ""Mark"", ""Stefan"", ""Joe""]
3
Several of the paths returned contain the Joe node twice. If we want to ensure that the nodes in a path are unique, we can use the NODE_PATH strategy.
Cypher
The following returns the nodes in paths starting from Joe and traversing the FOLLOWS relationship type from 1 to 3 hops, using the NODE_PATH strategy
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
    relationshipFilter: ""FOLLOWS>"",
    minLevel: 1,
    maxLevel: 3,
    uniqueness: ""NODE_PATH""
})
YIELD path
RETURN [node in nodes(path) | node.name] AS nodes, length(path) AS hops
ORDER BY hops;
Table 14. Results
nodes hops
[""Joe"", ""Zhen""]
1
[""Joe"", ""Praveena""]
1
[""Joe"", ""Mark""]
1
[""Joe"", ""Zhen"", ""John""]
2
[""Joe"", ""Mark"", ""Stefan""]
2
The paths returned now have unique lists of nodes.
Sequences of relationship types
Sequences of relationship types can be specified by comma separating the values passed to relationshipFilter.
For example, if we want to start from the Joe node and traverse a sequence of the FOLLOWS relationship in the outgoing direction and the KNOWS relationship in either direction, we can specify the relationship filter FOLLOWS>,KNOWS.
Cypher
The following returns the paths of 1 to 4 hops from Joe where the relationship types alternate between FOLLOWS and KNOWS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 15. Results
path hops
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
1
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
4
The minLevel and maxLevel values refer to the number of relationships in the path. Using a minLevel of 1 means that paths one hop from Joe with the FOLLOWS relationship type will be returned. If we want to ensure that the relationship type sequence defined in this relationshipFilter is matched at least once, we need to use a minLevel of 2 since there are two relationship types in the filter.
Cypher
The following returns the paths of 2 to 4 hops from Joe where the relationship types alternate between FOLLOWS and KNOWS
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Joe""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""FOLLOWS>,KNOWS"",
 beginSequenceAtStart: true,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 16. Results
path hops
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Martin""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:KNOWS]→(:Person:Product {name: ""Jake""})
2
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
3
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:DevRel {name: ""Lju""})-[:FOLLOWS]→(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})
4
(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
4
This config can also be used in combination with beginSequenceAtStart: false, which means that the sequence will start one hop away from the starting node. If we use this config, it means that the first relationship type defined in relationshipFilter will only apply to the starting node.
Cypher
The following returns the paths of 3 to 5 hops from Jake where the relationship types alternate between FOLLOWS and KNOWS, after first following KNOWS relationships from Jake
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Jake""})
CALL apoc.path.expandConfig(p, {
 relationshipFilter: ""KNOWS,FOLLOWS>,KNOWS"",
 beginSequenceAtStart: false,
 minLevel: 3,
 maxLevel: 7
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 17. Results
path hops
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
3
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})
3
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})
4
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:Product {name: ""Alicia""})-[:FOLLOWS]→(:Person:Sales {name: ""Jonny""})-[:KNOWS]→(:Person:Sales {name: ""Anthony""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
4
(:Person:Product {name: ""Jake""})←[:KNOWS]-(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})-[:FOLLOWS]→(:Person:Product {name: ""John""})-[:KNOWS]→(:Person:Sales {name: ""Rik""})
5
Sequences of node labels
Sequences of node labels can be specified by comma separating values passed to labelFilter. This is usually used in combination with beginSequenceAtStart: false, which means that sequences will start one hop away from the starting node.
For example, if we start from the Praveena node and want to return the paths that contain alternating Field and DevRel nodes, we can specify a label filter of ""+Field,+DevRel"".
Cypher
The following returns the paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field and DevRel labels.
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 1,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 18. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})
1
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})
1
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
The minLevel and maxLevel values refer to the number of relationships in the path. Using a minLevel of 1 means that paths where the node one hop from Praveena has the Field label will be returned. If we want to ensure that the label sequence defined in this labelFilter is matched at least once, we need to use a minLevel of 2.
Cypher
The following returns the paths of 2 to 4 hops from Praveena where the nodes alternate between having the Field and DevRel labels.
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 19. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
The paths that only contain a relationship from Praveena to Joe have now been filtered out.
But what if we don’t want to specify multiple labels exist, but instead want to find paths where a node doesn’t have a label? To find paths that contain alternating Field and not Field nodes, we can specify a label filter of ""+Field,-Field"".
Cypher
The following returns the paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field label and not having the Field label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,-Field"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
RETURN path, length(path) AS hops
ORDER BY hops;
Table 20. Results
path hops
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Sales {name: ""Anthony""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Product {name: ""Alicia""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Engineering {name: ""Praveena""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Sales {name: ""Anthony""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})←[:FOLLOWS]-(:Person:Product {name: ""Alicia""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Praveena""})
2
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})
2
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})
3
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})←[:FOLLOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Engineering {name: ""Praveena""})←[:FOLLOWS]-(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
4
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:Engineering {name: ""Zhen""})-[:KNOWS]→(:Person:Field {name: ""Stefan""})←[:FOLLOWS]-(:Person:DevRel {name: ""Mark""})
4
(:Person:Engineering {name: ""Praveena""})-[:FOLLOWS]→(:Person:Field {name: ""Joe""})-[:FOLLOWS]→(:Person:DevRel {name: ""Mark""})-[:FOLLOWS]→(:Person:Field {name: ""Stefan""})←[:KNOWS]-(:Person:Engineering {name: ""Zhen""})
4
We’ve got a lot more paths, with path lengths between 2 and 4 hops. These paths have the following labels:
2 hops - Field → Not Field
3 hops - Field → Not Field → Field
4 hops - Field → Not Field → Field → Not Field
These paths are a bit difficult to read, so we can simplify the output by using the nodes function to just return the nodes. We’ll also filter the results so that we only return paths that match the complete +Field,-Field label filter. We can do this by only returning paths of even length:
Cypher
The following returns nodes of paths of 1 to 4 hops from Praveena where the nodes alternate between having the Field label and not having the Field label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""+Field,-Field"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
WHERE length(path) % 2 = 0

// Remove the Praveena node from the returned path
RETURN nodes(path)[1..] AS nodes, length(path) AS hops

ORDER BY hops;
Table 21. Results
nodes hops
[(:Person:Field {name: ""Joe""}), (:Person:Sales {name: ""Anthony""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Product {name: ""Alicia""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Praveena""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Sales {name: ""Anthony""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Product {name: ""Alicia""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Praveena""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""}), (:Person:Field {name: ""Stefan""}), (:Person:DevRel {name: ""Mark""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Field {name: ""Stefan""}), (:Person:Engineering {name: ""Zhen""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:Engineering {name: ""Zhen""}), (:Person:Field {name: ""Stefan""}), (:Person:DevRel {name: ""Mark""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Field {name: ""Stefan""}), (:Person:Engineering {name: ""Zhen""})]
4
The * character can be used as a wildcard in a node sequence to indicate that any label can appear in that position. If we want to match a sequence of nodes with any label followed by one with the DevRel label, we can specify the label filter *,+DevRel
Cypher
The following returns nodes of paths of 2 to 4 hops from Praveena where the nodes alternate between having any label and the DevRel label
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name: ""Praveena""})
CALL apoc.path.expandConfig(p, {
 labelFilter: ""*,+DevRel"",
 beginSequenceAtStart: false,
 minLevel: 2,
 maxLevel: 4
})
YIELD path
WHERE length(path) % 2 = 0

// Remove the Praveena node from the returned path
RETURN nodes(path)[1..] AS nodes, length(path) AS hops

ORDER BY hops;
Table 22. Results
nodes hops
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""})]
2
[(:Person:Engineering {name: ""Zhen""}), (:Person:DevRel {name: ""Lju""})]
2
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Lju""})]
4
[(:Person:Field {name: ""Joe""}), (:Person:DevRel {name: ""Mark""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Lju""})]
4
[(:Person:Engineering {name: ""Zhen""}), (:Person:DevRel {name: ""Lju""}), (:Person:Product {name: ""Jake""}), (:Person:DevRel {name: ""Mark""})]
4
Expand paths
Expand to nodes in a subgraph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/database-introspection;"Database Introspection
The APOC library adds extra tools for introspecting the database.
For more on these procedures, see:
Meta Graph
Triggers
Meta Graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/data-structures;"Data Structures
Cypher brings along some basic functions for math, text, collections and maps.
Conversion Functions
Map Functions
Collection Functions
Deleting data
Conversion Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/data-structures/conversion-functions;"Conversion Functions
Sometimes type information gets lost, these functions help you to coerce an ""Any"" value to the concrete type
Qualified Name Type
apoc.convert.toMap
apoc.convert.toMap(value) | tries it’s best to convert the value to a map
Function
apoc.convert.toList
apoc.convert.toList(value) | tries it’s best to convert the value to a list
Function
apoc.convert.toNode
apoc.convert.toNode(value) | tries it’s best to convert the value to a node
Function
apoc.convert.toRelationship
apoc.convert.toRelationship(value) | tries it’s best to convert the value to a relationship
Function
apoc.convert.toSet
apoc.convert.toSet(value) | tries it’s best to convert the value to a set
Function
apoc.convert.toNodeList
apoc.convert.toNodeList(value) | tries it’s best to convert the value to a list of nodes
Function
apoc.convert.toRelationshipList
apoc.convert.toRelationshipList(value) | tries it’s best to convert the value to a list of relationships
Function
Data Structures
Map Functions
Was this page helpful?"
https://neo4j.com/docs/apoc/5/export;"Export
Neo4j supports exporting whole databases via the backup and dump commands. It doesn’t have support for exporting sub graphs or exporting data into standard data formats, which is where the APOC library comes in.
APOC adds support for exporting data into various data formats, including JSON, CSV, GraphML, and Cypher script.
In addition to exporting data in these formats, we can choose to export the whole database, specified nodes and relationships, a virtual graph, or the results of a Cypher query.
For more information on how to use these procedures, see:
Export to CSV
Export to JSON
Export to Cypher Script
Export to GraphML
Import GraphML
Export to CSV
Was this page helpful?"
https://neo4j.com/labs/apoc/4.2/overview/apoc.util/apoc.util.md5;"apoc.util.md5
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.md5([values]) | computes the md5 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.md5([""Michael""]) AS output;
Table 1. Results
output
""3e06fa3927cbdf4e9d93ba4541acce86""
More documentation of apoc.util.md5
apoc.util.decompress
apoc.util.sha1
Was this page helpful?"
https://neo4j.com/labs/apoc/4.2/overview/apoc.util/apoc.util.sha512;"apoc.util.sha512
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha512([values]) | computes the sha512 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha512([""Michael""]) AS output;
Table 1. Results
output
""e70bdf701bd91b2357ec83bd6fb74d602f2883beb6934de21c9bffa0fc0717a9ee6ef9327387ac2b3735a3be9796754a03941059405955999e2302b0ae7efeb6""
apoc.util.sha384
apoc.util.validatePredicate
Was this page helpful?"
https://neo4j.com/labs/apoc/4.2/overview/apoc.util/apoc.util.sha256;"apoc.util.sha256
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha256([values]) | computes the sha256 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha256([""Michael""]) AS output;
Table 1. Results
output
""f089eaef57aba315bc0e1455985c0c8e40c247f073ce1f4c5a1f8ffde8773176""
apoc.util.sha1
apoc.util.sha384
Was this page helpful?"
https://neo4j.com/labs/apoc/4.1/overview/apoc.util/apoc.util.sha512;"apoc.util.sha512
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha512([values]) | computes the sha512 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha512([""Michael""]) AS output;
Table 1. Results
output
""e70bdf701bd91b2357ec83bd6fb74d602f2883beb6934de21c9bffa0fc0717a9ee6ef9327387ac2b3735a3be9796754a03941059405955999e2302b0ae7efeb6""
apoc.util.sha384
apoc.util.validatePredicate
Was this page helpful?"
https://neo4j.com/labs/apoc/4.1/overview/apoc.util/apoc.util.sha256;"apoc.util.sha256
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha256([values]) | computes the sha256 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha256([""Michael""]) AS output;
Table 1. Results
output
""f089eaef57aba315bc0e1455985c0c8e40c247f073ce1f4c5a1f8ffde8773176""
apoc.util.sha1
apoc.util.sha384
Was this page helpful?"
https://neo4j.com/labs/apoc/4.1/overview/apoc.util/apoc.util.md5;"apoc.util.md5
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.md5([values]) | computes the md5 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.md5([""Michael""]) AS output;
Table 1. Results
output
""3e06fa3927cbdf4e9d93ba4541acce86""
More documentation of apoc.util.md5
apoc.util.decompress
apoc.util.sha1
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-deadlockdetectedexception-forseticlient-0-cant-acquire-exclusivelock;"Explanation of error ""DeadlockDetectedException: ForsetiClient[0] can’t acquire ExclusiveLock… …""
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags deadlock lock
Under specific scenarios a DeadlockDetectedException may be encountered and the behavior is described at https://neo4j.com/docs/java-reference/current/transaction-management/#transactions-deadlocks. When a DeadlockDetected is encountered one option is to simply retry the statement. As a deadlock detection error is a safe-to-retry error and the user is expected to handle these in all application code, since there may be legitimate deadlocks at any time, this behavior is actually by design to gain scalability. The following describes a scenario where a deadlock can be demonstrated/reproduced.
Time Transaction Cypher Statement
08:00:01
tx1001
Begin
08:00:02
tx1001
MATCH (n:Person {name:'Tom Hanks'}) set n.age=59;
08:00:03
tx1002
Begin
08:00:04
tx1002
MATCH (n:Movie {title:'Cast Away'}) set n.gross=233630478;
08:00:05
tx1001
MATCH (n:Movie {title:'Cast Away'}) set n.budget=90000000;
08:00:06
tx1002
MATCH (n:Person {name:'Tom Hanks'}) set n.residence=California;
In the above scenario tx1001 is started at 08:00:01 and then @ 08:00:02 performs an update on the Person node for 'Tom Hanks' and defines age to be 59, resulting in a Write-Lock placed on this node.
tx1002 is then started at 08:00:03 and subsequently at 08:00:04 performs an update on the Movie node for Cast Away and defines the gross to be 233630478, resulting on a Write-Lock on this node.
tx1001 @ 08:00:05 then attempts to update the Movie node for Cast Away but is blocked as a result of the transaction @ 08:00:04 which has a Write-Lock on this node.
tx1002 @08:00:06 then attempts to update the Person node for Tom Hanks but is blocked as a result of the transaction at 08:00:02 which has a Write-Lock on this node.
Since the last two statements are waiting on each other, the dead lock is detected and the transaction at 08:00:06 is aborted with the following error
DeadlockDetectedException: ForsetiClient[0] can't acquire ExclusiveLock{owner=ForsetiClient[1]} on NODE(200153), because holders of that lock are waiting for ForsetiClient[0].
 Wait list:ExclusiveLock[
Client[1] waits for [0]]
Was this page helpful?"
https://neo4j.com/developer/kb/diagnose-locking-issues;"How to diagnose locking issues
Author Stefan Armbruster Applicable versions 3.5 4.0 4.1 4.2 Tags performance tuning write read lock
Since Neo4j 3.4 it’s possible to better understand locking issues caused by concurrent query. This KB article will not detail the basics of locking in Neo4j. We assume a situation where you concurrently run lots of queries - might be the same parameterized query or different queries. The typical execution times of these are much higher than you expect - you basically think that Neo4j is ""slow"". In fact the source for this kind of observation might be that your queries try to grab locks on a common node, therefore they need to wait until the lock holder releases the lock. The queries waiting for the common lock are effectively serialized.
In a previous version of neo4j the query logging feature allowed for the adding of information related to how long that query was in waiting state, whether waiting on locks or waiting on IO. This can be switched on through neo4j.conf parameter of dbms.logs.query.time_logging_enabled=true. However this gives us only information on the total waiting time and no insight in which contended node or relationship might have caused it.
Commencing with Neo4j 3.4, and along with new stored procedure dbms.listTransactions() one can better understand the cause of the delay. To demonstrate the procedures with 2 cypher-shell connections run the following cypher
session1:    merge (n:Lock {id:1}) set n.age=20 with n call apoc.util.sleep(200000) return n;
session2:    Match (n:Lock {id:1}) set n.age=85 return n;
The first session will set the age property to 20 on the :Lock labelled node with id=1 and then sleep for 200 seconds (thus keeping the lock on said node). The 2nd session will attempt to update the same node and set its age property to 85 but will be blocked for these 200 seconds.
During these 200 seconds and via the Neo4j Browser, running call dbms.listTransactions() yield transactionId, startTime, currentQueryId, currentQuery, status will return output similar to
To which from this output we can see that transaction-1381/query-1378 reports its status of Blocked by: [transaction-1380] and to which transaction-1380 is also listed in the output and both transactions describe the currentQuery.
Also, running call dbms.listActiveLocks('<currentQueryId>'); for example call dbms.listActiveLocks('query-1377'); will return output similar to
From the output above we see that query-1377 has a EXCLUSIVE NODE lock on a node with id(n)=8432.
With these 2 procedures you have powerful tooling at hand to understand what nodes/relationships might be a source for lock contention.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-define-display-use-parameters-with-neo4j-shell;"How do I define, display, and use parameters with neo4j-shell
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags parameters neo4j-shell quotes
bin/neo4j-shell allows for a command line interface to query your graph via Cypher statements and to include parameters to those statements. Usage of parameters, rather than hard coding values, will allow for re-use of the query plan cache.
A parameter can be defined within neo4j-shell via the export command, for example:
Shell
Copy to Clipboard
neo4j-sh (?)$ export p1=""Nora Ephron""
Multi-word values for parameters should be enclosed in double quotes.
Parameters can be displayed within neo4j-shell via the env command, for example:
Shell
Copy to Clipboard
neo4j-sh (?)$ export p1=""Nora Ephron""
neo4j-sh (?)$ env
TITLE_MAX_LENGTH=40
p1=Nora Ephron
TITLE_KEYS=.*name.*,.*title.*
Once a parameter is defined, it can be used in a Cypher statement, for example:
Shell
Copy to Clipboard
neo4j-sh (?)$ export p1=""Nora Ephron""
neo4j-sh (?)$ env
TITLE_MAX_LENGTH=40
p1=Nora Ephron
TITLE_KEYS=.*name.*,.*title.*
neo4j-sh (?)$ match (n:Person {name:'Tom Hanks'})-[:ACTED_IN]->(n1:Movie)<-[:DIRECTED]-(n2:Person {name:{p1}}) return n1.title;
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-use-load-csv-with-data-including-quotes;"How do I use LOAD CSV with data including quotes
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load csv quotes
When using LOAD CSV to read a file which includes data with double quote characters (""), the quotes need to be escaped as 2 double quote characters
For example if your data file (courses.csv) included the following content
Csv
Copy to Clipboard
COURSE_ID,COURSE_TITLE
1215,""""""Graphs are EveryWhere"""" : An Introduction to Neo4j""
and using the following LOAD CSV command
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM ""file:///courses.csv"" AS row CREATE (:Course { courseID: toInt(row.COURSE_ID), courseTitle: row.COURSE_TITLE});
this would create a Course node with the following properties
courseID = 1215
courseTitle = ""Graphs are Everywhere"" : An Introduction to Neo4j
Was this page helpful?"
https://neo4j.com/developer/kb/using-neo4j-shell-neo4j-ce-3x;"Access to the neo4j-shell in NEO4J CE 3.x
Author Michael Hunger Applicable versions 3.0 Tags import shell cypher
From Neo4j 3.0 access to neo4j-shell is no longer possible from the desktop-installers for Windows and OSX.
To use neo4j-shell, you have to download the TAR/ZIP distribution from: http://neo4j.com/download/other-releases/
For importing files that contain semicolon separated cypher commands, you can also use:
LazyWebCypher, a web based tool
CyCli-Shell (Python) (pip install cycli)
libneo4j-client (Ansi-C)
The official Neo4j-Docker image can also come handy.
Shell
Copy to Clipboard
$ docker pull neo4j
$ CONTAINER=$(docker run -d --name neo4j -p 7474:7474 -v /path/to/data:/data -v /path/to/csv-files:/var/lib/neo4j/import neo4j)
$ echo ""Running Neo4j as $CONTAINER, waiting for startup""
$ sleep 10
# to import a file from `/path/to/csv-files/import.cypher`
$ docker exec $CONTAINER /var/lib/neo4j/bin/neo4j-shell -f /var/lib/neo4j/import/import.cypher
# or for interactive mode
$ docker exec -ti $CONTAINER /var/lib/neo4j/bin/neo4j-shell
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-on-session-connection-using-uniform-drivers;"Explanation of error on session connection using uniform drivers
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags connection security tls
As described by http://neo4j.com/docs/developer-manual/current/drivers/#_trust, when establishing an encrypted connection, it needs to be verified that the remote peer is who we expected to connect to. The default connection is to 'Trust on first use' and to do so indicates that we will read and write a certificate value in ~/.neo4j/known_hosts.
Upon upgrading from 3.0.0 to 3.0.1 future connections may error, when establishing the connection to Neo4j, for example:
Java:
General SSLEngine problem
Python:
neo4j.v1.exceptions.ProtocolError: Server certificate does not match known certificate for 'localhost'; check details in file /home/neo4j/.neo4j/known_hosts
As detailed in the Python error message, the failure is a result of reading the /home/neo4j/.neo4j/known_hosts, where /home/neo4j is the users default home directory, and to which the file at `~/.neo4j/`known_hosts has a certificate which is no longer valid. An example of the content of this file is:
localhost:MIIBoTCCAQqgAwIBAgIIe+AjK7iGHqMwDQYJKoZIhvcNAQENBQAwEjEQMA4GA1UEAwwHMC4wLjAuMDAgFw0xNTA1MTExODE3MzZaGA85OTk5MTIzMTIzNTk1OVowEjEQMA4GA1UEAwwHMC4wLjAuMDCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEA0Q5XpjnNv2oRs2mB+hx9Ef9txxk3pOWz/FICKb8cZHxMmCDP6IPcuxMh3fW4FRtAeZQCxyRfOrnevnedtW2PdPvqf14lUi1aFDcXHav1Rc6sAgpdLaj3C25G4XjDrBH9tADp6+xbYOpiVmrrwGjRy9SI0k4NgDj4j8YF1yE1boUCAwEAATANBgkqhkiG9w0BAQ0FAAOBgQAkJp+2Z0bD4BJE0XR0HJUOfQwLTxLp4pzSWn77xI11m9AfH0dFdpz2KIIntLNT7fJh8jo25OUH5QqhKIIkzg9wZU80LkTcyEOjbDUW2Sf5yhiu9I2cIQaiJ4Mr8BHaEFbC73iVObGOperSVmOuddcSJAKKHmfeMH4Xmo/uBlc2/Q==
To resolve the failure above, simply delete the line which references localhost from the known_hosts file.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-enable-remote-https-access-with-neo4j-30x;"How do I enable remote HTTPS access with Neo4j 3.0.x
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags https connection
With 3.0.x to enabled remote clients to connect to a HTTPS enabled browser the following parameters in the $NEO4J_HOME/conf/neo4j.conf need to be changed from the default of
Properties
Copy to Clipboard
#dbms.connector.https.address=localhost:7473
to
Properties
Copy to Clipboard
dbms.connector.https.address=0.0.0.0:7473
The change from localhost:7473 to 0.0.0.0:7473 will allow for remote connections to https://<Neo4j_Host_IP>:7473
Was this page helpful?"
https://neo4j.com/developer/kb/an-example-of-neo4j-import-steps-in-a-causal-cluster-environment;"An example of neo4j-import steps in a Causal Cluster environment
Author Dana Canzano Applicable versions 3.5 Tags import causal-cluster ha
The following steps are provided to describe how to use neo4j-import in a Causal Cluster environment and was run from an environment of a single linux host with 3 copies for Neo4j 3.1.2 installed in the following paths
~/HA/ha1/neo4j-enterprise-3.1.2
~/HA/ha2/neo4j-enterprise-3.1.2
~/HA/ha3/neo4j-enterprise-3.1.2
This is similar to the instructions for Set up a local Causal Cluster
validated a Causal Cluster would form (after configuring $NEO4J_HOME/cond/neo4j.conf) and ran
Shell
~/HA/ha1/neo4j-enterprise-3.1.2/bin/neo4j start; ~/HA/ha2/neo4j-enterprise-3.1.2/bin/neo4j start;
~/HA/ha3/neo4j-enterprise-3.1.2/bin/neo4j start
this assumes the default database of graph.db
Since starting a Causal Cluster takes a number of configurations I wanted to ensure that it would at least start and with an empty database.
stopped the causal cluster by by running
Shell
~/HA/ha1/neo4j-enterprise-3.1.2/bin/neo4j stop; ~/HA/ha2/neo4j-enterprise-3.1.2/bin/neo4j stop;
~/HA/ha3/neo4j-enterprise-3.1.2/bin/neo4j stop
which produced the following output
Stopping Neo4j..................................... stopped
Stopping Neo4j.................................... stopped
Stopping Neo4j..................................... stopped
unbound each of the 3 causal cluster databases. (this is not necessary if you skip #1 and #2 but if you have failure further on with getting the cluster to form then you need to sort out if it is a cluster configuration issue or something about the database import). Further unbind is detailed here
Shell
$ ~/HA/ha2/neo4j-enterprise-3.1.2/bin/neo4j-admin unbind --database=graph.db
$ ~/HA/ha1/neo4j-enterprise-3.1.2/bin/neo4j-admin unbind --database=graph.db
$ ~/HA/ha3/neo4j-enterprise-3.1.2/bin/neo4j-admin unbind --database=graph.db
created ~/HA/ha1/neo4j-enterprise-3.1.2/importer and added 3 files namely actors.csv, movies.csv, roles.csv and they are defined with content detailed here
ran neo4j-import and loaded the data into ~/HA/ha1/neo4j-enterprise-3.1.2/data/databases/graph.db.importer
Shell
~/HA/ha1/neo4j-enterprise-3.1.2/bin/neo4j-import --into ~/HA/ha1/neo4j-enterprise-3.1.2/data/databases/graph.db.importer --nodes ~/HA/ha1/neo4j-enterprise-3.1.2/importer/movies.csv --nodes ~/HA/ha1/neo4j-enterprise-3.1.2/importer/actors.csv --relationships ~/HA/ha1/neo4j-enterprise-3.1.2/importer/roles.csv
and this produced the following output
WARNING: neo4j-import is deprecated and support for it will be removed in a future
version of Neo4j; please use neo4j-admin import instead.

Neo4j version: 3.1.2
Importing the contents of these files into /home/neo4j/HA/ha1/neo4j-enterprise-3.1.2/data/databases/graph.db.importer:
Nodes:
  /home/neo4j/HA/ha1/neo4j-enterprise-3.1.2/importer/movies.csv

  /home/neo4j/HA/ha1/neo4j-enterprise-3.1.2/importer/actors.csv
Relationships:
  /home/neo4j/HA/ha1/neo4j-enterprise-3.1.2/importer/roles.csv

Available resources:
  Free machine memory: 5.01 GB
  Max heap memory : 1.47 GB
  Processors: 1

Nodes

Done in 100ms
Prepare node index

Done in 26ms
Calculate dense nodes

Done in 43ms
Node --> Relationship Sparse

Done in 10ms
Relationship --> Relationship Sparse

Done in 11ms
Minority relationships

Done in 32ms
Count groups

Done in 10ms
Gather

Done in 11ms
Write

Done in 10ms
Node --> Group

Done in 11ms
Node counts

Done in 53ms
Relationship counts

Done in 11ms

IMPORT DONE in 1s 881ms.
Imported:
  6 nodes
  0 relationships
  15 properties
Peak memory usage: 7.63 MB
updated each of the 3 $NEO4J_HOME/conf/neo4j.conf and defined the
Properties
Copy to Clipboard
# The name of the database to mount
dbms.active_database=graph.db.importer
as this represents the name of the database prepared from neo4j-import.
copy the graph.db.importer from instance 1 to instance 2 and 3 via a
Shell
Copy to Clipboard
cp -R ~/HA/ha1/neo4j-enterprise-3.1.2/data/databases/graph.db.importer ~/HA/ha2/neo4j-enterprise-3.1.2/data/databases/graph.db.importer
cp -R ~/HA/ha1/neo4j-enterprise-3.1.2/data/databases/graph.db.importer ~/HA/ha3/neo4j-enterprise-3.1.2/data/databases/graph.db.importer
start all 3 instances as follows
Shell
Copy to Clipboard
~/HA/ha1/neo4j-enterprise-3.1.2/bin/neo4j start;  ~/HA/ha2/neo4j-enterprise-3.1.2/bin/neo4j start;
~/HA/ha3/neo4j-enterprise-3.1.2/bin/neo4j start
which produces the following output:
Starting Neo4j.
Started neo4j (pid 3976). It is available at http://0.0.0.0:7414/
There may be a short delay until the server is ready.
See /home/neo4j/HA/ha1/neo4j-enterprise-3.1.2/logs/neo4j.log for current status.
Starting Neo4j.
Started neo4j (pid 4040). It is available at http://0.0.0.0:7424/
There may be a short delay until the server is ready.
See /home/neo4j/HA/ha2/neo4j-enterprise-3.1.2/logs/neo4j.log for current status.
Starting Neo4j.
Started neo4j (pid 4104). It is available at http://0.0.0.0:7434/
There may be a short delay until the server is ready.
See /home/neo4j/HA/ha3/neo4j-enterprise-3.1.2/logs/neo4j.log for current status.
ran match (n) return n limit 10 on each of the 3 instances and all reported a total of 6 nodes, which corresponds to the output of neo4j-import which reports
Imported:
  6 nodes
  0 relationships
  15 properties
From the leader I ran:
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (n:Tester {id:105});
and validated it was created on the leader as well as the followers.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/installation;"Installation
Contents
Neo4j Server
Docker
Restricted procedures/functions
APOC Extended can be downloaded using one of the methods described in the sections below.
Neo4j Server
Since APOC relies on Neo4j’s internal APIs you need to use the matching APOC version for your Neo4j installation. Make sure that the first two version numbers match between Neo4j and APOC.
Go to here for all the APOC extended releases and download the binary jar to place into your $NEO4J_HOME/plugins folder.
After you move the jar file to the plugins folder you have to restart neo4j with neo4j restart
Since APOC relies on Neo4j’s internal APIs, you need to use the right APOC version for your Neo4j installation.
APOC uses a consistent versioning scheme: <neo4j-version>.<apoc> version. The trailing <apoc> part of the version number will be incremented with every apoc release.
The version compatibility matrix explains the mapping between Neo4j and APOC versions:
apoc version neo4j version
5.1.0
5.1.0 (5.1.x)
4.4.0.1
4.4.0 (4.3.x)
4.3.0.4
4.3.7 (4.3.x)
4.2.0.9
4.2.11 (4.2.x)
If by mistake a jar not compatible with the neo4j version is inserted, a log.warn like this will appear in neo4j.log:
None
Copy to Clipboard
The apoc version (<APOC_VERSION>) and the Neo4j DBMS versions [NEO4J_VERSION] are incompatible.
See the compatibility matrix in https://neo4j.com/labs/apoc/4.4/installation/ to see the correct version
Docker
APOC Extended can be used with Docker.
This feature is intended to facilitate using APOC in development environments, but it is not recommended for use in production environments.
Download the APOC release matching our Neo4j version and, copy it to a local folder, and supply it as a data volume mounted at /plugins.
Bash
The following downloads the APOC Extended library into the plugins directory and then mounts that folder to the Neo4j Docker container
Copy to Clipboard
mkdir plugins
pushd plugins
wget https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases/download/5.0.0-rc01/apoc-5.0.0-rc01-extended.jar
popd
docker run --rm -e NEO4J_AUTH=none -p 7474:7474 -v $PWD/plugins:/plugins -p 7687:7687 neo4j:5.0
If you want to pass custom apoc config to your Docker instance, you can use environment variables, like here:
Bash
Copy to Clipboard
docker run \
    -p 7474:7474 -p 7687:7687 \
    -v $PWD/data:/data -v $PWD/plugins:/plugins \
    --name neo4j-apoc \
    -e NEO4J_apoc_export_file_enabled=true \
    -e NEO4J_apoc_import_file_enabled=true \
    -e NEO4J_apoc_import_file_use__neo4j__config=true \
    neo4j
Restricted procedures/functions
For security reasons, procedures that use internal APIs are disabled by default. They can be enabled by specifying config in $NEO4J_HOME/conf/neo4j.conf e.g. dbms.security.procedures.unrestricted=apoc.*
If you want to do this when using the Neo4j Docker container, you need to amend -e NEO4J_dbms_security_procedures_unrestricted=apoc.\\\* to your docker run … command. The three backslashes are necessary to prevent wildcard expansions.
You can also whitelist procedures and functions in general to be loaded using: dbms.security.procedures.whitelist=apoc.coll.*,apoc.load.*
Was this page helpful?"
https://neo4j.com/developer/kb/kernel-api-returned-non-existent-relationship-type-exception;"Why did I get the “Kernel API returned non-existent relationship type: -1” exception?
Author Vivek Saran Applicable versions 3.5 Tags kernel exception relationships transaction bolt
In rare situations, the Neo4j Bolt driver throws an IllegalStateException. The top part of the stack appears as:
java.lang.IllegalStateException: Kernel API returned non-existent relationship type: -1
    at org.neo4j.kernel.impl.factory.GraphDatabaseFacade.getRelationshipTypeById(GraphDatabaseFacade.java:991)
Under the covers, this is what happens. The getRelationshipTypeById(int type) method is trying to search a relationship with type = -1. The value of -1 is used as a token-value for the id of the relationship when it does not exist. When the embedded Java API does not find the relationship with an id, it simply passes -1 to this method, and the call that throws the exception is getRelationshipTypeById(-1).
The above scenario occurs when read transactions conflict with overlapping delete transactions. The conflict sometimes happens because the transactions in Neo4j use a read-committed isolation level. Because the isolation level is read-committed, the read queries are not isolated from write queries.
If your result set includes relationships, and those relationships are deleted before, or while the result is streamed back over the bolt, you will encounter the Kernel API returned non-existent relationship type: -1 exception.
Here is a link describing the Isolation Levels in Neo4j.
The good news is that in 3.5.5, a fix was introduced to provide better messaging for this issue. Here is the related text from the release notes for 3.5.5:
Fix a number of cases where unhelpful exceptions were thrown, when a committed write transaction that performs deletes or removals cause conflicts in an overlapping read transaction. We now throw IllegalStateException from the embedded API and TransientException (which tells clients to retry their transactions) from the driver (Bolt) API.
Was this page helpful?"
https://neo4j.com/developer/kb/cluster-unable-to-find-transaction;"Cluster: org.neo4j.kernel.impl.transaction.log.NoSuchTransactionException: Unable to find transaction 1 in any of my logical logs: Couldn’t find any log containing 1
Author Mark Needham Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster exception
When operating a causal cluster, if ""the store"" (data/databases/graph.db) is removed from a server that was previously a member of the cluster we will get the following exception when that server is started:
java.lang.RuntimeException: Error starting org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory, /path/to/neo4j/data/databases/graph.db

 at org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:209)
 at org.neo4j.causalclustering.core.CoreGraphDatabase.<init>(CoreGraphDatabase.java:49)
 at org.neo4j.causalclustering.discovery.CoreClusterMember.start(CoreClusterMember.java:149)
 at org.neo4j.causalclustering.scenarios.CoreReplicationIT.shouldReplicateTransactionsToCoreMembers(CoreReplicationIT.java:88)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:497)
 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 at org.neo4j.test.rule.VerboseTimeout$VerboseFailOnTimeout$CallableStatement.call(VerboseTimeout.java:237)
 at org.neo4j.test.rule.VerboseTimeout$VerboseFailOnTimeout$CallableStatement.call(VerboseTimeout.java:228)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.lang.Thread.run(Thread.java:745)
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.causalclustering.core.state.CoreLife@2b63e070' was successfully initialized, but failed to start. Please see the attached cause exception ""Unable to find transaction 1 in any of my logical logs: Couldn't find any log containing 1"".
 at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:444)
 at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:107)
 at org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:205)
 ... 16 more
Caused by: java.lang.RuntimeException: org.neo4j.kernel.impl.transaction.log.NoSuchTransactionException: Unable to find transaction 1 in any of my logical logs: Couldn't find any log containing 1
 at org.neo4j.causalclustering.core.state.machines.tx.LastCommittedIndexFinder.getLastCommittedIndex(LastCommittedIndexFinder.java:67)
 at org.neo4j.causalclustering.core.state.machines.tx.RecoverConsensusLogIndex.findLastAppliedIndex(RecoverConsensusLogIndex.java:48)
 at org.neo4j.causalclustering.core.state.machines.CoreStateMachines.installCommitProcess(CoreStateMachines.java:138)
 at org.neo4j.causalclustering.core.state.CoreLife.start(CoreLife.java:82)
 at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:434)
 ... 18 more
Caused by: org.neo4j.kernel.impl.transaction.log.NoSuchTransactionException: Unable to find transaction 1 in any of my logical logs: Couldn't find any log containing 1
 at org.neo4j.kernel.impl.transaction.log.PhysicalLogicalTransactionStore$LogVersionLocator.getLogPosition(PhysicalLogicalTransactionStore.java:223)
 at org.neo4j.kernel.impl.transaction.log.PhysicalLogicalTransactionStore.getTransactions(PhysicalLogicalTransactionStore.java:83)
 at org.neo4j.causalclustering.core.state.machines.tx.LastCommittedIndexFinder.getLastCommittedIndex(LastCommittedIndexFinder.java:57)
 ... 22 more
This exception is thrown because the store is now out of sync with the cluster state.
If we want to have this server rejoin the cluster we need to unbind it from the cluster. We can do this by executing the following command:
Shell
Copy to Clipboard
$ neo4j-admin unbind --database=graph.db
We can now start the server and it will be able to rejoin the cluster.
Was this page helpful?"
https://neo4j.com/developer/kb/unable-to-create-new-native-thread;"java.lang.OutOfMemoryError: unable to create new native thread
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags out-of-memory bolt exception
When a client application establishes a session with a Neo4j server via the bolt or bolt+routing protocols, the server allocates a thread to serve as the server-side bolt worker to handle that connection. There is no server-side limitation on the number of bolt worker threads that the Neo4j server will spawn, so it is possible for the JVM to run out of native threads. The exact number depends on server hardware specifications, but is likely in the thousands.
If you find an exception of the type java.lang.OutOfMemoryError: unable to create new native thread in the debug.log or neo4j.log on the Neo4j server, this is almost certainly a result of clients not properly closing sessions within your application code.
2017-12-14 00:00:35.710+0000 ERROR [o.n.b.t.SocketTransportHandler] Fatal error occurred when handling a client connection: unable to
create new native thread unable to create new native thread
java.lang.OutOfMemoryError: unable to create new native thread
The remedy for this is to examine your application code for anywhere that you are creating Session objects, and verify that they follow the guidance from the documentation. For example, if you are using the Neo4j Java Driver, use try-with-resources:
Neo4j-Java-Driver GH Project: https://github.com/neo4j/neo4j-java-driver/blob/1.6/examples/src/main/java/org/neo4j/docs/driver/SessionExample.java#L38
Developer Documentation: http://neo4j.com/docs/developer-manual/current/drivers/sessions-transactions/#driver-sessions
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-configure-init-and-max-java-heap-when-running-bin-neo4j-backup;"How do I configure init and max java heap when running bin/neo4j-backup
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags backup heap out-of-memory operations
When running $NEO4J_HOME/bin/neo4j-backup if a Java out of heap/memory error occurs you may want define the init and max Java heap to be used by neo4j-backup. The default behavior is to allow the JVM to define the init and max heap as as described here.
To define the init and max heap, before running $NEO4J_HOME/bin/neo4j-backup define the environment varaible JAVA_OPTS, for example:
Bash
Copy to Clipboard
export JAVA_OPTS='-Xms2048m -Xmx2048m'
which will set the init and max Java heap to 2GB.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-fix-cannot-close-the-pagecache-while-files-are-still-mapped;"How to fix ""Cannot close the PageCache while files are still mapped""
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags shutdown page-cache
Incorrect file permissions on store files
It is common to start the database as different users, this can leave store files owned by other user ids. ( e.g. root )
In such case, you might want to fix the store files and directory. For example : ${NEO4J_HOME}/data/databases/graph.db/
Disk space is full
From Neo4j version 3.5, you should be able to recover by clearing up some space and restarting the affected node.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-estimate-initial-memory-configuration;"How to estimate initial memory configuration
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags heap memory jvm page-cache cache
The initial and eventual memory configuration parameters can be a moving target, based on how your store changes in size and how your workload increases or changes over time.
This guidance is meant for the initial configuration.
In order to decide on an appropriate configuration, you need the following information:
Amount of physical memory on the machine hosting Neo4j.
Estimates of the following:
Number of nodes.
Number of relationships.
Average number of properties per node and per relationship.
A fairly high-level rule of thumb is Total Physical Memory = Heap + Page Cache + OS Memory.
Usually reserving 1-2GB for the OS is sufficient. The heap and page cache are detailed below.
First, we need to decide on a good heap size.
A heap should not be overly large, as that can cause much longer Stop-the-World pauses when a full garbage collection (GC) cycle is needed. It should also be big enough to allow enough memory for your workload. On systems with a large amount of physical memory (>56GB), keeping the heap to 16GB and under typically works well.
Second, consider the page cache.
This is where the store files will be mapped in main memory for quicker access. The default page-cache size is 50% of the available memory. A good rule of thumb is Store size + expected growth + 10%. So, for a store that is 5GB in size, and you expect that to double in size in the next year, you would ideally allocate 5GB + 5GB + 1GB = 11GB.
This last section is no longer relevant for Neo4j versions 2.3 and later.
Lastly, let’s look at the object cache options.
The object cache is where nodes, relationships, and other objects are mapped to main memory. By default on Neo4j 2.2.x, this is set to High Performance Cache (hpc). On small stores (~10GB or smaller), this performs well. On larger stores, you will probably see better performance turning off the cache (set cache_type=none).
If you are using the object cache and need to tune it further, consider starting with the cache.memory_ratio option. This is on-heap, so it is the percentage of the heap to use for object cache. The default is 50%, but you can increase this a bit (to as high as 65-70%), especially if the JVM is not using all of its heap consistently.
Was this page helpful?"
https://neo4j.com/developer/kb/recommendations-for-recovery-upon-out-of-memory-error;"Recommendations for recovery upon Out Of Memory error
Author Daniel Terlizzi Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jvm memory exception error
It is possible to configure the JVM (Java Virtual Machine) such that upon encountering an OOM (Out-Of-Memory) error it will force an exception and crash or simply shut down the application. Taking action upon first OOM occurrence can help in avoiding further victims of low memory situations that may encounter OOM depending on their memory demand at the time and also reduce the time to recovery. Additionally, this may actually allow the failed operations due to OOM to complete successfully after restarting the application and retry of such operations since the memory footprint has changed. Choosing CrashOnOutOfMemoryError over ExitOnOutOfMemoryError is preferred if diagnosing the issue is a priority.
CrashOnOutOfMemoryError
If this option is enabled, when an out-of-memory error occurs, the JVM crashes and produces text and binary crash files (if core files are enabled).
Format
-XX:+|-CrashOnOutOfMemoryError
Example
java -XX:+CrashOnOutOfMemoryError
Conf
Neo4j configuration file (neo4j.conf) entry:
Copy to Clipboard
dbms.jvm.additional=-XX:+CrashOnOutOfMemoryError
ExitOnOutOfMemoryError
When you enable this option, the JVM exits on the first occurrence of an out-of-memory error. It can be used if you prefer restarting an instance of the JVM rather than handling out of memory errors.
Format
-XX:+|-ExitOnOutOfMemoryError
Conf
Neo4j configuration file (neo4j.conf) entry:
Copy to Clipboard
dbms.jvm.additional=-XX:+ExitOnOutOfMemoryError
-XX:+ExitOnOutOfMemoryError takes precedence over -XX:+CrashOnOutOfMemoryError.
The ExitOnOutOfMemoryError and CrashOnOutOfMemoryError flags were added to Java SE 8 Update 92. For more information, see the 'New JVM Options' section of the 8u92 Update Release Notes.
JDK-8155004 : CrashOnOutOfMemoryError doesn’t work for OOM caused by inability to create threads
There are many types of OutOfMemoryError
java.lang.OutOfMemoryError: Java heap space
This error will be triggered when the application attempts to add more data into the heap space area, but there is not enough room for it. Note that there might be plenty of physical memory available, but the java.lang.OutOfMemoryError: Java heap space error is thrown whenever the JVM reaches the heap size limit.
java.lang.OutOfMemoryError: GC overhead limit exceeded
This error means that the GC tried to free memory but was pretty much unable to get anything done. By default, it happens when the JVM spends more than 98% of the total time in GC and when after GC less than 2% of the heap is recovered.
java.lang.OutOfMemoryError: Metaspace/Compressed class space
The main cause for this error is either too many classes or too big classes being loaded to the Metaspace.
java.lang.OutOfMemoryError: Unable to create new native thread
Whenever the underlying OS cannot allocate a new native thread, this OutOfMemoryError will be thrown. The exact limit for native threads is very platform-dependent
java.lang.OutOfMemoryError: Out of swap space?
This error is thrown by JVM when an allocation request for bytes from the native heap fails and the native heap is close to exhaustion. It is often caused by operating system level issues, such as:
The operating system is configured with insufficient swap space.
Another process on the system is consuming all memory resources.
java.lang.OutOfMemoryError: Requested array size exceeds VM limit
This means that the application that crashes with the error is trying to allocate an array larger than the Java Virtual Machine can support
Source.
Was this page helpful?"
https://neo4j.com/developer/kb/fulltext-search-in-neo4j;"Fulltext search in Neo4j
Author Dave Gordon Applicable versions 3.5 Tags fulltext search indexing
Please note that in Neo4j 3.5 fulltext search is available in Neo4j as part of Cypher stored procedures. More documentation can be found here: https://neo4j.com/docs/cypher-manual/current/indexes-for-full-text-search/#administration-indexes-fulltext-search-create-and-configure.
Fulltext search in Neo4j is supported by means of fulltext schema indexes. Fulltext schema indexes are created, dropped, and updated transactionally, and are automatically replicated throughout a cluster.
For example let’s say we have a database containing books and movies. Both have the properties title and description, but only the books have the property review.
We can create a fulltext index on nodes with label :Movie or :Book that have the properties title, description and review. We give it the name titlesAndDescriptions.
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.createNodeIndex(""titlesAndDescriptions"",[""Movie"", ""Book""],[""title"", ""description"", ""review""])
Let’s see what results we get from the following query:
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.queryNodes(""titlesAndDescriptions"", ""Full Metal Jacket"") YIELD node, score
RETURN node.title, node.review, score
Table 1. Result
node.title node.review score
""Full Metal Jacket""
<null>
0.8093575239181519
""The Jacket""
<null>
0.1152719184756279
""Full Moon High""
<null>
0.0836455449461937
""Yellow Jacket""
<null>
0.07204495370388031
Then movie nodes will be included in the index, even though they only have one of the indexed labels, and only two of the indexed properties.
Also, as you can see, fulltext indexes will, in addition to any exact matches, also return approximate matches to a given query. The score that is returned alongside each result entry, represents how well the index thinks that entry matches the query. The results are always returned in descending score order, where the best matching result entry is put first.
What if we wish to only get results that match the search string entered? When we put 'Full Metal Jacket' in quotes, we get only exact matches:
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.queryNodes(""titlesAndDescriptions"", ""'Full Metal Jacket'"") YIELD node, score
RETURN node.title, score
Table 2. Result
node.title score
""Full Metal Jacket""
1.3701786994934082
We can also use logical operators, such as AND and OR, to search for terms:
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.queryNodes(""titlesAndDescriptions"", 'full AND metal') YIELD node, score
RETURN node.title, score
Only the ""Full Metal Jacket"" movie in our database has both the words ""full"" and ""metal"":
Table 3. Result
node.title score
""Full Metal Jacket""
0.7603841423988342
It is also possible to search for only specific properties, by putting the property name and a colon in front of the text being searched for:
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.queryNodes(""titlesAndDescriptions"", 'description:""surreal adventure""') YIELD node, score
RETURN node.title, node.description, score
Table 4. Result
node.title node.description score
""Metallica Through The Never""
""The movie follows the young roadie Trip through his surreal adventure with the band.""
1.311632513999939
Similar to nodes, fulltext indexes can be created on relationships.
For the full description of fulltext search in Neo4j, see: https://neo4j.com/docs/cypher-manual/current/indexes-for-full-text-search/.
Fulltext schema indexes are powered by the Apache Lucene indexing and search library. A complete description of the Lucene query syntax can be found in the Lucene documentation.
Was this page helpful?"
https://neo4j.com/developer/kb/using-explicit-indexes-for-text-search-in-neo4j;"Using explicit indexes for text search
Author Dave Gordon Applicable versions 3.4 3.5 Tags fulltext indexing
Please note that in Neo4j 3.5 FullText search is available in Neo4j as part of Cypher stored procedures. More documentation is found here: https://neo4j.com/docs/cypher-manual/3.5/schema/index/#schema-index-fulltext-search.
As of Neo4j 3.4.x, the schema index is optimal for indexing exact property values, but does not support ""fuzzy"" or full-text search. However, legacy indexing does allow for optimization for these types of queries, relying on auto-indexes or explicit indexes. In Neo4j version 3.4, addtional support for explicit indexes using built-in stored procedures was added to leverage text search in Neo4j for nodes and/or relationships.
Below is an example on how to do textual search on Node properties.
Create and add the nodes to the index:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Movie)
with n
call db.index.explicit.addNode(""MovieTitle"",n,""title"",n.title) yield success return count(*)
Verify the index was created by running the following command:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call db.index.explicit.list
Outputs:
╒══════╤════════════╤════════════════════════════════════╕
│""type""│""name""      │""config""                            │
╞══════╪════════════╪════════════════════════════════════╡
│""NODE""│""MovieTitle""│{""type"":""exact"",""provider"":""lucene""}│
└──────┴────────────┴────────────────────────────────────┘
Run the query to find the names of the movies starting with The:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call db.index.explicit.searchNodes('MovieTitle','title:The*')
Outputs:
╒════════════════════════════════════════════════════════════════════════════════════════════════════════════╤════════╕
│""node""                                                                                                      │""weight""│
╞════════════════════════════════════════════════════════════════════════════════════════════════════════════╪════════╡
│{""title"":""The Matrix Revolutions"",""tagline"":""Everything that has a beginning has an end"",""released"":2003}   │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Da Vinci Code"",""tagline"":""Break The Codes"",""released"":2006}                                   │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Green Mile"",""tagline"":""Walk a mile you'll never forget."",""released"":1999}                     │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Devil's Advocate"",""tagline"":""Evil has its winning ways"",""released"":1997}                      │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Polar Express"",""tagline"":""This Holiday Season… Believe"",""released"":2004}                      │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Replacements"",""tagline"":""Pain heals, Chicks dig scars... Glory lasts forever"",""released"":2000}│1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Matrix"",""tagline"":""Welcome to the Real World"",""released"":1999}                                │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Matrix Reloaded"",""tagline"":""Free your mind"",""released"":2003}                                  │1.0     │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┤
│{""title"":""The Birdcage"",""tagline"":""Come as you are"",""released"":1996}                                        │1.0     │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────┘
If more data is added associated to that index it does not automatically update the nodes to the index. Those additional nodes needs to be added to the index as follows:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Movie)
with n
call db.index.explicit.addNode(""MovieTitle"",n,""title"",n.title) yield success return count(*)
Was this page helpful?"
https://neo4j.com/developer/kb/index-limitations-and-workaround;"Index limitations and workarounds
Author Anton Persson Applicable versions 4.0 Tags indexing
In this article we discuss index providers and what limitations and workarounds there are.
There are two index types in Neo4j, btree and full-text. This article target btree indexes, up until 4.0 called schema indexes. This is the normal index you get when you create an index or index backed constraint through Cypher.
Cypher
Query
Copy to Clipboard
Run in Neo4j Browser
CREATE INDEX ""My index"" FOR (p:Person) ON (p.name)
All indexes are backed by an index provider. Full-text indexes are backed by fulltext-1.0 and btree indexes are backed by native-btree-1.0 (default) or lucene+native-3.0.
The table below lists the available btree index providers and their support for native indexing:
Index provider Value types supported for native indexing
native-btree-1.0
Native for all types
lucene+native-3.0
Lucene for single-property strings, native for the rest
Key size limit
The native-btree-1.0 index provider has a key size limit of 8167 bytes. This limit manifests itself in different ways depending on whether the key holds a single string, a single array, or multiple values (i.e. is the key in a composite index).
If a transaction reaches the key size limit for one or more of its changes, that transaction will fail before committing any changes. If the limit is reached during index population, the resulting index will be in a failed state, thus not be usable for any queries.
See below for details on how to calculate key sizes for native indexes.
If keys does not fit in this limit, most likely a full-text index is a better fit for what the use case, if that’s not the case the lucene+native-3.0 has a key size limit of 32766 bytes.
Contains and ends with queries
The native-btree-1.0 index provider have limited support for ENDS WITH and CONTAINS queries. These queries will not be able to do an optimized search the way they do for queries that use STARTS WITH, = and <>. Instead, the index result will be a stream of an index scan with filtering.
For single-property strings lucene+native-3.0 can be used instead which have full support for both ENDS WITH and CONSTAINS.
To create an index with a different provider than default, the easiest way is to use db.createIndex, db.createUniquePropertyConstraint or db.createNodeKey procedures to which you can provide index provider name. Another option is to configure the default index provider using dbms.index.default_schema_provider. Note that a restart is necessary for this config option to take effect.
Key size calculation
This part describes how to calculate key sizes for native indexes.
As described in the section about key size there are limitations to how large the key size can be when using native-btree-1.0 index provider. This appendix describes in detail how the sizes can be calculated.
Element size calculations
It is useful to know how to calculate the size of a single value when calculating the total size of the resulting key. In some cases those entry sizes is different based on whether the entry is in an array or not.
Table 1. Element sizes
Type elementSizeifSingle * elementSizeifInArray **
Byte
3
1
Short
4
2
Int
6
4
Long
10
8
Float
6
4
Double
10
8
Boolean
2
1
Date
9
8
Time
13
12
LocalTime
9
8
DateTime
17
16
LocalDateTime
13
12
Duration
29
28
Period
29
28
Point (Cartesian)
28
24
Point (Cartesian 3D)
36
32
Point (WGS-84)
28
24
Point (WGS-84 3D)
36
32
String
3 + utf8StringSize ***
2 + utf8StringSize ***
Array
†
Nested arrays are not supported
* elementSizeifSingle denotes the size of an element if is a single entry.
** elementSizeifInArray denotes the size of an element if it is part of an array.
*** utf8StringSize is the size of the String in bytes when encoded with UTF8.
† elementSizeArray is the size of an array element, and is calculated using the following formulas:
If the data type of the array is a numeric data type:
elementSizeArray = 4 + ( arrayLength * elementSizeifInArray )
If the data type of the array is a geometry data type:
elementSizeArray = 6 + ( arrayLength * elementSizeifInArray )
If the data type of the array is non-numeric:
elementSizeArray = 3 + ( arrayLength * elementSizeifInArray )
String encoding with UTF8
It is worth noting that common characters, such as letters, digits and some symbols, translate into one byte per character. Non-Latin characters may occupy more than one byte per character. Therefore, for example, a string that contains 100 characters or less may be longer than 100 bytes if it contains multi-byte characters.
More specifically, the relevant length in bytes of a string is when encoded with UTF8.
Example 1. Calculate the size of a string when used in an index
Consider the string His name was Måns Lööv.
This string has 19 characters that each occupies 1 byte. Additionally, there are 3 characters that each occupy 2 bytes per character, which add 6 to the total. Therefore, the size of the String in bytes when encoded with UTF8, utf8StringSize, is 25 bytes.
If this string is part of a native index, we get:
elementSize = 2 + utf8StringSize = 2 + 25 = 27 bytes
Example 2. Calculate the size of an array when used in an index
Consider the array [19, 84, 20, 11, 54, 9, 59, 76, 82, 27, 9, 35, 56, 80, 65, 95, 16, 91, 61, 11].
This array has 20 elements of the type Int. Since they are in an array, we need to use elementSizeifInArray, which is 4 for Int.
Applying the formula for arrays of numeric data types, we get:
elementSizeArray = 4 + ( arrayLength * elementSizeifInArray ) = 4 + ( 20 * 4 ) = 84 bytes
Non-composite indexes
The only way that a non-composite index can violate the size limit is if the value is a long string or a large array.
Strings
Strings in non-composite indexes have a key size limit of 8164 bytes.
Arrays
The following formula is used for arrays in non-composite indexes:
1 + elementSizeArray =< 8167
Here elementSizeArray is the number calculated from Element sizes.
If we count backwards, we can get the exact array length limit for each data type:
maxArrayLength = FLOOR( ( 8167 - 4 ) / elementSizeifInArray ) for numeric types.
maxArrayLength = FLOOR( ( 8167 - 4 ) / elementSizeifInArray ) for non-numeric types.
These calculations result in the table below:
Table 2. Maximum array length, per data type
Data type maxArrayLength
Byte
8163
Short
4081
Int
2040
Long
1020
Float
2040
Double
1020
Boolean
8164
String
See Maximum array length, examples for strings
Date
1020
Time
680
LocalTime
1020
DateTime
510
LocalDateTime
680
Duration
291
Period
291
Point (Cartesian)
340
Point (Cartesian 3D)
255
Point (WGS-84)
340
Point (WGS-84 3D)
255
Note that in most cases, Cypher will use Long or Double when working with numbers.
Properties with the type of String are a special case because they are dynamically sized. The table below shows the maximum number of array elements in an array, based on certain string sizes:
Table 3. Maximum array length, examples for strings
String size maxArrayLength
1
2721
10
680
100
80
1000
8
The table can be used as a reference point. For example: if we know that all the strings in an array occupy 100 bytes or less, then arrays of length 80 or lower will definitely fit.
Composite indexes
This limitation only applies if one or more of the following criteria is met:
Composite index contains strings
Composite index contains arrays
Composite index targets many different properties (>50)
We denote a targeted property of a composite index a slot. For example, an index on :Person(firstName, surName, age) has three properties and thus three slots.
In the index, each slot is filled by an element. In order to calculate the size of the index, we must have the size of each element in the index, i.e. the elementSize, as calculated in previous sections.
The following equation can be used to verify that a specific composite index entry is within bounds:
sum( elementSize ) =< 8167
Here, sum( elementSize ) is the sum of the sizes of all the elements of the composite key as defined in elementSizeifSingle in [index-configuration-limitations-element-size-calculations].
Example 3. The size of a composite index containing strings
Consider a composite index of five strings that each can occupy the maximum of 500 bytes.
Using the equation above we get:
sum( elementSize ) = 5 * ( 3 + 500 ) = 2515 < 8167
We are well within bounds for our composite index.
Example 4. The size of an index containing arrays
Consider a composite index of 10 arrays of type Float that each have a length of 250.
First we calculate the size of each array element:
elementSizeArray = 4 + ( arrayLength * elementSizeifInArray ) = 4 + ( 250 * 4 ) = 1004
Then we calculate the size of the composite index:
sum( elementSizeArray ) = 10 * 1004 = 10040 > 8167
This index key will exceed the key size limit for native indexes.
Was this page helpful?"
https://neo4j.com/developer/kb/control-number-of-file-handles-created-per-lucene-index;"Control number of file handles created per Lucene Index
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags indexing lucence open files cpu memory
In the more recent Neo4j versions (3.4 onwards), the number of file handles opened by Neo4j may seem to increase compared with that in older versions. Native indexes require a per-index constant number of file handles, and this number scales as a function of the number of CPU cores available on the system.
This is because certain index implementations, e.g. lucene+native-1.0, uses more file descriptors and for a high number of indexes (1000+ is more than avarage), hitting 60K open file descriptors limit becomes likely. This is because, in order to optimize I/O performance, we open multiple channels to all the files. The lucene+native combination, creates files for both index engines to be prepared to handle both, even if one of these isn’t used. While the consumed disk space is negligible, it’s still a couple of extra file descriptors, per index, that gets used. Currently, there is no way to toggle this off but a pure native index option in future may address this.
The Lucene based indexes require a per-index number of file handles that scales as a function of the number of open transactions that interact with indexes. e.g. in a case of 72 cpu cores and for 100 native indexes, the number of file handles will top out at 64 file handles per index. It may be useful, firstly to determine the current number of schema indexes (the number of rows from CALL db.indexes()) as well as the current default index provider. This is set by the value of dbms.index.default_schema_provider in neo4j.conf, e.g. lucene+native-1.0 or native-btree-1.0.
The number of file descriptors will most likely spike during high load, so even if the database manages to start it can still fail during runtime due to that limit, so it is recommended to keep a margin there. This is because the index creates a lot of smaller files during transaction execution, which is then merged to a single large file in a background thread. Generally, this merging is faster than the rate of transactions, but there is still a bit of lag before those files get merge and this temporarily increases the number of open files.
The impact of this increased number of open files however, is highly depending on the OS and hardware. If required, one can tweak the striping factor with an undocumented feature flag, e.g.
-Dorg.neo4j.io.pagecache.implSingleFilePageSwapper.channelStripePower=2
The default value is calculated from the number of available CPU cores, rounded up to the closest number of the ones listed above. The integer value of the above parameter, is the exponent to which 2 is raised. Therefore, if channelStripePower is 5, then you will get 2^5 = 32 stripes aka. file descriptors for every individual mapped file. One can set it to 0 to have only one file descriptor per mapped file. Setting it to 1 will open 2 file descriptors, 2 will open 4, 3 opens 8, and so on. Note that setting channelStripePower=0 can have a performance penalty, which is why it is not the default value. Lowering this setting might impact performance, especially on Windows, but on e.g. macOS, you can probably get away with lowering it. As every hardware is different, it is best to trial using various values to see with what works for a given hardware setup.
References:
https://github.com/neo4j/neo4j/issues/11739
Was this page helpful?"
https://neo4j.com/developer/kb/hosting-multiple-neo4j-instances-on-one-machine;"Hosting Multiple Neo4j Instances On One Machine
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags hardware planning monitoring cpu ram
This document lists some considerations whilst planning to host multiple neo4j instances on the same physical host machine.
Multiple instances are allowed though this is not typically seen in the field. As a starting point of planning one should ideally monitor the following over e.g. 1-2 weeks of production for each neo4j instance planned to be co-hosted:
peak memory utilisation and times
peak cpu usage and times
standard variance between peaks and average
memory and cpu utilisation at rest
We then need to consider the following neo4j specific requirements:
heap initial & max size allocations (should be same by default)
pagecache allocation
2-3 GB for the OS
Max open files limit (https://docs.oracle.com/cd/E19623-01/820-6168/file-descriptor-requirements.html)
current size of the database, standard variance in size and foreseeable growth via import etc.
type of queries, both read and write, periodic jobs running such queries and corresponding resource utilisation
Once above are estimated/profiled, we can account for expected growth and if the host is capable enough to account for additional instances (for which the above is also estimated), then we can proceed with adding further instances.
Lets have a sample machine with below specs:
Total memory (RAM) = 200GB
Total CPU(s) = 12
CPU clock frequency = 2.5GHz
And the following sample neo4j parameters set for a single neo4j instance already running on the machine:
Total database size = 12G
Page Cache = 15G
Heap = 12G
Following are sample cpu and memory profiles for the above single instance over a 6 month period:
We can see the CPU peaking occasionally at 30% which seems reasonably low if a second instance were to be added to the host machine.
We can see that memory usage has peaked frequently above 90% and then 50% at times.
Assuming in our example, that Neo4j was the only production application (and the primary memory using application we would need to see transactions executed at the time when memory utilisation peaked at 50% and above 90% and adding in the expected workload of the second instance will then give an idea of the required RAM on the machine.
Ideally, one would want to keep as much of the database in pagecache as possible (to minimize disk hits), whilst allowing for store sizes, indexes and expected growth. A rule of thumb is store size + expected growth + 10%. So, for a store thats 12GB, and we expect that to double in size in the next year, we would ideally allocate 12GB + 12GB + 1.2GB = 25.2GB. Again, this depends largely on expected growth. 8GB-12GB in most cases is a good default figure for heap, but this eventually depends on executed transaction types.
Assuming above, one would need 25.2GB(pagecache) + 12GB(heap) + 3GB (OS) = approx 40GB per instance of ram. Since we assume there is 200GB on the host machine, this should be sufficient, but what we really need to see whilst profiling, is the peak memory usage of each instance over e.g. 1-2 weeks in production.
Importantly also, lets say the peak cpu utilisation by instance 1 never exceeds X% and if instance 2 never exceeds Y% and X+Y (peak) is always less than 90% of total CPU, then in such case, hosting a second instance on that machine may work fine.
Another important consideration in terms of cpu, is how many threads simultaneously can the total CPUs handle and what is the CPU clock frequency. Hyperthreaded cores are claimed to be able to handle twice the number of threads (although in practice, they just use a thread’s waiting time more efficiently to process other threads). It is perhaps therefore best to assume the max simultaneous thread executions to be equal number of cores, i.e. 12 in our example. How transactions are submitted by the read/write queries and well as the thread processing capability (cpu’s clock rate) will determine what percentage of the cpu is used at peak, by each neo4j instance. This is best estimated by actual profiling over time.
Do also consider the store size and transaction log growth over time, per instance to avoid running out of disk space. Peak expected growth total for each instances should never increase beyond available disk space (here is a good reference about transaction log growth and rotation: https://neo4j.com/docs/operations-manual/current/configuration/transaction-logs/).
Finally, configuring multiple instances one needs to be mindful of port allocations, availability and conflicts, particularly with those used by other Neo4j instances. If the multiple instances being set up, are to be clustered, communications between cluster member via ports/IPs must be correctly configured in each member’s configuration.
Was this page helpful?"
https://neo4j.com/developer/kb/changes-to-metrics-csv-reporting-from-2-x-to-3-x;"Changes to metrics.csv reporting from 2.x to 3.x
Author Dana Canzano Applicable versions 2.3 3.0 Tags metrics csv monitoring
Metrics reporting is an Enterprise feature which upon enablement allows for the creation of .csv files at a specified interval to record key metrics. This is described in detail at http://neo4j.com/docs/operations-manual/current/monitoring/.
Differences between 2.x and 3.x are as follows:
File Name Changes
In 2.x all data was written to a single file named metrics.csv with multiple metrics per each line. When enabling all metrics, the contents of the metrics.csv would appear as follows
Csv
Copy to Clipboard
timestamp,datetime,neo4j.check_point.events,neo4j.check_point.total_time,neo4j.cluster.slave_pull_update_up_to_tx,neo4j.cluster.slave_pull_updates,neo4j.ids_in_use.node,neo4j.ids_in_use.property,neo4j.ids_in_use.relationship,neo4j.ids_in_use.relationship_type,neo4j.log_rotation.events,neo4j.log_rotation.total_time,neo4j.network.master_network_store_writes,neo4j.network.master_network_tx_writes,neo4j.network.slave_network_tx_writes,neo4j.page_cache.eviction_exceptions,neo4j.page_cache.evictions,neo4j.page_cache.flushes,neo4j.page_cache.page_faults,neo4j.page_cache.pins,neo4j.page_cache.unpins,neo4j.transaction.active,neo4j.transaction.committed,neo4j.transaction.peak_concurrent,neo4j.transaction.rollbacks,neo4j.transaction.started,neo4j.transaction.terminated,vm.gc.count.g1_old_generation,vm.gc.count.g1_young_generation,vm.gc.time.g1_old_generation,vm.gc.time.g1_young_generation,vm.memory.buffer.direct.capacity,vm.memory.buffer.direct.count,vm.memory.buffer.direct.used,vm.memory.buffer.mapped.capacity,vm.memory.buffer.mapped.count,vm.memory.buffer.mapped.used,vm.memory.pool.code_cache,vm.memory.pool.compressed_class_space,vm.memory.pool.g1_eden_space,vm.memory.pool.g1_old_gen,vm.memory.pool.g1_survivor_space,vm.memory.pool.metaspace,vm.thread.count +
1462999417,2016-05-11 16:43:37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,3,1,0,3,0,0,10,0,143,200704,4,200704,0,0,0,6481152,6456096,40894464,41358552,8388608,41533256,19
1462999420,2016-05-11 16:43:40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,3,1,0,3,0,0,12,0,192,200704,4,200704,0,0,0,8297600,6933152,23068672,47649992,6291456,45081632,20
1462999423,2016-05-11 16:43:43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,3,1,0,3,0,0,12,0,192,200704,4,200704,0,0,0,8298368,6933152,23068672,47649992,6291456,45081920,20
In 3.x each metric is written to its own file, rather than a single metrics.csv. For example the following files are created
neo4j.bolt.accumulated_processing_time.csv     neo4j.page_cache.page_faults.csv            neo4j.transaction.terminated_write.csv
neo4j.bolt.accumulated_queue_time.csv          neo4j.page_cache.pins.csv                   vm.gc.count.g1_old_generation.csv
neo4j.bolt.messages_done.csv                   neo4j.page_cache.unpins.csv                 vm.gc.count.g1_young_generation.csv
neo4j.bolt.messages_received.csv               neo4j.server.threads.jetty.all.csv          vm.gc.time.g1_old_generation.csv
neo4j.bolt.messages_started.csv                neo4j.server.threads.jetty.idle.csv         vm.gc.time.g1_young_generation.csv
neo4j.check_point.events.csv                   neo4j.transaction.active.csv                vm.memory.buffer.direct.capacity.csv
neo4j.check_point.total_time.csv               neo4j.transaction.active_read.csv           vm.memory.buffer.direct.count.csv
neo4j.cypher.replan_events.csv                 neo4j.transaction.active_write.csv          vm.memory.buffer.direct.used.csv
neo4j.ids_in_use.node.csv                      neo4j.transaction.committed.csv             vm.memory.buffer.mapped.capacity.csv
neo4j.ids_in_use.property.csv                  neo4j.transaction.committed_read.csv        vm.memory.buffer.mapped.count.csv
neo4j.ids_in_use.relationship.csv              neo4j.transaction.committed_write.csv       vm.memory.buffer.mapped.used.csv
neo4j.ids_in_use.relationship_type.csv         neo4j.transaction.last_closed_tx_id.csv     vm.memory.pool.code_cache.csv
neo4j.log_rotation.events.csv                  neo4j.transaction.last_committed_tx_id.csv  vm.memory.pool.compressed_class_space.csv
neo4j.log_rotation.total_time.csv              neo4j.transaction.peak_concurrent.csv       vm.memory.pool.g1_eden_space.csv
neo4j.network.master_network_store_writes.csv  neo4j.transaction.rollbacks.csv             vm.memory.pool.g1_old_gen.csv
neo4j.network.master_network_tx_writes.csv     neo4j.transaction.rollbacks_read.csv        vm.memory.pool.g1_survivor_space.csv
neo4j.network.slave_network_tx_writes.csv      neo4j.transaction.rollbacks_write.csv       vm.memory.pool.metaspace.csv
neo4j.page_cache.eviction_exceptions.csv       neo4j.transaction.started.csv               vm.thread.count.csv
neo4j.page_cache.evictions.csv                 neo4j.transaction.terminated.csv            vm.thread.total.csv
neo4j.page_cache.flushes.csv                   neo4j.transaction.terminated_read.csv
Location
In 2.x the default path for the .csv files is in data/graph.db
In 3.x the default path for the .csv files is in $NEO4J_HOME/metrics
Was this page helpful?"
https://neo4j.com/developer/kb/parsing-of-quotes-for-load-csv-and-or-import;"Parsing of quotes for LOAD CSV and/or Import
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load-csv quotes csv
When using LOAD CSV or neo4j-admin import if your data contains quotes they must be properly escaped to be imported otherwise one might encounter the error
neo4j-admin import error
Shell
Copy to Clipboard
$ ./neo4j-admin import --database=hr.db --nodes:Staff hr.csv
Neo4j version: 3.3.0
Importing the contents of these files into /home/neo4j/neo4j-enterprise-3.3.0/data/databases/hr.db:
Nodes:
  :Staff
  /home/neo4j/neo4j-enterprise-3.3.0/bin/hr.csv

Available resources:
  Total machine memory: 4.95 GB
  Free machine memory: 4.46 GB
  Max heap memory : 989.88 MB
  Processors: 1
  Configured max memory: 3.14 GB

Nodes, started 2017-12-07 14:35:45.158+0000
[*>:??----------------------------------------------------------------------------------------]    0 ∆    0
Done in 159ms
Error in input data
Caused by:ERROR in input
  data source: BufferedCharSeeker[source:/home/neo4j/neo4j-enterprise-3.3.0/bin/hr.csv, position:59, line:2]
  in field: name:string:2
  for header: [id:int, name:string, supervisor:int]
  raw field value: 2
  original error: At /home/neo4j/neo4j-enterprise-3.3.0/bin/hr.csv:2 -  there's a field starting with a quote and whereas it ends that quote there seems to be characters in that field after that ending quote. That isn't supported. This is what I read: 'Bill""'
View all (9 more lines)
LOAD CSV error
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM ""file:///hr.csv"" AS row FIELDTERMINATOR ','  CREATE (n:Staff { staffid: toInt(row.id), staff_name: row.name});
At /home/neo4j/neo4j-enterprise-3.3.0/import/hr.csv:2 -  there's a field starting with a quote and whereas it ends that quote there seems to be characters in that field after that ending quote. That isn't supported. This is what I read: 'Bill""'
For the above case my hr.csv is defined as
Csv
Copy to Clipboard
id:int,name:string,supervisor:int
1,Emil Eifrem,1
2,""Bill"" William Smith,1
3,Dana Canzano,2
And the failure is with parsing line 2 and as a result of the line starting with a "". In order to import the above into Neo4j and have line 2 be recognized as ""Bill"" William Smith the data needs to be reformatted to
Csv
Copy to Clipboard
id:int,name:string,supervisor:int
1,Emil Eifrem,1
2,""""""Bill"""" William Smith"",1
3,Dana Canzano,2
The data will then successfully import as evidence
Cypher-shell
Copy to Clipboard
neo4j> match (n) return n;
+-----------------------------------------------------------------+
| n                                                               |
+-----------------------------------------------------------------+
| (:Staff {name: ""Emil Eifrem"", id: 1, supervisor: 1})            |
| (:Staff {name: ""\""Bill\"" William Smith"", id: 2, supervisor: 1}) |
| (:Staff {name: ""Dana Canzano"", id: 3, supervisor: 2})           |
+-----------------------------------------------------------------+
Note this same syntax structure of the CSV data relative to inclusion of quoted data is also successfully processed by MS Excel, Open Office Calc
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-specific-http-request-user-agent-strings;"Neo4j specific http request user agent strings
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load-csv apoc user-agent webserver logging
For those APOC commands that retrieve data using HTTP/HTTPS, and or running Cypher LOAD CSV the request will be sent with Neo4j specific user-agent/browser identifiers.
Below is an example log from an Apache webservers access log at /var/log/apache2/access.log and includes 4 request made by:
Chrome Browser,
Firefox Browser,
linux curl
apoc.load.json
LOAD CSV request submitted via bin/cypher-shell
192.168.2.38 - - [26/Mar/2018:19:16:52 -0400] ""GET / HTTP/1.1"" 200 3477 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36""
192.168.2.38 - - [26/Mar/2018:19:17:23 -0400] ""GET / HTTP/1.1"" 404 3477 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0""
192.168.2.40 - - [26/Mar/2018:19:21:11 -0400] ""GET /test.json HTTP/1.1"" 200 989 ""-"" ""curl/7.55.1""
192.168.2.40 - - [26/Mar/2018:19:26:37 -0400] ""GET /test.json HTTP/1.1"" 200 989 ""-"" ""APOC Procedures for Neo4j""
192.168.2.40 - - [26/Mar/2018:19:46:01 -0400] ""GET /test.csv HTTP/1.1"" 200 502 ""-"" ""NeoLoadCSV_Java/1.8.0_151""
From the above we see that apoc.load.json sent a user-agent of APOC Procedures for Neo4j and LOAD CSV sent a user-agent of NeoLoadCSV_Java/1.8.0_151. Additionally; for any Bolt enabled application, for example Neo4j Browser and cypher-shell the user-agent will be the same since the work is actually being done on the server itself.
As such if your Network Firewall is to only allow HTTP(s) request traffic of the typical known user-agent/browser identifiers, and reject all other traffic you may encounter where a request through a typical browser reports data but when using APOC or LOAD CSV no data is returned.
Was this page helpful?"
https://neo4j.com/developer/kb/configuring-remote-jmx-monitoring;"Configuring Remote JMX monitoring
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jmx monitoring
In order to enable JMX Remote monitoring, edit the neo4j.conf file in Neo4j 3.1.x versions and uncomment the following lines:
Properties
Copy to Clipboard
dbms.jvm.additional=-Dcom.sun.management.jmxremote.port=3637
dbms.jvm.additional=-Dcom.sun.management.jmxremote.authenticate=true
dbms.jvm.additional=-Dcom.sun.management.jmxremote.password.file=conf/jmx.password
dbms.jvm.additional=-Dcom.sun.management.jmxremote.access.file=conf/jmx.access
After uncommenting the above lines, restart neo4j. If the neo4j process does not start, look in the logs/neo4j.log file and look for errors.
If you see one of the following errors:
Error: Password file not found: conf/jmx.password
or
Error: Access file not found: conf/jmx.access
It means neo4j it is unable to locate the jmx.password and/or jmx.access files. In order to fix this issue, one will need to specify the complete path for those files as shown below:
Properties
Copy to Clipboard
dbms.jvm.additional=-Dcom.sun.management.jmxremote.password.file=$NEO4J_HOME/conf/jmx.password
dbms.jvm.additional=-Dcom.sun.management.jmxremote.access.file=$NEO4J_HOME/conf/jmx.access
After making the above changes restart neo4j and verify that the database comes online.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-display-date-and-time-of-when-neo4j-was-started-and-other-metrics;"How do I display date and time of when neo4j was started and other metrics
Author Dana Canzano Applicable versions 3.1 Tags functions apoc jmx
The following Cypher will utilize the JMX metrics as part of 3.1 Enterprise and display the date/time when Neo4j was started.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL dbms.queryJmx(""org.neo4j:instance=kernel#0,name=Kernel"") yield attributes
       with  keys(attributes) as k , attributes
       unwind k as row
       return row,
         case row
             when 'StoreCreationDate' then apoc.date.format(attributes[row][""value""],""ms"", null, apoc.date.systemTimezone())
             when 'KernelStartTime' then apoc.date.format(attributes[row][""value""],""ms"", null, apoc.date.systemTimezone())
             else attributes[row][""value""] end as value;
which will produce output similar to:
""KernelVersion"", ""neo4j-kernel, version: 3.1.0-M13-beta3,ce6b3ff5d345f11e981c1fe5be4b0fe3640c5aee""
""DatabaseName"", ""graph.db""
""MBeanQuery"", ""org.neo4j:instance=kernel#0,name=*""
""StoreId"", ""43a957e6b0c46148""
""ReadOnly"", FALSE
""StoreCreationDate"", ""2016-11-04 20:34:32""
""StoreLogVersion"", 0
""KernelStartTime"", ""2016-11-18 18:24:18""
In the above output, the StoreCreationDate and KernelStartTime are expressed in the system timezone time. Note that this Cypher utilizes the user defined function apoc.date.format which is included as part of the APOC package.
Was this page helpful?"
https://neo4j.com/developer/kb/migrating-explicit-lucene-indexes-to-native-schema-indexes;"Migrating Explicit Lucene Indexes to Native Schema Indexes
Author Ali Maddahian Applicable versions 1.x 2.x 3.x 4.x Tags lucene index legacy explicit capacity schema full-text
Given that there are still some customers on the older Neo4j releases that utilize legacy/explicit indexes, we will discuss a few pointers here on how to convert these indexes to native schema indexes when upgrading to Neo4j version 4.x, as legacy/explicit indexes have been deprecated as of 3.5.x, and totally removed from the 4.x version.
As to the background, Legacy/explicit indexes were the only type of indexes available prior to Neo4j 3.2(release date 2017). These early version indexes which were implemented via Lucene under the cover, typically resulted in significant write performance degradation, and thus the need to replace them with the native schema indexes available in 3.3+ releases.
Aside from the performance perspective and equally important, explicit indexes also have to be explicitly/manually kept-up-to date when adding/removing/updating nodes/relationships/properties by way of the Java API (and/or stored procedures starting with 3.3.x), hence why they are called explicit indexes.
In contrast, native indexes are maintained automatically, thus eliminating the need for any such manual steps and/or extra code to keep them current.
From an implementation perspective, these legacy indexes do not list much of schema details and besides the original author’s chosen naming convention at the time of the index creation, there is not a whole lot of usable clue to help with implementing an automated process for migrating these indexes to Neo4j’s native schema indexes in a scripted manner.
Thus any index migration would have to be done on an index by index basis and might involve some level of guessing. This means you having to look at the API code and assess which node or relationship properties are being indexed, and accordingly implement a complementing schema index on those properties and/or look at the cypher query and come up with supporting indexes to optimize its execution.
Overall at a high level, here is the recommended approach:
1) Get a listing of all your indexes on your existing version
Example: in 3.x you can use ""call db.index.explicit.list();"" which will show the index name as well as its type, which can be either “exact” or “full-text”, as well as if it is a node or relationship index, which will help you to determine what type of schema index to construct.
2) Next look at your cypher and/or Java API code and convert them accordingly to 4.x+ format.
For example, convert ""start"" statements to equivalent Match statement. Example:
START n=node:myExplicitIndexYear(""myid:1234567"") RETURN n;
The above query would be changed to the following:
MATCH (n:Person{myid:1234567}) RETURN n;
3) Implement the equivalent schema index that you would need to support and optimize the execution of the associated/converted queries from step 2.
Example: CREATE INDEX index_name FOR (n:Person) ON (n.myid);
More specifically:
Inspect all cypher queries for what they actually write to that index and derive either a create index (for integer, strings, dates, geospatial, etc) and/or call db.index.fulltext.createIndexForNodes (FTS) statements.
Inspect all reads to that index and adopt the statements to use the new index (this would mean to enable query logging to capture generated cypher queries and its performance attributes such as execution time vs io vs memory, vs cpu to flag longest running queries to troubleshoot individually one at a time - and more than likely your query patterns are similar to each other, hence, once one query is fixed, it will similarly help other similar queries.).
4) Once finished with all the explicit indexes, then shut down the database and move/delete the associated index subfolder(e.g. /data/databases/graph.db/index).
Please note, if it happens that having converted a legacy index to an equivalent schema index, the search query using the legacy indexes are returning an unexpected number of rows (compared to schema indexes), then this likely indicates that the schema index may have been incorrectly defined (on wrong label:properties), or, the legacy index is not up to date (remember legacy indexes must be manually kept up to date, hence as an example, without the appropriate error handling in your Java API code, it is entirely possible that a transaction would not have been correctly retried and applied commits when encountering a rollback due to any reason, such as server restarts, etc). Here is a 3.x example demonstrating such case:
None
Copy to Clipboard
// Create New Nodes
//
CREATE (p:Person {name:'Steve_1',year:1990});
CREATE (p:Person {name:'Steve_2',year:1990});
CREATE (p:Person {name:'Steve_3',year:1990});


// Create Two Explicit Indexes(also called Legacy/Manual/Lucene Indexes)
//
CALL db.index.explicit.forNodes('myExplicitIndexFTS', {type: 'fulltext', provider: 'lucene'});
CALL db.index.explicit.forNodes('myExplicitIndexYear', {type: 'exact', provider: 'lucene'});

// List Explicit Indexes
//
call db.index.explicit.list;

// Index nodes with name property
//
MATCH (p:Person{name:'Steve_1'}) call db.index.explicit.addNode('myExplicitIndexFTS', p, 'name', 'Steve_1') yield success return count(*);
MATCH (p:Person{name:'Steve_2'}) call db.index.explicit.addNode('myExplicitIndexFTS', p, 'name', 'Steve_2') yield success return count(*);

// Index nodes with ""birth year"" property
//
match (p:Person{name:'Steve_1'})
with p
call db.index.explicit.addNode(""myExplicitIndexYear"",p,""year"",p.year) yield success return count(*);

// Search for persons with matching name VE, which will only return Steve_1, and Steve_2
//
CALL db.index.explicit.searchNodes('myExplicitIndexFTS','name:*VE*');

// Search for persons with year=1990 which will only return Steve_1
//
CALL db.index.explicit.searchNodes('myExplicitIndexYear','year:1990');

// Search for persons with year=1990 using explicit index which will only return Steve_1
//
start n=node:myExplicitIndexYear(""year:1990"") return n;

// Convert ""start"" to equivalent Match statement, and this statement returns all 3 rows corresponding to year=1990 (and of course ideally, you would want to create an index on :Person(
year) or :Person(name) for best performance when creating equivalent native schema indexes on these two properties.
match (n:Person{year:1990}) return n;
View all (27 more lines)
Appendix:
For a full list of deprecated features per each version please visit the following link: https://neo4j.com/docs/cypher-manual/current/deprecations-additions-removals-compatibility/
As noted above, 3.3.x, also offered explicit index implementations using stored-procedures in order to make them easier to implement without resorting to using Java API, however, these also would have had to be maintained manually. Additionally, these sets of procedures were also deprecated as of 3.5.x, and were replaced in 4.0,4.1,4.2 with new set of procedures (to be used solely for Full-Text-Search usecases) as documented here: https://neo4j.com/docs/cypher-manual/current/administration/indexes-for-full-text-search/
Additionally, per 4.3.0 changelog, all FTI procedures are deprecated.
""Introduce CREATE FULLTEXT INDEX… Cypher command. Deprecate db.index.fulltext.createNodeIndex, db.index.fulltext.createRelationshipIndex and db.index.fulltext.drop."".
Documentation to pre-3.x Java API code that would have to modified/removed:
https://neo4j.com/docs/java-reference/3.0/indexing/
https://neo4j.com/docs/stable/indexing-create.html
https://neo4j.com/docs/java-reference/3.0/javadocs/
Was this page helpful?"
https://neo4j.com/developer/kb/setting-max-open-file-limits-on-osx;"Setting Max Open File Limits on Mac OSX
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags open-files
This document provides a process for setting soft and hard max open file limits on MAC OSX. Each thread created by a user process will require availability in max open file limits.
Caused by: java.io.IOException: Too many open files
It should be ensured the user running the the neo4j process has the open file limits correctly set. The below process was tested on OSX 10.12.x (Sierra) and Mojave (10.14.x) to change file limits. The same is also reported to work for Yosemite and El Capitan OSX versions, but do note that the process may differ for other OSX versions.
1) In /Library/LaunchDaemons create a file named limit.maxfiles.plist and paste the following in (You can change the two numbers 64000 and 200000 in this case, which are the soft and hard limits, respectively as required). One can check soft limit by ulimit -Sn and hard limit as ulimit -Hn :
Xml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
  <!DOCTYPE plist PUBLIC ""-//Apple//DTD PLIST 1.0//EN""
          ""http://www.apple.com/DTDs/PropertyList-1.0.dtd"">
  <plist version=""1.0"">
    <dict>
      <key>Label</key>
      <string>limit.maxfiles</string>
      <key>ProgramArguments</key>
      <array>
        <string>launchctl</string>
        <string>limit</string>
        <string>maxfiles</string>
        <string>64000</string>
        <string>200000</string>
      </array>
      RunAtLoad
      
      ServiceIPC
      
    
  
View all (6 more lines)
2) Change the owner of your new file:
Shell
Copy to Clipboard
$ sudo chown root:wheel /Library/LaunchDaemons/limit.maxfiles.plist
3) Load these new settings:
Shell
Copy to Clipboard
$ sudo launchctl load -w /Library/LaunchDaemons/limit.maxfiles.plist
4) Finally, check that the limits are correct:
Shell
Copy to Clipboard
$ launchctl limit maxfiles
5) In some cases a machine restart may be required for above to take effect.
References: https://gist.github.com/tombigel/d503800a282fcadbee14b537735d202c
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-lucene-1-0-too-many-open-files-error;"Explanation of lucene-1.0: Too many open files error
Author Dana Canzano Applicable versions 3.5 Tags index open-files
If one encounters a 'Too many open files' error in their $NEO4J_HOME/logs/debug.log similar to
Caused by: java.nio.file.FileSystemException: /data/neo4j/db/schema/index/lucene_native-2.0/1612/lucene-1.0: Too many open files
    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
    at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:427)
    at java.nio.file.Files.newDirectoryStream(Files.java:457)
this can be addressed by setting in your $NEO4J_HOME/conf/neo4j.conf and parameter
Properties
Copy to Clipboard
dbms.jvm.additional=-Dorg.neo4j.io.pagecache.implSingleFilePageSwapper.channelStripePower=0
Without this parameter for each index we will maintain many open file handles into a single file whereby each is responsible for a portion of the file. Whereas with the parameter set as above then we will have one open file handle per file thus reducing the number of open file handles.
It should be noted that in Neo4j 4.0 this parameter will automatically default to 0.
Was this page helpful?"
https://neo4j.com/developer/kb/graph-analytics-in-layman-terms;"Graph Analytics In Layman Terms
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags analytics storage graph gds
Graphs in general are very powerful in providing answers where relations do matter a lot. In this context, using graph queries (Cypher) allows us to answer specific questions when we know what to look for, such as:
Finding fraudsters as well as victims by way of using transaction data,
And then further extending this relationship to the associated product catalogs to come up with recommendations,
And from there integrating it with process flows to come up with its digital twin as well as supply chain information.
So by way of defining the relationships between the above domains we can add immense value to such use cases such as customer360, fraud detection, product recommendation, digital twin, supply chains and so on.
That said, beyond the specific pointed queries, what if we wanted to gain deep insight against such data to answer general questions such as finding communities or just what’s generally important?
Then for such use cases, Graph Data Science Libraries(GDS) is where it comes handy, as it provides a number of useful algos allowing us to do fancy things in a timely manner.
Unsupervised Algorithms
For instance, what if you wanted to get a picture of what is important? Well, GDS has over 50+ (unsupervised learning) algorithms which can provide you answers to a variety of example queries such as below:
Which nodes are most important?
Which nodes are clustered together?
Which nodes are most similar?
Which nodes are most unusual?
OR
Where are the clusters?
Which parts of my graph are more densely connected to each other?
Which parts are likely to be connected?
What patterns are common?
Finding associations and lower dimensional representations with embeddings.
Generally speaking, the unsupervised GDS algorithms allow us to find patterns such as:
Centrality computation — Finding objects in the network that are critical and central to the graph,
Similarity algorithms — Similarity between objects (based on properties and connections)
Path finding algorithms — Shortest path to something
Community Detection algorithms — what communities are there
Heuristic link prediction - Predicting relationships based on set of rules
Supervised Algorithms and Machine learning
More often than not, you want to leverage your graph data to make predictions about the future based on the data from the past, such as labeling (i.e. potential fraudsters) or recommendations(i.e. churns).
In such cases, you can use graph embedding to create a numerical/tabular representation of the graph that can be fed to ML models to make such tasks easier, but more importantly, we can further leverage feature extraction algos to further enrich the training data (and hence the models) for continuous improved accuracy of our predictions.
At the end of the day, embedded trained data from in-database graph data has the advantage that the data doesn’t have to be moved from external sources, and such tasks can be done immensely faster and easier.
Was this page helpful?"
https://neo4j.com/developer/kb/diagnose-storage-performance-issues;"Diagnose storage performance issues
Author Jeremie Phoulchand Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags storage performance installation configuration
Slow storage can affect Neo4j performance, therefore we recommend using Solid State Drives in the product documentation.
Benchmark your underlying system
On Ubuntu or RedHat, you can use fio tool to benchmark your underlying storage.
The command below will create a 1GB file in the current folder:
Shell
Copy to Clipboard
$ fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=random_read_write.fio --bs=4k --iodepth=64 --size=1G --readwrite=randrw --rwmixread=50
It produces the following output on an AWS instance with a gp2 (General Purpose SSD). We can see 1500iops:
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.1.5
Starting 1 process
test: Laying out IO file(s) (1 file(s) / 1024MB)
Jobs: 1 (f=1): [m] [100.0% done] [6100KB/5892KB/0KB /s] [1525/1473/0 iops] [eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2394: Thu Nov  7 15:34:32 2019
  read : io=524704KB, bw=6074.2KB/s, iops=1518, runt= 86383msec
  write: io=523872KB, bw=6064.6KB/s, iops=1516, runt= 86383msec
  cpu          : usr=0.23%, sys=1.21%, ctx=86679, majf=0, minf=6
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=131176/w=130968/d=0, short=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=524704KB, aggrb=6074KB/s, minb=6074KB/s, maxb=6074KB/s, mint=86383msec, maxt=86383msec
  WRITE: io=523872KB, aggrb=6064KB/s, minb=6064KB/s, maxb=6064KB/s, mint=86383msec, maxt=86383msec

Disk stats (read/write):
  nvme0n1: ios=131032/130833, merge=0/27, ticks=1289168/1306400, in_queue=2508680, util=99.78%
On a modern laptop, you can expect 13000iops.
Shell
Copy to Clipboard
$ fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=random_read_write.fio --bs=4k --iodepth=64 --size=1G --readwrite=randrw --rwmixread=50
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.7
Starting 1 process
Jobs: 1 (f=1): [m(1)][100.0%][r=52.4MiB/s,w=52.4MiB/s][r=13.4k,w=13.4k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=8720: Thu Nov 14 15:25:49 2019
   read: IOPS=13.4k, BW=52.2MiB/s (54.7MB/s)(512MiB/9804msec)
   bw (  KiB/s): min=51625, max=55192, per=99.55%, avg=53220.42, stdev=977.74, samples=19
   iops        : min=12906, max=13798, avg=13304.89, stdev=244.52, samples=19
  write: IOPS=13.4k, BW=52.2MiB/s (54.8MB/s)(512MiB/9804msec)
   bw (  KiB/s): min=51865, max=54634, per=99.55%, avg=53247.68, stdev=774.47, samples=19
   iops        : min=12966, max=13658, avg=13311.63, stdev=193.63, samples=19
  cpu          : usr=4.52%, sys=75.46%, ctx=1117, majf=0, minf=28
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=131040,131104,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=52.2MiB/s (54.7MB/s), 52.2MiB/s-52.2MiB/s (54.7MB/s-54.7MB/s), io=512MiB (537MB), run=9804-9804msec
  WRITE: bw=52.2MiB/s (54.8MB/s), 52.2MiB/s-52.2MiB/s (54.8MB/s-54.8MB/s), io=512MiB (537MB), run=9804-9804msec

Disk stats (read/write):
  sda: ios=128856/128900, merge=19/39, ticks=148871/43881, in_queue=192710, util=99.10%
View all (10 more lines)
On an nvme locally attached drive: we get 100 000 iops.
Shell
Copy to Clipboard
$ fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=random_read_write.fio --bs=4k --iodepth=64 --size=1G --readwrite=randrw --rwmixread=50
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.1.5
Starting 1 process
test: Laying out IO file(s) (1 file(s) / 1024MB)
Jobs: 1 (f=1)
test: (groupid=0, jobs=1): err= 0: pid=5451: Sat Nov 30 04:12:00 2019
  read : io=524704KB, bw=411856KB/s, iops=102963, runt=  1274msec
  write: io=523872KB, bw=411203KB/s, iops=102800, runt=  1274msec
  cpu          : usr=28.91%, sys=63.71%, ctx=5080, majf=0, minf=5
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=131176/w=130968/d=0, short=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=524704KB, aggrb=411855KB/s, minb=411855KB/s, maxb=411855KB/s, mint=1274msec, maxt=1274msec
  WRITE: io=523872KB, aggrb=411202KB/s, minb=411202KB/s, maxb=411202KB/s, mint=1274msec, maxt=1274msec

Disk stats (read/write):
  nvme0n1: ios=108546/108561, merge=0/0, ticks=40192/9032, in_queue=48820, util=86.23%
View all (8 more lines)
A throughput optimised HDD will be able to handle significantly less iops: 66 iops
Shell
Copy to Clipboard
$ fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=random_read_write.fio --bs=4k --iodepth=64 --size=1G --readwrite=randrw --rwmixread=50
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.1.5
Starting 1 process
Jobs: 1 (f=1): [m] [99.9% done] [768KB/732KB/0KB /s] [192/183/0 iops] [eta 00m:02s]
test: (groupid=0, jobs=1): err= 0: pid=967: Fri Nov 29 17:35:59 2019
  read : io=524704KB, bw=273928B/s, iops=66, runt=1961452msec
  write: io=523872KB, bw=273493B/s, iops=66, runt=1961452msec
  cpu          : usr=0.08%, sys=0.18%, ctx=235668, majf=0, minf=5
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=131176/w=130968/d=0, short=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=524704KB, aggrb=267KB/s, minb=267KB/s, maxb=267KB/s, mint=1961452msec, maxt=1961452msec
  WRITE: io=523872KB, aggrb=267KB/s, minb=267KB/s, maxb=267KB/s, mint=1961452msec, maxt=1961452msec

Disk stats (read/write):
  xvdba: ios=130360/130859, merge=641/1085, ticks=59917432/59357236, in_queue=119277180, util=100.00%
View all (6 more lines)
Monitor a specific storage device in Real-Time
First, you need to identify which storage device is used by Neo4j.
Shell
Copy to Clipboard
$ df /var/lib/neo4j/
Filesystem     1K-blocks    Used Available Use% Mounted on
/dev/sda1        4972896 3534496   1188180  75% /
You can use iostat which is provided in sysstat package. The command below will give you the disk activity for every devices every 3 seconds.
Shell
Copy to Clipboard
$ iostat -m 3
Linux 3.10.0-1062.4.1.el7.x86_64 (node02)  14/11/19  _x86_64_ (1 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.67    0.00    0.79    0.06    0.00   98.48

Device:            tps    MB_read/s    MB_wrtn/s    MB_read    MB_wrtn
sda             119.72         0.35         0.27        807        624

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.00    0.00    0.00    0.00    0.00  100.00

Device:            tps    MB_read/s    MB_wrtn/s    MB_read    MB_wrtn
sda               0.00         0.00         0.00          0          0

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.00    0.00    0.00    0.00    0.00  100.00

Device:            tps    MB_read/s    MB_wrtn/s    MB_read    MB_wrtn
sda               0.00         0.00         0.00          0          0

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.00    0.00    0.00    0.00    0.00  100.00
View all (9 more lines)
Review abnormal error messages in the console
Run the command below:
Shell
Copy to Clipboard
$ dmesg | grep -v ""eth0\|IPv6\|IPVS\|docker\|promiscuous""
If you see similar errors INFO: task neo4j.FileIOHel:78205 blocked for more than 120 seconds. You might want to review the storage configuration with your system administrator.
[Sun Oct 20 10:26:10 2019] INFO: task neo4j.FileIOHel:78205 blocked for more than 120 seconds.
[Sun Oct 20 10:26:10 2019] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[Sun Oct 20 10:26:10 2019] neo4j.FileIOHel D ffff959abd738000     0 78205      1 0x00000080
[Sun Oct 20 10:26:10 2019] Call Trace:
[Sun Oct 20 10:26:10 2019]  [<ffffffff90d7ceb4>] ? __radix_tree_lookup+0x84/0xf0
[Sun Oct 20 10:26:10 2019]  [<ffffffff91167020>] ? bit_wait+0x50/0x50
[Sun Oct 20 10:26:10 2019]  [<ffffffff91168ed9>] schedule+0x29/0x70
[Sun Oct 20 10:26:10 2019]  [<ffffffff911669e1>] schedule_timeout+0x221/0x2d0
[Sun Oct 20 10:26:10 2019]  [<ffffffff90b01292>] ? ktime_get_ts64+0x52/0xf0
[Sun Oct 20 10:26:10 2019]  [<ffffffff91167020>] ? bit_wait+0x50/0x50
[Sun Oct 20 10:26:10 2019]  [<ffffffff911685ad>] io_schedule_timeout+0xad/0x130
[Sun Oct 20 10:26:10 2019]  [<ffffffff91168648>] io_schedule+0x18/0x20
[Sun Oct 20 10:26:10 2019]  [<ffffffff91167031>] bit_wait_io+0x11/0x50
[Sun Oct 20 10:26:10 2019]  [<ffffffff91166b57>] __wait_on_bit+0x67/0x90
[Sun Oct 20 10:26:10 2019]  [<ffffffff90bb960e>] ? __find_get_pages+0x11e/0x1c0
[Sun Oct 20 10:26:10 2019]  [<ffffffff90bb5ab1>] wait_on_page_bit+0x81/0xa0
[Sun Oct 20 10:26:10 2019]  [<ffffffff90ac2f30>] ? wake_bit_function+0x40/0x40
[Sun Oct 20 10:26:10 2019]  [<ffffffff90bc722b>] truncate_inode_pages_range+0x42b/0x700
[Sun Oct 20 10:26:10 2019]  [<ffffffffc025c167>] ? __xfs_trans_commit+0x157/0x260 [xfs]
[Sun Oct 20 10:26:10 2019]  [<ffffffffc025c530>] ? xfs_trans_commit+0x10/0x20 [xfs]
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c7005a>] ? __inode_wait_for_writeback+0x7a/0xf0
[Sun Oct 20 10:26:10 2019]  [<ffffffff90ac2f30>] ? wake_bit_function+0x40/0x40
[Sun Oct 20 10:26:10 2019]  [<ffffffff90bc756f>] truncate_inode_pages_final+0x4f/0x60
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c5f16c>] evict+0x16c/0x180
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c5f9bc>] iput+0xfc/0x190
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c53a6e>] do_unlinkat+0x1ae/0x2d0
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c4777e>] ? SYSC_newstat+0x3e/0x60
[Sun Oct 20 10:26:10 2019]  [<ffffffff90c54b26>] SyS_unlink+0x16/0x20
[Sun Oct 20 10:26:10 2019]  [<ffffffff91175ddb>] system_call_fastpath+0x22/0x27
Additional links
For Cloud environments, IO throttling can also cause performance issues:
Azure
https://blogs.msdn.microsoft.com/mast/2014/08/02/how-to-monitor-for-storage-account-throttling/
https://blogs.msdn.microsoft.com/mast/2017/09/29/monitor-alert-disk-vm-io-throttling-linux-vms-arm/
AWS
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/benchmark_procedures.html
The tests were done in November 2019.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-configure-neo4j-so-that-data-graph-db-messages-log-is-automatically-rotated;"How do i configure Neo4j so that data/graph.db/messages.log is automatically rotated
Author Dana Canzano Applicable versions 2.3 Tags server configuration
As tested and verified with Neo4j 2.3.0, the data/graph.db/messages.log, its size and number of rotated archives is governed by the following parameters in the conf/neo4j.properties file
Name Description Default
store.internal_log.max_archives
Maximum number of history files for the internal log.
7
store.internal_log.rotation_threshold
Threshold for rotation of the internal log.
20MB
With the above default parameters one should expect to see no data/graph.db/messages.log exceed 20MB and we will keep up to 7 archives, namely data/graph.db/messages.log.1, data/graph.db/messages.log.2 … data/graph.db/messages.log.7.
If you wish to change the defaults the conf/neo4j.properties file would need to include the new values for
Properties
Copy to Clipboard
store.internal_log.max_archives=<N number of archives>
store.internal_log.rotation_threshold=<# of bytes before the file is rotated>
and then issue a bin/neo4j restart for the new parameters to take effect.
Prior to 2.3.0 one would need to use the linux built in functionality of logrotate
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-install-neo4j-in-a-disconnected-environment;"How to install Neo4j in a disconnected environment
Author Daniel Terlizzi Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags offline server
Premise: You are working with a private/disconnected environment and would like to install the Neo4j Database using RPM packages as a source.
You can download the RPM packages on a separate machine (with internet access) with the following command. Then you can transfer the packages by any means possible to the intended machine.
Shell
Copy to Clipboard
$ yum install --downloadonly --downloaddir=/tmp/neo4j_rpm_install_packages neo4j-enterprise-3.5.7
https://neo4j.com/docs/operations-manual/current/installation/linux/rpm
When working with a private/disconnected environment where you can use wget https* you can prepare all files elsewhere, then place them on a cloud storage repository to use with the wget command from the disconnected machine to transfer all the needed files.
To install Neo4j you will need to install the GPG Key. You can download it elsewhere and transfer it to the intended machine and then perform the needed steps before installing Neo4j Enterprise edition:
Shell
Copy to Clipboard
$ wget https://debian.neo4j.org/neotechnology.gpg.key
In this case, you would then use the local file to import the GPG Key in the disconnected environment:
Shell
Copy to Clipboard
$ rpm --import neotechnology.gpg.key
To install the Neo4j Database you install the RPM package with the command rpm -i <package.rpm>:
Shell
Copy to Clipboard
$ rpm -i neo4j-enterprise-3.5.7-1.noarch.rpm
Note 1: To install another JDK you would need to perform similar steps and download the RPM package from another source.
Note 2: For non-interactive installation you can accept the license agreement by setting a variable in the environment before installing Neo4j Enterprise edition:
Shell
Copy to Clipboard
$ export NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
$ rpm -i neo4j-enterprise-3.5.7-1.noarch.rpm
https://neo4j.com/docs/operations-manual/current/installation/linux/rpm/#linux-noninteractive
Configure Neo4j with the configuration file. See the file locations for RPM installation
https://neo4j.com/docs/operations-manual/current/configuration/file-locations/
In Cloud environments you will need to edit the neo4j.template file to make changes to the neo4j.conf file. See the link for details: https://neo4j.com/developer/neo4j-cloud-vms/#vm-config
You can enable the service for startup upon reboot with (use root or sudo):
Shell
Copy to Clipboard
$ systemctl enable neo4j
https://neo4j.com/docs/operations-manual/current/installation/linux/systemd/
To view the neo4j.log for Debian and RPM, use
Shell
Copy to Clipboard
$ journalctl --unit=neo4j
Or
Shell
Copy to Clipboard
$ journalctl -e -u neo4j
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-automate-the-copy-of-auth-files-in-a-clustered-environment;"How do I automate the copy of auth files in a clustered environment
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging server
In a clustered Neo4j implementation, user authentication files are recorded in each instance at $NEO4J_HOME/data/dbms. Since this defined per each instance in the cluster if for example you change the password of a user on instance 1, for consistency you should also then change the users password on the other instances.
Attached is a tgz file which can be used so as to automate the copying of $NEO4J_HOME/data/dbms from each instance to the other using linux rsync and then automating this to run via cron on a regular interval from each instance in the cluster.
This package is provided AS-IS.
Installation is as follows:
copy the .tgz to the linux server where instance 1 is defined.
untar the package as tar
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-log-to-neo4jlog-in-an-unmanaged-extension;"How to log to neo4j.log in an Unmanaged Extension
Author Dave Gordon Applicable versions 3.0 3.1 Tags java api logging extension
As part of the major changes in 3.0, the way to log to the user log, now neo4j.log (in server mode), has changed. To log within an Unmanaged Extension is quite straightforward:
Include this package: import org.neo4j.logging.Log;
In the method for the Unmanaged Extension, include @Context Log log as an argument:
Java
Copy to Clipboard
@GET
@Path(""/friendOfFriend/{userId}"")
public Response getFofs(@PathParam(""userId"") String userId, @Context GraphDatabaseService db, @Context Log log) throws IOException {
Now log using the appropriate method for the log object:
Java
Copy to Clipboard
        // Method variables
        try (Transaction tx = db.beginTx()) {
            // Get the user node
            final Node user = db.findNode(Labels.Person, ""userId"");
            // Let's write that to neo4j.log!
            log.info(""Found user node: "" + user.toString());
            // Code to find fofs, and build result set formatted
        }

        // Return results, which are contained in method variable ""results""
        return Response.ok().entity(objectMapper.writeValueAsString(results)).build();
        // Let's write to neo4j.log again!
        log.debug(""We are all done!"");
}
We get a log that contains lines like this:
2016-12-05 17:33:21.223+0000 INFO  Found user node: Node[63564]
2016-12-05 17:33:21.345+0000 DEBUG  We are all done!
Was this page helpful?"
https://neo4j.com/developer/kb/using-supervisord-to-manage-neo4j-process;"Using supervisord to manage Neo4j process
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags operations startup shutdown monitoring
In general, running the neo4j process directly is the most common way to start and stop the neo4j server. However, if you use supervisord to manage processes, this has worked for others.
Things to keep in mind:
supervisord can only manage non-daemonized processes, so you will need to use neo4j console instead of neo4j start.
You need to configure the correct ""stopsignal"" in the supervisord configuration so as not to cause issues with the cluster on unexpected restart.
In particular, set:
Properties
Copy to Clipboard
stopsignal=SIGTERM
Here is an example supervisord configuration that has worked in production:
Ini
Copy to Clipboard
[program:neo4j]
command=/usr/local/neo4j-enterprise/bin/neo4j console
user=neo4j
autostart=true
autorestart=unexpected
startsecs=30
startretries=999
priorities=90
exitcodes=0,1,2
stopsignal=SIGTERM
stopasgroup=true
killasgroup=true
redirect_stderr=true
stdout_logfile=/usr/local/neo4j-enterprise/data/log/neo4j.out
stdout_logfile_backups=10
stderr_capture_maxbytes=20MB
Was this page helpful?"
https://neo4j.com/developer/kb/running-docker-as-nonroot-user;"Running Docker as Non-Root User
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags startup permissions docker
When running Neo4j Docker, it will run as neo4j user inside the container. But to run docker as a different user one can specify the --user argument. Documentation has a section for running as non-root user:
https://neo4j.com/docs/operations-manual/current/docker/introduction/#docker-user
but would like to elaborate on the same in this KB article.
When using the --user flag needs to have a valid, non-root user value provided. Our Docker container assumes/requires that the user is a) not root b) has write access to data and logs directories and has read access to conf directory. It is important to note that if you are passing 0:0 or 0 or root etc. as --user, it will still not use root to run neo4j but the container will use its own internal neo4j user and neo4j user group (these happen to currently have uid 101 and gid 101 but that should not be relied upon). The Docker entrypoint is specifically written to avoid running the neo4j docker image as root.
So best approach here is to create a User and group and pass that on to the Docker input --user.
create a user neo4j without a home directory
Shell
Copy to Clipboard
$ sudo useradd -M neo4j
prevent neo4j from logging in
Shell
Copy to Clipboard
$ sudo usermod -L neo4j
Create data dir.
Shell
Copy to Clipboard
$ sudo mkdir -p /neo4j/data
$ sudo chown -R neo4j /neo4j/data
$ sudo chgrp -R neo4j /neo4j/data
Note we only give group read permissions here
Shell
Copy to Clipboard
$ sudo chmod -R u+rwX,g+rX,o-wrx /neo4j/data
We do not recommend any application other than neo4j writing to the data dir. This can corrupt the data store.
Shell
Copy to Clipboard
$ sudo mkdir -p /neo4j/conf
$ sudo chown -R neo4j /neo4j/conf
$ sudo chgrp -R neo4j /neo4j/conf
Group gets write permissions here
Shell
Copy to Clipboard
$ sudo chmod -R u+rX,g+rwX,o-wrx /neo4j/conf
If you make external changes to the conf dir you must restart the docker image to pickup new configuration (conf is copied from the mounted volume on startup).
Shell
Copy to Clipboard
$ sudo mkdir -p /neo4j/plugins
$ sudo chown -R neo4j /neo4j/plugins
$ sudo chgrp -R neo4j /neo4j/plugins
Group gets write permissions here
Shell
Copy to Clipboard
$ sudo chmod -R u+rwX,g+rwX,o-wrx /neo4j/plugins # N.b. if you make external changes to the plugins dir you must restart neo4j before it will pickup new plugins
Let’s assume that the logs dir is being used by multiple applications n.b. if something interferes with neo4j writing logs it can crash the neo4j process. Create a logs group for all things log related
Shell
Copy to Clipboard
$ sudo groupadd logs
Add neo4j to logs group
Shell
Copy to Clipboard
$ sudo usermod -a -G logs neo4j
$ sudo mkdir -p /logs/neo4j
$ sudo chown -R root /logs/neo4j
$ sudo chgrp -R logs /logs/neo4j
$ sudo chmod -R u+rwX,g+rwX,o-wrx /logs/neo4j
If docker does not run as root
Shell
Copy to Clipboard
$ docker_user=root
$ sudo usermod -a -G logs ""${docker_user}""
$ sudo usermod -a -G neo4j ""${docker_user}""
Add ourselves to the neo4j group so /neo4j/* dirs created above can be read and edited.
Shell
Copy to Clipboard
$ current_user=$(id -un)
$ sudo usermod -a -G neo4j ""${current_user}""
Start a new shell to pick up this group assignment.
Note docker doesn’t pull in secondary groups automatically so one has to do this explicitly:
Shell
Copy to Clipboard
$ groups=( $( id --real --groups neo4j ) )
$ docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=/neo4j/data:/data \
    --volume=/neo4j/plugins:/plugins \
    --volume=/neo4j/conf:/conf \
    --volume=/logs/neo4j:/logs \
    --user=""$(id -u neo4j):$(id -g neo4j)"" \
    --group-add=$groups \
    neo4j:3.4
Was this page helpful?"
https://neo4j.com/developer/kb/permission-denied-errors-after-neo4j-admin;"Getting ""Permission Denied"" errors after using neo4j-admin commands
Author Dave Shiposh Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags permissions rpm neo4j-admin linux debian
If you have leveraged Debian or RPM Packages to install Neo4j on Linux (or used one of the Public Cloud Marketplace offerings), you need to be careful of file and folder permissions. The installs create a user: ""neo4j"" that owns all the files for the Neo4j Installation:
$ sudo ls -l /var/lib/neo4j/data/databases/
total 4
drwxr-xr-x 4 neo4j neo4j 4096 Sep 18 17:59 graph.db
-rw-r--r-- 1 neo4j neo4j    0 Sep 18 17:59 store_lock
Many operational tasks are achieved with the neo4j-admin utility. As this utility reads and writes to/from the file system, special care must be taken to ensur its run with the correct permissions.
As an example, consider a backup taken as follows:
$ sudo neo4j-admin backup --from=localhost --name=graph.db_backup --backup-dir=/tmp
....................  10%
....................  20%
....................  30%
....................  40%
....................  50%
....................  60%
....................  70%
....................  80%
....................  90%
Checking node and relationship counts
Backup complete.
Note that sudo was leveraged, meaning that this will be run as root. We can see this in the backup location:
$ ls -l /tmp/graph.db_backup/
total 372
-rw-r--r-- 1 root root 58959 Sep 18 18:09 debug.log
-rw-r--r-- 1 root root 57805 Sep 18 18:07 debug.log.1568830062412
-rw-r--r-- 1 root root 58726 Sep 18 18:07 debug.log.1568830143398
drwxr-xr-x 2 root root  4096 Sep 18 18:07 index
drwxr-xr-x 2 root root  4096 Sep 18 18:07 metrics
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore
-rw-r--r-- 1 root root    96 Sep 18 18:07 neostore.counts.db.a
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.id
-rw-r--r-- 1 root root 40960 Sep 18 18:09 neostore.labelscanstore.db
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.labeltokenstore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.labeltokenstore.db.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.labeltokenstore.db.names
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.labeltokenstore.db.names.id
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.nodestore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.nodestore.db.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.nodestore.db.labels
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.nodestore.db.labels.id
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.propertystore.db
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.propertystore.db.arrays
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.propertystore.db.arrays.id
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.propertystore.db.id
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.propertystore.db.index
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.propertystore.db.index.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.propertystore.db.index.keys
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.propertystore.db.index.keys.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.propertystore.db.strings
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.propertystore.db.strings.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.relationshipgroupstore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.relationshipgroupstore.db.id
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.relationshipstore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.relationshipstore.db.id
-rw-r--r-- 1 root root     0 Sep 18 18:07 neostore.relationshiptypestore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.relationshiptypestore.db.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.relationshiptypestore.db.names
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.relationshiptypestore.db.names.id
-rw-r--r-- 1 root root  8192 Sep 18 18:07 neostore.schemastore.db
-rw-r--r-- 1 root root     9 Sep 18 18:09 neostore.schemastore.db.id
-rw-r--r-- 1 root root   106 Sep 18 18:09 neostore.transaction.db.0
drwxr-xr-x 2 root root  4096 Sep 18 18:07 profiles
View all (26 more lines)
If an administrator were to at some point restore with this backup:
$ sudo neo4j-admin restore --from=/tmp/graph.db_backup --database=graph.db --force=true
The restored database folder and files would now be owned by root:
$ sudo ls -l /var/lib/neo4j/data/databases/
total 4
drwxr-xr-x 5 root  root  4096 Sep 18 18:12 graph.db
-rw-r--r-- 1 neo4j neo4j    0 Sep 18 17:59 store_lock
Attempting to start the Neo4j Service would now fail, with an error similar to:
Starting Neo4j.
Sep 18 18:13:55 proddb1-ubuntu neo4j[6805]: 2019-09-18 18:13:55.143+0000 INFO  ======== Neo4j 3.5.9 ========
Sep 18 18:13:55 proddb1-ubuntu neo4j[6805]: 2019-09-18 18:13:55.163+0000 INFO  Starting...
Sep 18 18:13:56 proddb1-ubuntu neo4j[6805]: 2019-09-18 18:13:56.624+0000 INFO  Initiating metrics...
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]: 2019-09-18 18:13:57.116+0000 ERROR Failed to start Neo4j: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@2b52c0d6' was successfully initial
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]: org.neo4j.server.ServerStartupException: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@2b52c0d6' was successfully initialized, but failed
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.exception.ServerStartupErrors.translateToServerStartupError(ServerStartupErrors.java:45)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:187)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:124)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:91)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at com.neo4j.server.enterprise.CommercialEntryPoint.main(CommercialEntryPoint.java:22)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]: Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.server.database.LifecycleManagingDatabase@2b52c0d6' was successfully initialized, but failed to sta
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:473)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:111)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:180)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         ... 3 more
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]: Caused by: java.lang.RuntimeException: Error starting org.neo4j.graphdb.facade.GraphDatabaseFacadeFactory, /var/lib/neo4j/data/databases
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.graphdb.facade.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:232)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at com.neo4j.commercial.edition.CommercialGraphDatabase.<init>(CommercialGraphDatabase.java:20)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at com.neo4j.server.database.CommercialGraphFactory.newGraphDatabase(CommercialGraphFactory.java:40)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.server.database.LifecycleManagingDatabase.start(LifecycleManagingDatabase.java:90)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:452)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         ... 5 more
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]: Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.kernel.NeoStoreDataSource@4b6166aa' was successfully initialized, but failed to start. Please see t
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:473)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:111)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.impl.transaction.state.DataSourceManager.start(DataSourceManager.java:116)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:452)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:111)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         at org.neo4j.graphdb.facade.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:227)
Sep 18 18:13:57 proddb1-ubuntu neo4j[6805]:         ... 9 more
The recommended approach to all neo4j-admin commands, such as backup, restore, store-info, import is to leverage sudo -u neo4j:
$ sudo -u neo4j neo4j-admin backup --from=localhost --name=graph.db_backup_with_user --backup-dir=/tmp

$ sudo -u neo4j neo4j-admin restore --from=/tmp/graph.db_backup --database=graph.db --force=true
Was this page helpful?"
https://neo4j.com/developer/kb/where-is-my-neo4jlog-in-ubuntu-linux;"Where is my neo4j.log in Ubuntu Linux?
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging linux ubuntu
In most Neo4j server environments, all logs will be found in NEO4J_HOME/logs. However, when Neo4j is running as a service on a Ubuntu (debian) Linux environment, usually installed via apt-get install neo4j or similar, the neo4j.log is not present.
To get the contents of this, since neo4j.log just contains STDOUT content, simply look for the neo4j service log contents using journalctl:
Shell
Copy to Clipboard
neo4j@ubuntu:/var/log/neo4j$ journalctl -u neo4j -b > neo4j.log
neo4j@ubuntu:/var/log/neo4j$ vi neo4j.log
For a complete reference of where logs and other files are located in various environments, please refer to the official documentation:
https://neo4j.com/docs/operations-manual/current/configuration/file-locations/
Was this page helpful?"
https://neo4j.com/developer/kb/embed-neo4j-enterprise-within-your-java-application;"Embed neo4j-enterprise within your java application
Author Jérémie Phoulchand Applicable versions 3.5 Tags intellij enterprise embedded installation
The Neo4j Java Reference Documentation generally describes how to embed Neo4j Community Edition within your Java application. If you are licensed for Neo4j Enterprise, this article will guide you through setting up the project to use Neo4j Enterprise embedded within your application.
Create a new project
First you will need to download IntelliJ community edition. Once done, create a New Project>Java>Command Line App.
Specify its name embedded and the base package
Configure the maven repository
Create a folder .m2 in your home directory
Create the ${HOME}/.m2/settings.xml file as following.
Refer to the KB Dependency location
Xml
Copy to Clipboard
<settings xmlns=""http://maven.apache.org/SETTINGS/1.0.0""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xsi:schemaLocation=""http://maven.apache.org/SETTINGS/1.0.0
                        https://maven.apache.org/xsd/settings-1.0.0.xsd"">
    <servers>
        <server>
            <id>neo4j-enterprise</id>
            <username>neo4j-enterprise</username>
            <password>modify password there</password>
        </server>
    </servers>
</settings>
Create a project pom.xml file
A Project Object Model or POM is the fundamental unit of work in Maven. It is an XML file that contains information about the project and configuration details used by Maven to build the project. It contains default values for most projects.
Create a new text file at the root of your project using intelliJ and name it pom.xml
Xml
Copy to Clipboard
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0
http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <!-- maven specific -->
    <modelVersion>4.0.0</modelVersion>
    <artifactId>embedded</artifactId>

    <!-- your own project settings-->
    <groupId>com.example</groupId>
    <version>1.0-snapshot</version>
    <name>embedded</name>
    <description>Embedded demo project</description>

    
    
        
            
                false
            
            neo4j-enterprise
            Neo4j Enterprise Artifacts
            http://m2.neo4j.com/enterprise
        
    

    
    

        
            com.neo4j
            
            neo4j-enterprise
            3.5.3
        
    

    
    
        install
        
            
                org.apache.maven.plugins
                maven-compiler-plugin
                3.5.1
                
                    11 
                    11 
                
            
        
    
View all (39 more lines)
Create the java class
In intelliJ, right-click on src and choose New > Java Class and name it EmbeddedNeo4j. You can paste the following code or follow the java reference manual
Java
Copy to Clipboard
/*
 * Licensed to Neo4j under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Neo4j licenses this file to you under
 * the Apache License, Version 2.0 (the ""License""); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied. See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

 java.io.File;
 java.io.IOException;

 org.neo4j.graphdb.Direction;
 org.neo4j.graphdb.GraphDatabaseService;
 org.neo4j.graphdb.Node;
 org.neo4j.graphdb.Relationship;
 org.neo4j.graphdb.RelationshipType;
 org.neo4j.graphdb.Transaction;
 org.neo4j.graphdb.factory.EnterpriseGraphDatabaseFactory;
 org.neo4j.io.fs.FileUtils;

 {
       File databaseDirectory =  File(  );

     String greeting;

    
    GraphDatabaseService graphDb;
    Node firstNode;
    Node secondNode;
    Relationship relationship;
    

    
      RelTypes implements RelationshipType
    {
        KNOWS
    }
    

    {
        EmbeddedNeo4j hello =  EmbeddedNeo4j();
        hello.createDb();
        hello.removeData();
        hello.shutDown();
    }

    {
        FileUtils.deleteRecursively( databaseDirectory );

        
        graphDb =  EnterpriseGraphDatabaseFactory().newEmbeddedDatabase( databaseDirectory );
        registerShutdownHook( graphDb );
        

        
         ( Transaction tx = graphDb.beginTx() )
        {
            
            
            
            firstNode = graphDb.createNode();
            firstNode.setProperty( ,  );
            secondNode = graphDb.createNode();
            secondNode.setProperty( ,  );

            relationship = firstNode.createRelationshipTo( secondNode, RelTypes.KNOWS );
            relationship.setProperty( ,  );
            

            
            System.out.print( firstNode.getProperty(  ) );
            System.out.print( relationship.getProperty(  ) );
            System.out.print( secondNode.getProperty(  ) );
            

            greeting = ( (String) firstNode.getProperty(  ) )
                    + ( (String) relationship.getProperty(  ) )
                    + ( (String) secondNode.getProperty(  ) );

            
            tx.success();
        }
        
    }

    {
         ( Transaction tx = graphDb.beginTx() )
        {
            
            
            firstNode.getSingleRelationship( RelTypes.KNOWS, Direction.OUTGOING ).delete();
            firstNode.delete();
            secondNode.delete();
            

            tx.success();
        }
    }

    {
        System.out.println();
        System.out.println(  );
        
        graphDb.shutdown();
        
    }

    
    {
        
        
        
        Runtime.getRuntime().addShutdownHook(  Thread()
        {
            
            {
                graphDb.shutdown();
            }
        } );
    }
    
}
View all (125 more lines)
Was this page helpful?"
https://neo4j.com/developer/kb/change-logging-levels-in-neo4j-embedded;"Change logging levels in Neo4j Embedded
Author Dave Gordon Tags logging embedded configuration
In order to change the default logging levels in a Neo4j embedded instance, you must edit/define the configuration file, which is XML. In particular the file is neo4j-logback.xml.
The neo4j-logback.xml file must be located in the classpath, so that org.neo4j.kernel.logging.LogbackService can find and read the configuration.
Was this page helpful?"
https://neo4j.com/developer/kb/solve-dependency-issues;"Solve dependency issues
Author Jérémie Phoulchand Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags maven java embedded user-defined-procedures dependencies upgrade
There are multiple ways to include neo4j artifacts. In this article, we will focus on maven based on different scenarios or errors. The most common issue is setting up the dependencies properly in pom.xml.
Verify that you have the right dependencies
You can execute the following maven command in the folder where you have the pom.xml :
Shell
Copy to Clipboard
# resolve dependency in the local repository (by default in ~/.m2/)
$ mvn dependency:resolve

# displays the dependencies as a tree
$ mvn dependency:tree

# purge local repo and resolve dependencies
$ mvn dependency:purge-local-repository

# perform integration tests
$ mvn verify
In version 3.5, only 3 artifacts are required even if you are running unit tests:
For Enterprise, your pom.xml should contains:
Xml
pom.xml
Copy to Clipboard
<project>
  <!-- .... -->
  <properties>
    <neo4j.version>3.5.6</neo4j.version>
  </properties>
  <dependencies>
    <dependency>
       <groupId>com.neo4j</groupId>
       <artifactId>neo4j-enterprise</artifactId>
       <version>${neo4j.version}</version>
       <scope>provided</scope>
    </dependency>
    <dependency>
       <groupId>org.neo4j.driver</groupId>
       <artifactId>neo4j-java-driver</artifactId>
       ${neo4j-java-driver.version}
       test
    
    
       com.neo4j.test
       neo4j-harness-enterprise
       ${neo4j.version}
       test
    
  
  
View all (12 more lines)
For Community Edition, your pom.xml should contains:
Xml
pom.xml
Copy to Clipboard
<project>
  <!-- ... -->
  <properties>
    <neo4j.version>3.5.6</neo4j.version>
  </properties>
  <dependencies>
    <dependency>
      <groupId>org.neo4j</groupId>
      <artifactId>neo4j</artifactId>
      <version>${neo4j.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.neo4j.driver</groupId>
      <artifactId>neo4j-java-driver</artifactId>
      ${neo4j-java-driver.version}
      test
    
    
      com.neo4j.test
      neo4j-harness-enterprise
      ${neo4j.version}
      test
    
  
  
View all (12 more lines)
Resolving dependencies using a private sonatype nexus configured as a mirror repository
This is the preferred approach. It allows you to stay up to date and automatically fetch the updates. To do that, you need to login into nexus as an admin or reach out to your nexus adminstrator and ensure that the repositories are available and healthy.
For community edition, you need to add one repository:
org.neo4j:neo4j, the public maven repo url is https://repo.maven.apache.org/maven2/
For enterprise, you need to add the two below repositories:
com.neo4j:neo4j-enterprise (see 'KB Dependency location for Neo4j Enterprise Edition artifacts' for url/username/password)
org.neo4j:neo4j (available on public repo https://repo.maven.apache.org/maven2/)
The naming convention is groupId:artifactId. For example: org.neo4j:neo4j is actually groupid=org.neo4j AND artifactId=neo4j
Resolving dependencies using a private sonatype nexus configured as a hosted repository
This approach is not recommended since it is manual and prone to error. It should be used as a last resort solution.
Please keep in mind that neo4j requires more than 70-200 artifacts depending on the version and the scope used.
The easiest way to implement this is to compress the .m2/repository folder once you have downloaded all the dependencies
You will need to upload BOTH the jar and the associated pom file into your repository.
Execute the following maven the command and compare it on a machine that has access to the official repositories
Shell
Copy to Clipboard
$ mvn dependency:tree
If something you spot differences, browse your nexus repository with a web browser and check the signature of the .pom file.
Resolving dependencies using a local folder (Internet required)
This is the easiest approach but you will enventually have to repeat those steps to upgrade to the latest maintenance release.
Open a terminal and go into the project folder that contains the pom.xml
Use the following mvn command to download jars from a source machine that has access to internet. It will copy them into a local folder
mvn dependency:go-offline -Dmaven.repo.local=./remoterepo
(You can request support to do it if your internet is restricted)
Zip the folder on the source
Extract it on the target machine
Specify the following in your pom.xml
Xml
pom.xml
Copy to Clipboard
<repositories>
  <repository>
    <id>neo4j</id>
    <url>file://</url>
    <!-- ie <url>file:///home/neo4j/maven/remoterepo</url> -->
  </repository>
  <repository>
    <id>neo4j-enterprise</id>
    <url>file://</url>
    <!-- ie <url>file:///home/neo4j/maven/remoterepoenterprise</url> -->
  </repository>
</repositories>
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-memory-consumption;"Understanding memory consumption
Author José Rocha Applicable versions 3.0 3.1 3.2 3.3 3.4 3.5 Tags performance memory java
So you have configured Neo4j to use 4GB of heap and 6GB of page cache and sat back relaxed, thinking the Java process would not go above 10GB in your 12GB machine only to realise that Neo4j had an OOM error and crashed. What’s happening under the hood? Why is Neo4j consuming more memory than you allocated? Is this a memory leak or normal behaviour? So many questions! Let’s try to answer some of these questions so that you’re not caught off guard when it comes to memory.
While memory leaks can happen, more often than not, a higher memory consumption is normal behaviour by the JVM. In order to function correctly, the JVM needs to allocate more memory in several other categories. The most significant categories of JVM memory are:
Heap - The heap is where your Class instantiations or “Objects” are stored.
Thread stacks - Each thread has its own call stack. The stack stores primitive local variables and object references along with the call stack (list of method invocations) itself. The stack is cleaned up as stack frames move out of context so there is no GC performed here.
Metaspace (PermGen in older Java versions) - Metaspace stores the Class definitions of your Objects, and some other metadata.
Code cache - The JIT compiler stores native code it generates in the code cache to improve performance by reusing it.
Garbage collection - In order for the GC to know which objects are eligible for collection, it needs to keep track of the object graphs. So this is one part of the memory lost to this internal bookkeeping.
Buffer pools - Many libraries and frameworks allocate buffers outside of the heap to improve performance. These buffer pools can be used to share memory between Java code and native code, or map regions of a file into memory.
You can end up using memory for other reasons than listed above as well, but I just wanted to make aware that there is a significant amount of memory eaten up by the JVM internals.
Do I need to worry about all this?
Let’s put this into perspective!
When configuring Neo4j’s memory, you may start encountering many terms such as on-heap, off-heap, page cache, direct memory, OS memory… What does this all mean and what should you be aware when configuring your memory? First, let’s start by understanding some of these terms:
Heap: The JVM has a heap that is the runtime data area from which memory for all class instances and arrays are allocated. Heap storage for objects is reclaimed by an automatic storage management system (known as a garbage collector or GC)
Off-Heap: Sometimes heap memory is not enough, especially when we need to cache a lot of data without increasing GC pauses, share cached data between JVMs or add a persistence layer in memory resistant to JVM crashes. In all mentioned cases off-heap memory is one of possible solutions. As the off-heap store continues to be managed in memory, it is slightly slower than the on-heap store, but still faster than the disk store (and also not subject to GC).
Page cache: The page cache lives off-heap and is used to cache the Neo4j data (and native indexes). The caching of graph data and indexes into memory will help avoid costly disk access and result in optimal performance.
While heap and off-heap are general Java terms, page cache refers to Neo4j’s native caching.
Below is a picture of how this all falls into place:
Figure 1: Memory consumption in Neo4j
As you can see above we can divide the Neo4j’s memory consumption into 2 main areas: On-heap and off-heap:
On-heap is where the runtime data lives and it’s also where query execution, graph management and transaction state1 exist.
Setting the heap to an optimal value is a tricky task by itself and this article doesn’t aim to cover that but rather understand Neo4j’s memory consumption as a whole.
Off-heap can itself be divided into 3 categories. Not only do we have Neo4j’s page cache (responsible for caching the graph data into memory) but also all other memory the JVM needs to work (JVM Internals). The remaining block you see there is direct memory, we’ll get to that in a minute.
In Neo4j there are three memory settings you can configure: initial heap size (-Xms), maximum heap size (-Xmx) and page cache. In reality, the first two affect the same memory space so Neo4j only allows you to configure two of all of the above mentioned memory categories. These are the ones you can impose limits on though. Setting the max heap to 4GB and page cache to another 4GB guarantees that those specific components will not grow bigger than that. So how can your process consume more than the values set? A common miss-conception is that by setting both heap and page cache, Neo4j’s process memory consumption will not grow beyond that but it’s more likely that the memory footprint of Neo4j is larger.
Well - as we’ve seen above - the JVM will require some extra memory to function correctly. For example, running a highly concurrent environment means that the memory occupied by the thread stack will be equal to the number of concurrent threads the JVM will process times the thread stack size (-Xss).
There are harder to find sources of non-heap memory use, such as buffer pools. Enter direct memory. Direct byte buffers are important for improving performance because they allow native code and Java code to share data without copying it. However this is expensive, which means byte buffers are usually reused once they’re created. As a result, some frameworks keep them around for the life of the process. One example is Netty. Neo4j uses Netty (an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients, https://netty.io/) and that’s by far the primary user of direct memory. It is used predominantly for buffering and IO and but it’s used by several components in Neo4j.
In almost all cases, your direct memory usage will not grow to problematic levels but in very extreme and demanding use cases (ie: when we have loads of concurrent accesses and updates), you may start seeing Neo4j’s process consume way more memory than what we configured or you can also get some Out of Memory errors regarding direct memory:
2018-11-14 09:32:49.292+0000 ERROR [o.n.b.t.SocketTransportHandler] Fatal error occurred when handling a client connection: failed to allocate 16777216 byte(s) of direct memory (used: 6442450944, max: 6442450944) failed to allocate 16777216 byte(s) of direct memory (used: 6442450944, max: 6442450944)
io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16777216 byte(s) of direct memory (used: 6442450944, max: 6442450944)
at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:624)
at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:578)
at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:718)
at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:707)
...
These symptoms are related to direct memory growth. While we do not manage the memory Netty uses, there is a way to limit the direct memory Neo4j (and any Java process) can use via a JVM setting: -XX:MaxDirectMemorySize. This works in conjunction with dbms.jvm.additional=-Dio.netty.maxDirectMemory=0 in the neo4j.conf file. This will force Netty to use the direct memory settings and thus effectively limiting how much it can grow.
THESE ARE SENSITIVE SETTINGS THAT WILL AFFECT THE NORMAL FUNCTIONALITY OF NEO4J. Please do not change these settings without consulting with Neo4j’s professionals. You can just log a support ticket if you’re running into issues with Direct Memory and we’ll advise you the best we can.
Indexes
Depending on whether you are using Lucene or native indexes, the memory taken by these will live in different places. If you are using Lucene indexes, these will live off-heap and we have no control on what memory is used by them. On the image above, they would live alongside the page cache but in an unmanaged block.
If you are using native indexes, the memory taken by them will live inside the page cache meaning we can somewhat control how much memory they can take. You should account for this when setting the page cache size.
Monitoring
By now you must have realized that memory configuration is not that trivial. What do you have to make your life easier? You can use the Native Memory Tracking which is a JVM feature and tracks internal memory usage. To enable it you need to add the following to your neo4j.conf file:
Properties
Copy to Clipboard
dbms.jvm.additional=-XX:NativeMemoryTracking=detail
Then grab the PID of Neo4j, and use jcmd to print out native memory use for the process using jcmd <PID> VM.native_memory summary. You will get the detailed allocation information for each category in memory, as shown below:
Shell
Copy to Clipboard
$ jcmd <PID> VM.native_memory summary
Native Memory Tracking:

Total: reserved=3554519KB, committed=542799KB
-                 Java Heap (reserved=2097152KB, committed=372736KB)
                            (mmap: reserved=2097152KB, committed=372736KB)

-                     Class (reserved=1083039KB, committed=38047KB)
                            (classes #5879)
                            (malloc=5791KB #6512)
                            (mmap: reserved=1077248KB, committed=32256KB)

-                    Thread (reserved=22654KB, committed=22654KB)
                            (thread #23)
                            (stack: reserved=22528KB, committed=22528KB)
                            (malloc=68KB #116)
                            (arena=58KB #44)

-                      Code (reserved=251925KB, committed=15585KB)
                            (malloc=2325KB #3622)
                            (mmap: reserved=249600KB, committed=13260KB)

-                        GC (reserved=82398KB, committed=76426KB)
                            (malloc=5774KB #182)
                            (mmap: reserved=76624KB, committed=70652KB)

-                  Compiler (reserved=139KB, committed=139KB)
                            (malloc=9KB #128)
                            (arena=131KB #3)

-                  Internal (reserved=6127KB, committed=6127KB)
                            (malloc=6095KB #7439)
                            (mmap: reserved=32KB, committed=32KB)

-                    Symbol (reserved=9513KB, committed=9513KB)
                            (malloc=6724KB #60789)
                            (arena=2789KB #1)

-    Native Memory Tracking (reserved=1385KB, committed=1385KB)
                            (malloc=121KB #1921)
                            (tracking overhead=1263KB)

-               Arena Chunk (reserved=186KB, committed=186KB)
                            (malloc=186KB)
View all (29 more lines)
Usually, the jcmd dump is only moderately useful by itself. It’s more common to take multiple dumps and compare them by running jcmd <PID> VM.native_memory summary.diff
This is a great tool for debugging memory problems.
1 Starting from 3.5, transaction state can also be configured to be allocated separately from the heap
Was this page helpful?"
https://neo4j.com/developer/kb/enabling-transaction-timeout-within-application;"Enabling Transaction Timeout Within Application
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags transaction timeout java drivers
There is a dbms.transaction.timeout global setting on Neo4j that can be set in neo4j.conf file so if any query from any user exceeds the timeout threshold specified, that query is terminated.
But how do you achieve this from within an application? Neo4j Java Driver API provides the class TransactionConfig that has a method called Timeout(<time in seconds>) that would allow transaction timeout to be set within the application.
More information on the api can be found here: https://neo4j.com/docs/java-manual/current/session-api/simple/#_transaction_timeout
Below is an example of the same.
Here we are defining the TransactionConfig and using it for explicit transactions.
Java
Copy to Clipboard
TransactionConfig config = TransactionConfig.builder()
    .withTimeout(Duration.ofSeconds(4))
    .withMetadata(metadata)
    .build();
Defining the TransactionConfig and setting the timeout to 4 seconds. Using the configuration in explicit transactions.
Java
Copy to Clipboard
try (Transaction tx = session.beginTransaction(config)) {
  // ...
} finally {
  // ...
}
So if this transaction exceeds 4 seconds it will be terminated.
Similarly, one can implement TransactionConfig to work with autocommit transactions and transaction functions.
Was this page helpful?"
https://neo4j.com/developer/kb/linux-out-of-memory-killer;"Linux Out of Memory killer
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags performance memory java out-of-memory
The Out Of Memory Killer or OOM Killer is a process that the linux kernel employs when the system is critically low on memory. This situation occurs because the linux kernel has over allocated memory to its processes.
When a process starts it requests a block of memory from the kernel. This initial request is usually a large request that the process will not immediately or indeed ever use all of. The kernel, aware of this tendency for processes to request redundant memory, over allocates the system memory. This means that when the system has, for example, 2GB of RAM the kernel may allocate 2.5GB to processes.
Normally, this situation does not cause a problem. However, if enough processes begin to use all of their requested memory blocks then there will not be enough physical memory to support them all. This means that the running processes require more memory than is physically available. This situation is critical and must be resolved immediately.
The solution that the linux kernel employs is to invoke the OOM Killer to review all running processes and kill one or more of them in order to free up system memory and keep the system running.
The OOM Killer will only get invoked when the system is critically low on memory.
Due to its nature, Neo4j will always have a high memory footprint and it’s always likely to be a candidate to be killed when the OOM Killer sweeps the running processes. While what gets killed often seems random or simply the highest memory consumer, the OOM Killer doesn’t operate like that. Instead, it chooses which process to kill based on its oom_score. This is a value controled by the operation system itself based on a number of criteria.
You can check the oom_score of a process by looking at /proc/$PID/oom_score.
While we can’t truly prevent Neo4j from being killed if needed, we can adjust the oom_score to make its process less likely to be terminated by the OOM Killer. To do this, you can edit the following file:
/proc/$PID/oom_score_adj
Files in /proc are not actual files, they’re an interface to lower-levels of the operating system. Therefore you cannot edit them using nano or vi. Rather, you can echo the value into the file as such:
Shell
Copy to Clipboard
$echo -100 > /proc/$PID/oom_score_adj
You can adjust the value on this file, valid values are integers in the range of -1000 to 1000. The lower the value, the lower the chance that it’s going to be killed.
Again this will not prevent Neo4j from being killed, but it will influence the likelihood of it happening.
Be aware that if the process restarts, you will have to set the oom_score_adj again. If you want to implement this as a more permanent solution it’s recommended that you automate this adjustment whenever Neo4j starts, for its new PID.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-start-failure-noclassdeffounderror-org-neo4j-kernel-impl-logging-logservice;"Explanation of start failure ""java.lang.NoClassDefFoundError: org/neo4j/kernel/impl/logging/LogService""
Author Dana Canzano Applicable versions 3.5 Tags upgrade apoc logservice start
Upon starting Neo4j 3.5 if one encounters the following error in the logs/neo4j.log
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.kernel.extension.GlobalKernelExtensions@14c16d' failed to initialize. Please see the attached cause exception ""org.neo4j.kernel.impl.logging.LogService"".
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.init(LifeSupport.java:434)
        at org.neo4j.kernel.lifecycle.LifeSupport.init(LifeSupport.java:66)
        at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:102)
        at org.neo4j.graphdb.facade.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:203)
        ... 9 more
Caused by: java.lang.NoClassDefFoundError: org/neo4j/kernel/impl/logging/LogService
        at java.lang.Class.getDeclaredMethods0(Native Method)
        at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
        at java.lang.Class.privateGetPublicMethods(Class.java:2902)
        at java.lang.Class.getMethods(Class.java:1615)
        at sun.misc.ProxyGenerator.generateClassFile(ProxyGenerator.java:451)
        at sun.misc.ProxyGenerator.generateProxyClass(ProxyGenerator.java:339)
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:639)
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:557)
        at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:230)
        at java.lang.reflect.WeakCache.get(WeakCache.java:127)
        at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:419)
        at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:719)
        at org.neo4j.kernel.impl.util.DependenciesProxy.dependencies(DependenciesProxy.java:55)
        at org.neo4j.kernel.extension.AbstractKernelExtensions.getKernelExtensionDependencies(AbstractKernelExtensions.java:111)
        at org.neo4j.kernel.extension.AbstractKernelExtensions.init(AbstractKernelExtensions.java:59)
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.init(LifeSupport.java:413)
        ... 12 more
Caused by: java.lang.ClassNotFoundException: org.neo4j.kernel.impl.logging.LogService
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 28 more
this is usually indicative of a incompatible APOC jar file installed into $NEO4J_HOME/plugins. With Neo4j 3.5.0 the correct APOC jar to use so as to avoid this error is:
Shell
Copy to Clipboard
$ ls -al apoc*
-rw-rw-r-- 1 neo4j neo4j 12880869 Nov 30 11:49 apoc-3.5.0.1-all.jar
This jar is available at here
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-database-constraints-have-changed-txid-84-after-this-transaction-txid-81-started;"Explanation of error ""Database constraints have changed (txId=xxxxx) after this transaction (txId=yyyyy) started, which is not yet supported""
Author Dana Canzano Applicable versions 2.2 2.3 3.0 Tags constraint
The following error, via bin/neo4j-shell:
Database constraints have changed (txId=84) after this transaction (txId=81) started, which is not yet supported. Please retry your transaction to ensure all constraints are executed.
or as logged in log/debug.log (3.x) or graph.db/messages.log (2.3.x):
2016-10-18 16:40:43.595+0000 ERROR [o.n.s.r.t.TransactionFacade]: Failed to commit transaction.
java.lang.RuntimeException: org.neo4j.kernel.api.exceptions.TransactionFailureException: Database constraints have changed (txId=81) after this transaction
(txId=84) started, which is not yet supported. Please retry your transaction to ensure all constraints are executed.
at org.neo4j.server.rest.transactional.TransitionalTxManagementKernelTransaction.commit(TransitionalTxManagementKernelTransaction.java:87) ~[neo4j-server-2.2.8.jar:2.2.8]
at org.neo4j.server.rest.transactional.TransactionHandle.closeContextAndCollectErrors(TransactionHandle.java:278) [neo4j-server-2.2.8.jar:2.2.8]
can be explained by the following scenario:
txID Date/time Cypher Statement
81
Oct-19-2012 09:00
Begin
84
Oct-19-2012 09:01
Begin
84
Oct-19-2012 09:02
create constraint on (n:Person) assert n.user_id is unique;
84
Oct-19-2012 09:03
Commit
81
Oct-19-2012 09:04
create (n:Person {user_id:1234})
81
Oct-19-2012 09:05
Commit
where the exception is thrown at Oct-19-2012 09:05 by the Cypher statement with txID 81 when it tries to create a node which applies to the newly committed constraint, and the transaction is rolled back. Correct remedial action is to resubmit the failed transaction.
Was this page helpful?"
https://neo4j.com/developer/kb/using-cypher-to-generate-cypher-statements-to-recreate-indexes-and-constraints;"Using Cypher to generate Cypher statements to recreate indexes and constraints
Author Dana Canzano Applicable versions 3.0 4.0 Tags indexing constraint cypher
The following can be used to extract index definitions and constraint definitions from an existing database and the resultant output can be played back on another Neo4j database. For example with the :play movies dataset as when run from the Neo4j Browser, we can define the following indexes and constraints
Cypher
Copy to Clipboard
Run in Neo4j Browser
// create a schema index on :Movie(title)
// 4.0 syntax
create index movieTitles for (n:Movies) on (n.title);
//
// or 3.x syntax and a schema index on :Person(name)
create index on :Person(name);
//
// create a constraint on :Movie such that no 2 Movies have the same tagline
create constraint on (n:Movie) assert (n.tagline) is unique;
and with the above dataset the following is produced
3.x ( note the output only includes 2 indexes since the first index statement above is in 4.x format and will not run on 3.x)
Cypher-shell
all indexes
Copy to Clipboard
neo4j> call db.indexes();
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| description                | indexName       | tokenNames | properties  | state    | type                   | progress | provider                              | id | failureMessage |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ""INDEX ON :Person(name)""   | ""Unnamed index"" | [""Person""] | [""name""]    | ""ONLINE"" | ""node_label_property""  | 100.0    | {version: ""1.0"", key: ""native-btree""} | 1  | """"             |
| ""INDEX ON :Movie(tagline)"" | ""index_3""       | [""Movie""]  | [""tagline""] | ""ONLINE"" | ""node_unique_property"" | 100.0    | {version: ""1.0"", key: ""native-btree""} | 3  | """"             |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

2 rows available after 244 ms, consumed after another 12 ms
Cypher-shell
all constraints
Copy to Clipboard
neo4j> call db.constraints();
+----------------------------------------------------------------+
| description                                                    |
+----------------------------------------------------------------+
| ""CONSTRAINT ON ( movie:Movie ) ASSERT movie.tagline IS UNIQUE"" |
+----------------------------------------------------------------+

1 row available after 13 ms, consumed after another 1 ms
4.0.x
Cypher-shell
all indexes
Copy to Clipboard
neo4j> call db.indexes();
+---------------------------------------------------------------------------------------------------------------------------------------------------+
| id | name                  | state    | populationPercent | uniqueness  | type    | entityType | labelsOrTypes | properties  | provider           |
+---------------------------------------------------------------------------------------------------------------------------------------------------+
| 3  | ""constraint_e7afa4cc"" | ""ONLINE"" | 100.0             | ""UNIQUE""    | ""BTREE"" | ""NODE""     | [""Movie""]     | [""tagline""] | ""native-btree-1.0"" |
| 2  | ""index_5c0607ad""      | ""ONLINE"" | 100.0             | ""NONUNIQUE"" | ""BTREE"" | ""NODE""     | [""Person""]    | [""name""]    | ""native-btree-1.0"" |
| 1  | ""movieTitles""         | ""ONLINE"" | 100.0             | ""NONUNIQUE"" | ""BTREE"" | ""NODE""     | [""Movies""]    | [""title""]   | ""native-btree-1.0"" |
+---------------------------------------------------------------------------------------------------------------------------------------------------+

3 rows available after 16 ms, consumed after another 1 ms
Cypher-shell
all constriants
Copy to Clipboard
neo4j> call db.constraints();
+------------------------------------------------------------------------------------------+
| name                  | description                                                      |
+------------------------------------------------------------------------------------------+
| ""constraint_e7afa4cc"" | ""CONSTRAINT ON ( movie:Movie ) ASSERT (movie.tagline) IS UNIQUE"" |
+------------------------------------------------------------------------------------------+

1 row available after 10 ms, consumed after another 6 ms
3.x To export the DROP AND CREATE statement for indexes and constraints one can run:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.indexes() YIELD description
RETURN 'CREATE ' + description + ';'   ;
To extract Cypher CREATE CONSTRAINT statements run:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.constraints() YIELD description
RETURN 'CREATE ' + description + ';' ;
4.0.x
Cypher-shell
Copy to Clipboard
neo4j> call db.schemaStatements();
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| name                  | type         | createStatement                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | dropStatement                           |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ""movieTitles""         | ""INDEX""      | ""CALL db.createIndex('movieTitles', ['Movies'], ['title'], 'native-btree-1.0', {`spatial.cartesian-3d.min`: [-1000000.0, -1000000.0, -1000000.0],`spatial.cartesian.min`: [-1000000.0, -1000000.0],`spatial.wgs-84.min`: [-180.0, -90.0],`spatial.cartesian-3d.max`: [1000000.0, 1000000.0, 1000000.0],`spatial.cartesian.max`: [1000000.0, 1000000.0],`spatial.wgs-84-3d.min`: [-180.0, -90.0, -1000000.0],`spatial.wgs-84-3d.max`: [180.0, 90.0, 1000000.0],`spatial.wgs-84.max`: [180.0, 90.0]})""                               | ""DROP INDEX `movieTitles`""              |
| ""constraint_e7afa4cc"" | ""CONSTRAINT"" | ""CALL db.createUniquePropertyConstraint( 'constraint_e7afa4cc', ['Movie'], ['tagline'], 'native-btree-1.0', {`spatial.cartesian-3d.min`: [-1000000.0, -1000000.0, -1000000.0],`spatial.cartesian.min`: [-1000000.0, -1000000.0],`spatial.wgs-84.min`: [-180.0, -90.0],`spatial.cartesian-3d.max`: [1000000.0, 1000000.0, 1000000.0],`spatial.cartesian.max`: [1000000.0, 1000000.0],`spatial.wgs-84-3d.min`: [-180.0, -90.0, -1000000.0],`spatial.wgs-84-3d.max`: [180.0, 90.0, 1000000.0],`spatial.wgs-84.max`: [180.0, 90.0]} )"" | ""DROP CONSTRAINT `constraint_e7afa4cc`"" |
| ""index_5c0607ad""      | ""INDEX""      | ""CALL db.createIndex('index_5c0607ad', ['Person'], ['name'], 'native-btree-1.0', {`spatial.cartesian-3d.min`: [-1000000.0, -1000000.0, -1000000.0],`spatial.cartesian.min`: [-1000000.0, -1000000.0],`spatial.wgs-84.min`: [-180.0, -90.0],`spatial.cartesian-3d.max`: [1000000.0, 1000000.0, 1000000.0],`spatial.cartesian.max`: [1000000.0, 1000000.0],`spatial.wgs-84-3d.min`: [-180.0, -90.0, -1000000.0],`spatial.wgs-84-3d.max`: [180.0, 90.0, 1000000.0],`spatial.wgs-84.max`: [180.0, 90.0]})""                             | ""DROP INDEX `index_5c0607ad`""           |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

3 rows available after 24 ms, consumed after another 7 ms
Was this page helpful?"
https://neo4j.com/developer/kb/recreating-indexes-and-constraints-on-35;"Recreating Indexes and Constraints on 3.5
Author Dave Shiposh Applicable versions 3.5 Tags indexing constraint upgrade
This article describes the process to drop and recreate all indexes and constraints on 3.5.x. This is a recommended step after upgrading from versions earlier then 3.5 so that all indexes and constraints can be rebuilt with the latest index provider and take advantage of native indexes.
More details on index providers can be found in the documentation: https://neo4j.com/docs/operations-manual/current/performance/index-configuration/schema-indexes/#index-configuration-index-providers
Customers who are upgrading from a 3.5 version prior to 3.5.8 may also want to do this process as noted in this Support Notification: https://support.neo4j.com/hc/en-us/articles/360027344873-Neo4j-3-5-x-Index-Inconsistency-Vulnerability-Fixed-in-Release-3-5-8
Step 1 - Generating Cypher Scripts to recreate Constraints:
Execute the following Cypher statement to generate a cypher script output which will be used to drop and create constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.constraints() YIELD description
RETURN 'DROP ' + description + '; CREATE ' + description + ';'
This can be done in either the Neo4j Browser or cypher-shell. Depending on your version, you may need to strip out double quotes from the export.
Save this file, for example: recreate-constraints.cypher
Step 2 - Generating Cypher Scripts to recreate Indexes:
Execute the following Cypher statement to generate a cypher script output which will be used to drop and create constraints:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.indexes() YIELD description,type
WHERE type='node_label_property'
RETURN 'DROP ' + description + '; CREATE ' + description + ';'
Like the recreate constraints script, strip any double quotes and save the file: recreate-indexes.cypher
Step 3 (Optional) - Confirm Propery key sizes
If you are updating from 3.3 or earlier, it’s possible that the index creation could fail on string properties if any of the properties have a size greater then 4036 bytes. If you would like to check this prior to dropping and recreating, the following Cypher can be used to see if there are any values that would cause a failure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:<LABEL>)
with n, size(n.<property>) as prop_length
where prop_length >= 4036
return n.<property>, prop_length, id(n)
order by n.id desc
This will need to done for each Label/propery combination noted in steps 1 and 2. If any of the queries return any rows, you will need to either clean up / remove the nodes, or remove the drop/create from the generated cypher file for that index/constraint.
Step 4 - Confirm Index Provider
Check your configuration (neo4j.conf) and confirm that dbms.index.default_schema_provider is either commented out, or set to native-btree-1.0.
Step 5 - Run script to recreate indexes
In either the Neo4j Browser or via cypher-shell, paste in the recreate-indexes.cypher script and execute. Monitor for any errors.
Step 6 - Run script to recreate constraints
In either the Neo4j Browser or via cypher-shell, paste in the recreate-constraints.cypher script and execute. Monitor for any errors.
Step 7 - Confirm all indexes and constraints were populated, are online and are the correct index provider:
In either the Neo4j Browser or cypher-shell, run:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call db.indexes();
Verify that all indexes/constraints have a state of ONLINE, and a provider of:
Json
Copy to Clipboard
{
  ""version"": ""1.0"",
  ""key"": ""native-btree""
}
Was this page helpful?"
https://neo4j.com/developer/kb/manually-migrating-configuration-settings-from-neo4j-2x-to-neo4j-3x;"Manually Migrating Configuration Settings from Neo4j 2.x to Neo4j 3.x
Author Dave Gordon Applicable versions 3.0 3.1 Tags configuration upgrade migration
One of the major changes in Neo4j 3.0 was the reworking of configuration files and the individual configuration setting naming convention to make it more consitent and managable going forward. A config-migrator tool is supplied in Neo4j 3.0 to assist in automating this. However, for some users, this is not an option or not ideal. For those users, the following reference table lists the previous configuration setting name, the new name, and the resulting change from the pre-3.0 setting.
Note that the configuration files conf/neo4j.properties and conf/neo4j-server.properties were merged into a single conf/neo4j.conf in Neo4j 3.0. Configuration setting names in conf/neo4j-wrapper.conf were also changed, but most remain in that same configuration file (which is being merged into neo4j.conf in Neo4j 3.1).
Pre 3.0 Name 3.0 Name Net Change
consistency_check_execution_order
—
Removed
consistency_check_report_file
—
Removed
dbms.querylog.filename
—
Derived
ha.cluster_join_timeout
—
Replaced with ha.join_timeout
ha.server_type
—
Merged into dbms.mode
logging.threshold_for_rotation
—
Removed
neo_store
—
Removed
org.neo4j.server.database.location
—
Removed
org.neo4j.server.db.tuning.properties
—
Removed
org.neo4j.server.http.log.config
—
Removed
org.neo4j.server.http.unsafe.content_log.enabled
—
Removed
org.neo4j.server.properties
—
Removed
org.neo4j.server.webadmin.rrdb.location
—
Removed
org.neo4j.server.webserver.https.cert.location
—
Replaced by dbms.directories.certificates
org.neo4j.server.webserver.https.key.location
—
Replaced by dbms.directories.certificates
org.neo4j.server.webserver.https.keystore.location
—
Removed
org.neo4j.server.webserver.statistics
—
Removed
relationship_grab_size
—
Removed
store.internal_log.location
—
Removed
wrapper.user
—
Removed
dbms.security.allow_outgoing_browser_connections
browser.allow_outgoing_connections
Renamed
dbms.browser.credential_timeout
browser.credential_timeout
Renamed
dbms.browser.remote_content_hostname_whitelist
browser.remote_content_hostname_whitelist
Renamed
dbms.browser.store_credentials
browser.retain_connection_credentials
Renamed
cypher_parser_version
cypher.default_language_version
Renamed
dbms.cypher.forbid.exhaustive.shortestpath
cypher.forbid_exhaustive_shortestpath
Renamed
dbms.cypher.hints.error
cypher.hints_error
Renamed
dbms.cypher.min_replan_interval
cypher.min_replan_interval
Renamed
dbms.cypher.planner
cypher.planner
Renamed
dbms.cypher.statistics_divergence_threshold
cypher.statistics_divergence_threshold
Renamed
dbms.active_database
dbms.active_database
—
allow_store_upgrade
dbms.allow_format_migration
Renamed
node_auto_indexing
dbms.auto_index.nodes.enabled
Renamed
node_keys_indexable
dbms.auto_index.nodes.keys
Renamed
relationship_auto_indexing
dbms.auto_index.relationships.enabled
Renamed
relationship_keys_indexable
dbms.auto_index.relationships.keys
Renamed
online_backup_server
dbms.backup.address
Renamed
online_backup_enabled
dbms.backup.enabled
Renamed
dbms.checkpoint.interval.time
dbms.checkpoint.interval.time
—
dbms.checkpoint.interval.tx
dbms.checkpoint.interval.tx
—
org.neo4j.server.webserver.address
dbms.connector.*
Converteded to dbms.connector.*
org.neo4j.server.webserver.https.enabled
dbms.connector.*
Converteded to dbms.connector.*
org.neo4j.server.webserver.https.port
dbms.connector.*
Converteded to dbms.connector.*
org.neo4j.server.webserver.port
dbms.connector.*
Converteded to dbms.connector.*
—
dbms.connector.<n>.address
—
—
dbms.connector.<n>.enabled
—
dbms.connector.<n>.tls.level
dbms.connector.<n>.tls_level
Renamed
—
dbms.directories.bin
Added
dbms.directories.data
dbms.directories.data
—
dbms.security.load_csv_file_url_root
dbms.directories.import
Renamed
—
dbms.directories.lib
Added
—
dbms.directories.logs
Added
metrics.csv.path
dbms.directories.metrics
Renamed
dbms.plugin.directory
dbms.directories.plugins
Renamed
wrapper.pidfile
dbms.directories.run
Converteded to directory and rename
index_background_sampling_enabled
dbms.index_sampling.background_enabled
Renamed
index_sampling_buffer_size
dbms.index_sampling.buffer_size
Renamed
index_sampling_update_percentage
dbms.index_sampling.update_percentage
Renamed
lucene_searcher_cache_size
dbms.index_searcher_cache_size
Renamed
wrapper.java.additional
dbms.jvm.additional
Renamed
store.internal_log.level
dbms.logs.debug.level
Renamed
store.internal_log.rotation_delay
dbms.logs.debug.rotation.delay
Renamed
store.internal_log.max_archives
dbms.logs.debug.rotation.keep_number
Renamed
store.internal_log.rotation_threshold
dbms.logs.debug.rotation.size
Renamed
—
dbms.logs.gc.enabled
Converted from wrapper.java.additional
—
dbms.logs.gc.options
Converted from wrapper.java.additional
—
dbms.logs.gc.rotation.keep_number
Converted from wrapper.java.additional
—
dbms.logs.gc.rotation.size
Converted from wrapper.java.additional
org.neo4j.server.http.log.enabled
dbms.logs.http.enabled
Renamed
—
dbms.logs.http.rotation.keep_number
Added
—
dbms.logs.http.rotation.size
Added
dbms.querylog.enabled
dbms.logs.query.enabled
Renamed
dbms.querylog.max_archives
dbms.logs.query.rotation.keep_number
Renamed
dbms.querylog.rotation.threshold
dbms.logs.query.rotation.size
Renamed
dbms.querylog.threshold
dbms.logs.query.threshold
Renamed
wrapper.java.initmemory
dbms.memory.heap.initial_size
Renamed
wrapper.java.maxmemory
dbms.memory.heap.max_size
Renamed
dbms.pagecache.memory
dbms.memory.pagecache.size
Renamed
dbms.pagecache.swapper
dbms.memory.pagecache.swapper
Renamed
org.neo4j.server.database.mode
dbms.mode
Renamed
query_cache_size
dbms.query_cache_size
Renamed
read_only
dbms.read_only
Renamed
dense_node_threshold
dbms.relationship_grouping_threshold
Renamed
allow_file_urls
dbms.security.allow_csv_import_from_file_urls
Renamed
dbms.security.auth_enabled
dbms.security.auth_enabled
—
—
dbms.security.ha_status_auth_enabled
—
org.neo4j.server.rest.security_rules
dbms.security.http_authorization_classes
Renamed
remote_shell_enabled
dbms.shell.enabled
Renamed
remote_shell_host
dbms.shell.host
Renamed
remote_shell_port
dbms.shell.port
Renamed
remote_shell_read_only
dbms.shell.read_only
Renamed
remote_shell_name
dbms.shell.rmi_name
Renamed
org.neo4j.server.webserver.maxthreads
dbms.threads.worker_count
Renamed
org.neo4j.server.transaction.timeout
dbms.transaction_timeout
Renamed
keep_logical_logs
dbms.tx_log.rotation.retention_policy
Renamed
logical_log_rotation_threshold
dbms.tx_log.rotation.size
Renamed
neo4j.ext.udc.enabled
dbms.udc.enabled
Renamed
org.neo4j.server.thirdparty_jaxrs_classes
dbms.unmanaged_extension_classes
Renamed
wrapper.name
dbms.windows_service_name
Renamed
ha.allow_init_cluster
ha.allow_init_cluster
—
ha.branched_data_policy
ha.branched_data_policy
—
ha.broadcast_timeout
ha.broadcast_timeout
—
ha.configuration_timeout
ha.configuration_timeout
—
ha.com_chunk_size
ha.data_chunk_size
Renamed
ha.default_timeout
ha.default_timeout
—
ha.election_timeout
ha.election_timeout
—
ha.heartbeat_interval
ha.heartbeat_interval
—
ha.heartbeat_timeout
ha.heartbeat_timeout
—
ha.cluster_server
ha.host.coordination
Renamed
ha.server
ha.host.data
Renamed
ha.initial_hosts
ha.initial_hosts
—
ha.internal_state_switch_timeout
ha.internal_role_switch_timeout
Renamed
ha.join_timeout
ha.join_timeout
—
ha.learn_timeout
ha.learn_timeout
—
ha.leave_timeout
ha.leave_timeout
—
ha.max_concurrent_channels_per_slave
ha.max_channels_per_slave
Renamed
ha.paxos_timeout
ha.paxos_timeout
—
ha.phase1_timeout
ha.phase1_timeout
—
ha.phase2_timeout
ha.phase2_timeout
—
ha.pull_apply_batch_size
ha.pull_batch_size
Renamed
ha.pull_interval
ha.pull_interval
—
ha.state_switch_timeout
ha.role_switch_timeout
Renamed
ha.server_id
ha.server_id
—
ha.lock_read_timeout
ha.slave_lock_timeout
Renamed
ha.slave_only
ha.slave_only
—
ha.read_timeout
ha.slave_read_timeout
Renamed
ha.tx_push_factor
ha.tx_push_factor
—
ha.tx_push_strategy
ha.tx_push_strategy
—
consistency_check_graph
tools.consistency_checker.check_graph
Renamed
consistency_check_indexes
tools.consistency_checker.check_indexes
Renamed
consistency_check_label_scan_store
tools.consistency_checker.check_label_scan_store
Renamed
consistency_check_property_owners
tools.consistency_checker.check_property_owners
Renamed
dbms.cypher.compiler_tracing
unsupported.cypher.compiler_tracing
Renamed
dbms.cypher.idp_solver_duration_threshold
unsupported.cypher.idp_solver_duration_threshold
Renamed
dbms.cypher.idp_solver_table_threshold
unsupported.cypher.idp_solver_table_threshold
Renamed
dbms.cypher.non_indexed_label_warning_threshold
unsupported.cypher.non_indexed_label_warning_threshold
Renamed
dbms.cypher.runtime
unsupported.cypher.runtime
Renamed
array_block_size
unsupported.dbms.block_size.array_properties
Renamed
label_block_size
unsupported.dbms.block_size.labels
Renamed
string_block_size
unsupported.dbms.block_size.strings
Renamed
dbms.webadmin.enabled
unsupported.dbms.console_module.enabled
Renamed
org.neo4j.server.manage.console_engines
unsupported.dbms.console_module.engines
Renamed
store.interval.log.rotation
unsupported.dbms.counts_store_rotation_timeout
Renamed
dbms.internal.derived.directories.database
unsupported.dbms.directories.database
Renamed
edition
unsupported.dbms.edition
Renamed
ephemeral
unsupported.dbms.ephemeral
Renamed
execution_guard_enabled
unsupported.dbms.executiontime_limit.enabled
Renamed
org.neo4j.server.webserver.limit.executiontime
unsupported.dbms.executiontime_limit.time
Renamed
gc_monitor_threshold
unsupported.dbms.gc_monitor_threshold
Renamed
gc_monitor_wait_time
unsupported.dbms.gc_monitor_wait_time
Renamed
rebuild_idgenerators_fast
unsupported.dbms.id_generator_fast_rebuild_enabled
Renamed
forced_kernel_id
unsupported.dbms.kernel_id
Renamed
lock_manager
unsupported.dbms.lock_manager
Renamed
store.internal_log.debug_contexts
unsupported.dbms.logs.debug.debug_loggers
Renamed
org.neo4j.server.webserver.max.request.header
unsupported.dbms.max_http_request_header_size
Renamed
org.neo4j.server.webserver.max.response.header
unsupported.dbms.max_http_response_header_size
Renamed
dbms.pagecache.pagesize
unsupported.dbms.memory.pagecache.pagesize
Renamed
multi_threaded_schema_index_population_enabled
unsupported.dbms.multi_threaded_schema_index_population_enabled
Renamed
record_format
unsupported.dbms.record_format
Renamed
dump_configuration
unsupported.dbms.report_configuration
Renamed
dbms.security.auth_store.location
unsupported.dbms.security.auth_store.location
Renamed
org.neo4j.server.script.sandboxing.enabled
unsupported.dbms.security.script_sandboxing_enabled
Renamed
shutdown_transaction_end_timeout
unsupported.dbms.shutdown_transaction_end_timeout
Renamed
dbms.tracer
unsupported.dbms.tracer
Renamed
transaction_start_timeout
unsupported.dbms.transaction_start_timeout
Renamed
neo4j.ext.udc.first_delay
unsupported.dbms.udc.first_delay
Renamed
neo4j.ext.udc.host
unsupported.dbms.udc.host
Renamed
neo4j.ext.udc.interval
unsupported.dbms.udc.interval
Renamed
neo4j.ext.udc.reg
unsupported.dbms.udc.reg
Renamed
neo4j.ext.udc.source
unsupported.dbms.udc.source
Renamed
org.neo4j.server.webadmin.browser.uri
unsupported.dbms.uris.browser
Renamed
org.neo4j.server.webadmin.management.uri
unsupported.dbms.uris.management
Renamed
org.neo4j.server.webadmin.data.uri
unsupported.dbms.uris.rest
Renamed
experimental.use_read_locks_on_property_reads
unsupported.dbms.use_read_locks_on_property_reads
Renamed
unsupported_wadl_generation_enabled
unsupported.dbms.wadl_generation_enabled
Renamed
ha.cluster_name
unsupported.ha.cluster_name
Renamed
ha.instance_name
unsupported.ha.instance_name
Renamed
batch_inserter_batch_size
unsupported.tools.batch_inserter.batch_size
Renamed
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-3dot5-to-4-dot-x-migrations-best-practices;"Neo4j 3.5 to 4.x Migration Help and Resources
Author Dave Shiposh Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags upgrade migration
This guide is designed to provide key details and links on various 3.5 to 4.x migration resources.
With this document, you should be able to read and/or find everything you need to successfully migrate your Neo4j deployment to take advantage of the most up-to-date features, and the extended support which comes from running the most recent versions of Neo4j.
Special Migration focused Customer Success Office Hours
On June 10th, the Neo4j Customer Success team held a focused office hours session specifically answering questions on the migration process.
The Replay of this event can be found here: June 10, 2021 Office Hours Recording
Neo4j 3.5 to 4.x Migration Best Practices Guide
The following document was written by the Customer Success team and is a deep dive in the migration process. This guide aims to serve as a best practice guide for a migration from Neo4j 3.5.x to Neo4j 4.x. It is not intended to be a replacement for the current documentation, in fact, this document will often point to (or reference) said documentation. You can think of it as a one-stop-shop or starting point for everything related to going from a 3.5.x to a 4.x deployment.
Find the Guide Here (support login required): Neo4j 3.5 to 4.x Migration Best Practices Guide
Neo4j Migration Documentation
The product documentation continues to be updated and refreshed and is a key resource on the upgrade and migration process.
The online documentation can be found here:
Migration Guide
Upgrade Documentation
Neo4j Community
Feel free to ask your questions within the Neo4j Community: Neo4j Community
Neo4j Professional Services
The Neo4j Professional Services team can offer packaged migration services to assist with your migration: Neo4j Professional Services
Was this page helpful?"
https://neo4j.com/developer/kb/upstream-strategy-behaviour-change;"Upstream strategy behaviour change
Author José Rocha Applicable versions 3.2 3.3 3.4 3.5 Tags network multi-datacenter
Starting with version 3.4, we changed in the behaviour of how instances sync with the Leader. This change can potentially affect the behaviour of your cluster when using strategy plugins, depending on your configuration.
Pre-3.4 - on the context of multi datacenter architectures - strategy plugins were sets of rules that defined how Read Replicas contacted servers in the cluster in order to synchronize transaction logs. Post-3.4 this was expanded to Core instances as well, meaning that you can actively select the desired strategy from where your Core instances pull updates from.
This is particularly important if you have a user-defined strategy that restricts the instances from where your Read Replicas pull updates from.
Imagine the following scenario:
Figure 1: North & South DCs
Let’s say you want to prevent the Read Replica in the South DC to pull updates from the North DC. You could set causal_clustering.upstream_selection_strategy=user-defined and have the following strategy configured
Conf
Copy to Clipboard
causal_clustering.user_defined_upstream_strategy=groups(south); halt()
Please note that the upstream strategy defined above only works when you define server groups on your instances. In the picture, all instances on the South DC belong to server group south whereas the ones on the North DC belong to server group north. You can read more about server groups here.
This will effectively prevent the Read Replica to connect to the North DC. However, what we’ve seen in several implementations was that - for ease or coherence - customers would set causal_clustering.upstream_selection_strategy to be the same on ALL instances, knowing that setting would only apply to Read Replicas. Post-3.5, if you do this, the Core instances in the South DC in the example above will not be able to pull updates from Leader over at the North DC.
It is therefore recommended that, for Core instances, you configure a less restrictive upstream strategy. You can use the ones available out-of-the-box:
connect-to-random-core-server - Connect to any Core Server selecting at random from those currently available.
typically-connect-to-random-read-replica - Connect to any available Read Replica, but around 10% of the time connect to any random Core Server.
connect-randomly-to-server-group - Connect at random to any available Read Replica in any of the server groups specified in the comma-separated list causal_clustering.connect-randomly-to-server-group.
leader-only - Connect only to the current Raft leader of the Core Servers.
Setting the Core instances upstream strategy to leader-only will make Neo4j behave like pre-3.4 but you can choose another one. The important is to make sure you select a strategy that will allow your Core instances to pull from the Leader regardless of where it’s located.
Also, you can select multiple upstream strategies by separating them with a comma ("",""). It is perfectly acceptable to have the following configuration:
Properties
Copy to Clipboard
causal_clustering.upstream_selection_strategy=user-defined, leader-only
This will first try the user-defined strategy and then the leader-only strategy.
Was this page helpful?"
https://neo4j.com/developer/kb/setup-routing-policies-for-different-user-types;"Setup Routing Policies for Different User Types To Direct them to Different Servers
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal cluster multi-datacenter
Problem statement
There is a Causal Cluster Setup with 3 Cores and 1 Read Replica. There are 2 user groups - OLTP users and OLAP users. OLTP user queries should only go to the 2 Followers and not to the Read Replica. OLAP user queries should only go to the Read Replica and not to any of the Followers. The reason being that OLTP users should not be impacted by the long running queries from OLAP users.
How to achieve this in Causal Cluster setup?
To assist with this, Multi-DC setup is required, which was introduced in Neo4j version 3.2. First set up the multi-dc license. More information can be obtained from the Neo4j Operations Manual - https://neo4j.com/docs/operations-manual/current/clustering/causal-clustering/multi-data-center/.
Configure the Causal Cluster(CC) with 3 Cores and 1 Read Replica as described in the Neo4j documentation. Then make the corresponding changes in neo4j.conf file to configure which apps/users should access which instances of the cluster. The below configuration creates a server group with oltp_app and also enables multi-dc license, which is required for server groups.
Properties
Core 1, Core 2 and Core 3
Copy to Clipboard
causal_clustering.server_groups=oltp_app
causal_clustering.multi_dc_license=true
causal_clustering.load_balancing.plugin=server_policies
causal_clustering.load_balancing.config.server_policies.oltp=groups(oltp_app); halt();
More documentation on the above config properties can be read here: https://neo4j.com/docs/operations-manual/current/clustering/causal-clustering/multi-data-center/load-balancing/#_prerequisite_configuration
Now, to service only the OLAP users on Read Replica configure the read replica as follows:
Properties
READ_REPLICA
Copy to Clipboard
causal_clustering.server_groups=olap_app
causal_clustering.multi_dc_license=true
causal_clustering.load_balancing.plugin=server_policies
causal_clustering.load_balancing.config.server_policies.olap=groups(olap_app); halt();
How to use the Driver from the application?
The application used by OLTP users will have the driver configuration below:
Client Application URL:
Java
Copy to Clipboard
Driver driver = GraphDatabase.driver( ""bolt+routing://127.0.0.1:7687?policy=oltp"" , AuthTokens.basic( ""neo4j"", ""password""), Config.build().withMaxTransactionRetryTime( 15, TimeUnit.SECONDS ).toConfig() );
We specify the server_policy name in the URI - bolt+routing://127.0.0.1:7687?policy=oltp. When using the above URI the READ ONLY queries will only be routed to the 2 Followers since the Core server_groups are set as oltp_app.
The documentation link for Routing Context in present in the drivers section: https://neo4j.com/docs/developer-manual/current/drivers/client-applications/#_routing_drivers_with_routing_context
Multi-DC feature is only available in Neo4j version 3.2 and above.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-display-a-hostname-rather-than-ip-address-in-causal-clustering-members-section-of-sysinfo;"How do I display a hostname rather than IP address in the Causal Clustering Members section of sysinfo
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags sysinfo causal cluster ip address hostname
Via the browser one can enter :sysinfo to display data about the Neo4j system. When Neo4j is configured as a causal cluster, the bottom-right corner of the `:sysinfo' output will display the members in the cluster as depicted below:
Each of the addresses are presented as hyperlinks.
If you want to replace the IP addresses with hostnames, this can be achieved by modifying the config option dbms.connectors.default_advertised_address in the file $NEO4J_HOME/conf/neo4j.conf.
For example if you define this setting as follows:
Properties
Copy to Clipboard
# The address at which this server can be reached by its clients. This may be the server's IP address or DNS name, or
# it may be the address of a reverse proxy which sits in front of the server. This setting may be overridden for
# individual connectors below.
dbms.connectors.default_advertised_address=neo4j-CoreEdge
then upon restart of Neo4j, re-running :sysinfo in the browser will now yield:
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-generate-sysinfo-output-from-cypher;"How to generate sysinfo output from Cypher
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher sysinfo
If you need to generate the equivalent output from command :sysinfo as run from the Neo4j Browser at http://localhost:7474 this can be achieved by running the following Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.queryJmx(""org.neo4j:instance=kernel#0,name=Store file sizes"") yield attributes
       with  keys(attributes) as k , attributes
       unwind k as row
       return ""StoreSizes"" as type,row,attributes[row][""value""]

union all

call dbms.queryJmx(""org.neo4j:instance=kernel#0,name=Page cache"") yield attributes
       with  keys(attributes) as k , attributes
       unwind k as row
       return ""PageCache"" as type,row,attributes[row][""value""]

union all

call dbms.queryJmx(""org.neo4j:instance=kernel#0,name=Primitive count"") yield attributes
         k , attributes
        k  row
          type,row,attributes[row][]

 all

 dbms.queryJmx()  attributes
         k , attributes
        k  row
          type,row,attributes[row][]

 all

 dbms.queryJmx()  attributes
         k , attributes
        k  row
          type,row,attributes[row][]

 all

 dbms.queryJmx()  attributes
         k , attributes
        k  row
          type,row,attributes[row][];
View all (24 more lines)
To which this will generate output similar to
+------------------------------------------------------------------------------------+
| type             | row                                  | attributes[row][""value""] |
+------------------------------------------------------------------------------------+
| ""StoreSizes""     | ""LogicalLogSize""                     | 90                       |
| ""StoreSizes""     | ""StringStoreSize""                    | 8192                     |
| ""StoreSizes""     | ""ArrayStoreSize""                     | 8192                     |
| ""StoreSizes""     | ""RelationshipStoreSize""              | 0                        |
| ""StoreSizes""     | ""PropertyStoreSize""                  | 0                        |
| ""StoreSizes""     | ""TotalStoreSize""                     | 139579                   |
| ""StoreSizes""     | ""NodeStoreSize""                      | 0                        |
| ""PageCache""      | ""Faults""                             | 62                       |
| ""PageCache""      | ""EvictionExceptions""                 | 0                        |
| ""PageCache""      | ""BytesWritten""                       | 196598                   |
| ""PageCache""      | ""Flushes""                            | 20                       |
| ""PageCache""      | ""Evictions""                          | 0                        |
| ""PageCache""      | ""FileUnmappings""                     | 76                       |
| ""PageCache""      | ""BytesRead""                          | 327650                   |
| ""PageCache""      | ""Pins""                               | 126                      |
| ""PageCache""      | ""FileMappings""                       | 93                       |
...
Was this page helpful?"
https://neo4j.com/developer/kb/stopping-and-restoring-neo4j-docker-image;"Stopping the Neo4j docker image in order to restore from a backup
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags docker restore backup
In a neo4j docker installation, the neo4j-admin restore requires the neo4j service to be stopped as one can’t do a restore on a running database. Subsequently, running as a docker image, stopping neo4j server could be done using a Ctrl-C (from within the docker terminal) or docker stop <container id> from a separate terminal window. However, it would terminate the container itself as the container is simply an instance of the neo4j application. In such case, a restore using ./neo4j-admin restore would not be a workable option.
Following is a workaround to doing a neo4-admin restore in docker:
Get the container name by executing docker ps
Backup neo4j by executing docker exec --interactive --tty <container id> bin/neo4j-admin backup replacing <container id> with the id fetched as above.
Prior to restore, the neo4j instance needs to be stopped. If executing from the same terminal as the docker process, use Ctrl-C which will stop the neo4j docker container process. Else, if neo4j container was created indicating --dettach, then Ctrl-C won’t work and one would need to stop the container via a docker cmd from a separate terminal. To do this from a separate terminal, execute docker stop <container id>
Replace the graph.db folder with that from the backup created earlier.
Start container and it should come up with the restored db.
Shell
Copy to Clipboard
$ docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=$HOME/neo4j/data:/data \
    --volume=$HOME/neo4j/logs:/logs \
    neo4j:3.3.0
Alternatively, one can specify --dbms.active_database=new.db as a startup option as
Shell
Copy to Clipboard
$ docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=$HOME/neo4j/data:/data \
    --volume=$HOME/neo4j/logs:/logs \
    --dbms.active_database=new.db
    neo4j:3.3.0`
Following are a few items noticed as part of the testing:
At the time of writing this KB, neo4j Community Edition doesn’t support online backups. Enterprise version can be installed using --neo4j:3.3.0-enterprise instead of the --neo4j:3.3.0 (which by default will install Community edition.
For a docker setup, the /data, /conf and /logs directories specified at the container spin-up, are persistent to disk. Replacing graph.db on a running instance will continue showing the un-restored version of the database, unless the neo4j instance is restarted.
Was this page helpful?"
https://neo4j.com/developer/kb/docker-image-cannot-run-on-kubernetes-as-non-root-user;"Neo4j Docker image cannot run on kubernetes as non root user
Author Kambiz Chehresa Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags kubernetes docker security
In Kubernetes (K8S) various levels of security can be set which apply cluster-wide to Pods running containers. One of which is a policy which prevents containers within a Pod to be executed/run as root user (runAsNonRoot).
If this config is set, but the Pod definition for your K8S cluster does override securityContext>runAsUser value then upon trying to have neo4j container(s) started you will see an error along the lines of:
Error: container has runAsNonRoot and image will run as root
To resolve this issue, make sure that in your K8S' cluster Pod definition, you have something similar to the following:
Yaml
Copy to Clipboard
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000
# ....
runAsUser is the UID used to run the entrypoint of the container process, in this case Neo4j’s. The value is a high number chosen to avoid conflicts with the host’s user table.
Reference: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
Was this page helpful?"
https://neo4j.com/developer/kb/docker-permission-denied;"Docker ""Permission Denied"" Error
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags docker permission denied user
When a docker instance is started, one could get a permission denied error such as
2018-06-14 23:20:50.962+0000 ERROR Failed to start Neo4j: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@7880cdf3' was successfully initialized, but failed to start. Please see the attached cause exception ""/logs/debug.log (Permission denied)"". Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@7880cdf3' was successfully initialized, but failed to start. Please see the attached cause exception ""/logs/debug.log (Permission denied)"".
and may fail to start.
Docker used to run as root and now has been changed. This change was introduced in 3.1.8, 3.2.9, 3.3.4 docker images and in 3.4 onwards. In order for any of the newer neo4j to continue having access to these older logs, conf, data you will have to change the permissions of files created by the old version - in particular this applies to existing log and data files.
Granting “everyone” access to the logs directory does circumvent the “Permission Denied” error. However, that is not a preferred solution. Our recommendation is either:
A) give the user they are passing in to docker ownership or primary group on the logs dir along with read and write permissions How to pass --user as parameter to docker can be found in the following KB article. https://support.neo4j.com/hc/en-us/articles/360012923574-Running-Docker-as-Non-Root-User
Or
B) create a secondary group that has access to logs directory e.g. sudo groupadd logs and add the user they use to run neo4j to that group. If this is done, one has to pass the secondary groups in additionally to docker using the --group-add flag. For example:
Bash
Copy to Clipboard
group-add=""$(getent group logs | cut -d "":"" -f3)""
Was this page helpful?"
https://neo4j.com/developer/kb/using-cypher-to-generate-cypher-statements-to-recreate-users-and-roles;"Using Cypher to generate Cypher statements to recreate Users and Roles
Author Dana Canzano Applicable versions 3.1 Tags user role schema
The following can be used to extract user and role definitions from an existing database and the resultant output can be played back on another Neo4j database.
Cypher
Copy to Clipboard
Run in Neo4j Browser
//export roles
return '//export Roles' as output
union all
call dbms.security.listRoles() yield role return 'call dbms.security.createRole(\'' + role + '\');' as output
union all
//export users
return '//export Users' as output
union all
call dbms.security.listUsers() yield username return 'call dbms.security.createUser(\'' + username + '\',\'newpassword\');' as output
union all
// export user to role maps
return '//export Roles to User map' as output
union all
call dbms.security.listRoles() yield role,users with role,users unwind users as user return 'call dbms.security.addRoleToUser(\'' + role + '\',' + user + '\');'  as output
The resultant output will default all users passwords to 'newpassword' and the user will be required to change their password on initial log on. Sample output is as follows:
Cypher
Copy to Clipboard
Run in Neo4j Browser
//export Roles
call dbms.security.createRole('reader');
call dbms.security.createRole('architect');
call dbms.security.createRole('admin');
call dbms.security.createRole('publisher');
//export Users
call dbms.security.createUser('neo4j_dba','newpassword');
call dbms.security.createUser('neo4j','newpassword');
//export Roles to User map
call dbms.security.addRoleToUser('admin',neo4j');
call dbms.security.addRoleToUser('admin',neo4j_dba');
The approach used above is similar to related knowledgebase document ""Using Cypher to generate Cypher statements to recreate indexes and constraints""
Was this page helpful?"
https://neo4j.com/developer/kb/useful-cypher-statements-for-suspending-and-reactivating-users;"Useful Cypher statements for suspending and reactivating users
Author Dana Canzano Applicable versions 3.1 Tags suspend activate security user
Commencing with Neo4j 3.1 and implementaion of native database users it is possible to suspend a user, thus preventing the user from further authenticating in.
To view all suspended users run the following Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.security.listUsers() yield username, flags
with username,flags
where 'is_suspended' in flags
return username
Further if you encounter the need to suspend all users, for example to prevent all database access during a weekend maintenance period, the following Cypher can be used to generate Cypher statements which can then be used to suspend and subsequently reactivate all users.
Build the Cypher statements to activate all currently 'active' users
Cypher
Copy to Clipboard
Run in Neo4j Browser
// users with no  is_suspended flag and build the statement to activate the user and not force a password change
call dbms.security.listUsers() yield username, flags with username, flags
where not 'is_suspended' in flags
return 'call dbms.security.activateUser(\'' + username + '\',false);'
Build the Cypher statements to suspend all currently 'active' users
Cypher
Copy to Clipboard
Run in Neo4j Browser
// users with no  is_suspended flag
call dbms.security.listUsers() yield username, flags with username, flags
where not 'is_suspended' in flags
return 'call dbms.security.suspendUser(\'' + username + '\');'
Finally, at the time of the maintenance window one would first run the generated Cypher statements from above to suspend all users. Note it is not possible to suspend the user you are currently logged in as and as such you may see a call dbms.security.suspendUser result in failure error message of 'Suspending yourself (user 'neo4j') is not allowed.'
At the completion of the maintenance window, one would then run the generated Cypher statement to activate all the currrently defined suspended users.
Was this page helpful?"
https://neo4j.com/developer/kb/enabling-tlsv1-2-with-ibm-jdk9;"Enabling TLSv1.2 with IBM JDK9
Author Dave Fauth Applicable versions 3.4 Tags jdk security tls cypher-shell
Neo4j 3.4.0 only supports TLSv1.2 by default. IBM JDK9 uses the TLSv1 protocol by default. When attempting to run cypher-shell, users will be unable to connect to Neo4j.
To enable TLSv1.2 in the IBM JDK, set the following JAVA OPT:
Bash
Copy to Clipboard
export JAVA_OPTS='-Dcom.ibm.jsse2.overrideDefaultTLS=true'
If you want the JAVA_OPT to be set for every shell you start afterwards, add that line to ~/.profile as well.
Was this page helpful?"
https://neo4j.com/developer/kb/use-java-runtime-11-with-neo4j-3-5-x;"Use Java Runtime 11 with Neo4J 3.5.x
Author Jérémie Phoulchand Applicable versions 3.5 Tags jdk jre java11
Neo4j 3.5.x supports Java 11 as runtime, however custom code should still be compiled against Java 8. As a best practice, it is recommended to maintain your infrastructure environment on supported components (Hypervisor, Operating System, Java Virtual Machine). In this example, we will show you how to upgrade the Java JDK from version 8 to Java JDK 11 on Linux.
Java JDK 11 Installation
The first step is to install Java 11, you can refer to your preferred vendor instructions. We recommend to use a JDK to be able to run Neo4j in production. Java diagnostic commands might be required when engaging Neo4J support:
neo4j-admin report command requires a JDK.
jstack or jmap dumps the heap memory into a file which can be requested to troubleshoot issues.
jfr : profiling tool used to gather diagnostics and profiling data from a running Java application. It is available for free since java 11.
At this stage, Java 8 will still be used. It is allowed to have multiple JVM installations on the same machine.
java -version will still display Java 8.
Switch to Java 11 as default
To use Java 11 runtime by default,
For RedHat, CentOS, Fedora, Amazon AMI: run sudo alternatives --config java For Debian-based systems, Debian, Ubuntu, Suse: run sudo update-alternatives --config java
Pick the right version and press enter. There are 2 installed binaries that provides 'java' in this example:
Shell
Copy to Clipboard
$ sudo alternatives --config java

Selection    Command
1           java-1.8.0-openjdk.x86_64 (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.amzn2.0.1.x86_64/jre/bin/java)
2           /usr/lib/jvm/java-11-amazon-corretto/bin/java
Choose the second option and press enter to validate.
java -version should now display Java 11.
Edit Neo4J.conf
Comment or remove the following line:
Properties
Copy to Clipboard
dbms.logs.gc.options=-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution
Uncomment the following setting:
Properties
Copy to Clipboard
dbms.logs.gc.options=-Xlog:gc,safepoint,age=trace
Start Neo4J
You will immediately see WARNING messages in your neo4j.log You can safely disregard them as shown below:
WARNING: Please consider reporting this to the maintainers of org.eclipse.collections.impl.utility.ArrayListIterate
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-failed-to-obtain-connection-towards-write-server;"Explanation of error ""Failed to obtain connection towards WRITE server. Known routing table is: Ttl…""
Author Vivek Saran Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags cypher-shell bolt
In Neo4j 4.0, if you are logged into the READ_REPLICA of a Causal Cluster, and execute the following command to login into cypher-shell:
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/cypher-shell -u neo4j -p mypwd
You will encounter this error:
Failed to obtain connection towards WRITE server.
Known routing table is: Ttl 1589334991968, currentTime 1589334691977,
routers AddressSet=[localhost:7637], writers AddressSet=[],
readers AddressSet=[localhost:7637], database '<default database>'
Before the 4.0 version, the above was a completely valid/correct command to log into the cypher-shell.
The reason is that the default value for the address (-a) parameter in the command is neo4j://localhost:7687.
The syntax is documented in the cypher-shell command-line help as:
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/cypher-shell -help
 -a ADDRESS, --address ADDRESS
                         address and port to connect to (default: neo4j://localhost:7687)
The implication of the default value neo4j://localhost:7687 is that the cypher-shell is interpreting the login command as:
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/cypher-shell -u neo4j -p mypwd -a neo4j://localhost:7687
The above command is invalid/wrong. The neo4j URI scheme is the 4.0 equivalent of bolt+routing, and should only be used for connecting to one of the CORE servers in a Causal Cluster, not to any READ REPLICA.
To get around this error and logging into the cypher-shell of a READ_REPLICA, use the following command instead:
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/cypher-shell -u neo4j -p mypwd -a bolt://localhost:7687
While connecting to a READ REPLICA from a different Causal Cluster member, use the command as:
Shell
Copy to Clipboard
$ $NEO4J_HOME/bin/cypher-shell -u neo4j -p mypwd -a bolt://<read-replica-server-ip>:7687
A key takeaway from this article is that if you’re using neo4j or bolt+routing URI scheme, you should be connecting to the CORE nodes in the Causal Cluster, not a READ_REPLICA.
Was this page helpful?"
https://neo4j.com/developer/kb/troubleshooting-connection-issues;"Troubleshooting Connection Issues in Neo4j Browser and Cypher Shell
Author David Allen Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags https cypher-shell browser
This page describes common issues users may encounter in connecting Neo4j Browser or cypher-shell to a Neo4j database, and how to address them.
Connection Timeout
Symptom: connection attempts lag for a long time, and then fail with connection timed out errors.
Example:
Shell
Copy to Clipboard
$ cypher-shell -a 37.204.217.197 -u neo4j -p myPassword
connection timed out: /37.204.217.197:7687
Troubleshooting steps:
Ensure that the address is correct.
Ensure that if the server is listening for bolt connections on a port other than 7687, that you pass the port explicitly to your client (e.g. cypher-shell) or other program you have written.
Ensure that firewall rules do not prohibit traffic on the bolt port.
Common causes of this error:
A cloud instance of neo4j is launched with no security groups defined or port access. Bolt is available on at the right address, but firewall rules prevent access. Packets are dropped, and so the result is a connection timeout.
Non-standard configuration of neo4j which runs bolt on a port other than 7687, for example to comply with local network policies.
The server is not yet available. For a period of time while starting up, and particularly if the database is repairing files or migrating an old store, the bolt endpoint may not be available. You will know that it is available when the logs contain a message that looks like this: 2018-05-25 13:34:34.584+0000 INFO Bolt enabled on 127.0.0.1:7687.
ServiceUnavailable: WebSocket connection failure
A similar message you might see is: WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver.
Symptom: you can connect to Neo4j Browser and enter credentials, but fail to connect with a message about WebSocket connection failures.
Explanation: this is commonly seen with Firefox and some versions of Internet Explorer, when Neo4j Browser is used with an untrusted SSL certificate. When users click to accept the exception and permit traffic, those browsers authorize that action for only the port that Neo4j Browser is running on, not for all ports on that host. As a result, the browser’s security policy fails the WebSocket connection to the bolt port.
Available Resolutions: 1. Use a signed SSL certificate 2. Follow directions for your browser to trust the server’s certificate for the bolt port, and then refresh the page. 3. Use Chrome 4. Set dbms.connector.bolt.tls_level=OPTIONAL in your neo4j config. Be aware that bolt connections may not be encrypted, but this is a method of side-stepping web browser issues with the untrusted certificate.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-override-browser-configuration-settings;"How do I override browser configuration settings
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags browser configuration
Commencing with Neo4j 3.2.2 one can override default configuration settings of the browser whereby a number of these settings are defined under the left frame and through the 'gears' icon.
To implement said functionality you would first need to know the name of the parameter which defines the functionality. This can be displayed by running from the browser
Cypher
Copy to Clipboard
Run in Neo4j Browser
:config
and sample output is as follows:
Json
Copy to Clipboard
{
  ""cmdchar"": "":"",
  ""maxHistory"": 30,
  ""theme"": ""normal"",
  ""useBoltRouting"": false,
  ""initCmd"": "":play start"",
  ""initialNodeDisplay"": 300,
  ""maxNeighbours"": 100,
  ""showSampleScripts"": true,
  ""browserSyncDebugServer"": null,
  ""maxRows"": ""5000"",
  ""shouldReportUdc"": true,
  ""autoComplete"": true,
  ""scrollToTop"": true,
  ""maxFrames"": 30,
  ""editorAutocomplete"": true
}
This can be changed globally for all users of the browser or one can also override these setting at the Cypher prompt through the browser.
The following describes how to change Max Frames from 50 to 10 and the Theme to Outline
Globally
To make the changes globally modify the $NEO4J_HOME/conf/neo4j.conf and add the following
Properties
Copy to Clipboard
browser.post_connect_cmd=config {maxFrames:10, theme: ""outline""}
which would change the maxFrames from its default of 50 to 10 and then restart Neo4j.
Browser Instance
Within the browser at the Cypher prompt enter
Cypher
Copy to Clipboard
Run in Neo4j Browser
:config {maxFrames:10, theme: ""outline""}
Once making the change, rerunning :config should report that maxFrames has been set to 10, and the Theme is defined to 'Outline' and the Gears Icon should reflect this change.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-security-error-18-when-using-internet-explorer-and-neo4j-browser;"Explanation of error ""Security Error: 18"" when using Internet Explorer and Neo4j Browser
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags internet-explorer browser
When connecting to the Neo4j Browser http://localhost:7474 and using Internet Explorer 11, submission of cypher statements may result in error message:
Security Error: 18
As the Neo4j Browser is using websockets to connect , for example ws://localhost, you would need to add ws:\\localhost\ to Internet Explorer configurations ( Internet Options / Security / Local Intranet / Sites / Advanced) and as depicted.
To access the Internet Explorer configuration click the gears icon in the upper right corner of the browser.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-websocket-connection-failure;"Explanation of error ""WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver…
Author Dana Canzano Applicable versions 3.0 Tags browser bolt websocket
In Neo4j 3.0 and its implementation of the Bolt protocol, if a remote browser connects to Neo4j (http://<remote_neo4j_host>:7474) and attempts to authenticate, the following error may be encountered:
WebSocket connection failure.
Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver.
Please use your browsers development console to determine the root cause of the failure.
Common reasons include the database being unavailable, using the wrong connection URL or temporary network problems.
If you have enabled encryption, ensure your browser is configured to trust the certificate Neo4j is configured to use.
WebSocket readyState is: 3
This error can be resolved by editing the file $NEO4J_HOME/conf/neo4j.conf and uncommenting:
Properties
Copy to Clipboard
# To have Bolt accept non-local connections, uncomment this line:
dbms.connector.bolt.address=0.0.0.0:7687
Was this page helpful?"
https://neo4j.com/developer/kb/how-neo4j-browser-interacts-with-neo4j-server;"How Does Neo4j Browser interact with Neo4j Server?
Author Dave Shiposh Applicable versions 3.2 3.3 Tags browser bolt websocket
Starting with Neo4j 3.2, the Neo4j Browser only supports Bolt connectivity to the Neo4j Server. This requires that the network allows for socket communication between the browser and Bolt Port specified on the Neo4j Server. To see if your network allows for websockets one can use http://www.websocket.org/echo.html
If websockets are not allowed on your network, when attempting to authenticate via the Neo4j browser at http://localhost:7474 the following error will be logged
ServiceUnavailable: WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not
available to this Neo4j Driver. Please use your browsers development console to determine the root cause of the failure. Common reasons
include the database being unavailable, using the wrong connection URL or temporary network problems. If you have enabled encryption,
ensure your browser is configured to trust the certificate Neo4j is configured to use. WebSocket `readyState` is: 3
Additionally, to allow for remote browser connections your $NEO4J_HOME/conf/neo4j.conf needs to be configured as:
Properties
Copy to Clipboard
# To have Bolt accept non-local connections, uncomment this line:
dbms.connector.bolt.address=0.0.0.0:7687
Below is the communication process between the Neo4j Browser and Neo4j Server:
The Browser does one HTTP call on startup:
GET / HTTP/1.1
Host: <server>:7474
Content-Type: application/json
This request is there only to ask Neo4j what the Bolt URL is (configurable on the server with dbms.connectors.default_advertised_address). After that request the Browser tries to connect to the server over Bolt without credentials. This is for two reasons:
When the response comes back, we know if auth is enabled or not
If connection is successful, update app state to reflect that no credentials are needed to connect
If the first connection attempt is unsuccessful the Browser checks if there are any login credentials stored in the web browsers localstorage. If there is, the Browser tries to connect with them
If successful, all good.
If unsuccessful, give up and prompt the user for connection credentials
So, as a diagram this would look something like
Seq 0
Client === GET ==> Neo4j (HTTP 7474) Ask for Bolt connection URL
Client <== Resp === Neo4j (HTTP 7474)
Seq 1
Client === Bolt ==> Neo4j (WS 7687) without auth credentials
Alternate 1.1
Client <== Resp (success) === Neo4j (WS 7687)
(Success, stop)
Alternate 1.2
Client <== Resp (no success) === Neo4j (WS 7687)
(No success, goto Seq 2)
Seq 2
Client === Bolt ==> Neo4j (WS 7687) with auth credentials
Alternate 2.1
Client <== Resp (success) === Neo4j (WS 7687)
(Success, stop)
Alternate 2.2
Client <== Resp (no success) === Neo4j (WS 7687)
(No success, prompt user for credentials)
Note you will end up at the same page prompting for credentials both when you have invalid credentials and/or when you are unable to connect via Bolt, so it’s important to check both possible causes if you’re unable to connect.
Was this page helpful?"
https://neo4j.com/developer/kb/list-of-restricted-ports-in-browsers;"List of restricted ports in browsers
Author Umar Muzammil Applicable versions all Tags browser chrome ports url
This document provides a list of ports which generate an error when browsing via Chrome. It is a super-set of ports most of which are also restricted in Mozilla Firefox as they’re reserved for the services listed below and are therefore considered unsafe for other services to be hosted/accessible as these are the most commonly attempted ports for dos attacks etc. If used, neo4j would appear unreachable via chrome if customers set connector address ports (dbms.connector.http.listen_address=:7474 or dbms.connector.bolt.listen_address=:7687) to one of these. Note that the list is non-exhaustive and is subject to alteration over time.
Table 1. Restricted Ports on Chrome and corresponding services
Port Number
Service Name
1
tcpmux
7
echo
9
discard
11
systat
13
daytime
15
netstat
17
qotd
19
chargen
20
ftp data
21
ftp access
22
ssh
23
telnet
25
smtp
37
time
42
name
43
nicname
53
domain
77
priv-rjs
79
finger
87
ttylink
95
supdup
101
hostriame
102
iso-tsap
103
gppitnp
104
acr-nema
109
pop2
110
pop3
111
sunrpc
113
auth
115
sftp
117
uucp-path
119
nntp
123
NTP
135
loc-srv /epmap
139
netbios
143
imap2
179
BGP
389
ldap
465
smtp+ssl
512
print / exec
513
login
514
shell
515
printer
526
tempo
530
courier
531
chat
532
netnews
540
uucp
556
remotefs
563
nntp+ssl
587
stmp
601
??
636
ldap+ssl
993
ldap+ssl
995
pop3+ssl
2049
nfs
3659
apple-sasl / PasswordServer
4045
lockd
6000
X11
6665
Alternate IRC [Apple addition]
6666
Alternate IRC [Apple addition]
6667
Standard IRC [Apple addition]
6668
Alternate IRC [Apple addition]
6669
Alternate IRC [Apple addition]
References:
https://src.chromium.org/viewvc/chrome/trunk/src/net/base/net_util.cc?view=markup#l68
https://superuser.com/questions/188058/which-ports-are-considered-unsafe-on-chrome
http://e1tips.com/2014/03/17/allow-firefox-chrome-to-access-restricted-ports/
The following useful chrome extension (Open Port Check Tool) can be used to determine the current status of a port to check port status of an IP address and scan open ports on that connection. The tool can also be used to determine whether port forwarding is setup correctly or if the server applications are blocked or not by a firewall.
https://chrome.google.com/webstore/detail/open-port-check-tool/lefghalnfhaklfbndadklndcndabkadb
Was this page helpful?"
https://neo4j.com/developer/kb/a-light-weight-approach-to-validating-network-port-connectivity;"A light weight approach to validating network port connectivity
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags ports causal-cluster
If it becomes necessary to validate, particularly in a clustered environment whether Causal Cluster or High Availability, whether or not 1 instance can talk to another instance on a given port, and thus prove whether a firewall or iptables may be prohibiting traffic, one can use either of the 2 methods
if you have linux command netcat installed
Eestablish 2 terminal sessions.
From the first terminal session run from the linux command line/prompt
Shell
Copy to Clipboard
$ nc -l -p 5000
and to which this will start up a process on the host listening for traffic on port 5000. If the connection is possible then your terminal window will advance to the next line and simply await messages from another nc command.
If the port number is already in use by another linux process you will encounter error message
nc: Address already in use
From the second terminal session run from the linux command line/prompt
Shell
$ nc -v <hostname> 5000
replacing <hostname> with the internal IP address/hostname of the first terminal session. This command will make a connection to the <hostname> and port 5000. If the connection is successful then your terminal window will report the following and focus will advance to the next line:
Connection to <hostname> 5000 port [tcp/*] succeeded!
From here if you enter text, for example Hello, upon hitting return/enter you should then see the text on the first terminal window. And provided you see the text on the first terminal window connectivity has been successfully proved/established.
If the connection is not successful you may receive error messages similar to:
nc: getaddrinfo: Temporary failure in name resolution
nc: connection refused
If netcat is not installed one can run
` echo > ""/dev/tcp/<hostname/<port>"") >/dev/null 2>&1 && echo ""CAN CONNECT"" || echo ""CANNOT CONNECT"" `
replacing <hostname> with the hostname of the machine and <port> with the port you are trying to connect to. For example
` echo > ""/dev/tcp/production.neo4j.com/5001"") >/dev/null 2>&1 && echo ""CAN CONNECT"" || echo ""CANNOT CONNECT"" `
and if connection is possible you should then see CAN CONNECT and if not possible you would see CANNOT CONNECT
For the above to work this would require that <hostname> and <port> are open and in LISTEN status. This would normally be the case when Neo4j has been started
Was this page helpful?"
https://neo4j.com/developer/kb/connecting-bolt-when-using-tunnelling-or-nat;"Connecting via Bolt when using Tunnelling or NAT
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags bolt host url nat tunnel
This article aims to provide a method to connect to the Neo4j database over bolt, via Neo4j browser where the bolt host is different from the IP of the instance itself and, in cases where the bolt host IP/port is dynamic.
Unless dbms.connector.bolt.advertised_address=<server-name>:<port> is set, Neo4j browser uses the private IP of the instance as the bolt host IP, but e.g. when using an SSH tunnel to access a Neo4j instance, the client (e.g. Neo4j browser) uses a e.g. 127.0.0.1:port and changes a previously saved bolt host URL to use the instance IP instead, which wouldn’t connect.
One workaround is to specify dbms.connector.bolt.advertised_address=<server-name>:<port> in neo4j.conf (where <server-name>:<port> is the DNS name and port of the desired bolt host). However, if the host/port in certain environments, is custom each time, hard coding it with neo4j.conf via the above configuration, may not be useable where bolt should listen on the IP/port where it is mapped via the SSH tunnel. Some clients within the firewall may not use tunnelling, hence setting up tunnelling for every client, to match the hard coded address may not be desired.
In such cases, providing a custom dbms.connector.bolt.advertised_address=<server-name>:<port> at the neo4j browser landing/connection page, may not always honour that value e.g. at page refresh, the browser may forget the input bolt URL and overwrite it with the default advertised address.
To prevent the user-specified configuration from being overwritten, a connectUrl parameter can be passed along with the link to Neo4j Browser:
e.g. http://localhost:7474/browser/?connectURL=127.0.0.1:7687 or, e.g. http://browser.neo4j.com/?connectURL=neo4jdb.xxyyzz.com:26000.
If a hosted Neo4j Browser was available on http://browser.neo4j.com, it would set the bolt url to http://neo4jdb.xxyyzz.com:26000 and try to connect. The connectURL parameter may therefore be useful for use-cases as ones described above, where clients use tunnelling, network address translation, and other non-conventional access methods.
Was this page helpful?"
https://neo4j.com/developer/kb/configure-neo4j-operate-on-privileged-ports;"Configuring Neo4j to operate on privileged ports
Author David Fauth Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags server ports
In some environments, users are required to run Neo4j on ports lower than 1024 due to corporate policies. The following is a sample configuration showing how to configure Neo4j 3.5 and newer to listen on those ports.
Refer to a path/to/file.
Configure neo4j.conf to set the http, https and bolt ports.
On a debian installation it would look like this:
In the /etc/neo4j/pre-neo4j.sh file, configure this as follows:
Shell
Copy to Clipboard
# HTTPS
$ echo ""dbms_connector_https_enabled"" ""${dbms_connector_https_enabled:=true}""
$ echo ""dbms_connector_https_listen_address"" ""${dbms_connector_https_listen_address:=0.0.0.0:80}""

# HTTP
$ echo ""dbms_connector_http_enabled"" ""${dbms_connector_http_enabled:=false}""
$ echo ""dbms_connector_http_listen_address"" ""${dbms_connector_http_listen_address:=0.0.0.0:7474}""

# BOLT
$ echo ""dbms_connector_bolt_enabled"" ""${dbms_connector_bolt_enabled:=true}""
$ echo ""dbms_connector_bolt_listen_address"" ""${dbms_connector_bolt_listen_address:=0.0.0.0:8080}""
$ echo ""dbms_connector_bolt_tls_level"" ""${dbms_connector_bolt_tls_level:=REQUIRED}""
On a tar installation it would look like this:
Properties
Copy to Clipboard
# Bolt connector
dbms.connector.bolt.enabled=true
#dbms.connector.bolt.tls_level=OPTIONAL
dbms.connector.bolt.listen_address=:8080

# HTTP Connector. There can be zero or one HTTP connectors.
dbms.connector.http.enabled=false
#dbms.connector.http.listen_address=:7474

# HTTPS Connector. There can be zero or one HTTPS connectors.
dbms.connector.https.enabled=true
dbms.connector.https.listen_address=:80
Identify the location of the java installation.
Shell
Copy to Clipboard
$ readlink -f $(which java)
Bind the java executable to the privileged ports (use the path found in step 2).
Shell
Copy to Clipboard
$ sudo setcap cap_net_bind_service=+eip /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
Neo4j should start and allow access via https on port 80.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-export-cypher-favorites-recorded-in-the-browser;"How do I export Cypher Favorites recorded in the browser
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher browser
Cypher Favorites are common Cypher statements which one can save to the left panel of the Neo4j browser. A Favorite is created by entering the Cypher at the top prompt and then clicking the Favorite icon to the right as depicted:
After clicking on the Favorite Icon, the title of the Cypher statement (in this case 'my favorite Cypher') will be added to the left panel of the browser. For example:
These favorites are stored in local browser storage and as such are centric to the user/browser who has recorded those favorites. Additionally, if one clears their browser cache, recorded favorites will be removed.
To export favorites, use the Developer Console of Google Chrome and connect to the Neo4j browser URL.
Launch Google Chrome and connect to the Neo4j browser on http://localhost:7474
Access the Developer Console, https://developer.chrome.com/devtools/docs/console within Google Chrome
Use the keyboard shortcut Command+Option+J (Mac) or Control+Shift+J (Windows/Linux).
Enter the following in the Developer Console and hit return:
JavaScript
Copy to Clipboard
var res = JSON.parse(localStorage.getItem('neo4j.documents'))
for (x in res) {
  console.log(res[x]['content'])
}
Your output should be similar to the following, which lists the statements to recreate your Favorites
Was this page helpful?"
https://neo4j.com/developer/kb/why-do-my-deleted-property-keys-appear;"Why do my deleted property keys appear?
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags properties browser
When using the Neo4j Browser and selecting the left frame and top icon entitled Database Information or using the built in stored procedure db.propertyKeys() you may see property keys which are no longer associated with any nodes. This is expected. For example, using the Neo4j Browser and connecting to an empty graph, if one then runs :play movies one can populate the graph with a sample dataset. After the graph is populated if one then runs match (n) detach delete n; this will remove all nodes/relationships from the graph.
However both the Browser and the stored procedure will display the property keys from the movie graph, regardless if they are associated with any nodes, for example
Unlike labels and relationship types which have underlying meta-data that report the number of objects for each, there is no meta-data for property keys.
If you need to remove the property keys your options are either
recreate the graph
or
use https://github.com/jexp/store-utils which is an offline process to read a graph.db and copy its (contents, nodes, relationships) to a new graph.db and only include propertyKeys associated with nodes
Was this page helpful?"
https://neo4j.com/developer/kb/all-shortest-paths-between-set-of-nodes;"All shortest paths between a set of nodes
Author Michael Hunger Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher path unwind shortest-path
Consider a number of arbitrary nodes, A,B,C,D,E,F,…..
I wish to return all of the shortest paths between these nodes. The nodes may have many edges between them, but anticipate a maximum of 4. The graph is complex and non hierarchical (if this makes sense - any node may point to any other node). A typical node has the form: match (n:Entity { name: 'xyz' })
How would I write the match expression to return the shortest paths between the above nodes, in no specific order?
Solution
Find the set of nodes using an indexed lookup operation
Collect them into a list
Unwind the list twice, once for every side of the path
Remove inverse pairs by id comparison
match and return the paths
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Entity) where n.name IN {names}
WITH collect(n) as nodes
UNWIND nodes as n
UNWIND nodes as m
WITH * WHERE id(n) < id(m)
MATCH path = allShortestPaths( (n)-[*..4]-(m) )
RETURN path
Was this page helpful?"
https://neo4j.com/developer/kb/alternatives-to-union-queries;"Alternatives to UNION queries
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher union path
While UNIONs can be useful for certain cases, they can often be avoided completely with small changes to the query.
In this article we’ll present various example cases where a UNION isn’t necessary, and a simple Cypher query will do.
Starting node + all others through a common node
There are cases where you want all nodes connected to a common node in some way, including the starting node, and all of these nodes are connected by the same pattern.
A prototypical case is, for a given actor, to get all of the actors of movies they’ve worked on, including the starting actor.
A first attempt may look something like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(movie:Movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
Since Cypher only allows a single traversal of a relationship in each matched path, this won’t return Keanu Reeves as a coactor. The :ACTED_IN relationship used to match to the movie node can’t be traversed back again when finding coactors.
This can be addressed with a UNION:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(movie:Movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
UNION
MATCH (p:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(movie:Movie)
RETURN movie, p as coactor
This allows Keanu Reeves to show up in the results as desired. However this is more complicated than it needs to be, and we can’t continue processing the unioned result, if that’s something we need later.
Instead of using UNION for this, we can instead match to the central node, then make an additional MATCH out to the coactors:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(movie:Movie)
MATCH (movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
By using a second MATCH, we’ve broken up the paths used, so there’s no longer any restriction for the :ACTED_IN relationships when we match back out to coactors for a movie. The relationship to Keanu Reeves is treated as any other relationship from the MATCH, and Keanu Reeves appears in the results.
Optional connections
For some queries we may want the results from two similar patterns, but there may be some extra traversals on one that aren’t present in the other.
For example, building on the previous query for coactors of Keanu Reeves, maybe we want to find coactors not just through the movies Keanu Reeves has acted in, but similar movies.
We could do this through a UNION query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(movie:Movie)
MATCH (movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
UNION
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(:Movie)-[:SIMILAR]-(movie:Movie)
MATCH (movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
However the two match patterns are similar enough that we can actually get the results we want without UNION.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person {name:'Keanu Reeves'})-[:ACTED_IN]->(:Movie)-[:SIMILAR*0..1]-(movie:Movie)
MATCH (movie)<-[:ACTED_IN]-(coactor)
RETURN movie, coactor
We are using a variable-length relationship for :SIMILAR with a lower bound of 0.
This means that the two connected nodes in the pattern may be the same node, with no actual relationship between them.
This will allow movie to match both to the movies Keanu Reeves acted in, as well as any :SIMILAR movies if such a relationship exists.
This [*0..1] trick basically represents an optional connection, and can be used when we want both a node and a connected node to be treated the same way (and represented by the same variable, if needed) in the pattern.
Optional connections to get the right node
In the above example our optional connection was between :Movie nodes, allowing us to get nodes connected to both the starting node, and an adjacent node.
We can also use this approach when it’s possible the initial node isn’t the one we want, but an adjacent node that might possibly be beyond it.
Consider a social graph where people can recommend many things, including :Books, :Movies, :Games, and more:
Cypher
Copy to Clipboard
Run in Neo4j Browser
(:Person)-[:FRIENDS_WITH]->(:Person)
(:Person)-[:RECOMMENDS]->(:Movie)
(:Person)-[:RECOMMENDS]->(:Book)
(:Person)-[:RECOMMENDS]->(:Game)
(:Movie)-[:BASED_ON]->(:Book)
(:Movie)-[:BASED_ON]->(:Game)
(:Game)-[:BASED_ON]->(:Movie)
(:Game)-[:BASED_ON]->(:Book)
(:Book)-[:BASED_ON]->(:Game)
(:Book)-[:BASED_ON]->(:Movie)
If we want to return movie recommendations from friends, it’s easy enough just to return :Movie nodes recommended by a friend.
But if we also want to return movies associated with non-movie recommendations (such as movies based on recommended books or other media), then the query is a little more complicated.
We can do this with a UNION:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:Person {name:'Keanu Reeves'})-[:FRIENDS_WITH]-(friend)-[:RECOMMENDS]->(movie:Movie)
RETURN friend, movie
UNION
MATCH (me:Person {name:'Keanu Reeves'})-[:FRIENDS_WITH]-(friend)-[:RECOMMENDS]->()-[:BASED_ON]->(movie:Movie)
RETURN friend, movie
A better approach is to forgo the UNION and use an optional connection:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:Person {name:'Keanu Reeves'})-[:FRIENDS_WITH]-(friend)-[:RECOMMENDS]->()-[:BASED_ON*0..1]->(movie:Movie)
RETURN friend, movie
If the recommended item is a :Movie, it will be included, and if it’s something that a :Movie was based on, that movie will also be included.
If we also wanted to get movies anywhere in a :BASED_ON chain (for example, for recommended books based on a games based on movies) we could omit the upper bound of the relationship:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:Person {name:'Keanu Reeves'})-[:FRIENDS_WITH]-(friend)-[:RECOMMENDS]->()-[:BASED_ON*0..]->(movie:Movie)
RETURN friend, movie
Was this page helpful?"
https://neo4j.com/developer/kb/post-union-processing;"Post-UNION processing
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher union
Cypher does not allow further processing of UNION or UNION ALL results, since RETURN is required in all queries of the union.
Here are some workarounds.
Post-UNION processing in Neo4j 4.0
With Neo4j 4.0, post-UNION processing is now possible via subqueries.
An example of usage:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
  MATCH (movieOrPerson:Movie) RETURN movieOrPerson
  UNION
  MATCH (movieOrPerson:Person) RETURN movieOrPerson
}
WITH movieOrPerson
...
This allows us to keep working with the results of the UNION subquery.
However, with the initial 4.0 release only uncorrelated subqueries are supported, meaning the subquery cannot use variables from outside the call. This means that using a subquery for post-UNION processing in the middle of a more complex query may not be possible, as you cannot pass in variables from the outer query for use within the subquery.
In 4.0.x, correlated subqueries, which are more useful and can use variables from outside the subquery, are currently only available when using Neo4j Fabric.
Post-UNION processing enhancements in 4.1+
With the release of 4.1, the CALL subquery functionality has been enhanced to allow correlated subqueries. This lets us use existing variables mid-query within the subquery.
This requires the use of WITH as the first clause within the subquery CALL block, for the purpose of importing variables to the subquery.
When using UNION or UNION ALL, we can provide a similar importing WITH clause for each of the unioned queries:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie {title:'The Matrix'})
CALL {
    WITH m
    MATCH (m)<-[:ACTED_IN]-(p)
    RETURN p
    UNION
    WITH m
    MATCH (m)<-[:DIRECTED]-(p)
    RETURN p
}
RETURN p.name as name
ORDER BY name ASC
This will correctly return the alphabetically-sorted names of all actors and directors for The Matrix.
This import usage has some special restrictions that do not normally apply to WITH usage:
You may only include variables from the outer query and no others. + You cannot perform calculations, aggregations, or introduction of new variables in the initial WITH.
You cannot alias any variables within this initial WITH.
You cannot follow the initial WITH with a WHERE clause for filtering.
If you try any of these, you will be met with some kind of error, such as:
Importing WITH should consist only of simple references to outside variables. Aliasing or expressions are not supported.
or more cryptically, if you try to use a WHERE clause after the initial WITH
Variable `x` not defined
(where the variable is the first one present in the WITH clause)
You can get around all of these restrictions by simply introducing an additional WITH clause after the importing WITH, like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
WHERE m.title CONTAINS 'Matrix'
CALL {
    WITH m
    WITH m as movie
    MATCH (m)<-[:DIRECTED]-(p)
    RETURN p.name as name
    UNION
    WITH m
    WITH m
    WHERE m.title CONTAINS 'Reloaded'
    MATCH (m)<-[:ACTED_IN]-(p)
    RETURN p.name as name
}
RETURN DISTINCT name
ORDER BY name ASC
This demonstrates both the ability to alias the imported variable as well as to filter the imported variable provided we use a second WITH clause, which is not restricted in the same way as the initial WITH used for the import into the subquery.
For 3.5.x and earlier
For earlier versions, native subqueries are not available, so other workarounds must be used.
Combine collections, then UNWIND back to rows and apply DISTINCT
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
WITH collect(m) AS movies
MATCH (p:Person)
WITH movies + collect(p) AS moviesAndPeople
UNWIND moviesAndPeople AS movieOrPerson
WITH DISTINCT movieOrPerson
...
DISTINCT isn’t really needed in the above query, but it will be needed if it’s possible for a result to be present in multiple collections being combined, provided you want distinct values.
Use apoc.cypher.run() to return UNION results from a subquery
Using APOC Procedures, you can use apoc.cypher.run() to execute a UNION within a subquery, and return its results.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.run('
 MATCH (movieOrPerson:Movie)
 RETURN movieOrPerson
 UNION
 MATCH (movieOrPerson:Person)
 RETURN movieOrPerson',
 {}) yield value
WITH value.movieOrPerson as movieOrPerson
...
Remember that procedure calls are executed per-row, so using this approach when multiple rows already exist may lead to unintended and unexpected results.
Was this page helpful?"
https://neo4j.com/developer/kb/achieving-longestpath-using-cypher;"Achieving longestPath Using Cypher
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher path apoc
While Cypher is optimized for finding the shortest path between two nodes, with such functionality as shortestPath(), it does not have the same sort of function for longest path. In some cases, you may want this, and not the shortest route.
Root to leaf in a tree
If you had a tree structure you wanted to do the longest path between a root node and a leaf node, and you don’t know how many there are in between:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(parent:Root)-[r:HAS_CHILD*1..10]->(child:Node)
RETURN p
The problem with this is that it will give you all paths, one for each hop, until you get to the leaf node. What you want is just the longest path to see how the parent and leaf child are connected. To do this efficiently, do the following:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(parent:Root)-[:HAS_CHILD*1..10]->(child:Node)
WHERE NOT (child)-[:HAS_CHILD]->()
RETURN p
What the above query is doing: The variable length 1..10 will find all paths (there should be only one), for any Parent-Child path that spans at most 10 hops. The WHERE clause is needed to filter the paths to only those where the leaf child nodes have no outgoing :HAS_CHILD relationships (i.e. it finds the end of the chain).
Longest path when there are multiple paths present
If not using an acyclic tree structure, you may have several paths between two nodes, and you may want to get just the longest. We can do this by ordering by path length and only taking the longest path:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH p=(start:Node)-[:REL*1..10]->(end:Node)
WHERE id(start) = 123 AND id(end) = 456
RETURN p
ORDER BY length(p) DESC
LIMIT 1
Tips for making these queries more efficient
With a fairly well connected graph, variable-length path queries like this may get increasingly expensive. Here are some tips to keep these performant.
Constrain relationship type and direction - If possible, use only the relevant types needed, and use a directed relationship. This may cut down on the paths followed during expansion.
Supply an upper bound for the variable-length pattern - Patterns without bounds may get out of hand in a well connected graph. Setting an upper bound can help constrain the work the query needs to perform.
Use all() or none() in the WHERE clause following the MATCH - If predicates need to be evaluated during expansion, and they must apply to all nodes or relationships in the path, use all() or none() on the nodes or relationships from the path to evaluate during expansion rather than filtering after all paths are found.
Use APOC path expanders for special cases or restrictions - For certain restrictions, such as not repeating nodes during expansion, you may want to use path expander procs from APOC Procedures to enforce different configurations of uniqueness during expansion.
Was this page helpful?"
https://neo4j.com/developer/kb/comparing-relationship-properties-within-a-path;"Comparing relationship properties within a path
Author Michael Hunger Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher path relationships properties
You want to compare relationship-properties of a path, either by a global value or parameter, or with each other within a path.
Cypher
Basic model:
Copy to Clipboard
Run in Neo4j Browser
(:Person {person_id:'123'})-[:FRIEND {date:'1972-01-01'}]->(m:Person {person_id:'456'})
Make sure to have an constraint OR index on your nodes:
Cypher
Constraint
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT ON (p:Person) ASSERT p.person_id IS UNIQUE
Cypher
Index
Copy to Clipboard
Run in Neo4j Browser
CREATE INDEX ON :Person(person_id);
If you have your time in yyyy-mm-dd you can compare them directly: (with 2 digits aka 01) i.e. '2012-01-10' > '2011-08-31' )
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH '1962-01-01' AS maxdate
MATCH (n:Person)-[f1:FRIEND]-()-[f2:FRIEND]-(m:Person)
WHERE n.person_id='180' AND f1.date < maxdate AND f2.date < maxdate
RETURN m;
You can also use the short form: (n:Person {person_id:'180'}):
If you want to have a general expression on relationships in a path, use a variable rels (which is then a collection) within your variable-length-path pattern:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH '1962-01-01' AS maxdate
MATCH (n:Person {person_id:'180'})-[rels:FRIEND*2]-(m:Person)
WHERE ALL(r IN rels WHERE r.date < maxdate)
RETURN m;
You can also use rels(path) function.
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH '1962-01-01' AS maxdate
MATCH path = (n:Person {person_id:'180'})-[:FRIEND*2]-(m:Person)
WHERE ALL(r in rels(path) WHERE r.date < maxdate)
RETURN m;
Or if the relationships of a path are in relation to each other:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH '1962-01-01' AS maxdate
MATCH (n:Person  {person_id:'180'})-[rels:FRIEND*2]-(m:Person)
WHERE ALL(idx in range(0, size(rels)-2) WHERE (rels[idx]).date < maxdate AND (rels[idx]).date < (rels[idx+1]).date)
RETURN m;
Original question was on StackOverflow
Was this page helpful?"
https://neo4j.com/developer/kb/a-lightweight-approach-to-testing-the-neo4j-rest-api-with-authentication;"A lightweight approach to testing the Neo4j REST API with Authentication
Author Dana Canzano Applicable versions 3.5 Tags http authentication rest security
This article will show examples of how to test the Neo4j REST API for authentication via:
Google Chrome Advanced REST Client
Linux curl command
The Neo4j REST API describes each of the commands you can submit to the Neo4j server. The example below describes how to authenticate with the Neo4j server when authentication is enabled. To enable authentication, use parameter dbms.security.auth_enabled=true defined in the conf/neo4j-server.properties configuration file.
Google Chrome Advanced REST Client
After installing and launching the Google Chrome Advanced REST Client application, your browser should appear as follows:
For the field labeled URL, this should be replaced with the URL to the Neo4j server, for example, http://localhost:7474/user/neo4j.
For your instance, localhost may be an actual IP address, for example, http://192.168.1.106:7474/user/neo4j.
Per the documentation, /user/neo4j is the URI to which authentication occurs. Additionally, the HTTP method should be defined as GET.
Upon clicking the Form tab, you can define the payload for the REST request. Define the Name field as Authorization. Click the value field and you should see a CONSTRUCT pop-up, for example:
Clicking CONSTRUCT will then allow you to define the payload for this request. Specifically, we need to define the username/password, for example, neo4j/mypassword.
Clicking OK should then return you back to a display similar to:
Finally, clicking SEND will submit the request. You should see output similar to the following:
The output above including Status: 200 OK indicates the request was properly processed. A status of 4xx would be indicative of a failure. Further, the Response field details the JSON output provided by the REST API for the given command.
Linux curl command
On a single line (command line) issue the following command at the linux prompt:
Shell
Copy to Clipboard
$ curl -H accept:application/json -H content-type:application/json -H Authorization:""Basic bmVvNGo6cGFzc3dvcmQ="" http://192.168.1.106:7474/user/neo4j
Expected output:
Json
Copy to Clipboard
{
 ""password_change_required"" : false,
 ""password_change"" : ""http://192.168.1.106:7474/user/neo4j/password"",
 ""username"" : ""neo4j""
}
In the above example you may need to change the value of the IP address referenced in the http specification (i.e. http://192.168.1.106:7474/user/neo4j). Additionally, you will need to change the base64 encrypted value of the password (i.e. Basic bmVvNGo6cGFzc3dvcmQ=). To encrypt a string to base64 you can run:
Shell
Copy to Clipboard
$ echo -n 'neo4j:mypassword' | base64
Replace mypassword above with the actual password.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-allow-for-authentication-using-active-directory-attribute-samaccountname;"How do I allow for authentication using Active Directory attribute samAccountName
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags samaccountname account authentication authorization
Commencing with Neo4j 3.2.2, it is now possible to authenticate using Active Directory attribute samAccountName as opposed to the LDAP Display Name attribute. The following conf/neo4j.conf parameters must be enabled to use samAccountName.
Properties
Copy to Clipboard
dbms.security.auth_enabled=true
dbms.security.auth_provider=ldap
dbms.security.ldap.authentication.use_samaccountname=true

dbms.security.ldap.host=<the LDAP hostname>
dbms.security.ldap.authorization.use_system_account=true
dbms.security.ldap.authorization.system_username=cn=Administrator,cn=Users,dc=example,dc=com
dbms.security.ldap.authorization.system_password=<password for the Administrator>

dbms.security.ldap.authorization.user_search_base=cn=Users,dc=example,dc=com
dbms.security.ldap.authorization.user_search_filter=(&(objectClass=*)(samaccountname={0}))
dbms.security.ldap.authorization.user_search_base=cn=Users,dc=example,dc=com

dbms.security.ldap.authorization.group_to_role_mapping=\
""cn=Neo4j Read Only,cn=Users,dc=example,dc=com"" = reader ;\
""cn=Neo4j Read-Write,cn=Users,dc=example,dc=com"" = publisher ;\
""cn=Neo4j Schema Manager,cn=Users,dc=example,dc=com"" = architect ;\
""cn=Neo4j Administrator,cn=Users,dc=example,dc=com"" = admin ;\
""cn=Neo4j Procedures,cn=Users,dc=example,dc=com"" = allowed_role
View all (4 more lines)
With the following AD setup we can demonstrate successful authenication
Upon doing so connection is possible, as evidence
$ ./cypher-shell
username: neouser
password: ********
Connected to Neo4j 3.2.2 at bolt://localhost:7687 as user neouser.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j> create (n:Person {id:1});
0 rows available after 231 ms, consumed after another 1 ms
Added 1 nodes, Set 1 properties, Added 1 labels
neo4j> match (n:Person {id:1}) return n;
+-------------------+
| n                 |
+-------------------+
| (:Person {id: 1}) |
+-------------------+

1 row available after 106 ms, consumed after another 8 ms
Was this page helpful?"
https://neo4j.com/developer/kb/configure-neo4j-multiple-ous-using-active-directory-attribute-samaccountname;"Configure Neo4j to authenticate users from different OUs using the Active Directory attribute samAccountName
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags samaccountname account authentication authorization
Beginning with Neo4j version 3.2.2, it is possible to authenticate using the Active Directory attribute samAccountName as opposed to the LDAP Display Name attribute. This is described in detail in the following KB article: How do I allow for authentication using Active Directory attribute samAccountName
However, when you need to authenticate and authorize users who are defined under different OUs, and cannot define a System Account in the Neo4j configuration file, a slightly different configuration is needed. This is specific to Active Directory, and requires logging in with the samAccountName attribute (which we have found to be the common case).
The following conf/neo4j.conf parameters must be set to use samAccountName and support authenticating users from multiple OUs:
Properties
Copy to Clipboard
dbms.security.auth_enabled=true
dbms.security.auth_provider=ldap
dbms.security.ldap.host=<the LDAP hostname>

dbms.security.ldap.authentication.user_dn_template={0}@example.com
dbms.security.ldap.authorization.user_search_base=dc=example,dc=com
dbms.security.ldap.authorization.user_search_filter=(&(objectClass=user)(sAMAccountName={0}))

dbms.security.ldap.authorization.group_membership_attributes=memberOf
dbms.security.ldap.authorization.group_to_role_mapping=\
""cn=Neo4j Read Only,cn=Users,dc=example,dc=com"" = reader ;\
""cn=Neo4j Read-Write,cn=Users,dc=example,dc=com"" = publisher ;\
""cn=Neo4j Schema Manager,cn=Users,dc=example,dc=com"" = architect ;\
""cn=Neo4j Administrator,cn=Users,dc=example,dc=com"" = admin ;\
""cn=Neo4j Procedures,cn=Users,dc=example,dc=com"" = allowed_role
Key points:
The main difference that allows this to work is specifying the {0}@example.com pattern in the user_dn_template. This allows the authentication to start at the root Domain, and check the whole tree, regardless of where the User is located within it.
Notice you should NOT set dbms.security.ldap.authentication.use_samaccountname. It will not work properly.
With the following AD setup we successfully authenicate both users Admin User and Support User. They would login with adminuser and supportuser1 respectively:
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-authenticate-with-cypher-shell-without-specifying-the-username-and-password-on-the-command-line;"How do I authenticate with cypher-shell without specifying the username and password on the command line
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher-shell authentication
When using $NEO4J_HOME/bin/cypher-shell at the command line and authentication is enabled via the setting $NEO4J_HOME/conf/neo4j.conf:
Properties
Copy to Clipboard
# Whether requests to Neo4j are authenticated.
# To disable authentication, uncomment this line
dbms.security.auth_enabled=true
a username and password can be provided on the command line using the parameters -u <username> -p <password>. However, one can also define environment variables NEO4J_USERNAME and NEO4J_PASSWORD, for example:
Bash
Copy to Clipboard
export NEO4J_USERNAME='neo4j'
export NEO4J_PASSWORD='password'
Once the environment variables are defined one can now run $NEO4J_HOME/bin/cypher-shell and not specify the -u and -p on the command line. This has the added benefit that when running the linux 'history' command, which shows the last N command line invocations, the username and password will not be exposed.
Further if using linux, the export commands above could be placed in the user’s home directory in their .bashrc file (for example /home/neo4j/.bashrc) and for which the .bashrc is invoked upon initial login.
If using Windows, environment variables can be defined via Control Panel → System, Advanced tab, [Environment Variables] as pictured below:
Was this page helpful?"
https://neo4j.com/developer/kb/comparing-ha-vs-causal-clusters;"Comparing HA and Causal Clusters
Author Ali Maddahian Applicable versions 3.5 4.0 Tags ha cluster bolt http https load balancer
The legacy HA cluster mode has been deprecated as of Neo4j version 3.5, and will be totally removed from the product in version 4.0, with 4.0 expected to be released near the end of 2019.
Additionally, per Neo4j support terms, Neo4j supports patching a release for 18 months after it is released.
This means, although customers could use the HA functionality in the latest 3.5.x release, going forward, there will be no new feature release offering for the HA component as all development efforts are targeted for Causal Cluster. Causal Clustering has been around for nearly 3 years and is used by hundreds of customers in production.
As such, all new cluster implementations and existing HA implementations should proceed with using/migrating to Causal Cluster when possible.
For a high level comparative view of HA Clusters vs Causal Clusters, the table below provides a summary of differences:
Causal Cluster
High Availability (HA) Cluster
Raft Protocol
Paxos Protocol
Min of 3 instances
Min of 1 instance + optional Arbiter(s)
Set of Cores (3, 5 or 7) + ReadReplicas
Master(1) + Slave(0 or more)
Transactions are committed once a majority of the Core servers in the cluster (2N+1) have accepted the transaction
Transactions are committed on Master first and pushed optimistically to Slaves (doesn’t guarantee commits on slaves)
No branching
Can lead to branching (https://neo4j.com/docs/operations-manual/current/ha-cluster/architecture/#_branching)
Built-in load balancing and routing via Bolt Driver (The driver maintains routing table for all Core leader, followers, and Read Replicas)
Need an extra layer of load balancer
Intra-cluster Encryption
None
Multi-clustering
None
Multi-DC
None
One of the biggest differences is relative to the extra layer of protection that Causal Clustering provides in ensuring there will be zero chance for branching and/or data corruption, which HA is vulnerable to due to its underlying architecture.
Another point of interest is the ""bolt+routing"" feature in Causal Clusters which provides built-in automatic load balancing for applications connecting to the cluster, thus eliminating the need for any extra layer of load balancing which is typically required with HA clusters, resulting in a simpler and more robust overall architecture.
When migrating from older Neo4j implementations utilizing HA clusters, please also note that the REST api ( https://neo4j.com/docs/rest-docs/current) has also been deprecated as of Neo4j 3.4, and will be removed in Neo4j 4.0. It is therefore recommended to use Cypher or procedures instead, either via Bolt (Bolt+routing) using the official drivers or the HTTP API.
When deciding on choices of client layers such as HTTP(s) api vs Bolt, it should be noted that Bolt not only offers official drivers for Python, Java, Javascript, .Net, and Go, but the Browser and other tools (such as cypher-shell or Neo4j Bloom) also use Bolt exclusively for connecting to the database.
As an additional security consideration, Bolt can use TLS and can configure encryption on the client and use server side certificates.
Here are few articles that provide additional insight on the topic of bolt vs http vs causal clustering.
https://medium.com/neo4j/querying-neo4j-clusters-7d6fde75b5b4
https://neo4j.com/docs/drivers-apis/
https://neo4j.com/developer/language-guides/
https://dzone.com/articles/a-deeper-dive-into-neo4j-30-language-drivers
That said, for existing HA applications, customers can migrate from HA to Causal Cluster with a simple backup/restore and minor configuration changes as an inital step, and any re-architecting of the application layer around load balancing and/or choice of bolt vs HTTP can be addressed at a later time.
For a comprehensive listing of all new features introduced for every 3.x release, please refer to the table below:
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-how-merge-works;"Understanding how MERGE works
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 5 Tags merge cypher
What is MERGE, and how does it work?
The MERGE clause ensures that a pattern exists in the graph. Either the entire pattern already exists, or the entire pattern needs to be created.
In this way, it’s helpful to think of MERGE as attempting a MATCH on the pattern, and if no match is found, a CREATE of the pattern.
When the specified pattern is not present and needs to be created, any variables previously bound to existing graph elements will be reused in the pattern. All other elements of the pattern will be created.
It’s important to know which pattern elements will use existing graph elements and which will be created instead.
For the following examples, we’ll use a very simplistic graph of :Student, :Class, :ReportCard, and :Term nodes as follows.
Cypher
Copy to Clipboard
Run in Neo4j Browser
(:Student)-[:ENROLLED_IN]->(:Class)
(:Student)-[:EARNED]->(:ReportCard)
(:Class)-[:FOR_TERM]->(:Term)
There will be references to ""bound variables"" in this article, and this refers to variables that have been bound to existing elements in the graph from earlier clauses (usually MATCH or MERGE) that are being reused in a MERGE pattern. This means that in the MERGE pattern, it refers to an element that was previously found and currently exists in the graph.
In contrast, a ""new variable"" in a pattern refers to a variable that is being introduced for the first time in the pattern. As such, it does not yet refer to any elements currently in the graph, but as a result of the MERGE (matching to existing elements or creating new ones) it will become bound to graph elements.
Any element in the pattern that isn’t associated with a bound variable (and this includes both elements using new variables, as well as elements without variables at all) will result in new created elements in the graph if the MERGE has to create the entire pattern.
A MERGE without bound variables can create duplicate elements
The most common MERGE mistake is attempting to MERGE a pattern with no bound variables when you want to use existing graph elements.
For example, attempting to enroll an existing student in an existing class.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (student:Student{id:123})-[:ENROLLED_IN]->(class:Class{name:'Cypher101'})
In the above query, student and class are new variables, they haven’t been previously bound to any nodes in the graph, this is their first use in the query.
If the entire pattern already exists (the given student is already enrolled in the given class), the variables will be bound to the existing nodes in the graph as expected.
However, if the pattern doesn’t already exist, all new elements of the pattern will be created. In this case, all of them; a new :Student node will be created with the given id, and a new :Class node will be created with the given name, and a new :ENROLLED_IN relationship will be created between these brand new nodes.
This may result in the creation of duplicate nodes, if such a student already exists, or such a class already exists. If there is a unique constraint for the student or class nodes for the given properties, then an error will be thrown. Otherwise, the duplicate nodes will be created, which might escape notice, especially for novice users.
A MERGE with bound variables reuses existing graph elements
To use the existing nodes and relationships in the graph, MATCH or MERGE on the nodes or relationships first, and then MERGE in the pattern using the bound variables.
A correct version of the enrollment query from above will MATCH on the student and class first, and then MERGE the relationship.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MATCH (class:Class{name:'Cypher101'})
MERGE (student)-[:ENROLLED_IN]->(class)
Similarly, you could MERGE on the student and class prior to the MERGE on the relationship between them.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (student:Student{id:123})
MERGE (class:Class{name:'Cypher101'})
MERGE (student)-[:ENROLLED_IN]->(class)
This ensures that the student and class nodes exist (they will be created if they don’t exist already), and then the relationship is merged between them.
MERGE using combinations of bound and new elements for different use cases
While the above approach is correct for that particular use case, it’s not the right approach for all use cases. We may need to use combinations of bound and new elements in the MERGE for correct behavior.
Consider a query creating report cards for students.
If we reused the above approach, the query may look like this.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MERGE (reportCard:ReportCard{term:'Spring2017'})
MERGE (student)-[:EARNED]->(reportCard)
The problem in this query is that the same :ReportCard node is being reused for all students. If the query also needed to add grades to the :ReportCard, each subsequent entry would overwrite what was added before. If not caught, this approach would end up with all students having the exact same report card node, and thus the exact same grades, the grades entered by the last student processed.
What we really need is a separate :ReportCard per student. We can achieve this by binding the :Student node, but not the :ReportCard node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MERGE (student)-[:EARNED]->(reportCard:ReportCard{term:'Spring2017'})
Since the student variable is bound to a node, that node will be used if the pattern needs to be created, and the :ReportCard will be created just for this student, not shared among all students.
Note that we get the exact same behavior if we omit the reportCard variable entirely, since an element without a variable and an element with a newly-introduced variable are handled the exact same way, when the pattern needs to be created:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MERGE (student)-[:EARNED]->(:ReportCard{term:'Spring2017'})
Remember new relationships will be created too
The above examples should be easy to understand for nodes, but remember they apply to relationships too. New relationships in a pattern will be created if the entire pattern doesn’t exist. It’s easiest to see this in action when we use a larger pattern.
Consider if we needed to enroll a :Student in a :Class for a specific :Term. Let us assume the student, term, and class exist in the graph already.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MATCH (spring:Term{name:'Spring2017'})
MATCH (class:Class{name:'Cypher101'})
MERGE (student)-[:ENROLLED_IN]->(class)-[:FOR_TERM]->(spring)
This may look correct, and may behave correctly when neither of those relationships exist ahead of time, but if there is any imbalance here where only half of the pattern exists, then this will end up creating duplicate elements. This would be most apparent if the query was run for multiple students, instead of just one.
On the first run, for the first student, the relationships would be created as expected.
On the next run, for the next student, there is a :FOR_TERM relationship between the class and the term, but the student isn’t enrolled in the class. Since the entire pattern doesn’t exist, the entire pattern will be created (excluding bound nodes), so the student will be enrolled in the class, and new (duplicate) :FOR_TERM relationship will be created between the class and the term.
If the query was run 30 times to enroll 30 students for the same class and term, there would be 30 :FOR_TERM relationships between the class and the term by the time we finished.
To fix this, if it’s known that the :FOR_TERM relationship already exists between each :Class and its :Term, then move that part of the pattern into the MATCH.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MATCH (class:Class{name:'Cypher101'})-[:FOR_TERM]->(spring:Term{name:'Spring2017'})
MERGE (student)-[:ENROLLED_IN]->(class)
If we don’t know if the :FOR_TERM relationship exists already, then we would have to break this down further, MATCHing on the student, class, and term, then doing the MERGE for :FOR_TERM, then the MERGE for :ENROLLED_IN.
The takeaway here is that the MERGE of longer patterns should generally be avoided. If parts of the pattern exist but not the entire pattern, you will likely see duplicates, so consider breaking down the MERGE of larger patterns into separate MERGEs on smaller patterns.
Use ON MERGE and ON CREATE after MERGE to SET properties according to MERGE behavior
Often after a MERGE we need to SET properties on elements of the pattern, but we may want to conditionally set these properties depending on if MERGE matched to an existing pattern, or had to create it. For example, if we have default property values we want to set on creation.
The ON MERGE and ON CREATE clauses give us the control we need. This also makes it possible to re-run queries and ensure we aren’t overriding existing properties with defaults.
Here’s an example when setting student report cards and grades, assuming {grades} is a map parameter of grades we want to set when creating a new :ReportCard node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (student:Student{id:123})
MERGE (student)-[:EARNED]->(reportCard:ReportCard{term:'Spring2017'})
ON CREATE SET reportCard += {grades}
MERGE acquires locks on nodes and relationships in the pattern when resulting in pattern creation
When MERGE fails to find an existing pattern, it will acquire locks on all bound nodes and relationships in the pattern before creating the missing elements of the pattern.
This is to ensure a MERGE or CREATE can’t concurrently create the pattern (or alter the properties of an existing pattern to make it identical to the desired pattern) while the MERGE is executing, which would cause pattern duplication.
After locking on bound elements, MERGE performs another MATCH on the pattern to avoid race conditions where the pattern might get created in the time gap between when MERGE determined the pattern doesn’t exist, and when locks were acquired.
MERGE on a single node pattern may create duplicates unless there is a unique constraint
When performing MERGE on a single-node pattern when the node does not yet exist (and there is no unique constraint), there is nothing to lock on to avoid race conditions, so concurrent transactions may result in duplicate nodes.
For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (student:Student{id:123})
If there is no unique constraint, then concurrent executions of this query (or any other query that may be doing a MERGE or CREATE involving a :Student node with this id) may result in multiple nodes for the same student.
By adding a unique constraint on :Student(id), schema locks will ensure that the student nodes are unique, and no duplicates will occur.
MERGE on a larger pattern not using bound nodes may also create duplicates
In the above case of a single node (when the node doesn’t yet exist), we don’t have any bound nodes to use for locking. Similarly, if the MERGE is on a pattern larger than a single node, where the entire pattern doesn’t exist, and no bound nodes are used in the pattern, there is nothing to lock on to avoid race conditions, so it faces the same risk of duplication with concurrent writes.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (class:Class{name:'Cypher101'})-[:FOR_TERM]->(spring:Term{name:'Spring2017'})
Note for Neo4j < 3.0.9 for 3.0.x versions, and < 3.1.2 for 3.1.x versions
A bug in the cost planner for affected versions prevented double-checked locking on MERGE. This allowed race conditions which could result in duplicate patterns being created by concurrent MERGE operations, or other write operation which caused the previously non-existent pattern to exist.
We recommend upgrading to a version which includes this bug fix.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-cannot-merge-node-using-null-property-value;"Explanation of error ""Cannot merge node using null property value for""
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher merge
When running a MERGE, which is a combination of MATCH and/or CREATE one may encounter an error of Cannot merge node using null property value for if the MERGE is performing a MATCH against a null property. For example, when using the following input file, test.csv
Csv
Copy to Clipboard
id,name,employee_number
101,Emil Eifrem, Neo001
102,Mary Smith, Neo002
,Joseph Wilson-contractor, Neo003
and such that the 3rd value in the CSV has a NULL id property, if one runs
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv with headers from 'file:///test.csv' as row
merge (emp:Employee {id: row.id}) set emp.name=row.name, emp.employee_numer=row.employee_number;
this will error with
Cannot merge node using null property value for id
One can avoid this error by rerunning the cypher statement as
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv with headers from 'file:///test.csv' as row  with row where row.id is not null
merge (emp:Employee {id: row.id}) set emp.name=row.name, emp.employee_numer=row.employee_number;
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-use-load-csv-to-update-set-properties-of-existing-nodes;"How do I use LOAD CSV to update/set properties of existing nodes
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher import merge
One can use LOAD CSV to perform a bulk update to existing nodes, and create new nodes, as follows.
If we have a .csv called Movies.csv and its content is:
Csv
Copy to Clipboard
code,wysiwyg-indent3
code,wysiwyg-indent3
101,The Matrix,463420706
102,The Matrix Reloaded,738576929
103,The Matrix Revolutions,427289109
104,A Few Good Men,24234017
and the current graph includes nodes with a label Movie for the 1st three movies listed, then the following LOAD CSV Cypher statement will result in updating the TotalRevenue property for the three existing Movie nodes and creating a new node for the fourth movie, namely A Few Good Men:
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV FROM ""file:///Movies.csv"" AS csvLine
MERGE (n:Movie {id:csvLine[0]})
ON CREATE SET n.id=csvLine[0],n.name=csvLine[1], n.TotalRevenue = csvLine[2]
ON MATCH SET n.TotalRevenue = csvLine[2]
Running the above Cypher the first time will result in:
Added 1 label, created 1 node, set 7 properties
Subsequent re-runs of the same LOAD CSV will result in:
Set 4 properties
Was this page helpful?"
https://neo4j.com/developer/kb/protecting-against-cypher-injection;"Protecting against Cypher injection
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher security
What is Cypher injection?
Cypher injection is a way for maliciously formatted input to jump out of its context, and by altering the query itself, hijack the query and perform unexpected operations on the database.
This is a cousin to SQL injection, but affecting our Cypher query language.
One of the best illustrations of injection attacks is from an XKCD comic featuring Little Bobby Tables:
The boy’s mother named him Robert'; DROP TABLE STUDENTS;--, ensuring that if his name was appended into a SQL statement that didn’t clean their inputs or protect against an injection attack, the quote would end the context of a quoted name, the semicolon would end that statement, the STUDENTS table would be dropped, and the -- would turn the remaining part of the query into a comment, so the remaining query could be ignored and avoid any syntax errors.
This syntax is of course specific to SQL. Given that Bobby’s mother would likely have continued her crusade, she might have had another child specifically for targeting Cypher, used by the leading graph database Neo4j. Lets call him Little Robby Labels, to differentiate him from his older brother:
""Robby' WITH DISTINCT true as haxxored MATCH (s:Student) DETACH DELETE s //""
This is an attempt at Cypher injection, the equivalent of the SQL injection attack, except the deletion of all :Student nodes happens within the same statement instead of splitting it into a separate statement. (The WITH clause in the middle is just to ensure we reduce down to a single row of input before matching to deleting all students, it’s for efficiency)
And if names from outside input are string-appended into a Cypher query like so, this attack may succeed:
String queryString = ""CREATE (s:Student) SET s.name = '"" + studentName + ""'"";

Result result = session.run(queryString);
Parameter usage prevents Cypher injection
We can easily prevent Cypher injection by always submitting input as parameters to our query.
https://neo4j.com/docs/cypher-manual/current/syntax/parameters/
The parameter might get set like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
:param name => ""Robby' WITH DISTINCT true as haxxored MATCH (s:Student) DETACH DELETE s //""
And the parameterized query would look like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (s:Student)
SET s.name = $studentName
When using parameters like this, it is impossible for the parameter, in part or in whole, to be interpreted as part of the query. It cannot hijack it.
One reason for this is that parameters are separate from the query. The query alone is compiled into an executable plan, and once compiled, can use any parameter map for execution. The parameters cannot alter the compiled plan, and have no opportunity to be included in the plan compilation.
In other words, once a query plan has been compiled, it is set, and nothing in the data submitted to it can change it, alter it, or hijack it.
Other common injection attempts also fail
Not all inputs can be submitted as parameters. Maybe some malicious input made it into a CSV file for processing. A CSV of the names of new students for the year, for example.
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM ""file:///students_2021.csv"" AS row
CREATE (s:Student)
SET s.year = 2021, s.name = row.student_name
Is this vulnerable to Little Robby Labels?
No, it is not. Cypher injection is still impossible here, even if parameters aren’t being used.
The LOAD query is independent of the CSV that is to be processed. As such, the query is compiled separately from the CSV. By the time the query is executing and the CSV data starts to be accessed, the query has already been completely compiled, and the CSV data has no opportunity to affect or hijack the query itself.
Likewise, any other injection attacks will fail that attempt to pull in malicious input via reading it from somewhere, or even a malicious property value that somehow was saved into the database already. This is because unless the malicious value is string-appended into the query itself, rather than read at the time the query executes, it will not have the opportunity to get compiled into and affect the query plan.
Be careful when string appending into dynamically-executed Cypher strings
Some procedures in our APOC Procedures library allow for execution of Cypher strings within a query, and this does present a vulnerability for Cypher injection.
Some of the more notable examples include:
apoc.cypher.run()
apoc.cypher.doIt()
apoc.periodic.iterate() (and other periodic procs)
apoc.when()
apoc.do.when()
apoc.case()
apoc.do.case()
String appending into the query string is possible here, and so Cypher injection becomes possible.
Consider this query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.doIt(""CREATE (s:Student) SET s.name = '"" + $studentName + ""' RETURN true"", {}) YIELD value
RETURN value;
Even though we passed $studentName as a parameter to the query, the parameter is being appended into the query string for execution by apoc.cypher.doIt(). The same vulnerability would exist if we were processing a LOAD CSV query like before, and appending into a query string for execution by APOC.
Little Robby Labels would end up wiping out all our student data.
Pass parameters to APOC procs instead of appending into the query string
Parameter usage here is still the answer to this vulnerability.
Instead of appending into the string, pass the value as a parameter to the procedure call:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.doIt(""CREATE (s:Student) SET s.name = $name  RETURN true"", {name:$name}) YIELD value
RETURN value;
Little Robby Labels becomes powerless here.
All of the APOC procedures that execute dynamic Cypher strings should have a way to pass a parameter map to the call, providing protection from injection attacks once again.
When you MUST append into a query string, sanitize your inputs
There are some cases where we can’t pass a parameter into the procedure call, or a query, and string appending is the only option.
For example, there are some things in Cypher that cannot be parameterized, such as node labels and relation types. There are some APOC Procs that can help (and should be used if so), but aside from these, the only option may be to append into a query string.
In these cases, it is extremely important to sanitize your inputs, removing quote or delimiter characters (depending on their context of use) that would allow input to break out of the context within which you’re trying to use it.
In these cases it is better to sanitize input in your own code at the client level, as there are many utilities across various languages for input sanitization, and it makes sense to address it at that level rather than lower down at the database itself.
Beware of participation in stored scripting and web site injection attacks
This doesn’t really fall into the category of Cypher injection, since it’s not an attack on Cypher or the database itself, but it’s important to be aware of it.
Stored cross site scripting attacks use values in a database as a vector for attacks on a web site. Malicious values (usually malicious javascript or HTML) are saved to the database (and these values do not affect or impact Cypher or the database in any way), but when retrieved and displayed on a vulnerable page, these values result in a cross-site scripting attack, or an injection attack, resulting in the malicious code affecting the javascript or HTML on the page.
So the vulnerability is actually in the HTML or Javascript on the page itself, and has nothing to do with Neo4j. To mitigate, the HTML and javascript used on the page itself ought to be secured such that results from a database call are sanitized before display, inclusion in the DOM, or execution as script. That said, it may be a good idea to sanitize outside input for HTML/Javascript control characters before saving to the database, so your stored data can’t be used as a vector in these kinds of attacks.
It’s often most reliable to do this in your code client-side, so you pass in parameters that have already been sanitized.
https://en.wikipedia.org/wiki/Cross-site_scripting#Persistent_(or_stored)
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/current;"Neo4j GraphQL Library
Documentation license: Creative Commons 4.0
This is the documentation for the Neo4j GraphQL Library, authored by the Neo4j GraphQL Team.
Are you a GRANDstack user? We have deprecated the GRANDstack starter app, find more information here.
This documentation covers the following topics:
Introduction - Introduction to the Neo4j GraphQL Library.
Getting Started - Start here if you want to quickly get up and running with the library.
Type Definitions - Define your nodes and relationships using type definitions as documented here.
Queries - GraphQL Queries allow you to read data in your Neo4j database.
Mutations - GraphQL Mutations allow you to change data in your Neo4j database.
Subscriptions - GraphQL Subscriptions for real-time data updates.
Filtering - This chapter covers how to filter your data in Queries and Mutations.
Sorting - This chapter covers how to sort the data being returned.
Pagination - This chapter covers the pagination options offered by the Neo4j GraphQL Library.
Mathematical operators - This chapter covers how to use the Mathematical operators.
Array methods - This chapter covers how to use the Array methods.
Custom Resolvers - Learn how to implement custom functionality accessible through your API.
Auth - Covers the authentication and authorization options offered by this library.
Directives - An index of all of the directives offered by the Neo4j GraphQL Library.
API Reference - API reference for constructing an instance of the library.
OGM - This chapter covers the OGM (Object Graph Mapper), a programmatic way of using your API.
Introspector - This chapter covers how you can introspect an existing Neo4j database and automatically generate GraphQL type definitions from that.
GraphQL Toolbox - Purpose-built Developer UI for your Neo4j GraphQL API.
Driver Configuration - How to configure a database driver for use with this library.
Guides - Guides for usage of the library, including migration guides for moving between versions.
Troubleshooting - Having problems with the library? See if your problem has been found and solved before.
Deprecations - Overview and information regarding deprecated products and applications.
This manual is primarily written for software engineers building an API using the Neo4j GraphQL Library.
Introduction
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/pagination;"Pagination
The Neo4j GraphQL Library offers two mechanisms for pagination:
Offset-based pagination - Pagination based on offsets, often associated with navigation via pages.
Cursor-based pagination - Pagination based on cursors, often associated with infinitely-scrolling applications.
Sorting
Offset-based pagination
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/pagination/offset-based;"Offset-based pagination
Contents
Total number of pages
Paginating relationship fields
Offset-based pagination, often associated with navigation via pages, can be achieved through the use of the offset and limit options available when querying for data.
Using the following type definition:
Graphql
Copy to Clipboard
type User {
    name: String!
}
You would fetch the first ""page"" of 10 by executing:
Graphql
Copy to Clipboard
query {
    users(options: {
        limit: 10
    }) {
        name
    }
}
And then on subsequent calls, introduce the offset argument and increment it by 10 on each call.
Page 2:
Graphql
Copy to Clipboard
query {
    users(options: {
        offset: 10
        limit: 10
    }) {
        name
    }
}
Page 3:
Graphql
Copy to Clipboard
query {
    users(options: {
        offset: 20
        limit: 10
    }) {
        name
    }
}
And so on, so forth.
Total number of pages
You can fetch the total number of records for a certain type using its count query, and then divide that number by your entries per page in order to calculate the total number of pages. This will allow to to determine what the last page is, and whether there is a next page.
See Count queries for details on how to execute these queries.
Paginating relationship fields
Say that in addition to the User type above, there is also a Post type which a User has many of. You can also fetch a User and then paginate through their posts:
Graphql
Copy to Clipboard
query {
    users(where: {
        name: ""Billy""
    }) {
        name
        posts(options: {
            offset: 20
            limit: 10
        }) {
            content
        }
    }
}
Pagination
Cursor-based pagination
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/queries;"Queries
Contents
Query
Querying for all User nodes
Query for user with name ""Jane Smith"" and their posts
Undirected Queries
Aggregate
Counting Using aggregation
Counting User nodes where name starts with ""J""
Querying for the longest User name
Querying for first Post date
Aggregate related nodes
Counting all posts per users
Finding longest post per user
Aggregate relationships
Undirected aggregation queries
Each node defined in type definitions will have two Query fields generated for it:
One for querying data
One for aggregating data
The examples in this chapter will use the following type definitions:
Graphql
Copy to Clipboard
type Post {
    id: ID! @id
    content: String!
    creator: User! @relationship(type: ""HAS_POST"", direction: IN, properties: ""PostedAt"")
    createdAt: DateTime!
}

type User {
    id: ID! @id
    name: String!
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT, properties: ""PostedAt"")
    friends: [User!]! @relationship(type: ""FRIENDS_WITH"", direction: OUT)
}

interface PostedAt {
    date: DateTime
}
For which the following Query fields will be generated:
Graphql
Copy to Clipboard
type Query {
    posts(where: PostWhere, options: PostOptions): [Post!]!
    postsAggregate(where: PostWhere): PostAggregationSelection!

    users(where: UserWhere, options: UserOptions): [User!]!
    usersAggregate(where: UserWhere): UserAggregationSelection!
}
Query
Each field for querying data accepts two arguments:
where - used for Filtering data
options - used to specify Sorting and Pagination options
Querying for all User nodes
The following Query will return all User nodes, returning their ID and name.
Graphql
Copy to Clipboard
query {
    users {
        id
        name
    }
}
Query for user with name ""Jane Smith"" and their posts
The following Query will return all Users, returning the content which they have posted.
Graphql
Copy to Clipboard
query {
    users(where: { name: ""Jane Smith"" }) {
        id
        name
        posts {
            content
        }
    }
}
Undirected Queries
All relationships are created with a direction from one node to another. By default, all queries follow the direction defined in the relationship, however, in some cases we may need to query for all related nodes, regardless of the direction of the relationship. This can be achieved with the argument directed: false.
For example, the following query:
Graphql
Copy to Clipboard
query {
    users {
        name
        friends: friends(directed: false) {
            name
        }
    }
}
Will return all user friends, regardless on the direction of the relationship ""FRIENDS_WITH"".
Undirected relationships can also be used in the same fashion with connections:
Graphql
Copy to Clipboard
query Query {
  users {
    friendsConnection(directed: false) {
      edges {
        node {
          name
        }
      }
    }
  }
}
Note that undirected relationships are only supported in queries.
The type definitions for a relationship may define a different behaviour, so the directed option may not be available in some cases.
Aggregate
Neo4j GraphQL supports aggregations on fields with type:
ID- String
String - String
Int - Numerical
Float - Numerical
BigInt - Numerical
DateTime
Time
LocalTime
LocalDateTime
Duration
Numerical Fields will expose the following aggregation selections:
min
max
average
sum
String fields will expose:
shortest
longest
The rest will only expose:
min
max
Aggregation queries accepts a where argument for filtering data.
Counting Using aggregation
The following Query will count all User nodes:
Graphql
Copy to Clipboard
query {
    usersAggregate {
        count
    }
}
Counting User nodes where name starts with ""J""
Graphql
Copy to Clipboard
query {
    usersAggregate(where: { name_STARTS_WITH: ""J"" }) {
        count
    }
}
Querying for the longest User name
Graphql
Copy to Clipboard
query {
    usersAggregate {
        name {
            longest
        }
    }
}
Querying for first Post date
Graphql
Copy to Clipboard
query {
    postsAggregate {
        createdAt {
            min
        }
    }
}
Aggregate related nodes
Related nodes can also be aggregated within a query by accessing the aggregation fields in the node. In these fields, you can count, aggregate the nodes or edges fields.
The same selections and types as before are available in relationship aggregations.
Counting all posts per users
Graphql
Copy to Clipboard
query {
    users {
        id
        postsAggregate {
            count
        }
    }
}
Finding longest post per user
By using the node field, related nodes properties can be aggregated.
Graphql
Copy to Clipboard
query {
    users {
        name
        postsAggregate {
            node {
                content {
                  longest
                }
            }
        }
    }
}
Aggregate relationships
Relationship properties can be aggregated as well by using the edge field.
Graphql
Copy to Clipboard
query {
    users {
        name
        postsAggregate {
            edge {
              date {
                max
              }
            }
        }
    }
}
Undirected aggregation queries
When performing an aggregation on related nodes, the query against the relationship can be defined as an undirected using the argument directed: false:
Graphql
Copy to Clipboard
query {
    users {
        id
        postsAggregate(directed: false) {
            count
        }
    }
}
Indexes and Constraints
Mutations
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/indexes-and-constraints;"Indexes and Constraints
Contents
Unique node property constraints
@unique directive usage
Fulltext indexes
Specifying the @fulltext directive
Using the @fulltext directive
Asserting constraints
Unique node property constraints
Unique node property constraints map to @unique directives used in your type definitions, which has the following definition:
Graphql
Copy to Clipboard
""""""Informs @neo4j/graphql that there should be a uniqueness constraint in the database for the decorated field.""""""
directive @unique(
    """"""The name which should be used for this constraint. By default; type name, followed by an underscore, followed by the field name.""""""
    constraintName: String
) on FIELD_DEFINITION
Additionally, the usage of the @id directive by default implies that there should be a unique node property constraint in the database for that property.
Using this directive does not automatically ensure the existence of these constraints, and you will need to run a function on server startup. See the section Asserting constraints below for details.
@unique directive usage
@unique directives can only be used in GraphQL object types representing nodes, and will only be applied for the ""main"" label for the node. You can find some examples below.
In the following example, a unique constraint will be asserted for the label Colour and the property hexadecimal:
Graphql
Copy to Clipboard
type Colour {
    hexadecimal: String! @unique
}
In the next example, a unique constraint with name unique_colour will be asserted for the label Colour and the property hexadecimal:
Graphql
Copy to Clipboard
type Colour {
    hexadecimal: String! @unique(constraintName: ""unique_colour"")
}
The @node directive is used to change the database label mapping in this next example, so a unique constraint will be asserted for the label Color and the property hexadecimal:
Graphql
Copy to Clipboard
type Colour @node(label: ""Color"") {
    hexadecimal: String! @unique
}
In the following example, the additionalLabels argument of the @node directive is ignored when it comes to asserting constraints, so the outcome is the same as the example above:
Graphql
Copy to Clipboard
type Colour @node(label: ""Color"", additionalLabels: [""Hue""]) {
    hexadecimal: String! @unique
}
Fulltext indexes
You can use the @fulltext directive to add a Full text index inside Neo4j.
Graphql
Copy to Clipboard
input FullTextInput {
  indexName: String
  queryName: String
  fields: [String]!
  name: String # Deprecated and will be removed in version 4.0. of the library. Use indexName instead.
}

""""""
Informs @neo4j/graphql that there should be a fulltext index in the database, allows users to search by the index in the generated schema.
""""""
directive @fulltext(indexes: [FullTextInput]!) on OBJECT
Using this directive does not automatically ensure the existence of these indexes, and you will need to run a function on server startup. See the section Asserting constraints below for details.
Specifying the @fulltext directive
The directive can be used on nodes. Here we add a Fulltext index, called 'ProductName', for the name field, on the Product node.
Graphql
Copy to Clipboard
type Product @fulltext(indexes: [{ indexName: ""ProductName"", fields: [""name""] }]) {
    name: String!
    color: Color! @relationship(type: ""OF_COLOR"", direction: OUT)
}
When you run Asserting constraints this shall do the index creation like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.index.fulltext.createNodeIndex(""ProductName"", [""Product""], [""name""])
Using the @fulltext directive
For every index specified, a new top level query will be generated by the library. For example, for the type definitions above, the following query and types would be generated:
Graphql
Copy to Clipboard
type Query {
    productsFulltextProductName(phrase: String!, where: ProductFulltextWhere, sort: [ProductFulltextSort!],
    limit: Int, offset: Int): [ProductFulltextResult!]!
}

""""""The result of a fulltext search on an index of Product""""""
type ProductFulltextResult {
  score: Float
  product: Product
}

""""""The input for filtering a fulltext query on an index of Product""""""
input ProductFulltextWhere {
  score: FloatWhere
  product: ProductWhere
}


input {
  score:
  product:
}


input {
  min:
  max:
}
View all (14 more lines)
This query can then be used to perform a Lucene full-text query to match and return products. Below is an example of this:
Graphql
Copy to Clipboard
query {
  productsFulltextProductName(phrase: ""Hot sauce"", where: { score: { min: 1.1 } } sort: [{ product: { name: ASC } }]) {
    score
    product {
      name
    }
  }
}
The above query would produce results in the following format:
Json
Copy to Clipboard
{
  ""data"": {
    ""productsFulltextProductName"": [
      {
        ""score"": 2.1265015602111816,
        ""product"": {
          ""name"": ""Louisiana Fiery Hot Pepper Sauce""
        }
      },
      {
        ""score"": 1.2077560424804688,
        ""product"": {
          ""name"": ""Louisiana Hot Spiced Okra""
        }
      },
      {
        : ,
        : {
          : 
        }
      }
    ]
  }
}
View all (9 more lines)
Additionally, it is possible to define a custom query name as part of the @fulltext directive, using the queryName argument as shown below:
Graphql
Copy to Clipboard
type Product @fulltext(indexes: [{ queryName: ""CustomProductFulltextQuery"", indexName: ""ProductName"", fields: [""name""] }]) {
    name: String!
    color: Color! @relationship(type: ""OF_COLOR"", direction: OUT)
}
This would then produce the following top-level query:
Graphql
Copy to Clipboard
type Query {
    CustomProductFulltextQuery(phrase: String!, where: ProductFulltextWhere, sort: [ProductFulltextSort!],
    limit: Int, offset: Int): [ProductFulltextResult!]!
}
This query can then be used as shown below:
Graphql
Copy to Clipboard
query {
  CustomProductFulltextQuery(phrase: ""Hot sauce"", sort: [{ score: ASC }]) {
    score
    product {
      name
    }
  }
}
Deprecated usage
Querying full-text indexes in the following ways has been deprecated and will be removed in version 4.0.
Once you specify the index, you will now gain a 'Top Level' fulltext key on the following operations:
read
count
aggregate
Here we use the fulltext key, and the phrase is using Lucene’s full-text query language to match and return Products:
Graphql
Copy to Clipboard
query {
    products(fulltext: { ProductName: { phrase: ""beer OR cerveza"" } }) {
        name
    }
}
Note that you can only query one Fulltext index at once and that the fulltext key is only available on 'Top Level' queries.
Asserting constraints
In order to ensure that the specified constraints exist in the database, you will need to run the function assertIndexesAndConstraints, the full details of which can be found in the API reference. A simple example to create the necessary constraints might look like the following, assuming a valid driver instance in the variable driver. This will create two constraints, one for each field decorated with @id, @unique and apply the indexes specified in @fulltext:
JavaScript
Copy to Clipboard
const typeDefs = gql`
    type Colour {
        id: ID! @id
        hexadecimal: String! @unique
    }

    type Product @fulltext(indexes: [{ indexName: ""ProductName"", fields: [""name""] }]) {
        name: String!
        color: Color! @relationship(type: ""OF_COLOR"", direction: OUT)
    }
`;

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

await neoSchema.assertIndexesAndConstraints({ options: { create: true }});
Database Mapping
Queries
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/autogeneration;"Autogeneration
Contents
@id
Definition
Usage
@timestamp
Timestamps
Definition
Usage
@populatedBy
Definition
Usage
@callback
Definition
Usage
@id
This directive marks a field as the unique identifier for an object type, and by default; enables autogeneration of IDs for the field and implies that a unique node property constraint should exist for the property.
The format of each generated ID is a UUID generated by randomUUID() function.
If autogeneration for an ID field is enabled, the field will not be present in input types for Mutations.
See Unique node property constraints for details on how to assert the existence of the necessary database constraints for relevant fields.
Definition
Graphql
Copy to Clipboard
""""""Indicates that the field is an identifier for the object type. By default; autogenerated, and has a unique node property constraint in the database.""""""
directive @id(
    autogenerate: Boolean! = true
    unique: Boolean! = true
) on FIELD_DEFINITION
Usage
The following two type definitions are equivalent in that they both specify an ID which will benefit from autogeneration:
Graphql
Copy to Clipboard
type User {
    id: ID! @id
    username: String!
}
Graphql
Copy to Clipboard
type User {
    id: ID! @id(autogenerate: true)
    username: String!
}
The following type definition is currently a no-op, as the @id directive only provides autogeneration as it stands:
Graphql
Copy to Clipboard
type User {
    id: ID! @id(autogenerate: false)
    username: String!
}
You can disable the mapping of the @id directive to a unique node property constraint by setting the unique argument to false:
Graphql
Copy to Clipboard
type User {
    id: ID! @id(unique: false)
    username: String!
}
@timestamp
Timestamps
This directive marks a field as a timestamp field, which will be used to store timestamps of when particular events happen through the GraphQL API.
These events are triggered and stored at the GraphQL API layer. Events happening in your database through other routes will not trigger updates of these timestamps.
Definition
Graphql
Copy to Clipboard
enum TimestampOperation {
    CREATE
    UPDATE
}

""""""Instructs @neo4j/graphql to generate timestamps on particular events, which will be available as the value of the specified field.""""""
directive @timestamp(
    """"""Which events to generate timestamps on. Defaults to both create and update.""""""
    operations: [TimestampOperation!]! = [CREATE, UPDATE]
) on FIELD_DEFINITION
Usage
The following type definition has two individual fields to store the timestamps of create and update events.
Graphql
Copy to Clipboard
type User {
    createdAt: DateTime! @timestamp(operations: [CREATE])
    updatedAt: DateTime! @timestamp(operations: [UPDATE])
}
The following two equivalent type definitions have a single field storing the event timestamp of the last create or update:
Graphql
Copy to Clipboard
type User {
    lastModified: DateTime! @timestamp
}
Graphql
Copy to Clipboard
type User {
    lastModified: DateTime! @timestamp(operations: [CREATE, UPDATE])
}
@populatedBy
The @populatedBy directive is used to specify a callback function that gets executed during GraphQL query parsing, to populate fields which have not been provided within the input.
For non-required values, callbacks may return undefined (meaning that nothing will be changed or added to the property) or null (meaning that the property will be removed).
Definition
Graphql
Copy to Clipboard
enum PopulatedByOperation {
    CREATE
    UPDATE
}

""""""Instructs @neo4j/graphql to invoke the specified callback function to populate the field when updating or creating the properties on a node or relationship.""""""
directive @populatedBy(
    """"""The name of the callback function.""""""
    callback: String!
    """"""Which events to invoke the callback on.""""""
    operations: [PopulatedByOperation!]! = [CREATE, UPDATE]
) on FIELD_DEFINITION
Usage
Type Definitions:
Graphql
Copy to Clipboard
type Product {
    name: String!
    slug: String! @populatedBy(callback: ""slug"", operations: [CREATE, UPDATE])
}
Schema Construction:
Note that the callback is asynchronous!
JavaScript
Copy to Clipboard
const slugCallback = async (root) => {
    return `${root.name}_slug`
}

new Neo4jGraphQL({
    typeDefs,
    driver,
    config: {
        callbacks: {
            slug: slugCallback
        }
    }
})
Using GraphQL context values
The GraphQL context for the request is available as the third argument in a callback. This maps to the argument pattern for GraphQL resolvers.
For example, if you wanted a field modifiedBy:
Graphql
Copy to Clipboard
type Record {
    content: String!
    modifiedBy: @populatedBy(callback: ""modifiedBy"", operations: [CREATE, UPDATE])
}
If the username is located in context.username, you could define a callback such as:
JavaScript
Copy to Clipboard
const modifiedByCallback = async (_parent, _args, context) => {
    return context.username;
}

new Neo4jGraphQL({
    typeDefs,
    driver,
    config: {
        callbacks: {
            modifiedBy: modifiedByCallback
        }
    }
})
The second positional argument, in this case _args, has a type of Record<string, never>, and as such will always be an empty object.
@callback
The @callback directive has been deprecated and will be removed in version 4.0. Please use @populatedBy instead.
The @callback directive is used to specify a function that will be invoked when updating or creating the properties on a node or relationship.
For non-required values, callbacks may return undefined (meaning that nothing will be changed or added to the property) or null (meaning that the property will be removed).
Definition
Graphql
Copy to Clipboard
enum CallbackOperation {
    CREATE
    UPDATE
}

""""""Instructs @neo4j/graphql to invoke the specified callback function when updating or creating the properties on a node or relationship.""""""
directive @callback(
    """"""Which events to invoke the callback on.""""""
    operations: [CallbackOperation!]! = [CREATE, UPDATE]
    """"""The name of the callback function.""""""
    name: String!
) on FIELD_DEFINITION
Usage
Type Definitions:
Graphql
Copy to Clipboard
type Product {
    name: String!
    slug: String! @callback(operations: [CREATE, UPDATE], name: ""slug"")
}
Schema Construction:
Note that the callback is asynchronous!
JavaScript
Copy to Clipboard
const slugCallback = async (root) => {
    return `${root.name}_slug`
}

new Neo4jGraphQL({
    typeDefs,
    driver,
    config: {
        callbacks: {
            slug: slugCallback
        }
    }
})
Using GraphQL context values
The GraphQL context for the request is available as the third argument in a callback. This maps to the argument pattern for GraphQL resolvers.
For example, if you wanted a field modifiedBy:
Graphql
Copy to Clipboard
type Record {
    content: String!
    modifiedBy: @callback(operations: [CREATE, UPDATE], name: ""modifiedBy"")
}
If the username is located in context.username, you could define a callback such as:
JavaScript
Copy to Clipboard
const modifiedByCallback = async (_parent, _args, context) => {
    return context.username;
}

new Neo4jGraphQL({
    typeDefs,
    driver,
    config: {
        callbacks: {
            modifiedBy: modifiedByCallback
        }
    }
})
The second positional argument, in this case _args, has a type of Record<string, never>, and as such will always be an empty object.
Access Control
@cypher directive
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/cypher;"@cypher directive
Contents
Definition
Character Escaping
Globals
this
auth
cypherParams
Return values
Scalar values
Object types
columnName
Usage examples
On an object type field
On a Query type field
On a Mutation type field
The @cypher directive binds a GraphQL field to the result(s) of a Cypher query.
Definition
Graphql
Copy to Clipboard
""""""Instructs @neo4j/graphql to run the specified Cypher statement in order to resolve the value of the field to which the directive is applied.""""""
directive @cypher(
    """"""The Cypher statement to run which returns a value of the same type composition as the field definition on which the directive is applied.""""""
    statement: String!,
    """"""[Experimental] Name of the returned variable from the Cypher statement, if provided, the query will be optimized to improve performance.""""""
    columnName: String
) on FIELD_DEFINITION
Character Escaping
All double quotes must be double escaped when used in a @cypher directive - once for GraphQL and once for the function in which the Cypher is wrapped. For example, at its simplest:
Graphql
Copy to Clipboard
type Example {
    string: String!
        @cypher(
            statement: """"""
            RETURN \\""field-level string\\""
            """"""
        )
}

type Query {
    string: String!
        @cypher(
            statement: """"""
            RETURN \\""Query-level string\\""
            """"""
        )
}
Note the double-backslash (\\) before each double quote ("").
Globals
Global variables are available for use within the Cypher statement.
this
The value this is a reference to the currently resolved node, and it can be used to traverse the graph.
This can be seen in the usage example On an object type field below.
auth
The value auth is represented by the following TypeScript interface definition:
Typescript
Copy to Clipboard
interface Auth {
    isAuthenticated: boolean;
    roles?: string[];
    jwt: any;
}
For example, you could use the JWT in the request to return the value of the currently logged in User:
Graphql
Copy to Clipboard
type User {
    id: String
}

type Query {
    me: User @cypher(
        statement: """"""
        MATCH (user:User {id: $auth.jwt.sub})
        RETURN user
        """"""
    )
}
cypherParams
Use to inject values into the cypher query from the GraphQL context function.
Inject into context:
Typescript
Copy to Clipboard
const server = new ApolloServer({
    typeDefs,
    context: () => {
        return {
            cypherParams: { userId: ""user-id-01"" }
        }
    }
});
Use in cypher query:
Graphql
Copy to Clipboard
type Query {
    userPosts: [Post] @cypher(statement: """"""
        MATCH (:User {id: $cypherParams.userId})-[:POSTED]->(p:Post)
        RETURN p
    """""")
}
Return values
The return value of the Cypher statement must be of the same type to which the directive is applied.
Scalar values
The Cypher statement must return a value which matches the scalar type to which the directive was applied.
Graphql
Copy to Clipboard
type Query {
    randomNumber: Int @cypher(statement: ""RETURN rand()"")
}
Object types
When returning an object type, all fields of the type must be available in the Cypher return value. This can be achieved by either returning the entire object from the Cypher query, or returning a map of the fields which are required for the object type. Both approaches are demonstrated below:
Graphql
Copy to Clipboard
type User {
    id
}

type Query {
    users: [User]
        @cypher(
            statement: """"""
            MATCH (u:User)
            RETURN u
            """"""
        )
}
Graphql
Copy to Clipboard
type User {
    id
}

type Query {
    users: [User] @cypher(statement: """"""
        MATCH (u:User)
        RETURN {
            id: u.id
        }
    """""")
}
The downside of the latter approach is that you will need to adjust the return object as you change your object type definition.
columnName
The columName argument will change the translation of custom Cypher. Instead of using apoc.cypher.runFirstColumnMany it will directly wrap the query within a CALL { } subquery. This behvaiour has proven to be much more performant for the same queries.
columnName should be the name of the returned variable to be used in the rest of the query. For example:
The graphql query:
Graphql
Copy to Clipboard
type query {
    test: String! @cypher(statement: ""MATCH(m:Movie) RETURN m"", columnName: ""m"")
}
Would get translated to:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
    MATCH(m:Movie) RETURN m
}
WITH m AS this
RETURN this
Additionally, escaping strings is no longer needed when columName is set.
This alternative behaviour may lead to unexpected changes, mainly if using Neo4j 5.x, where subqueries need to be aliased.
Usage examples
On an object type field
In the example below, a field similarMovies is bound to the Movie type, to find other movies with an overlap of actors:
Graphql
Copy to Clipboard
type Actor {
    actorId: ID!
    name: String
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    movieId: ID!
    title: String
    description: String
    year: Int
    actors(limit: Int = 10): [Actor!]!
        @relationship(type: ""ACTED_IN"", direction: IN)
    similarMovies(limit: Int = 10): [Movie]
        @cypher(
            statement: 
        )
}
View all (8 more lines)
On a Query type field
The example below demonstrates a simple Query to return all of the actors in the database:
Graphql
Copy to Clipboard
type Actor {
    actorId: ID!
    name: String
}

type Query {
    allActors: [Actor]
        @cypher(
            statement: """"""
            MATCH (a:Actor)
            RETURN a
            """"""
        )
}
On a Mutation type field
The example below demonstrates a simple Mutation using a Cypher query to insert a single actor with the specified name argument:
Graphql
Copy to Clipboard
type Actor {
    actorId: ID!
    name: String
}

type Mutation {
    createActor(name: String!): Actor
        @cypher(
            statement: """"""
            CREATE (a:Actor {name: $name})
            RETURN a
            """"""
        )
}
Autogeneration
Default Values
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/default-values;"Default Values
Contents
@default
Definition
Usage with Enums
@coalesce
Definition
Usage with Enums
@queryOptions
Definition
Limit
@default
When generating the input type for the create mutation, the value specified in this directive will be used as the default value for this field.
Definition
Graphql
Copy to Clipboard
""""""Int | Float | String | Boolean | ID | DateTime | Enum""""""
scalar Scalar

""""""Instructs @neo4j/graphql to set the specified value as the default value in the CreateInput type for the object type in which this directive is used.""""""
directive @default(
    """"""The default value to use. Must be a scalar type and must match the type of the field with which this directive decorates.""""""
    value: Scalar!,
) on FIELD_DEFINITION
Usage with Enums
@default may be used with enums. When setting the default value for an enum field, the value must be one of the enumerated enum values.
Graphql
Copy to Clipboard
enum Location {
    HERE
    THERE
    EVERYWHERE
}

type SomeType {
    firstLocation: Location! @default(value: HERE) # valid usage
    secondLocation: Location! @default(value: ELSEWHERE) # invalid usage, will throw an error
}
@coalesce
When translating from GraphQL to Cypher, any instances of fields to which this directive is applied will be wrapped in a coalesce() function in the WHERE clause (see https://neo4j.com/developer/kb/understanding-non-existent-properties-and-null-values/#_use_coalesce_to_use_a_default_for_a_null_value). This helps to query against non-existent properties in a database, however it is encouraged to populate these properties with meaningful values if this is becoming the norm. This is a very primitive implementation of the function which only takes a static default value as opposed to using another property in a node or a Cypher expression.
Definition
Graphql
Copy to Clipboard
""""""Int | Float | String | Boolean | ID | DateTime | Enum""""""
scalar ScalarOrEnum

""""""Instructs @neo4j/graphql to wrap the property in a coalesce() function during queries, using the single value specified.""""""
directive @coalesce(
    """"""The value to use in the coalesce() function. Must be a scalar type and must match the type of the field with which this directive decorates.""""""
    value: Scalar!,
) on FIELD_DEFINITION
Usage with Enums
@coalesce may be used with enums. When setting the default value for an enum field, the value must be one of the enumerated enum values.
Graphql
Copy to Clipboard
enum Status {
    ACTIVE
    INACTIVE
}
type Movie {
    status: Status @coalesce(value: ACTIVE)
}
@queryOptions
The @queryOptions is to be used on nodes, where applied will inject values into a query such as the limit.
Definition
Graphql
Copy to Clipboard
""""""The `@queryOptions` is to be used on nodes, where applied will inject values into a query such as the `limit`.""""""
directive @queryOptions(
    """"""If no limit argument is supplied on query will fallback to this value.""""""
    limit: {
        default: Int
        max: Int
    }
) on OBJECT
Limit
Limit has 2 arguments:
default - If no limit argument is passed to the query, the default limit will be used. The query may still pass a higher or lower limit.
max - Defines the maximum limit to be passed to the query. If a higher value is passed, this will be used instead. If no default value is set, max will be used for queries without limit.
@cypher directive
Database Mapping
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/database-mapping;"Database Mapping
Contents
@alias
Definition
Usage
@plural
@node
Definition
Usage
@alias
This directive maps a GraphQL field to a Neo4j property on a node or relationship.
This can be used on any fields that are not @cypher or @relationship fields.
Definition
Graphql
Copy to Clipboard
""""""Indicates that the field is to be mapped to the underlying Neo4j under a different property name.""""""
directive @alias(property: String!) on FIELD_DEFINITION
Usage
Graphql
Copy to Clipboard
type User {
    id: ID! @id @alias(property: ""dbId"")
    username: String!
}
Graphql
Copy to Clipboard
type User {
    id: ID! @id
    username: String! @alias(property: ""dbUserName"")
    livesIn: [City!]! @relationship(direction: OUT, type: ""LIVES_IN"", properties: ""UserLivesInProperties"")
}

type City {
    name: String
}

interface UserLivesInProperties @relationshipProperties {
    since: DateTime @alias(property: ""moveInDate"")
}
@plural
The @plural directive redefines how to compose the plural of the type for the generated operations. This is particularly useful for types that are not correctly pluralized or are non-English words.
Graphql
Copy to Clipboard
type Tech @plural(value: ""Techs"") {
  name: String
}
This way, instead of the wrongly generated teches, the type is properly written as techs:
Graphql
Copy to Clipboard
{
  techs {
    title
  }
}
The same is applied to other operations such as createTechs. Note that database labels will not change.
@node
The plural argument has been deprecated and will be removed in version 4.0. Please use the @plural directive instead.
The @node directive is used to specify the configuration of a GraphQL object type which represents a Neo4j node.
Definition
Graphql
Copy to Clipboard
""""""Informs @neo4j/graphql of node metadata""""""
directive @node(
    """"""Map the GraphQL type to a custom Neo4j node label""""""
    label: String
    """"""Map the GraphQL type to match additional Neo4j node labels""""""
    additionalLabels: [String]
    """"""Allows for the specification of the plural of the type name.""""""
    plural: String
) on OBJECT
Usage
@node can be used with the following optional parameters.
label
The parameter label defines the label to be used in Neo4j instead of the GraphQL type name:
Graphql
Copy to Clipboard
type Movie @node(label: ""Film"") {
    title: String!
}
This way, the following query:
Graphql
Copy to Clipboard
{
  movies {
    title
  }
}
Generates the cypher query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (this: Film)
RETURN this { .title } as this
Using $jwt and $context
In some cases, we may want to generate dynamic labels depending on the user requesting. In these cases, we can use the variable $jwt to define a custom label define in the JWT (similarly to how it is used in the @auth directive):
Graphql
Copy to Clipboard
type User @node(label: ""$jwt.username"") {
    name: String!
}
The following query will yield a different cypher query depending on the user JWT:
Graphql
Copy to Clipboard
{
  users {
    name
  }
}
Assuming an user with the value ""username"": ""arthur"" in JWT, the Cypher query will look like:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (this:arthur)
RETURN this { .name } as this
Similarly, context values can be passed directly:
Graphql
Copy to Clipboard
type User @node(label: ""$context.appId"") {
    name: String!
}
When running the server with Apollo:
Js
Copy to Clipboard
neoSchema.getSchema().then((schema) => {
    new ApolloServer({
        schema,
        context: ({ req }) => ({ req, appId: ""myApp"" }),
    });
})
additionalLabels
additionalLabels lets you define extra Neo4j labels that need to exist on the node for that GraphQL type.
Graphql
Copy to Clipboard
type Actor @node(additionalLabels: [""Person"", ""User""]) {
    name: String!
}
The following query:
Graphql
Copy to Clipboard
{
  Actor {
    name
  }
}
Generates the following cypher query, with the labels Actor, Person and User:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (this:Actor:Person:User)
RETURN this { .name } as this
Note that additionalLabels can be used along with label:
Graphql
Copy to Clipboard
type Actor @node(label: ""ActorDB"", additionalLabels: [""Person""]) {
    name: String!
}
In this case, the resulting Cypher query will use the labels ActorDB and Person instead of Actor:
MATCH (this:ActorDB:Person)
RETURN this { .name } as this
Context and JWT variables can be used with additionalLabels in the same fashion as in label:
Graphql
Copy to Clipboard
type User @node(additionalLabels: [""$jwt.username""]) {
    name: String!
}
plural
The plural argument has been deprecated and will be removed in version 4.0. Please use the @plural directive instead.
The parameter plural redefines how to compose the plural of the type for the generated operations. This is particularly useful for types that are not correctly pluralized or are non-English words.
Graphql
Copy to Clipboard
type Tech @node(plural: ""Techs"") {
  name: String
}
This way, instead of the wrongly generated teches, the type is properly written as techs:
Graphql
Copy to Clipboard
{
  techs {
    title
  }
}
The same is applied to other operations such as createTechs. Note that database labels will not change.
Default Values
Indexes and Constraints
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth;"Auth
Contents
Quickstart examples
In this chapter you will learn more about how to secure your GraphQL API using the Neo4j GraphQL Library’s built-in auth mechanics.
Setup
@auth directive
Global authentication
Authentication
Authorization
Subscriptions
Quickstart examples
Only authenticated users can create Post nodes:
Graphql
Copy to Clipboard
type Post @auth(rules: [
    { operations: [CREATE], isAuthenticated: true }
]) {
    title: String!
}
Use extend to avoid large and unwieldy type definitions:
Graphql
Copy to Clipboard
type Post {
    title: String!
}

extend type Post @auth(rules: [
    { operations: [CREATE], isAuthenticated: true }
])
You can use the directive types as seen in the example above, but you can also apply the directive on any field so as long as it’s not decorated with @relationship. In the following example, the password field is only accessible to users with role ""admin"", or the user themselves:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}

extend type User {
    password: String! @auth(rules: [
        {
            OR: [{ roles: [""admin""] }, { allow: { id: ""$jwt.sub"" } }]
        }
    ])
}
Custom Resolvers
Setup
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/global-authentication;"Global Authentication
Contents
Configuration
Functionality
For some cases the GraphQL API needs to be secured globally to restrict access to any of the top-level GraphQL types without prior authentication. In the Neo4j GraphQL Library this is referred to as global authentication. It is also known as API-wide authorization.
Configuration
To use the global authentication functionality, it is required to have an instance of an auth plugin for the Neo4j GraphQL Library. For most use cases you will only need to use our provided plugins at @neo4j/graphql-plugin-auth. Below is an example configuration enabling global authentication via the Neo4jGraphQLAuthJWTPlugin class:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWTPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWTPlugin({
            secret: ""super-secret"",
            globalAuthentication: true,
        })
    }
});
Observe that the Neo4jGraphQLAuthJWTPlugin class does not accept to enable both noVerify and globalAuthentication simultaneously.
If you would like to use JWKS decoding and enable global authentication then use the Neo4jGraphQLAuthJWKSPlugin class like so:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWKSPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWKSPlugin({
            jwksEndpoint: ""https://YOUR_DOMAIN/well-known/jwks.json"",
            globalAuthentication: true,
        })
    }
});
Functionality
If global authentication is enabled in the auth plugin for the Neo4j GraphQL Library, it is required that each request contains a valid JWT token in the authorization header. Otherwise an authentication error will be thrown.
@auth directive
Authentication
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/auth-directive;"@auth directive
Contents
rules
operations
Auth Value Plucking
The @auth directive definition is dynamically generated on runtime based on user type definitions.
rules
You can have many rules for many operations. Each rule is fallen through until a match is found against the corresponding operation. If no match is found, an error is thrown. You can think of rules as a big OR.
Graphql
Copy to Clipboard
@auth(rules: [
    { operations: [CREATE, UPDATE], ... }, ## or
    { operations: [READ, UPDATE], ...}, ## or
    { operations: [DELETE, UPDATE], ... } ## or
])
operations
operations is an array which allows you to re-use the same rule for many operations.
Graphql
Copy to Clipboard
@auth(rules: [
    { operations: [CREATE, UPDATE, DELETE, CONNECT, DISCONNECT, SUBSCRIBE] },
    { operations: [READ] }
])
Note that the absence of an operations argument will imply all operations.
Many different operations can be called at once, for example in the following Mutation:
Graphql
Copy to Clipboard
mutation {
    createPosts(
        input: [
            {
                content: ""I like GraphQL"",
                creator: { connect: { where: { id: ""user-01"" } } }
            }
        ]
    ) {
        posts {
            content
        }
    }
}
In the above example, there is a CREATE operation followed by a CONNECT, so the auth rule must allow a user to perform both of these operations.
Auth Value Plucking
When using the @auth directive, you use the following prefixes to substitute in their relevant values:
$jwt. - pulls value from JWT
$context. - pulls value from context
Setup
Global Authentication
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/setup;"Setup
Contents
Configuration
Auth Roles Object Paths
Cypher predicate used to evaluate bind rules
Passing in JWTs
Decoded JWTs
Auth and Custom Resolvers
Auth and @cypher fields
Configuration
To get started with auth you need an instance of an auth plugin for the Neo4j GraphQL Library. For most use cases you will only need to use our provided plugins at @neo4j/graphql-plugin-auth. Below is a basic example using the Neo4jGraphQLAuthJWTPlugin class:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWTPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWTPlugin({
            secret: ""super-secret""
        })
    }
});
If you would like to use JWKS decoding then use the Neo4jGraphQLAuthJWKSPlugin class:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWKSPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWKSPlugin({
            jwksEndpoint: ""https://YOUR_DOMAIN/well-known/jwks.json"",
        })
    }
});
If you need to create your own auth plugin then ensure it adheres to the following interface:
JavaScript
Copy to Clipboard
interface Neo4jGraphQLAuthPlugin {
    rolesPath?: string;
    isGlobalAuthenticationEnabled?: boolean;

    decode<T>(token: string | any): Promise<T | undefined>;
}
It is also possible to pass in JWTs which have already been decoded, in which case the jwt option is not necessary. This is covered in the section Passing in JWTs below. Note that the plugin’s base decode method only supports HS256 and RS256 algorithms.
Auth Roles Object Paths
If you are using a 3rd party auth provider such as Auth0 you may find your roles property being nested inside an object:
Json
Copy to Clipboard
{
    ""https://auth0.mysite.com/claims"": {
        ""https://auth0.mysite.com/claims/roles"": [""admin""]
    }
}
In order to make use of this, you must pass it in as a ""dot path"" into the rolesPath option:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWKSPlugin({
            jwksEndpoint: ""https://YOUR_DOMAIN/well-known/jwks.json"",
            rolesPath: ""https://auth0\\.mysite\\.com/claims.https://auth0\\.mysite\\.com/claims/roles""
        })
    }
});
Note that . characters within a key of the JWT must be escaped with \\, whilst a . character indicating traversal into a value must not be escaped.
Cypher predicate used to evaluate bind rules
By default, bind rules are evaluated using an all predicate in Cypher, which can lead to rules not being satisfied when they perhaps should, for instance only one related user matching the current JWT, rather than all of them.
To avoid a breaking change to a security-critical feature like authorization, a flag, bindPredicate, has been exposed to switch this predicate to any, which can be used as follows:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWTPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWTPlugin({
            secret: ""super-secret"",
            bindPredicate: ""any""
        })
    }
});
In the next major release, this will become the default behaviour when evaluating bind rules.
Passing in JWTs
If you wish to pass in an encoded JWT, this must be included in the authorization header of your requests, in the format:
None
Copy to Clipboard
POST / HTTP/1.1
authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyLCJyb2xlcyI6WyJ1c2VyX2FkbWluIiwicG9zdF9hZG1pbiIsImdyb3VwX2FkbWluIl19.IY0LWqgHcjEtOsOw60mqKazhuRFKroSXFQkpCtWpgQI
content-type: application/json
Note the string ""Bearer"" before the inclusion of the JWT.
Then, using Apollo Server as an example, you must include the request in the GraphQL context, as follows (using the neoSchema instance from the example above):
JavaScript
Copy to Clipboard
neoSchema.getSchema().then((schema) => {
    const server = new ApolloServer({
        schema,
        context: ({ req }) => ({ req }),
    });
});
Note that the request key req is appropriate for Express servers, but different middlewares use different keys for request objects. You can more details at https://www.apollographql.com/docs/apollo-server/api/apollo-server/#middleware-specific-context-fields.
Decoded JWTs
Alternatively, you can pass a key jwt of type JwtPayload into the context, which has the following definition:
Typescript
Copy to Clipboard
// standard claims https://datatracker.ietf.org/doc/html/rfc7519#section-4.1
interface JwtPayload {
    [key: string]: any;
    iss?: string | undefined;
    sub?: string | undefined;
    aud?: string | string[] | undefined;
    exp?: number | undefined;
    nbf?: number | undefined;
    iat?: number | undefined;
    jti?: string | undefined;
}
Do not pass in the header or the signature.
For example, you might have a function decodeJWT which returns a decoded JWT:
JavaScript
Copy to Clipboard
const decodedJWT = decodeJWT(encodedJWT)

neoSchema.getSchema().then((schema) => {
    const server = new ApolloServer({
        schema,
        context: { jwt: decodedJWT.payload },
    });
});
Auth and Custom Resolvers
You can’t use the @auth directive on custom resolvers, however, an auth parameter is injected into the context for use in them. It will be available under the auth property. For example, the following custom resolver returns the sub field from the JWT:
JavaScript
Copy to Clipboard
const typeDefs = `
    type Query {
        myId: ID!
    }
`;

const resolvers = {
    Query: {
        myId(_source, _args, context) {
            return context.auth.jwt.sub
        }
    }
};
Auth and @cypher fields
You can put the @auth directive on a field alongside the @cypher directive. Functionality like allow and bind will not work but you can still utilize isAuthenticated and roles. Additionally, you don’t need to specify operations for @auth directives on @cypher fields.
The following example uses the isAuthenticated rule to ensure a user is authenticated, before returning the User associated with the JWT:
Graphql
Copy to Clipboard
type User @exclude {
    id: ID
    name: String
}

type Query {
    me: User
        @cypher(statement: ""MATCH (u:User { id: $auth.jwt.sub }) RETURN u"")
        @auth(rules: [{ isAuthenticated: true }])
}
In the following example, the current user must have role ""admin"" in order to query the history field on the type User:
Graphql
Copy to Clipboard
type History @exclude {
    website: String!
}

type User {
    id: ID
    name: String
    history: [History]
        @cypher(statement: ""MATCH (this)-[:HAS_HISTORY]->(h:History) RETURN h"")
        @auth(rules: [{ roles: [""admin""] }])
}
Auth
@auth directive
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authentication;"Authentication
Contents
isAuthenticated
allowUnauthenticated
The Neo4j GraphQL Library expects an authorization header in the request object, which means you can authenticate users however you like. You could have a custom sign-in mutation, integrate with Auth0, or roll your own SSO server. The point here is that it’s just a JWT which the library decodes to make sure it’s valid - but it’s down to the user to issue tokens.
The example at Custom Resolvers demonstrates a hypothetical sign-up/sign-in flow using the OGM, which will be a good starting point for inspiration.
isAuthenticated
This is the most basic of authentication, used to ensure that there is a valid decoded JWT in the request. The most basic of type definitions could look something like the following, which states you must be authenticated to access Todo objects:
Graphql
Copy to Clipboard
type Todo {
    id: ID
    title: String
}

extend type Todo @auth(rules: [{ isAuthenticated: true }])
allowUnauthenticated
In some cases, you may want to allow unauthenticated requests while also having auth-based rules. You can use the allowUnauthenticated parameter to avoid throwing an exception if no auth is present in the context.
In the example below, only the publisher can see his blog posts if it is not published yet. Once the blog post is published, anyone can see it:
Graphql
Copy to Clipboard
type BlogPost
    @auth(
        rules: [
            {
                operations: [READ]
                where: { OR: [{ publisher: ""$jwt.sub"" }, { published: true }] }
                allowUnauthenticated: true
            }
        ]
    ) {
    id: ID!
    publisher: String!
    published: Boolean!
}
Global Authentication
Authorization
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm;"OGM
Contents
Excluded directives
Most applications won’t just expose a single GraphQL API. There may also be scheduled jobs, authentication and migrations keeping an application ticking over. The OGM (Object Graph Mapper) can be used to programmatically interact with your Neo4j GraphQL API, which may help with achieving these goals.
Installation
Examples
@private Directive
Selection Set
TypeScript Type Generation
API Reference
Before diving into the OGM, it’s important to have a good understanding of the Neo4j GraphQL Library first. It’s recommended to at least work through the Getting Started guide.
Excluded directives
The following directives are excluded from the OGM’s schema:
@auth
@exclude
@private
@readonly
@writeonly
This is because the OGM is only ever used programmatically, as opposed to an exposed API which needs these security measures.
See also: @private Directive
@neo4j/graphql-ogm
Installation
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/examples;"Examples
This chapter runs through some examples of how you might take advantage of the OGM.
Custom Resolvers - using the OGM in custom resolvers within your Neo4j GraphQL API
REST API - exposing your Neo4j GraphQL API through a REST API, using the OGM
Installation
Custom Resolvers
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/examples/custom-resolvers;"Custom Resolvers
A common case for using the OGM will be within custom resolvers inside a Neo4j GraphQL instance (very meta!), due to the fact that it has access to some fields which the Neo4j GraphQL Library may not. A common use case might be to have a password field marked with directive @private, and a custom resolver for creating users with passwords.
To get started with this example, create your example application directory, create a new project and also the file which will contain your application code:
Bash
Copy to Clipboard
mkdir ogm-custom-resolvers-example
cd ogm-custom-resolvers-example
npm init --yes
touch index.js
Then you need to install your dependencies:
Bash
Copy to Clipboard
npm install @neo4j/graphql-ogm graphql neo4j-driver apollo-server
Assuming a running Neo4j database at ""bolt://localhost:7687"" with username ""neo4j"" and password ""password"", in your empty index.js file, add the following code:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const { OGM } = require(""@neo4j/graphql-ogm"");
const { Neo4jGraphQLAuthJWTPlugin } = require(""@neo4j/graphql-plugin-auth"");
const { ApolloServer } = require(""apollo-server"");
const neo4j = require(""neo4j-driver"");

const { createJWT, comparePassword } = require(""./utils""); // example util functions

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const typeDefs = `
    type User {
        id: ID @id
        username: String!
        password: String! @private
    }

    type Mutation {
        signUp(username: String!, password: String!): String! ### JWT
        signIn(username: String!, password: String!): String! ### JWT
    }
`;

 ogm =  OGM({ typeDefs, driver });
 User = ogm.model();

 resolvers = {
    : {
        :  (_source, { username, password }) => {
             [existing] =  User.find({
                : {
                    username,
                },
            });

             (existing) {
                  ();
            }

             { users } =  User.create({
                : [
                    {
                        username,
                        password,
                    }
                ]
            });

             createJWT({ : users[].id });
        },
        :  (_source, { username, password }) => {
             [user] =  User.find({
                : {
                    username,
                },
            });

             (!user) {
                  ();
            }

             correctPassword =  comparePassword(password, user.password);

             (!correctPassword) {
                  ();
            }

             createJWT({ : user.id });
        },
    },
};

 neoSchema =  Neo4jGraphQL({
    typeDefs,
    driver,
    resolvers,
    : {
        :  Neo4jGraphQLAuthJWTPlugin({
            : 
        })
    }
});

.all([neoSchema.getSchema(), ogm.init()]).then( {
     server =  ApolloServer({
        schema,
        :  ({ req }),
    });

    server.listen().then( {
        .log();
    });
});
View all (81 more lines)
It’s important to note the JWT secret being passed into the Neo4jGraphQL constructor in this example.
Back in the command line, run the following command to start your server:
Bash
Copy to Clipboard
node index.js
You should see the following output:
Bash
Copy to Clipboard
🚀 Server ready at http://localhost:4000/
You can execute the signUp Mutation against this GraphQL API to sign up, but when you go to query the user through the same API, the password field will not be available.
Examples
REST API
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/examples/rest-api;"REST API
This example demonstrates how you might use the OGM without exposing a Neo4j GraphQL API endpoint. The example starts an Express server and uses the OGM to interact with the Neo4j GraphQL Library, exposed over a REST endpoint.
First, create your example application directory, create a new project and also the file which will contain yur application code:
Bash
Copy to Clipboard
mkdir ogm-rest-example
cd ogm-rest-example
npm init --yes
touch index.js
Then you need to install your dependencies:
Bash
Copy to Clipboard
npm install @neo4j/graphql-ogm graphql neo4j-driver express
Assuming a running Neo4j database at ""bolt://localhost:7687"" with username ""neo4j"" and password ""password"", in your empty index.js file, add the following code:
JavaScript
Copy to Clipboard
const express = require(""express"");
const { OGM } = require(""@neo4j/graphql-ogm"");
const neo4j = require(""neo4j-driver"");

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const typeDefs = `
    type User {
        id: ID
        name: String
    }
`;

 ogm =  OGM({ typeDefs, driver });
 User = ogm.model();

 app = express();

app.get(,  (req, res) => {
     { search, offset, limit, sort } = req.query;

     regex = search ?  : ;

     users =  User.find({
        : { : regex },
        : {
            offset,
            limit,
            sort
        }
    });

     res.json(users).end();
});

 port = ;

ogm.init().then( {
    app.listen(port, () => {
        .log()
    });
});
View all (30 more lines)
In your application directory, you can run this application:
Bash
Copy to Clipboard
node index.js
Which should output:
Bash
Copy to Clipboard
Example app listening at http://localhost:4000
The REST API should now be ready to accept requests at the URL logged.
Custom Resolvers
@private Directive
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/private;"@private Directive
Contents
Definition
Definition
Example use-case
The @private directive allows you to specify fields that should only be accessible through the OGM. This is very handy as you can hide fields such as passwords to the outside world. Simply put the @private directive on the field you wish to be inaccessible through the exposed API;
Definition
Definition
Graphql
Copy to Clipboard
""""""Instructs @neo4j/graphql to only expose a field through the Neo4j GraphQL OGM.""""""
directive @private on FIELD_DEFINITION
Example use-case
Graphql
Copy to Clipboard
type User {
    username: String!
    email: String!
    password: String! @private
}
Using the password field is a great example here. In your application, you would want to hash passwords and hide them from snoopers. You could have a custom resolver, using the OGM, to update and set passwords. This is more apparent when you want to use the same type definitions to drive a public-facing schema and an OGM:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const { OGM } = require(""@neo4j/graphql-ogm"");
const neo4j = require(""neo4j-driver"");

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

const typeDefs = `
    type User {
        username: String!
        email: String!
        password: String! @private
    }
`;


 neoSchema =  Neo4jGraphQL({ typeDefs, driver });


 ogm =  OGM({ typeDefs, driver });

.all([neoSchema.getSchema(), ogm.init()]).then( {
     apolloServer =  ApolloServer({ schema });
})
View all (11 more lines)
REST API
Selection Set
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/selection-set;"Selection Set
Contents
Selection set at execution time
Selection set as a static
This is a GraphQL specific term. When you execute a query, you have the operation:
Graphql
Copy to Clipboard
query {
    myOperation
}
And you also have a selection set. For example, from the example below:
Graphql
Copy to Clipboard
query {
    myOperation {
        field1
        field2
    }
}
The following snippet is the selection set:
Graphql
Copy to Clipboard
{
    field1
    field2
}
When using the OGM, you do not have to provide a selection set by default. Doing so would make using the OGM feel more like querying the GraphQL schema directly, when the OGM is designed as an abstraction over it. This is achieved by automatically generated basic selection sets. Given the following type definition:
Graphql
Copy to Clipboard
type Movie {
    id: ID
    name: String
    genres: [Genre!]! @relationship(type: ""IN_GENRE"", direction: OUT)
    customCypher: String! @cypher(statement: ""RETURN someCustomData"")
}

type Genre {
    name: String
}
Neither relationship fields nor custom Cypher fields are included in the generated selection set, as they could be computationally expensive. So, given the type definition above, the generated selection set would be:
Graphql
Copy to Clipboard
{
    id
    name
}
This means that by default, querying for Node(s), you would only get the .id and .name properties returned. If you want to select more fields, you can either define a selection set at execution time or as a static on the Model, as described below.
Selection set at execution time
Using this approach, you would pass in a selection set every time you interact with the OGM. This would be an appropriate approach if the selection set is going to be different every time you ask for data. A full example of this would be as follows:
JavaScript
Copy to Clipboard
const { OGM } = require(""@neo4j/graphql-ogm"")
const neo4j = require(""neo4j-driver"");

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

const typeDefs = `
    type Movie {
        id: ID
        name: String
        genres: [Genre!]! @relationship(type: ""IN_GENRE"", direction: OUT)
        customCypher: String! @cypher(statement: ""RETURN someCustomData"")
    }

    type Genre {
        name: String
    }
`;

 ogm =  OGM({ typeDefs, driver });
 Movie = ogm.model();

 selectionSet = ;

ogm.init().then( {
    Movie.find({ selectionSet }).then( {
        
    })
});
View all (26 more lines)
Note that the argument selectionSet is passed every invocation of the Movie.find() function.
Selection set as a static
Using this approach, you can assign a selection set to a particular Model, so that whenever it is queried, it will always return those fields. This is useful if the default selection set doesn’t quite give you enough data, but you don’t need the selection set to be dynamic on each request. See a full example below:
JavaScript
Copy to Clipboard
const { OGM } = require(""@neo4j/graphql-ogm"")
const neo4j = require(""neo4j-driver"");

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

const typeDefs = `
    type Movie {
        id: ID
        name: String
        genres: [Genre!]! @relationship(type: ""IN_GENRE"", direction: OUT)
        customCypher: String! @cypher(statement: ""RETURN someCustomData"")
    }

    type Genre {
        name: String
    }
`;

 ogm =  OGM({ typeDefs, driver });
 Movie = ogm.model();

 selectionSet = ;

Movie.selectionSet = selectionSet;

ogm.init().then( {
    Movie.find().then( {
        
    })
});
View all (27 more lines)
Note that despite not passing this selection set into Movie.find(), the requested fields will be returned on each request.
@private Directive
Type Generation
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/type-generation;"Type Generation
Contents
Example
When you use the .model() method, you receive a generic instance of the Model class. There has been an effort to type the args and the return values of each method on the model however, due to the fact that each model’s return values and args are dependant on what you have in your schema, we cant know ahead of time what each type is. You can use the generate() function exposed from the @neo4j/graphql package to generate the TypeScript types for your models each time you make a schema change.
Example
The example below imports the generate function from @neo4j/graphql and adds a conditional branch to check if the process.env.GENERATE variable has been set like this:
Bash
Copy to Clipboard
GENERATE=""true"" ts-node index.ts
Then, once you run this with the variable set, the types will be available and you can import and use them as a generic. Here is a full working example:
Typescript
Copy to Clipboard
import { OGM, generate } from ""@neo4j/graphql-ogm"";
import { ModelMap } from ""./ogm-types""; // this file will be auto-generated using 'generate'
import * as neo4j from ""neo4j-driver""
import * as path from ""path""

const typeDefs = `
    type Movie {
        id: ID
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

// Generic is applied on the OGM
const ogm = new OGM<ModelMap>({ typeDefs, driver });

const Movie = ogm.model(""Movie"");

async function main() {
    // Only generate types when you make a schema change
    if (process.env.GENERATE) {
        const outFile = path.join(__dirname, ""ogm-types.ts"");

        await generate({
            ogm,
            outFile,
        });

        console.log(""Types Generated"");

        process.exit(1);
    }

    // Get full autocomplete on `Movie`, including where argument properties plus the return value
    const [theMatrix] = await Movie.find({ where: { name: ""The Matrix"" } });
}
main()
View all (26 more lines)
Selection Set
API Reference
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference;"API Reference
OGM
Model
Type Generation
Type Generation
OGM
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/type-generation;"generate
Contents
Example with outFile
Example with noWrite
Either writes to specified outFile or returns a string - if noWrite is set.
Example with outFile
Will write to outFile:
Typescript
Copy to Clipboard
import { OGM, generate } from ""@neo4j/graphql-ogm"";

const typeDefs = `
    type Movie {
        id: ID
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

const ogm = new OGM({ typeDefs, driver });

await generate({
    ogm,
    outFile: ""path/to/my/file.ts"",
});

console.log(""Types Generated"");
View all (8 more lines)
Example with noWrite
Will return a string:
Typescript
Copy to Clipboard
import { OGM, generate } from ""@neo4j/graphql-ogm"";

const typeDefs = `
    type Movie {
        id: ID
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""admin"", ""password"")
);

const ogm = new OGM({ typeDefs, driver });

const source = await generate({
    ogm,
    noWrite: true,
});

console.log(""Types Generated "", source);
View all (8 more lines)
OGM
Model
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/ogm;"OGM
Contents
constructor
Example
init
model
Example
constructor
Returns an OGM instance.
Takes an input object as a parameter, which is then passed to the Neo4jGraphQL constructor. Supported options are listed in the documentation for Neo4jGraphQL.
Example
JavaScript
Copy to Clipboard
const ogm = new OGM({
    typeDefs,
});
init
Asynchronous method to initialize the OGM. Internally, calls Neo4jGraphQL.getSchema() to generate a GraphQL schema, and stores the result. Initializes any models which have been created before this execution, and will throw an error if any of them are invalid.
model
Returns a Model instance matching the passed in name, or (if the OGM has been initialized) throws an Error if one can’t be found.
Accepts a single argument name of type string.
Example
For the following type definitions:
Graphql
Copy to Clipboard
type User {
    username: String!
}
The following would successfully return a Model instance:
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");
The following would throw an Error:
JavaScript
Copy to Clipboard
const User = ogm.model(""NotFound"");
API Reference
generate
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/api-reference/neo4jgraphql;"Neo4jGraphQL
Contents
constructor
Example
Input
getSchema
checkNeo4jCompat
Example
Input
assertIndexesAndConstraints
Example
Input
constructor
Returns a Neo4jGraphQL instance.
Takes an input object as a parameter, the supported fields of which are described below.
Example
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs,
});
Input
Accepts all of the options from makeExecutableSchema, plus the additional arguments below:
Name and Type Description
driver

Type: Driver
An instance of a Neo4j driver.
config

Type: Neo4jGraphQLConfig
Additional Neo4j GraphQL configuration options.
features

Type: Neo4jFeaturesSettings
Could be used for configure/enable/disable specific features.
plugins

Type: Neo4jGraphQLPlugins
Plugins for the Neo4j GraphQL Library.
Neo4jGraphQLConfig
Name and Type Description
driverConfig

Type: DriverConfig
Additional driver configuration options.
enableRegex

Type: boolean
Whether to enable RegEx filters, see RegEx matching for more information.
queryOptions

Type: CypherQueryOptions
Cypher query options, see Query Tuning for more information.
skipValidateTypeDefs

Type: boolean
Can be used to disable strict type definition validation if you are encountering unexpected errors.
DriverConfig
Name and Type Description
database

Type: string
The name of the database within the DBMS to connect to.
bookmarks

Type: string or Array<string>
One or more bookmarks to use for the connection.
CypherQueryOptions
All options are enum types imported from @neo4j/graphql, for example:
JavaScript
Copy to Clipboard
const { CypherRuntime } = require(""@neo4j/graphql"");
Name and Type Description
runtime

Type: CypherRuntime
Possible options:

- CypherRuntime.INTERPRETED
- CypherRuntime.SLOTTED
- CypherRuntime.PIPELINED
planner

Type: CypherPlanner
Possible options:

- CypherPlanner.COST
- CypherPlanner.IDP
- CypherPlanner.DP
connectComponentsPlanner

Type: CypherConnectComponentsPlanner
Possible options:

- CypherConnectComponentsPlanner.GREEDY
- CypherConnectComponentsPlanner.IDP
updateStrategy

Type: CypherUpdateStrategy
Possible options:

- CypherUpdateStrategy.DEFAULT
- CypherUpdateStrategy.EAGER
expressionEngine

Type: CypherExpressionEngine
Possible options:

- CypherExpressionEngine.DEFAULT
- CypherExpressionEngine.INTERPRETED
- CypherExpressionEngine.COMPILED
operatorEngine

Type: CypherOperatorEngine
Possible options:

- CypherOperatorEngine.DEFAULT
- CypherOperatorEngine.INTERPRETED
- CypherOperatorEngine.COMPILED
interpretedPipesFallback

Type: CypherInterpretedPipesFallback
Possible options:

- CypherInterpretedPipesFallback.DEFAULT
- CypherInterpretedPipesFallback.DISABLED
- CypherInterpretedPipesFallback.WHITELISTED_PLANS_ONLY
- CypherInterpretedPipesFallback.ALL
replan

Type: CypherReplanning
Possible options:

- CypherReplanning.DEFAULT
- CypherReplanning.FORCE
- CypherReplanning.SKIP
Neo4jFeaturesSettings
Name and Type Description
filters

Type: Neo4jFiltersSettings
Additional configuration for filters.
Neo4jFiltersSettings
Name and Type Description
String

Type: Neo4jStringFiltersSettings
Additional configuration for String filters.
Neo4jStringFiltersSettings
Name and Type Description
GT

Type: boolean
Enables GT comparator.
GTE

Type: boolean
Enables GTE comparator.
LT

Type: boolean
Enables LT comparator.
LTE

Type: boolean
Enables LTE comparator.
Neo4jGraphQLPlugins
Name and Type Description
auth

Type: Neo4jGraphQLAuthPlugin
Plugin slot for auth capabilities.
getSchema
An asynchronous method that generates the GraphQL schema to be used in a server. The result is memoized, so if this is called twice, the schema is only generated once.
checkNeo4jCompat
Asynchronous method to check the compatibility of the specified DBMS, that either resolves to void in a successful scenario, or throws an error if the database is not compatible with the Neo4j GraphQL Library.
Takes an input object as a parameter, the supported fields of which are described below.
Example
Given any valid type definitions saved to the variable typeDefs and a valid driver instance saved to the variable driver, the following will confirm database compatibility:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
await neoSchema.checkNeo4jCompat();
Input
Accepts the arguments below:
Name and Type Description
driver

Type: Driver
An instance of a Neo4j driver.
driverConfig

Type: DriverConfig
Additional driver configuration options.
DriverConfig
Name and Type Description
database

Type: string
The name of the database within the DBMS to connect to.
bookmarks

Type: string or Array<string>
One or more bookmarks to use for the connection.
assertIndexesAndConstraints
Asynchronous method to assert the existence of database constraints, that either resolves to void in a successful scenario, or throws an error if the necessary constraints do not exist following its execution.
Takes an input object as a parameter, the supported fields of which are described below.
Example
Given the following type definitions saved to the variable typeDefs and a valid driver instance saved to the variable driver:
Graphql
Copy to Clipboard
type Book {
    isbn: String! @unique
}
And the construction of a Neo4jGraphQL, using:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
const schema = await neoSchema.getSchema();
The following will check whether a unique node property constraint exists for label ""Book"" and property ""isbn"", and throw an error if it does not:
JavaScript
Copy to Clipboard
await neoSchema.assertIndexesAndConstraints();
The next example will create the constraint if it does not exist:
JavaScript
Copy to Clipboard
await neoSchema.assertIndexesAndConstraints({ options: { create: true } });
Input
Accepts the arguments below:
Name and Type Description
driver

Type: Driver
An instance of a Neo4j driver.
driverConfig

Type: DriverConfig
Additional driver configuration options.
options

Type: AssertConstraintsOptions
Options for the execution of assertIndexesAndConstraints.
DriverConfig
Name and Type Description
database

Type: string
The name of the database within the DBMS to connect to.
bookmarks

Type: string or Array<string>
One or more bookmarks to use for the connection.
AssertConstraintsOptions
Name and Type Description
create

Type: boolean
Whether or not to create constraints if they do not yet exist. Disabled by default.
API Reference
@neo4j/graphql-ogm
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/troubleshooting;"Troubleshooting
Contents
Debug Logging
For @neo4j/graphql
For @neo4j/introspector
Query Tuning
This chapter contains common troubleshooting steps. Additionally, there is a section for FAQs (Frequently Asked Questions) where you might find answers to your problems.
Debug Logging
For @neo4j/graphql
@neo4j/graphql uses the debug library for debug-level logging. You can turn on all debug logging by setting the environment variable DEBUG to @neo4j/graphql:* when running. For example:
Bash
Copy to Clipboard
DEBUG=@neo4j/graphql:* node src/index.js
Alternatively, if you are debugging a particular functionality, you can specify a number of namespaces to isolate certain log lines:
@neo4j/graphql:* - Logs all
@neo4j/graphql:auth - Logs the status of authorization header and token extraction, and decoding of JWT
@neo4j/graphql:graphql - Logs the GraphQL query and variables
@neo4j/graphql:execute - Logs the Cypher and Cypher paramaters before execution, and summary of execution
For @neo4j/introspector
@neo4j/introspector has its own debug logging namespace and you can turn on logging for it with:
Bash
Copy to Clipboard
DEBUG=@neo4j/introspector node src/index.js
Read more about the introspector.
Query Tuning
Hopefully you won’t need to perform any query tuning, but if you do, the Neo4j GraphQL Library allows you to set the full array of query options on construction of the library.
You can read more about the available query options at https://neo4j.com/docs/cypher-manual/current/query-tuning/query-options/#cypher-query-options.
Please only set these options if you know what you are doing.
For example, in order to set the Cypher runtime to ""interpreted"":
JavaScript
Copy to Clipboard
const { Neo4jGraphQL, CypherRuntime } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");
const { ApolloServer } = require(""apollo-server"");

const typeDefs = `
    type Movie {
        title: String!
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

 neoSchema =  Neo4jGraphQL({
    typeDefs,
    driver,
    : {
        : {
            : CypherRuntime.INTERPRETED,
        },
    },
});

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        :  ({ req }),
    });

    server.listen().then( {
        .log();
    });
});
View all (20 more lines)
4.0.0 Migration
FAQs
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/introspector;"Introspect schema from an existing Neo4j database
Contents
Features
Limitations
Usage examples
Introspect and persist to file
Introspect and spin up a read-only schema
Neo4j provides a tool that enables you, with very little effort, to generate GraphQL type definitions from an existing database. This is provided by a separate npm package, @neo4j/introspector.
This is usually a one-time-thing and should be considered a starting point for a GraphQL schema.
Features
This tool has full support for generating type definitions, including:
@relationship directive, including relationship properties
@node
label for mapping where a node label might use a character that’s not in the GraphQL supported character set
additionalLabels for nodes that has multiple labels
Generating a read-only version of the GraphQL type definitions, i.e. generate a @exclude(operations: [CREATE, DELETE, UPDATE]) directive on all node types.
Limitations
If an element property has mixed types through out your graph, that property will be excluded from the generated type definitions. The reason for this is that your GraphQL server will throw an error if it finds data that doesn’t match the specified type.
If any properties are skipped, there will be output in the Debug Logging.
Usage examples
Currently there’s a programmatic API for introspecting the Neo4j schema and generating GraphQL type definitions.
Introspect and persist to file
This example introspects the database schema, generates GraphQL type definitions and persists them to a file schema.graphql.
You can then serve this file with your GraphQL server.
JavaScript
Copy to Clipboard
const { toGraphQLTypeDefs } = require(""@neo4j/introspector"")
const neo4j = require(""neo4j-driver"");
const fs = require('fs');

const driver = neo4j.driver(
    ""neo4j://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const sessionFactory = () => driver.session({ defaultAccessMode: neo4j.session.READ })

// We create a async function here until ""top level await"" has landed
// so we can use async/await
async function main() {
    const typeDefs = await toGraphQLTypeDefs(sessionFactory)
    fs.writeFileSync(, typeDefs)
     driver.close();
}
main()
View all (4 more lines)
Introspect and spin up a read-only schema
This example generates a read-only version of the schema from the database and immediately spins up an Apollo server.
Here the type definitions are never persisted to disk.
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const { toGraphQLTypeDefs } = require(""@neo4j/introspector"")
const neo4j = require(""neo4j-driver"");

const driver = neo4j.driver(
    ""neo4j://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const sessionFactory = () => driver.session({ defaultAccessMode: neo4j.session.READ })

// We create a async function here until ""top level await"" has landed
// so we can use async/await
async function main() {
    const readonly = true; // We don't want to expose mutations in this case
     typeDefs =  toGraphQLTypeDefs(sessionFactory, readonly)

     neoSchema =  Neo4jGraphQL({ typeDefs, driver });

     server =  ApolloServer({
        :  neoSchema.getSchema(),
        :  ({ req }),
    });
}

main();
View all (11 more lines)
aggregate
GraphQL Toolbox
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model/aggregate;"aggregate
Contents
Example
Arguments
This method can be used to aggregate nodes, and maps to the underlying schema Aggregate.
Example
Find the longest User name:
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

const usersAggregate = await User.aggregate({
    aggregate: {
        name: {
            longest: true
        }
    }
});
Find the longest User name where name starts with the letter ""D"":
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

const usersAggregate = await User.aggregate({
    where: {
        name_STARTS_WITH: ""D""
    },
    aggregate: {
        name: {
            longest: true
        }
    }
});
Arguments
Name and Type Description
where

Type: GraphQLWhereArg
A JavaScript object representation of the GraphQL where input type used for Filtering.
delete
Introspector
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model/delete;"delete
Contents
Example
Arguments
This method can be used to delete nodes, and maps to the underlying Delete Mutation.
Returns a Promise which resolvers to a DeleteInfo object:
Name and Type Description
nodesDeleted

Type: number
The number of nodes deleted.
relationshipsDeleted

Type: number
The number of relationships deleted.
Example
To delete all User nodes where the name is ""Dan"":
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

await User.delete({ where: { name: ""Dan"" }});
Arguments
Name and Type Description
where

Type: GraphQLWhereArg
A JavaScript object representation of the GraphQL where input type used for Filtering.
delete

Type: string or DocumentNode or SelectionSetNode
A JavaScript object representation of the GraphQL delete input type used for Delete Mutations.
context

Type: any
The context value for the GraphQL Mutation.
rootValue

Type: any
The rootValue value for the GraphQL Mutation.
update
aggregate
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model/update;"update
Contents
Example
Arguments
This method can be used to update nodes, and maps to the underlying Update Mutation.
Returns a Promise that resolves to the equivalent of the Mutation response for this operation.
Example
For the User with name ""John"", update their name to be ""Jane"":
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

const { users } = await User.update({
    where: { name: ""John"" },
    update: { name: ""Jane"" },
});
Arguments
Name and Type Description
where

Type: GraphQLWhereArg
A JavaScript object representation of the GraphQL where input type used for Filtering.
update

Type: any
A JavaScript object representation of the GraphQL update input type used for Update Mutations.
connect

Type: any
A JavaScript object representation of the GraphQL connect input type used for Update Mutations.
disconnect

Type: any
A JavaScript object representation of the GraphQL disconnect input type used for Update Mutations.
create

Type: any
A JavaScript object representation of the GraphQL create input type used for Update Mutations.
options

Type: GraphQLOptionsArg
A JavaScript object representation of the GraphQL options input type used for Sorting and Pagination.
selectionSet

Type: string or DocumentNode or SelectionSetNode
Selection set for the Mutation, see Selection Set for more information.
args

Type: any
The args value for the GraphQL Mutation.
context

Type: any
The context value for the GraphQL Mutation.
rootValue

Type: any
The rootValue value for the GraphQL Mutation.
find
delete
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/mutations/update;"Update
Contents
Single update
Nested create
connectOrCreate relationships
Using the following type definitions for these examples:
Graphql
Copy to Clipboard
type Post {
    id: ID! @id
    content: String!
    creator: User! @relationship(type: ""HAS_POST"", direction: IN)
}

type User {
    id: ID! @id
    name: String
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}
The following update Mutations and response types will be generated for the above type definitions:
Graphql
Copy to Clipboard
type UpdatePostsMutationResponse {
    posts: [Post!]!
}

type UpdateUsersMutationResponse {
    users: [User!]!
}

type Mutation {
    updatePosts(
        where: PostWhere
        update: PostUpdateInput
        connect: PostConnectInput
        disconnect: PostDisconnectInput
        create: PostCreateInput
        delete:
    ):!
    updateUsers(
        where:
        update:
        connect:
        disconnect:
        create:
        delete:
    ):!
}
View all (11 more lines)
The id field not be update-able as the @id directive has been used.
Single update
Say you wanted to edit the content of a Post:
Graphql
Copy to Clipboard
mutation {
    updatePosts(
        where: {
            id: ""892CC104-A228-4BB3-8640-6ADC9F2C2A5F""
        }
        update: {
            content: ""Some new content for this Post!""
        }
    ) {
        posts {
            content
        }
    }
}
Nested create
Instead of creating a Post and connecting it to a User, you could update a User and create a Post as part of the Mutation:
Graphql
Copy to Clipboard
mutation {
    updateUsers(
        where: { name: ""John Doe"" }
        create: {
            posts: [
                { node: { content: ""An interesting way of adding a new Post!"" } }
            ]
        }
    ) {
        users {
            id
            name
            posts {
                content
            }
        }
    }
}
View all (3 more lines)
connectOrCreate relationships
If a related node has a @unique or @id directive defined, connectOrCreate can be used in a nested update to perform a MERGE operation on the related node, creating a new relationship and the related node if it doesn’t exist.
Consider the following type definitions:
Graphql
Copy to Clipboard
type Actor {
    name: String!
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    title: String
    id: ID! @id
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}
Because a movie ID is unique, connectOrCreate can be used in an Actor mutation to ensure a movie exists before connecting. Note that only @unique or @id fields can be used in where:
Graphql
Copy to Clipboard
mutation {
  updateActors(
    update: {
        movies: {
          connectOrCreate: {
            where: { node: { id: ""1234"" } }
            onCreate: { node: { title: ""Forrest Gump"" } }
          }
        }
    },
    where: { name: ""Tom Hanks"" }
  ) {
    info {
      nodesCreated
    }
  }
}
In this case, all actors matching ""Tom Hanks"" will be connected to the Movie with id ""1234"". If the movie with given ID does not exist, it will be created with the title ""Forrest Gump"".
For update operations, connectOrCreate can also be used as a top-level input:
Graphql
Copy to Clipboard
mutation {
  updateActors(
      connectOrCreate: {
        movies: {
            where: { node: { id: ""1234"" } }
            onCreate: { node: { title: ""Forrest Gump"" } }
        }
      },
      where: { name: ""Tom Hanks"" }
  ) {
    info {
      nodesCreated
    }
  }
}
This operation is equivalent to the previous example.
Create
Delete
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/mutations/delete;"Delete
Contents
Single Delete
Nested Delete
Using the following type definitions for these examples:
Graphql
Copy to Clipboard
type Post {
    id: ID! @id
    content: String!
    creator: User! @relationship(type: ""HAS_POST"", direction: IN)
}

type User {
    id: ID! @id
    name: String
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}
The following delete Mutations and response type will be generated for the above type definitions:
Graphql
Copy to Clipboard
type DeleteInfo {
    nodesDeleted: Int!
    relationshipsDeleted: Int!
}

type Mutation {
    deletePosts(where: PostWhere, delete: PostDeleteInput): DeleteInfo!
    deleteUsers(where: UserWhere, delete: UserDeleteInput): DeleteInfo!
}
Note that the DeleteInfo type is the common return type for all delete Mutations.
Single Delete
A single post can be deleted by executing the following GraphQL statement:
Graphql
Copy to Clipboard
mutation {
    deletePosts(where: {
        id: ""6042E807-47AE-4857-B7FE-1AADF522DE8B""
    }) {
        nodesDeleted
        relationshipsDeleted
    }
}
This will delete the post using the autogenerated ID that would have been returned after that post’s creation.
nodesDeleted would equal 1 (the post) and relationshipsDeleted would also equal equal 1 (the HAS_POST relationship between the Post and its author).
Nested Delete
Say that if when you delete a User, you want to delete all of their Posts as well. This can be achieved using a single nested delete operations:
Graphql
Copy to Clipboard
mutation {
    deleteUsers(
        where: {
            name: ""Jane Doe""
        },
        delete: {
            posts: [
                where: { }
            ]
        }
    ) {
        nodesDeleted
        relationshipsDeleted
    }
}
You may look at that empty where argument and wonder what that’s doing. By the time the traversal has reached that argument, it has the context of only posts that were created by Jane Doe, as the traversals to those Post nodes were from her User node. Essentially, the above query is equivalent to:
Graphql
Copy to Clipboard
mutation {
    deleteUsers(
        where: {
            name: ""Jane Doe""
        },
        delete: {
            posts: [
                where: {
                    node: {
                        creator: {
                            name: ""Jane Doe""
                        }
                    }
                }
            ]
        }
    ) {
        nodesDeleted
        relationshipsDeleted
    }
}
View all (6 more lines)
Slightly easier to reason with, but the output Cypher statement will have a redundant WHERE clause!
Update
Subscriptions
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions;"Subscriptions
Contents
Subscriptions with Auth
GraphQL subscriptions add real-time capabilities to your API. Subscriptions allow to listen for changes on the database.
The following subscriptions are available when using @neo4j/graphql:
Create - Listen for newly created nodes.
Update - Listen for changes to existing nodes.
Delete - Listen for deleted nodes.
Create Relationship - Listen for newly created relationships.
Delete Relationship - Listen for deleted relationships.
All events will be triggered individually, even in events caused by the same Mutation. Events are fired on the creation or deletion of nodes and relationships, and on the update of nodes.
Only changes made through @neo4j/graphql will trigger events. Changes made directly to the database or using the @cypher directive will not trigger any event.
Subscriptions with Auth
Some auth clauses can be used with subscriptions. How these work is documented here.
Delete
Getting Started
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/events/delete_relationship;"Delete Relationship Subscriptions
Contents
DELETE_RELATIONSHIP event
Examples
Delete Relationships with Standard Types
Delete Relationship with Abstract Types
Non-reciprocal relationships
Special Considerations
Types using the same Neo4j label
Subscriptions to DELETE_RELATIONSHIP events will listen for relationships to a node of the specified type that have been deleted.
This subscription operation is only available for types that define relationship fields.
As relationship-specific information, the event will contain the relationship field name, as well as an object containing all relationship field names of the specified type. This object will be populated with properties according to the deleted relationship.
A new event will be triggered for each deleted relationship.
This means that, if the type targeted for the subscriptions defines two or more relationships in the schema and one of each relationships are deleted following a mutation operation, the number of events triggered will be equivalent to the number of relationships deleted.
Each event will have the relationships object populated with the deleted relationship’s properties for one single relationship name only - all other relationship names will have a null value.
The event will also contain the properties of the nodes at both ends of the relationship, as well as the properties of the new relationship, if any.
The DELETE_RELATIONSHIP events represent relationships being deleted and contain information about the nodes at each end of the new relationship. However, the disconnected nodes may or may not have been deleted in the process. To subscribe to the node’s updates, you need to use the DELETE subscriptions.
DELETE_RELATIONSHIP event
A subscription to a type can be made with the top-level subscription [type]RelationshipDeleted. The subscription will contain the following fields:
event: The event triggering this subscription, in this case it will always be ""DELETE_RELATIONSHIP"".
timestamp: The timestamp in which the mutation was made. Note that multiple events may come with the same timestamp if triggered by the same query.
<typename>: The properties of the node target to the subscription. Only top-level properties, without relationships, are available. Note these are the properties before the operation that triggered the DELETE_RELATIONSHIP took place.
relationshipFieldName: The field name of the deleted relationship, as part of the node target to the subscription.
deletedRelationship: An object having as keys all field names of the node target to the subscription which represent its relationships. For any given event, all field names except the one corresponding to relationshipFieldName will be null. The field name equal to relationshipFieldName will contain the relationship properties if defined, and a node key containing the properties of the node on the other side of the relationship. Only top-level properties, without relationships, are available. Note these are the properties before the operation that triggered the DELETE_RELATIONSHIP took place.
Irrespective of the relationship direction in the database, the DELETE_RELATIONSHIP event is bound to the type targeted for the subscription. The consequence is that - given a relationship between types A and B that is not reciprocal (that is, in the GraphQL schema type A defines a relationship to B but B does not define a relationship to A) and a GraphQL operation that deletes the relationship between them - even though the two nodes will be disconnected in the database, the DELETE_RELATIONSHIP event will only be returned to the subscription to type A. Check out the Non-reciprocal Relationships section below for more details.
For example, considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    reviewers: [Reviewer] @relationship(type: ""REVIEWED"", direction: IN, properties: ""Reviewed"")
}

type Actor {
    name: String
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}

 {
    name:
    reputation:
}

  {
    score:!
}
View all (9 more lines)
An ongoing subscription to deleted relationships from the Movie type, upon a mutation deleting then Actor named Tom Hardy and the Reviewer named Jane from a Movie titled Inception would receive the following events:
Graphql
Copy to Clipboard
{
    # 1  - relationship type `ACTED_IN`
    event: ""DELETE_RELATIONSHIP"",
    timestamp,
    movie: {
        title: ""Inception"",
        genre: ""Adventure""
    },
    relationshipFieldName: ""actors"", # notice the field name specified here is populated below in the `createdRelationship` object
    deletedRelationship: {
        actors: {
            screenTime: 1000, # relationship properties for the relationship type `ACTED_IN` that was deleted
            node: { # top-level properties of the node at the other end of the relationship, in this case `Actor` type, before the delete occured
                name: ""Tom Hardy""
            }
        },
        reviewers:  
    }
}
{
    
    event: ,
    timestamp,
    movie: {
        title: ,
        genre: 
    },
    relationshipFieldName: , 
    deletedRelationship: {
        actors: , 
        reviewers: { 
            score: ,
            node: {
                name: ,
                reputation: 
            }
        }
    }
}
View all (24 more lines)
Examples
Delete Relationships with Standard Types
For example, considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
}

type Actor {
    name: String
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}
A subscription to any Movie deleted relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        deletedRelationship {
            actors {
                screenTime
                node {
                    name
                }
            }
        }
    }
}
View all (4 more lines)
Delete Relationship with Abstract Types
When using Abstract Types with relationships, you will need to specify one or more of the corresponding Concrete Types when performing the subscription operation.
These types are generated by the library and conform to the format [type]EventPayload, where [type] is a Concrete Type.
Union Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    directors: [Director!]! @relationship(type: ""DIRECTED"", properties: ""Directed"", direction: IN)
}

union Director = Person | Actor

type Actor {
    name: String
}

type Person {
    name: String
    reputation: Int
}

  {
    year:!
}
View all (5 more lines)
A subscription to Movie deleted relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        deletedRelationship {
           directors {
                year
                node {
                    ... on PersonEventPayload { # generated type
                        name
                        reputation
                    }
                      { 
                        name
                    }
                }
            }
        }
    }
}
View all (10 more lines)
Interface Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    reviewers: [Reviewer!]! @relationship(type: ""REVIEWED"", properties: ""Review"", direction: IN)
}

interface Reviewer {
    reputation: Int!
}

type Magazine implements Reviewer {
    title: String
    reputation: Int!
}

 implements {
    name:
    reputation:!
}

 {
    score:!
}
View all (9 more lines)
A subscription to Movie deleted relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        deletedRelationship {
            reviewers {
                score
                node {
                    reputation
                    ... on MagazineEventPayload { # generated type
                        title
                        reputation
                    }
                      { 
                        name
                        reputation
                    }
                }
            }
        }
    }
}
View all (12 more lines)
Non-reciprocal relationships
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    directors: [Director!]! @relationship(type: ""DIRECTED"", properties: ""Directed"", direction: IN)
}

type Actor {
    name: String
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: OUT)
}

type Person {
    name: String
    reputation: Int
}

 = |

  {
    screenTime:!
}

  {
    year:!
}
View all (11 more lines)
The type definitions contain 2 relationships: types ACTED_IN and DIRECTED.
It can be observed that the ACTED_IN relationship has a corresponding field defined in both the Movie and Actor types. As such, we can say that ACTED_IN is a reciprocal relationship.
DIRECTED on the other hand is only defined in the Movie type. The Director type does not define a matching field. As such, we can say DIRECTED is not a reciprocal relationship.
Let us now take a look at how we can subscribe to deleted relationships for the 3 types defined above:
Movie
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        deletedRelationship {
           actors { # corresponds to the `ACTED_IN` relationship type
                screenTime
                node {
                    name
                }
           }
           directors { 
                year
                node {
                      {
                        name
                        reputation
                    }
                      {
                        name
                    }
                }
            }
        }
    }
}
View all (16 more lines)
Person
As the Person type does not define any relationships, it is not possible to subscribe to DELETE_RELATIONSHIP events for this type.
Actor
Graphql
Copy to Clipboard
subscription {
    actorRelationshipDeleted {
        event
        timestamp
        actor {
            name
        }
        relationshipFieldName
        deletedRelationship {
           movies { # corresponds to the `ACTED_IN` relationship type
                screenTime
                node {
                    title
                    genre
                }
           }
           
        }
    }
}
View all (5 more lines)
The presence of the movie field inside of deletedRelationship for the actorRelationshipDeleted subscription reflects the fact that the ACTED_IN typed relationship is reciprocal.
Therefore, when a relationship of this type is deleted, such as by running the following mutations:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                actors: {
                    create: [
                        {
                            node: {
                                name: ""Keanu Reeves""
                            },
                            edge: {
                                screenTime: 420
                            }
                        }
                    ]
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}

 {
    deleteMovies(
        where: {
            title: 
        }
    ) {
        nodesDeleted
    }
}
View all (22 more lines)
Two events will be published (given that we subscribed to DELETE_RELATIONSHIP events on both types):
Graphql
Copy to Clipboard
{
    # from `movieRelationshipDeleted`
    event: ""DELETE_RELATIONSHIP""
    timestamp
    movie {
        title: ""John Wick"",
        genre: ""Action""
    }
    relationshipFieldName: ""actors"",
    deletedRelationship {
        actors: {
            screenTime: 420,
            node: {
                name: ""Keanu Reeves""
            }
        },
        directors: 
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        movies: {
            screenTime: ,
            node: {
                title: ,
                genre: 
            }
        }
    }
}
View all (22 more lines)
Since the DIRECTED relationship between types Movie and Director is not reciprocal, executing the following mutations:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                directors: {
                    Actor: { # relationship 1
                        create: [
                            {
                                node: {
                                    name: ""Woody Allen""
                                },
                                edge: {
                                    year: 1989
                                }
                            }
                        ]
                    },
                   : { 
                        create: [
                            {
                                node: {
                                    name: ,
                                    reputation: 
                                },
                                edge: {
                                    year: 
                                }
                            }
                        ]
                    }
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}

 {
    deleteMovies(
        where: {
            title: 
        }
    ) {
        nodesDeleted
    }
}
View all (38 more lines)
Two events will be published (given that we subscribed to DELETE_RELATIONSHIP events on the Movie type):
Graphql
Copy to Clipboard
{
    # relationship 1 - from `movieRelationshipDeleted`
    event: ""DELETE_RELATIONSHIP""
    timestamp
    movie {
        title: ""New York Stories"",
        genre: ""Comedy""
    }
    relationshipFieldName: ""directors"",
    deletedRelationship {
        actors: null,
        directors: {
            year: 1989,
            node: {
                name: ""Woody Allen""
            }
        }
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        actors: ,
        directors: {
            year: ,
            node: {
                 name: ,
                reputation: 
            }
        }
    }
}
View all (24 more lines)
Special Considerations
Types using the same Neo4j label
One case that deserves special consideration is overriding the label in Neo4j for a specific GraphQL type. This can be achieved using the @node directive, by specifying the label argument.
While this section serves an informative purpose, it should be mentioned that, in the majority of cases, this is not the recommended approach of designing your API.
Consider the following type definitions:
Graphql
Copy to Clipboard
type Actor @node(label: ""Person"") {
    name: String
    movies: [Movie!]! @relationship(type: ""PART_OF"", direction: OUT)
}

typePerson {
    name: String
    movies: [Movie!]! @relationship(type: ""PART_OF"", direction: OUT)
}

type Movie {
    title: String
    genre: String
    people: [Person!]!  @relationship(type: ""PART_OF"", direction: IN)
    actors: [Actor!]!  @relationship(type: ""PART_OF"", direction: IN)
}
Although we have 3 GraphQL types, in Neo4j there will only ever be 2 types of nodes: labeled Movie or labeled Person.
At the database level there is no distinction between Actor and Person. Therefore, when deleting a relationship of type PART_OF, there will be one event for each of the 2 types.
Considering the following subscriptions:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        deletedRelationship {
           people { # corresponds to the `PART_OF` relationship type
                node {
                    name
                }
           }
           actors { 
                node {
                    name
                }
           }
        }
    }
}

 {
    actorRelationshipDeleted {
        event
        timestamp
        actor {
            name
        }
        relationshipFieldName
        deletedRelationship {
           movies { 
                node {
                    title
                    genre
                }
           }
        }
    }
}
View all (27 more lines)
Running the following mutations:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                people: { # relationship 1
                    create: [
                        {
                            node: {
                                name: ""John Logan""
                            }
                        }
                    ]
                },
                actors: {  # relationship 2
                    create: [
                        {
                            node: {
                                name: 
                            }
                        }
                    ]
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}

 {
    deleteMovies(
        where: {
            title: 
        }
    ) {
        nodesDeleted
    }
}
View all (28 more lines)
Result in the following events:
Graphql
Copy to Clipboard
{
    # relationship 1 `people` - for GraphQL types `Movie`, `Person`
    event: ""DELETE_RELATIONSHIP""
    timestamp
    movie {
        title: ""Sweeney Todd"",
        genre: ""Horror""
    }
    relationshipFieldName: ""people"",
    deletedRelationship {
        people: {
            node: {
                name: ""John Logan""
            }
        },
        actors: 
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        people: ,
        actors: {
            node: {
                name: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        people: {
            node: {
                name: 
            }
        },
        actors: 
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        people: ,
        actors: {
            node: {
                name: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
View all (91 more lines)
Had we subscribed to Person as well, we would have received two more events:
Graphql
Copy to Clipboard
{
    # relationship 1 `movies` - for GraphQL types `Person`, `Movie`
    event: ""DELETE_RELATIONSHIP""
    timestamp
    actor {
        name: ""John Logan""
    }
    relationshipFieldName: ""movies"",
    deletedRelationship {
        movies: {
            node: {
                title: ""Sweeney Todd"",
                genre: ""Horror""
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    deletedRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
View all (20 more lines)
Create Relationship
Filtering
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/filtering;"Filtering
Contents
Operators
Equality operators
Numerical operators
String comparison
Array comparison
AND, OR operators
Subscribing to node events
Create
Update
Delete
Combining operators
Subscribing to relationship events
Create Relationship
Delete Relationship
Relationship-related filters
Filtering via implicit/explicit declaration
Abstract Types
Filtering can only be applied at the root of the Subscription operation.
Aggregations are not supported on subscription types, so there is currently no way to apply filter on these fields.
A Subscription can be created to target the changes to a node (Create/Update/Delete) or to a relationship (Create/Delete).
While the format slightly differs depending on whether the subscription targets a node or a relationship, providing a where argument allows for filtering on the events that are returned to the subscription.
Operators
When creating a Subscription, a number of operators are available for different types in the where argument.
Equality operators
All types can be tested for either equality or non-equality. For the Boolean type, these are the only available comparison operators.
Numerical operators
The following comparison operators are available for numeric types (Int, Float, BigInt)
_LT
_LTE
_GTE
_GT
Filtering on Temporal Types and Spatial Types: is not yet supported.
String comparison
The following case-sensitive comparison operators are only available for use on String and ID types:
_STARTS_WITH
_NOT_STARTS_WITH
_ENDS_WITH
_NOT_ENDS_WITH
_CONTAINS
_NOT_CONTAINS
Array comparison
The following two comparison operators are available on non-array fields, and accept an array argument:
_IN
_NOT_IN
Conversely, the following operators are available on array fields, and accept a single argument:
_INCLUDES
_NOT_INCLUDES
These four operators are available for all types apart from Boolean.
AND, OR operators
Complex combinations of operators are possible using the AND/ OR operators.
AND/OR operators accept as argument an array of items of the same format as the where argument.
Check out a usage example in the Combining operators section below.
Subscribing to node events
The where argument allows for specifying filters on top-level properties of the targeted nodes. Only events matching these properties and type will be returned to the subscription.
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    averageRating: Float
}
Below are some example of how filtering can be applied when creating a subscription.
Create
We can filter our movies by their genre:
Graphql
Copy to Clipboard
subscription {
    movieCreated(where: {genre: ""Drama""}) {
        createdMovie {
            title
        }
    }
}
This way, only newly created movies with the genre ""Drama"" will trigger events to this subscription.
where will only filter by properties set at the moment of creation.
Update
We can filter our movies with the average rating bigger than 8:
Graphql
Copy to Clipboard
subscription {
    movieUpdate(where: {averageRating_GT: 8}) {
        updatedMovie {
            title
        }
    }
}
This way, we will only receive events triggered by movies with the average rating bigger than 8 being modified.
Where will only filter by existing properties before the update.
Graphql
Copy to Clipboard
mutation {
    makeTheMatrix: createMovies(input: {title: ""The Matrix"", averageRating: 8.7}) {
        title
        averageRating
    },
    makeResurrections: createMovies(input: {title: ""The Matrix Resurrections"", averageRating: 5.7}) {
        title
        averageRating
    },
}

mutation {
    updateTheMatrix: updateMovie(
        where: {title: ""The Matrix""}
        update: {averageRating: 7.9}
    ) {
        title
    },
    updateResurrections: updateMovie(
        where: {title: }
        update: {averageRating: }
    ) {
        title
    }
}
View all (10 more lines)
Therefore, given the above subscription, these GraphQL operations will only be triggered for ""The Matrix"" movie.
Delete
we can filter our movies by their genre with the NOT filter:
Graphql
Copy to Clipboard
subscription {
    movieDeleted(where: {genre_NOT: ""Comedy""}) {
        deletedMovie {
            title
        }
    }
}
This way, only deleted movies of all genres except for ""Comedy"" will trigger events to this subscription.
Where will only filter by existing properties right before deletion.
Combining operators
All above-mentioned operators can be combined using the AND/OR operators. They accept an array argument with items of the same format as the where argument, which means they can also be nested to form complex combinations.
Say we are picky fans of comedy movies and we only accept ratings below 7 for movies released before the 2000’s. As an exception we also like the movie ""The Matrix"". However, we do not like any of its sequels. We could subscribe to any updates that we are interested in as follows:
Graphql
Copy to Clipboard
subscription {
    movieUpdate(where: {
        OR: [
            {title_ENDS_WITH: ""The Matrix""},
            {AND: [
                {genre: ""comedy""},
                {OR: [
                    {releasedIn_LTE: 2000},
                    {releasedIn_GT: 2000, averageRating_GT: 7}
                ]}
            ]}
        ]
    }) {
        updatedMovie {
            title
        }
    }
}
Subscribing to relationship events
When subscribing to relationship events, the where argument still allows for specifying filters on the top-level properties of the targeted nodes, and also supports specifying filters on the relationship properties (edge) and on the top-level properties (node) of the nodes at the other end of the relationship. This is done by using the operators described above, and the usage is very similar to the one in Subscribing to node events.
The relationship-related filtering logic is even more powerful, as filters can also express the expected relationship field, or the expected concrete type at the other end of the relationship when having relationships to Abstract Types. Note that each relationship field specified is combined with the others using a logical OR. Only events matching these relationship field names will be returned in the Subscription.
You can further filter each relationship field by node and relationship properties. As per usual, these fields are combined in the resulting filter with a logical AND.
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: IN)
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}

type Actor {
    name: String
}
The format of the where argument is:
Graphql
Copy to Clipboard
{
    movie: {
        # top-level properties of the node targeted for the subscription operation, supports operators
        title_IN: [""The Matrix"", ""Fight Club""]
    },
    createdRelationship: {
        actors: { # field name corresponding to a relationship in the type definition of the node targeted for the subscription operation
            edge: {
                 # properties of the relationship, supports operators
                screenTime_GT: 10,
            },
            node: {
                # top-level properties of the node on the other end of the relationship, supports operators
                name_STARTS_WITH: ""Brad""
            }
        }
    }
}
View all (3 more lines)
Below are some example of how filtering can be applied when creating a subscription to relationship events.
Create Relationship
The following example filters the subscriptions to newly created relationships that are connecting a Movie from genres other than ""Drama"", to an Actor with a screen time bigger than 10:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated(where: { movie: { genre_NOT: ""Drama"" }, createdRelationship: { actors: { edge: { screenTime_GT: 10 } } } }) {
        movie {
            title
        }
        createdRelationship {
            actors {
                screenTime
                node {
                    name
                }
            }
        }
    }
}
where will only filter by properties set at the moment of creation.
Delete Relationship
The following example filters the subscriptions to deleted relationships that were connecting a Movie of genre Comedy or Adventure to an Actor named ""Jim Carrey"":
Graphql
Copy to Clipboard
subscription {
    movieRelationshipDeleted(where: { movie: { genre_IN: [""Comedy"", ""Adventure""] }, createdRelationship: { actors: { node: { name: ""Jim Carrey"" } } } }) {
        movie {
            title
        }
        deletedRelationship {
            actors {
                screenTime
                node {
                    name
                }
            }
        }
    }
}
Where will only filter by existing properties right before deletion.
Relationship-related filters
In addition to filtering on node or relationship properties, the relationship-related filtering logic is even more powerful, as filters can also express the expected relationship field, or the expected concrete type at the other end of the relationship when having relationships to Abstract Types.
The following examples are valid for both CREATE_RELATIONSHIP/DELETE_RELATIONSHIP events. Their purpose is to illustrate the various ways in which a subscription to a relationship event can be filtered in a variety of ways.
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: IN)
    directors: [Director!]! @relationship(type: ""DIRECTED"", properties: ""Directed"", direction: IN)
    reviewers: [Reviewer!]! @relationship(type: ""REVIEWED"", properties: ""Review"", direction: IN)
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}

type Actor {
    name: String
}

 implements {
    name:
    reputation:
}

 = |

  {
    year:!
}

 {
    reputation:!
}

 implements {
    title:
    reputation:!
}

 {
    score:!
}
View all (24 more lines)
And the base subscription operation:
Graphql
Copy to Clipboard
subscription MovieRelationshipDeleted($where: MovieRelationshipDeletedSubscriptionWhere) {
    movieRelationshipDeleted(where: $where) {
        movie {
            title
        }
        deletedRelationship {
            actors {
                screenTime
                node {
                    name
                }
            }
            directors {
                year
                node {
                      { 
                        name
                        reputation
                    }
                      { 
                        name
                    }
                }
            }
            reviewers {
                score
                node {
                    reputation
                      { 
                        title
                        reputation
                    }
                      { 
                        name
                        reputation
                    }
                }
            }
        }
    }
}
View all (26 more lines)
Given the above subscription, you can use the following where inputs in the GraphQL variable values to get different results.
Filtering via implicit/explicit declaration
Implicit or explicit declaration is used to filter on the specific relationship types that are expected to be returned to a subscription.
For example, when subscribing to created or deleted relationships to a Movie we might only be interested in the relationship of type ACTED_IN, indifferent to the properties of the Actor node or of the relationship to it. Note that the corresponding field name of this relationship is actors.
By explicitly specifying the actors field name, we filter-out events to other relationship properties:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: {} # no properties specified here, therefore all relationships to this field name will be returned
        }
    }
}
If we were interested in Actor nodes conforming to some filters, for example with the name starting with the letter ""A"", it is no different than when Subscribing to node events:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: {
                node: { # use operations to specify filers on the top-level properties of the node at the other end of the relationship
                    name_STARTS_WITH: ""A""
                }
            }
        }
    }
}
Or we could also be interested in the relationship itself conforming to some filters, like the Actor to have spent no more than 40 minutes in the Movie:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: {
                edge: { # use operations to specify filers on the top-level properties of the relationship
                    screenTime_LT: 40,
                }
                node: {
                    name: ""Alvin""
                }
            }
        }
    }
}
Multiple relationship types can be included in the returned subscriptions by explicitly specifying the corresponding field names like so:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: {}, # include all relationships corresponding of type `ACTED_IN`
            directors: {} # include all relationships corresponding of type `DIRECTED`
            # exclude relationships of type `REVIEWED`
        }
    }
}
In case we are interested in all relationship types, we can either express this implicitly by not specifying any:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {} # include all relationships of all types
    }
}
Or explicitly by specifying the field names of all the relationships connected to the type targeted for the subscription:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            # include all relationships of all types
            # subscription target type is `Movie`, which has the following relationship field names:
            actors: {},
            directors: {},
            reviewers: {}
        }
    }
}
As soon as we want to apply any filter to any of the relationships, explicitly including those that we are interested in is mandatory
For example if all relationships should be returned, but we want to filter-out the REVIEWED ones with a score less than 7:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: {}, # include all relationships of type `ACTED_IN`
            directors: {}, # include all relationships of type `DIRECTED`
            reviewers: { # include all relationships of type `REVIEWED`, with the score property greater than 7
                edge: {
                    score_GT: 7
                }
            }
        }
    }
}
Different filters can be applied to the different relationships without any constraints:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            actors: { # include some relationships of type `ACTED_IN`, filtered by relationship property `screenTime` and node property `name`
                edge: {
                    screenTime_LT: 60,
                },
                node: {
                    name_IN: [""Tom Hardy"", ""George Clooney""]
                }
            },
            directors: {}, # include all relationships of type `DIRECTED`
            reviewers: { # include some relationships of type `REVIEWED`, filtered by relationship property `score` only
                edge: {
                    score_GT: 7
                }
            }
        }
    }
}
View all (5 more lines)
Note that in the above, there is an implicit logical OR between the actors, directors and reviewers, relationship fields. I.e. a relationship of either type ACTED_IN or of type DIRECTED or of type REVIEWED will trigger the subscription above.
Note that there is an implicit logical AND between the edge and node fields inside of the actors relationship field. I.e. a relationship of type ACTED_IN with the property screenTime less than 60 and a target node with name in [""Tom Hardy"", ""George Clooney""] will trigger the subscription.
Abstract Types
Union Type
The following example illustrates how to filter on the node at the other end of the relationship when it is of a Union type:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: { # relationship to a union type
                Person: { # concrete type that makes up the union type
                    edge: {
                        year_GT: 2010
                    },
                    node: {
                        name: ""John Doe"",
                        reputation: 10
                    }
                },
                Actor: { # concrete type that makes up the union type
                    edge: {
                        year_LT: 
                    },
                    node: {
                        name: 
                    }
                }
            },
        }
    }
}
View all (10 more lines)
The result is that only relationships of type DIRECTED are returned to the subscription, where the Director is a Person named John Doe who directed the movie after 2010, or where the Director is an Actor named Tom Hardy who directed the movie before 2005.
Note that the relationship field name is split into multiple sections, one for each of the Concrete types that make up the Union type. The relationship properties do not exist outside the confines of one of these sections, even though the properties are the same.
What about the example above that did not explicitly specify the Concrete types?
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: {}, # include all relationships of type `DIRECTED`
        }
    }
}
Following the same logic as for the relationship field names, when nothing is explicitly provided then all is accepted. Thus relationships of type DIRECTED between a Movie and any of the Concrete types that make up the Union type Director will be returned to the subscription. It is therefore equivalent to the following:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: { # include all relationships of type `DIRECTED`
                Actor: {},
                Person: {}
            }
        }
    }
}
Of course, it follows that explicitly specifying a Concrete type will exclude the other from the returned events:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: {
                Actor: {} # include all relationships of type `DIRECTED` to an `Actor` type
            }
        }
    }
}
In this case, only relationships of type DIRECTED between a Movie and an Actor will be returned to the subscription, those between a Movie and a Person being filtered out.
One reason why this might be done is to include some filters on the Actor type:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: {
                Actor: { # include some relationships of type `DIRECTED` to an `Actor` type, that conform to the filters
                    node: {
                        name_NOT: ""Tom Hardy""
                    }
                }
            }
        }
    }
}
To include filters on the Actor type but also include Person type in the result, we need to make the intent explicit:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            directors: {
                Actor: { # include some relationships of type `DIRECTED` to an `Actor` type, that conform to the filters
                    node: {
                        name_NOT: ""Tom Hardy""
                    }
                },
                Person: {} # include all relationships of type `DIRECTED` to a `Person` type
            }
        }
    }
}
Interface Type
The following example illustrates how to filter on the node at the other end of the relationship when it is of an Interface type:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            reviewers: { # relationship to an interface type
                edge: {
                    # relationship properties of a relationship of type `REVIEWED`
                    score_GT: 7
                },
                node: {
                    # common fields declared by the interface
                    reputation_GTE: 8
                    _on: { # specific fields depending on the concrete type
                        Person: { # concrete type that makes up the interface type
                            name: ""Jane Doe"",
                            reputation_GTE: 7
                        },
                       : { 
                            title_IN: [, ],
                            reputation_LT: 
                        }
                    }
                }
            },
        }
    }
}
View all (11 more lines)
The above will return events for relationships between the type Movie and Reviewer, where the score is greater than 7 and the Reviewer is a Person named ""Jane Doe"" with a reputation greater or equal to 7, or the Reviewer is a Magazine with the reputation of 8.
Notice how the reputation field is part of the Interface type, and can thus be specified in 3 ways: inside the node key, inside each Concrete type, or in both places. When specified in both places, the filter is composed with a logical AND. Type Person overrides the reputation_GTE operator so the final filter is reputation_GTE: 7, while type Magazine composes the original operator so the final filter is the interval reputation_GTE: 8 && reputation_LT: 9.
To get all relationships of type REVIEWED with a certain score returned, we can make use of the implicit filtering like so:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            reviewers: {
                edge: { # include some relationships of type `REVIEWED` to both `Person` and `Magazine` Concrete types, that conform to the filters
                    score: 10
                },
            },
        }
    }
}
Even for relationships of type REVIEWED to a Reviewer of a specific reputation, we can still make use of the implicit filtering:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            reviewers: {
                node: { # include some relationships of type `REVIEWED` to both `Person` and `Magazine` Concrete types, that conform to the filters
                    reputation: 9
                }
            },
        }
    }
}
It is only when a specific Concrete type needs to be filtered that we need to be explicit in the Concrete types that we are interested in:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            reviewers: {
                node: {
                    _on: {
                        Person: { # include some relationships of type `REVIEWED` to Concrete type `Person`, that conform to the filters
                            name: ""Jane Doe"",
                            reputation_GTE: 9
                        },
                    }
                }
            },
        }
    }
}
The above will not include relationships of type REVIEWED to the Magazine type. We can include them by making the intent explicit:
Graphql
Copy to Clipboard
{
    where: {
        deletedRelationship: {
            reviewers: {
                node: {
                    _on: {
                        Person: { # include some relationships of type `REVIEWED` to Concrete type `Person`, that conform to the filters
                            name: ""Jane Doe"",
                            reputation_GTE: 9
                        },
                        Magazine: {} # include all relationships of type `REVIEWED` to Concrete type `Magazine`
                    }
                }
            },
        }
    }
}
Delete Relationship
Horizontal Scaling
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/types;"Types
Contents
Int
Float
String
Boolean
ID
BigInt
Temporal Types
DateTime
Date
Duration
LocalDateTime
Time
LocalTime
Spatial Types
Point
CartesianPoint
Neo4j GraphQL supports all of the default GraphQL scalar types as well as additional scalar and object types specific to the Neo4j database.
Int
One of the default GraphQL scalar types. Supports up to 53-bit values - see BigInt for 64-bit value support.
Float
One of the default GraphQL scalar types.
String
One of the default GraphQL scalar types.
Boolean
One of the default GraphQL scalar types.
ID
One of the default GraphQL scalar types. Stored as a string in the database and always returned as a string.
BigInt
Supports up to 64 bit integers, serialized as strings in variables and in data responses. Shares the same Numerical operators as the other numeric types.
Graphql
Copy to Clipboard
type File {
    size: BigInt
}
Can be passed as a number (does not need quotes) when used directly in a query or mutation:
Graphql
Copy to Clipboard
query {
    files(where: { size: 9223372036854775807 }) {
        size
    }
}
Temporal Types
DateTime
ISO datetime string stored as a datetime temporal type.
Graphql
Copy to Clipboard
type User {
    createdAt: DateTime
}
Date
""yyyy-mm-dd"" date string stored as a date temporal type.
Graphql
Copy to Clipboard
type Movie {
    releaseDate: Date
}
Duration
ISO 8601 duration string stored as a duration type.
Graphql
Copy to Clipboard
type Movie {
    runningTime: Duration!
}
Note:
Decimal values are not currently accepted on [YMWD]
Comparisons are made according to the Cypher Developer Guide
LocalDateTime
""YYYY-MM-DDTHH:MM:SS"" datetime string stored as a LocalDateTime temporal type.
Graphql
Copy to Clipboard
type Movie {
    nextShowing: LocalDateTime
}
Time
RFC3339 time string stored as a Time temporal type.
Graphql
Copy to Clipboard
type Movie {
    nextShowing: Time
}
LocalTime
""HH:MM:SS[.sss+]"" time string stored as a LocalTime temporal type.
Graphql
Copy to Clipboard
type Movie {
    nextShowing: LocalTime
}
Spatial Types
Neo4j GraphQL spatial types translate to spatial values stored using point in the database. The use of either of these types in a GraphQL schema will automatically introduce the types needed to run queries and mutations relevant to these spatial types.
Point
The Point type is used to describe the two Geographic coordinate reference systems supported by Neo4j.
In order to use it in your schema, you quite simply add a field with a type Point to any type or types in schema, like the following:
Graphql
Copy to Clipboard
type TypeWithPoint {
    location: Point!
}
Once this has been done, the Point type will be automatically added to your schema, in addition to all of the input and output types you will need to query and manipulate spatial types through your API.
The rest of the documentation under this heading is documenting all of those automatically generated types and how to use them.
Type definition
Graphql
Copy to Clipboard
type Point {
    latitude: Float!
    longitude: Float!
    height: Float
}
Queries and Mutations
Due to the fact that Point is an object type, it has an additional type for input in queries and mutations. However, this input type has the same shape as the object type:
Graphql
Copy to Clipboard
input PointInput {
    latitude: Float!
    longitude: Float!
    height: Float
}
Query
For example, you can query for a User with an exact location:
Graphql
Copy to Clipboard
query Users($longitude: Float!, $latitude: Float!) {
    users(where: { location: { longitude: $longitude, latitude: $latitude } }) {
        name
        location {
            longitude
            latitude
        }
    }
}
Mutation
An example of creating a User with a location is as follows:
Graphql
Copy to Clipboard
mutation CreateUsers($name: String!, $longitude: Float!, $latitude: Float!) {
    createUsers(input: [{ name: $name, location: { longitude: $longitude, latitude: $latitude } }]) {
        users {
            name
            location {
                longitude
                latitude
            }
        }
    }
}
Filtering
In addition to the Numerical operators, the Point type has an additional _DISTANCE filter. All of the filters take the following type as an argument:
Graphql
Copy to Clipboard
input PointDistance {
    point: Point!
    distance: Float!
}
In essence, each of the filters mean the following:
_LT: Checks that the specified point field is less than the distance away in meters from the Point being compared against.
_LTE: Checks that the specified point field is less than or equal to the distance away in meters from the Point being compared against.
_DISTANCE: Checks that the specified point field is the exact distance away in meters from the Point being compared against.
_GTE: Checks that the specified point field is greater than the distance away in meters from the Point being compared against.
_GT: Checks that the specified point field is greater than or equal to the distance away in meters from the Point being compared against.
In practice, you can construct queries such as the following which will find all users within a 5km (5000m) radius of a Point:
Graphql
Copy to Clipboard
query CloseByUsers($longitude: Float!, $latitude: Float!) {
    users(where: { location_LTE: { point: { longitude: $longitude, latitude: $latitude }, distance: 5000 } }) {
        name
        location {
            longitude
            latitude
        }
    }
}
CartesianPoint
The CartesianPoint type is used to describe the two Cartesian coordinate reference systems supported by Neo4j.
In order to use it in your schema, you quite simply add a field with a type CartesianPoint to any type or types in schema, like the following:
Graphql
Copy to Clipboard
type TypeWithCartesianPoint {
    location: CartesianPoint!
}
Once this has been done, the CartesianPoint type will be automatically added to your schema, in addition to all of the input and output types you will need to query and manipulate spatial types through your API.
The rest of the documentation under this heading is documenting all of those automatically generated types and how to use them.
Type definition
Graphql
Copy to Clipboard
type CartesianPoint {
    x: Float!
    y: Float!
    z: Float
}
Queries and Mutations
Due to the fact that CartesianPoint is an object type, it has an additional type for input in queries and mutations. However, this input type has the same shape as the object type:
Graphql
Copy to Clipboard
input CartesianPointInput {
    x: Float!
    y: Float!
    z: Float
}
Filtering
In addition to the Numerical operators, the CartesianPoint type has an additional _DISTANCE filter. All of the filters take the following type as an argument:
Graphql
Copy to Clipboard
input CartesianPointDistance {
    point: CartesianPoint!
    distance: Float!
}
In essence, each of the filters mean the following:
_LT: Checks that the specified point field is less than the distance away from the CartesianPoint being compared against, in the units used to specify the points.
_LTE: Checks that the specified point field is less than or equal to the distance away from the CartesianPoint being compared against, in the units used to specify the points.
_DISTANCE: Checks that the specified point field is the exact distance away from the CartesianPoint being compared against, in the units used to specify the points.
_GTE: Checks that the specified point field is greater than the distance away from the CartesianPoint being compared against, in the units used to specify the points.
_GT: Checks that the specified point field is greater than or equal to the distance away from the CartesianPoint being compared against, in the units used to specify the points.
Basics
Union Types
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/basics;"Basics
Contents
Nodes
Relationships
Relationship properties
Each type in your GraphQL type definitions can be mapped to an entity in your Neo4j database.
Nodes
The most basic mapping is of GraphQL types to Neo4j nodes, where the GraphQL type name maps to the Neo4j node label.
For example, to represent a node with label ""Movie"" and a single property ""title"" of type string:
Graphql
Copy to Clipboard
type Movie {
    title: String
}
Relationships
Relationships are represented by marking particular fields with a directive. This directive, @relationship, defines the relationship type in the database, as well as which direction that relationship goes in.
Add a second node type, ""Actor"", and connect the two together:
Graphql
Copy to Clipboard
type Movie {
    title: String
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}

type Actor {
    name: String
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}
Note there is a directive on each ""end"" of the relationship in this case, but it is not essential.
Relationship properties
In order to add relationship properties to a relationship, you need to add a new type to your type definitions, but this time it will be of type interface. For example, for your ""ACTED_IN"" relationship, add a property ""roles"":
Graphql
Copy to Clipboard
type Movie {
    title: String
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
}

type Actor {
    name: String
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT, properties: ""ActedIn"")
}

interface ActedIn @relationshipProperties {
    roles: [String]
}
Note that in addition to this new interface type, there is an added a key properties in the existing @relationship directives.
Type Definitions
Types
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions;"Type Definitions
Basics - Learn how to define your nodes and relationships using GraphQL type definitions.
Types - Learn about the various data types available in the Neo4j GraphQL Library.
Unions - Learn about GraphQL unions and how they map to the Neo4j database.
Interfaces - Learn about GraphQL interfaces and how they map to the Neo4j database.
Relationships - Learn more about defining relationships using the Neo4j GraphQL Library.
Access Control - Learn about how to restrict access to certain types or fields.
Autogeneration - Learn about certain types which you can enable autogeneration of values for.
@cypher directive - Learn about how to add custom Cypher to your type definitions.
Default Values - Learn about different ways of setting default values for particular fields.
Database Mapping - Learn how to map the GraphQL Schema fields to custom Neo4j node and relationship properties.
Indexes and Constraints - Learn how to use schema directives to add indexes and constraints to your Neo4j database.
Infer GraphQL Type Definitions - If you have an existing database, you can learn how to automatically generate the type definition file from that.
Getting Started
Basics
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/unions;"Union Types
Contents
Querying a union
Creating a union
The Neo4j GraphQL Library supports the use of unions on relationship fields. For example, the following schema defines a User type, that has a relationship HAS_CONTENT, of type [Content!]!. Content is of type union representing either a Blog or a Post.
Graphql
Copy to Clipboard
union Content = Blog | Post

type Blog {
    title: String
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}

type Post {
    content: String
}

type User {
    name: String
    content: [Content!]! @relationship(type: ""HAS_CONTENT"", direction: OUT)
}
Below you can find some examples of how queries and mutations work with this example.
Querying a union
Which union members are returned by a Query are dictated by the where filter applied.
For example, the following will return all user content, and you will specifically get the title of each blog.
Graphql
Copy to Clipboard
query GetUsersWithBlogs {
    users {
        name
        content {
            ... on Blog {
                title
            }
        }
    }
}
Whilst the query below will only return blogs. You could for instance use a filter to check that the title is not null to essentially return all blogs:
Graphql
Copy to Clipboard
query GetUsersWithAllContent {
    users {
        name
        content(where: { Blog: { title_NOT: null }}) {
            ... on Blog {
                title
            }
        }
    }
}
This is to prevent overfetching, and you can find an explanation of this here.
Creating a union
The below mutation creates the user and their content:
Graphql
Copy to Clipboard
mutation CreateUserAndContent {
    createUsers(
        input: [
            {
                name: ""Dan""
                content: {
                    Blog: {
                        create: [
                            {
                                node: {
                                    title: ""My Cool Blog""
                                    posts: {
                                        create: [
                                            {
                                                node: {
                                                    content: 
                                                }
                                            }
                                        ]
                                    }
                                }
                            }
                        ]
                    }
                }
            }
        ]
    ) {
        users {
            name
        }
    }
}
View all (18 more lines)
Types
Interface Types
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/appendix/preventing-overfetching;"Preventing overfetching
When querying for unions and interfaces in Cypher, each union member/interface implementation is broken out into a subquery and joined with UNION. For example, using one of the examples above, when we query with no where argument, each subquery has a similar structure:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
    WITH this
    OPTIONAL MATCH (this)-[has_content:HAS_CONTENT]->(blog:Blog)
    RETURN { __resolveType: ""Blog"", title: blog.title }
UNION
    WITH this
    OPTIONAL MATCH (this)-[has_content:HAS_CONTENT]->(journal:Post)
    RETURN { __resolveType: ""Post"" }
}
Now if you were to leave both subqueries and add a WHERE clause for blogs, it would look like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
    WITH this
    OPTIONAL MATCH (this)-[has_content:HAS_CONTENT]->(blog:Blog)
    WHERE blog.title IS NOT NULL
    RETURN { __resolveType: ""Blog"", title: blog.title }
UNION
    WITH this
    OPTIONAL MATCH (this)-[has_content:HAS_CONTENT]->(journal:Post)
    RETURN { __resolveType: ""Post"" }
}
As you can see, the subqueries are now ""unbalanced"", which could result in massive overfetching of Post nodes.
So, when a where argument is passed in, only union members which are in the where object are fetched, so it is essentially acting as a logical OR gate, different from the rest of the where arguments in the schema:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
    WITH this
    OPTIONAL MATCH (this)-[has_content:HAS_CONTENT]->(blog:Blog)
    WHERE blog.title IS NOT NULL
    RETURN { __resolveType: ""Blog"", title: blog.title }
}
Appendix
Deprecations
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/appendix;"Appendix
Preventing overfetching - details on the steps taken to prevent overfetching when dealing with unions and interfaces.
Optimizing create operations
Preventing overfetching
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/troubleshooting/optimizing-create-operations;"Optimizing create operations
Contents
Subscriptions enabled
@populated_by
connect and connectOrCreate operations
It’s possible to use the Neo4jGraphQL library to create several nodes and relationships in a single mutation, however, it’s well known that performance issues are present in performing this task. A solution has been implemented that doesn’t require any changes from the user. However, there are still several situations where this kind of optimization is not achievable.
Subscriptions enabled
No optimizations are available if a Subscription plugin it’s being used.
@populated_by
No optimizations are available if a Node affected by the mutation has a field with the directive @populated_by.
connect and connectOrCreate operations
No optimizations are available if the GraphQL input contains the connect or connectOrCreate operation.
Security
Appendix
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/troubleshooting/security;"Security
Contents
Authorization not triggered for empty match
This chapter describes security considerations and known issues.
Authorization not triggered for empty match
If a query yields no results, the Authorization process will not be triggered. This means that the result will be empty, instead of throwing an authentication error. Unauthorized users may then discern whether or not a certain type exists in the database, even if data itself cannot be accessed.
FAQs
Optimizing create operations
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/troubleshooting/faqs;"FAQs
Contents
I’ve upgraded from <1.1.0 and my DateTime fields aren’t sorting as expected
I’ve created some data and then gone to query it, but it’s not there
What is _emptyInput in my update and create inputs?
Relationship nullability isn’t being enforced in my graph
This chapter contains commonly asked questions and their solutions.
I’ve upgraded from <1.1.0 and my DateTime fields aren’t sorting as expected
Due to a bug in versions less than 1.1.0, there is a chance that your DateTime fields are stored in the database as strings instead of temporal values. You should perform a rewrite of those properties in your database using a Cypher query. For an example where the affected node has label ""Movie"" and the affected property is ""timestamp"", you can do this using the following Cypher:
JavaScript
Copy to Clipboard
MATCH (m:Movie)
WHERE apoc.meta.type(m.timestamp) = ""STRING""
SET m.timestamp = datetime(m.timestamp)
RETURN m
I’ve created some data and then gone to query it, but it’s not there
If you use a causal cluster or an Aura Professional instance, there is a chance that the created data is not yet present on the server which gets connected to on the next GraphQL query.
You can ensure that the data is available to query by passing a bookmark into your request - see Specifying Neo4j Bookmarks for more information.
What is _emptyInput in my update and create inputs?
_emptyInput will appear in your update and create inputs if you define a type with only auto-generated and/or relationship properties. It is a placeholder property and therefore giving it a value in neither update nor create will give it a value on the node. _emptyInput will be removed if you add a user-provided property.
The following example will create inputs with _emptyInput:
Graphql
Copy to Clipboard
type Cookie {
    id: ID! @id
    owner: Owner!  @relationship(type: ""HAS_OWNER"", direction: OUT)
    # f: String # If you don't want _emptyInput, uncomment this line.
}
Relationship nullability isn’t being enforced in my graph
Currently, and given the typeDefs below, Neo4j GraphQL will enforce cardinality when creating and updating a one-one relationship such as the movie director field below:
Graphql
Copy to Clipboard
type Movie {
    title: String!
    director: Person! @relationship(type: ""DIRECTED"", direction: IN)
    actors: [Person!]! @relationship(type: ""ACTED_IN"", direction: IN)
}

type Person {
    name: String!
}
However, at this point, there is no mechanism to support validating the actors relationship. Furthermore, there is a known limitation given if you were create a movie and a director in one mutation:
Graphql
Copy to Clipboard
mutation {
  createMovies(
    input: [
      {
        title: ""Forrest Gump""
        director: { create: { node: { name: ""Robert Zemeckis"" } } }
      }
    ]
  ) {
    movies {
      title
      director {
        name
      }
    }
  }
}
Then delete the director node:
Graphql
Copy to Clipboard
mutation {
  deletePeople(where: { name: ""Robert Zemeckis"" }) {
    nodesDeleted
  }
}
No error is thrown, even though the schema states that all movies must have a director thus technically rendering the movie node invalid.
Finally, we do not enforce relationship cardinality on union or interface relationships.
Troubleshooting
Security
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/driver-configuration;"Driver Configuration
Contents
Neo4j Driver
Neo4j GraphQL Library
OGM
Database Compatibility
Neo4jGraphQL
OGM
Specifying Neo4j database
Context
Neo4jGraphQL constructor
Specifying Neo4j version
Context
Specifying Neo4j Bookmarks
Neo4j Driver
Either an instance of the Neo4j JavaScript driver must be passed in on construction of your Neo4jGraphQL instance (or alternatively, OGM), or a driver, session or transaction passed into the context.executionContext per request.
The examples in this chapter assume a Neo4j database running at ""bolt://localhost:7687"" with a username of ""neo4j"" and a password of ""password"".
Neo4j GraphQL Library
Driver in Neo4jGraphQL constructor
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        :  ({ req }),
    });
});
View all (8 more lines)
Driver in context
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        :  ({ req, : driver }),
    });
});
View all (8 more lines)
OGM
JavaScript
Copy to Clipboard
const { OGM } = require(""@neo4j/graphql-ogm"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const ogm = new OGM({ typeDefs, driver });
Database Compatibility
Use the checkNeo4jCompat method available on either a Neo4jGraphQL or OGM instance to ensure the specified DBMS is of the required version, and has the necessary functions and procedures available. The checkNeo4jCompat will throw an Error if the DBMS is incompatible, with details of the incompatibilities.
Neo4jGraphQL
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
await neoSchema.checkNeo4jCompat();
OGM
JavaScript
Copy to Clipboard
const { OGM } = require(""@neo4j/graphql-ogm"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const ogm = new OGM({ typeDefs, driver });
await ogm.checkNeo4jCompat();
Specifying Neo4j database
There are two ways to specify which database within a DBMS should be used.
Context
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        : { : { :  } },
    });
});
View all (8 more lines)
Neo4jGraphQL constructor
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    driver,
    : {
        : {
            : ,
        },
    },
});

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
    });
});
View all (15 more lines)
Specifying Neo4j version
When a connection is established, the library automatically detect the version of the Neo4j instance connected. The version will be then stored and used for the following queries. It is also possible to specify manually the Neo4j version in the Context.
Context
JavaScript
Copy to Clipboard
const { Neo4jGraphQL, Neo4jDatabaseInfo } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        : { :  Neo4jDatabaseInfo() },
    });
});
View all (8 more lines)
Specifying Neo4j Bookmarks
You might have a requirement to specify Neo4j bookmarks when executing a query against your GraphQL schema. Primarily you will need to do this to chain transactions to ensure causal consistency if using a causal cluster or Aura Professional.
You can read more about causal consistency in the clustering chapter of the Neo4j Operations manual, and more about bookmark chaining in the driver manual.
You can ask for the bookmark in the selection set from the info object of a Mutation response. For example, for a type User:
Graphql
Copy to Clipboard
mutation($name: String!) {
    createUsers(input: [{ name: $name }]) {
        info {
            bookmark
        }
        users {
            name
        }
    }
}
You can then pass this bookmark into the context of a subsequent query, like this setup to pass in via a HTTP request header for example:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });

neoSchema.getSchema().then( {
     server =  ApolloServer({
        schema,
        :  ({ : { : [req.headers[]] } }),
    });
});
View all (8 more lines)
GraphQL Toolbox
Guides
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides;"Guides
Contents
Usage with frameworks
Migration guides
Here you can find a selection of guides to help you work with the Neo4j GraphQL Library.
Usage with frameworks
Usage with Next.js - guide on how to use @neo4j/graphql with Next.js.
Migration guides
Migration Guide - migrating from neo4j-graphql-js to @neo4j/graphql
2.0.0 Migration - migrating from version 1.* of @neo4j/graphql to version 2.* for relationship property support
3.0.0 Migration - migrating from version 2.* of @neo4j/graphql to version 3.*
4.0.0 Migration - migrating from version 3.* of @neo4j/graphql to version 4.*
Driver Configuration
Usage with Next.js
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/migration-guide;"Migration Guide
Contents
How to Upgrade
@neo4j/graphql was never intended to be a drop-in replacement for neo4j-graphql-js. However, simple applications should have a fairly trivial migration process.
How to Upgrade
You need to uninstall the old library and install the new one (and its peer dependencies) using npm or your package manager of choice:
Bash
Copy to Clipboard
npm uninstall neo4j-graphql-js
npm install @neo4j/graphql graphql neo4j-driver
From this point on, see each section within this guide:
Server for how to generate a schema and host it using Apollo Server, including database configuration
Type Definitions for the changes needed in your type definitions, including GraphQL types and directives
Queries for how you need to change your queries to work with the new schema
Mutations for how you need to change your mutations to work with the new schema
Subscriptions are not supported at this stage.
Usage with Next.js
Server
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/migration-guide/queries;"Queries
Contents
Filtering (where)
Sorting and Pagination (options)
Sorting
Pagination
Using neo4j-graphql-js, all of the arguments for a Query were root-level arguments. For example, for the following simple type definition:
Graphql
Copy to Clipboard
type Movie {
    title: String!
    averageRating: Float
}
The following Query would have been generated:
Graphql
Copy to Clipboard
type Query {
    Movie(title: String, averageRating: Float, first: Int, offset: Int, orderBy: [_MovieOrdering], filter: _MovieFilter): [Movie]
}
In @neo4j/graphql, the ethos has been to simplify the top-level arguments:
Graphql
Copy to Clipboard
type Query {
    movies(where: MovieWhere, options: MovieOptions): [Movie]!
}
Changes to note for migration:
Query fields were previously named in the singular, and in PascalCase - they are now pluralized and in camelCase
Query return types were previously in nullable lists of nullable types - they are now non-nullable lists of non-nullable types, e.g. [Movie] is now [Movie!]!; ensuring either an array of defined Movie objects or an empty array.
In this example, the _MovieFilter type has essentially been renamed to MovieWhere, the filter arguments renamed to where, and the top-level field arguments title and averageRating removed - see Filtering (where) below
The first, offset and orderBy have been collapsed into the MovieOptions type and renamed limit, offset and sort, respectively - see Sorting and Pagination (options) below
Filtering (where)
Simple equality fields are no longer available at the root of Query fields. As a simple demonstration, a simple query using neo4j-graphql-js that looked like:
Graphql
Copy to Clipboard
query {
    Movie(title: ""Forrest Gump"") {
        averageRating
    }
}
Is now changed to the following using @neo4j/graphql:
Graphql
Copy to Clipboard
query {
    movies(where: { title: ""Forrest Gump"" }) {
        averageRating
    }
}
When discussing how the field where of type MovieWhere differs to the field filter of _MovieFilter the following table can be used for guidance:
Table 1. Comparing the fields of the _MovieFilter and MovieWhere types
neo4j-graphql-js @neo4j/graphql
AND: [_MovieFilter!]
AND: [MovieWhere!]
OR: [_MovieFilter!]
OR: [MovieWhere!]
title: String
title: String
title_not: String
title_NOT: String
title_in: [String!]
title_IN: [String!]
title_not_in: [String!]
title_NOT_IN: [String!]
title_contains: String
title_CONTAINS: String
title_not_contains: String
title_NOT_CONTAINS: String
title_starts_with: String
title_STARTS_WITH: String
title_not_starts_with: String
title_NOT_STARTS_WITH: String
title_ends_with: String
title_ENDS_WITH: String
title_not_ends_with: String
title_NOT_ENDS_WITH: String
title_regexp: String
title_MATCHES: String
averageRating: Float
averageRating: Float
averageRating_not: Float
averageRating_NOT: Float
averageRating_in: [Float!]
averageRating_IN: [Float]
averageRating_not_in: [Float!]
averageRating_NOT_IN: [Float]
averageRating_lt: Float
averageRating_LT: Float
averageRating_lte: Float
averageRating_LTE: Float
averageRating_gt: Float
averageRating_GT: Float
averageRating_gte: Float
averageRating_GTE: Float
For filtering on relationship fields, the _some, _none, _single and _every filters are not yet implemented.
Sorting and Pagination (options)
Sorting
Sorting has changed somewhat in @neo4j/graphql. For the example being used in this page, the _MovieOrdering type in neo4j-graphql-js was an enum which looked like the following:
Graphql
Copy to Clipboard
enum _MovieOrdering {
    title_asc
    title_desc
    averageRating_asc
    averageRating_desc
}
You could then query all movies ordered by title ascending by executing:
Graphql
Copy to Clipboard
query {
    Movie(orderBy: [title_asc]) {
        title
    }
}
In @neo4j/graphql, the sorting type MovieSort has become an input type with each field as an enum, like follows:
Graphql
Copy to Clipboard
enum SortDirection {
    ASC
    DESC
}

input MovieSort {
    title: SortDirection
    averageRating: SortDirection
}
To fetch all movies sorted by title ascending as per above, you would execute:
Graphql
Copy to Clipboard
query {
    movies(options: { sort: [{ title: ASC }] }) {
        title
    }
}
Pagination
Pagination is broadly similar, with the arguments just renamed and moved a level deeper. For example, to return ""page 3, with 10 results per page"" using neo4j-graphql-js was:
Graphql
Copy to Clipboard
query {
    Movie(offset: 20, first: 10) {
        title
    }
}
Using @neo4j/graphql, this will now be:
Graphql
Copy to Clipboard
query {
    movies(options: { offset: 20, limit: 10 }) {
        title
    }
}
Type Definitions
Mutations
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/migration-guide/type-definitions;"Type Definitions
Contents
Directives
@relation
Relationship Properties
@cypher
@neo4j_ignore
@isAuthenticated, @hasRole and @hasScope
@additionalLabels
@id
@unique, @index and @search
Types
Scalar Types
Temporal Types (DateTime, Date)
Spatial Types
Interface Types
Union Types
Fields
_id
This page will walk through what needs to change in your type definitions before you can pass them into @neo4j/graphql.
Directives
Both neo4j-graphql-js and @neo4j/graphql are highly driven by GraphQL directives. Each heading in this section will address how/if one or many directives available in neo4j-graphql-js can be migrated to @neo4j/graphql.
@relation
Migrating this directive is trivial:
Rename @relation to @relationship
Rename the argument name to type
For example, @relation(name: ""ACTED_IN"", direction: OUT) becomes @relationship(type: ""ACTED_IN"", direction: OUT).
See Relationships for more information on relationships in @neo4j/graphql.
Relationship Properties
If for instance using neo4j-graphql-js, you have the following type definitions defining an ACTED_IN relationship with a roles property:
Graphql
Copy to Clipboard
type Actor {
    movies: [ActedIn!]!
}

type Movie {
    actors: [ActedIn!]!
}

type ActedIn @relation(name: ""ACTED_IN"") {
    from: Actor
    to: Movie
    roles: [String!]
}
This will need to be refactored to the following in the new library:
Graphql
Copy to Clipboard
type Actor {
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: OUT)
}

type Movie {
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: IN)
}

interface ActedIn @relationshipProperties {
    roles: [String!]
}
Note the following changes to the ActedIn type:
Changed from type to interface
Removed @relation directive
Removed from and to fields
And note the following changes to the two node types:
Relationship field types changed from the relationship type to the neighbouring node type
Normal @relationship directive added to each relationship field, with an additional properties argument pointing to the relationship properties interface
@cypher
No change. See @cypher directive for more details on this directive in @neo4j/graphql.
@neo4j_ignore
@neo4j/graphql offers two directives for skipping autogeneration for specified types/fields:
@exclude: Skip generation of specified Query/Mutation fields for an object type
@computed: Ignore a field, which will need custom logic for resolution
@isAuthenticated, @hasRole and @hasScope
Will require significant migration, but will be worth the effort! See Auth.
@additionalLabels
Not supported at this time.
@id
There is an equivalent directive in the new library, but it does not work using database constraints as per the old library. See @id.
@unique, @index and @search
These all relate to database indexes and constraints, which are not currently supported by @neo4j/graphql.
Types
Scalar Types
Supported as you would expect, with additional BigInt support for 64 bit integers.
Temporal Types (DateTime, Date)
Temporal Types have been massively simplified in @neo4j/graphql, down to DateTime and Date, which use ISO 8601 and ""yyyy-mm-dd"" strings respectively for parsing and serialization.
In terms of migrating from the old library, the formatted field of the old DateTime type now becomes the value itself. For example, used in a query:
Graphql
Copy to Clipboard
{
  Movie(released: { formatted: ""1992-10-09T00:00:00Z"" }) {
    title
  }
}
Has become:
Graphql
Copy to Clipboard
{
  Movie(released: ""1992-10-09T00:00:00Z"") {
    title
  }
}
Due to the move to ISO 8601 strings, input types are no longer necessary for temporal instances, so _Neo4jDateTimeInput has become DateTime and _Neo4jDateInput has become Date for input.
See Temporal Types.
Spatial Types
The single type in neo4j-graphql-js, Point, has been split out into two types:
Point
CartesianPoint
Correspondingly, _Neo4jPointInput has also been split out into two input types:
PointInput
CartesianPointInput
Using them in Queries and Mutations should feel remarkably similar.
Interface Types
Supported, queryable using inline fragments as per neo4j-graphql-js, but can also be created using Nested Mutations. See Interfaces.
Union Types
Supported, queryable using inline fragments as per neo4j-graphql-js, but can also be created using Nested Mutations. See Unions.
Fields
_id
An _id field exposing the underlying node ID is not included in each type by default in @neo4j/graphql like it was in neo4j-graphql-js. If you require this functionality (however, it should be noted that underlying node IDs should not be relied on because they can be reused), you can include a field definition such as in the following type definition:
Graphql
Copy to Clipboard
type ExampleType {
  _id: ID! @cypher(statement: ""RETURN ID(this)"")
}
Server
Queries
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/relationships;"Relationships
Contents
Example graph
Type definitions
Relationship Properties
QueryDirection
Inserting data
Fetching your data
Cardinality
Without relationships, your type definitions are simply a collection of disconnected nodes, with little value. Adding relationships into your data model gives your data the context that it needs to run complex queries across wide sections of your graph. This section will run through writing some type definitions for a simple connected model, inserting some data through the schema, and then querying it.
Example graph
The following graph will be used in this example, where a Person type has two different relationship types which can connect it to a Movie type.
Figure 1. Example graph
Type definitions
First, to define the nodes, you should define the two distinct types in this model:
Graphql
Copy to Clipboard
type Person {
    name: String!
    born: Int!
}

type Movie {
    title: String!
    released: Int!
}
You can then connect these two types together using @relationship directives:
Graphql
Copy to Clipboard
type Person {
    name: String!
    born: Int!
    actedInMovies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
    directedMovies: [Movie!]! @relationship(type: ""DIRECTED"", direction: OUT)
}

type Movie {
    title: String!
    released: Int!
    actors: [Person!]! @relationship(type: ""ACTED_IN"", direction: IN)
    director: Person! @relationship(type: ""DIRECTED"", direction: IN)
}
The following should be noted about the fields you just added:
A Person can act in or direct multiple movies, and a Movie can have multiple actors. However, it is exceedingly rare for a Movie to have more than one director, and you can model this cardinality in your type definitions, to ensure accuracy of your data.
A Movie isn’t really a Movie without a director, and this has been signified by marking the director field as non-nullable, meaning that a Movie must have a DIRECTED relationship coming into it.
To figure out whether the direction argument of the @relationship directive should be IN or OUT, visualise your relationships like in the diagram above, and model out the direction of the arrows.
The @relationship directive is a reference to Neo4j relationships, whereas in the schema, the phrase edge(s) is used to be consistent with the general API language used by Relay.
Relationship Properties
Relationship properties can be added to the above type definitions in two steps:
Add an interface definition containing the desired relationship properties
Add a properties argument to both ""sides"" of the @relationship directive which points to the newly defined interface
For example, to distinguish which roles an actor played in a movie:
Graphql
Copy to Clipboard
type Person {
    name: String!
    born: Int!
    actedInMovies: [Movie!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: OUT)
    directedMovies: [Movie!]! @relationship(type: ""DIRECTED"", direction: OUT)
}

type Movie {
    title: String!
    released: Int!
    actors: [Person!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: IN)
    director: Person! @relationship(type: ""DIRECTED"", direction: IN)
}

interface ActedIn @relationshipProperties {
    roles: [String!]
}
QueryDirection
All relationships have a direction, however, when querying it is possible to perform undirected queries. When defining a relationship you can define the default behaviour when performing queries over this relationship with the argument queryDirection:
Graphql
Copy to Clipboard
type Person {
    name: String!
    born: Int!
    actedInMovies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT, queryDirection: DEFAULT_DIRECTED)
}
queryDirection can have the following values:
DEFAULT_DIRECTED (default): All queries will be directed by default, but users may perform undirected queries.
DEFAULT_UNDIRECTED: All queries will be undirected by default, but users may perform directed queries.
DIRECTED_ONLY: Only directed queries can be perform on this relationship.
UNDIRECTED_ONLY: Only undirected queries can be perform on this relationship.
Inserting data
Nested mutations mean that there are many ways in which you can insert data into your database through the GraphQL schema. You can’t create a Movie without adding a director, and you can do that by either creating the director first and then creating and connecting the movie, or you can create both the Movie and the director in the same mutation. With the latter approach:
Graphql
Copy to Clipboard
mutation CreateMovieAndDirector {
    createMovies(input: [
        {
            title: ""Forrest Gump""
            released: 1994
            director: {
                create: {
                    node: {
                        name: ""Robert Zemeckis""
                        born: 1951
                    }
                }
            }
        }
    ]) {
        movies {
            title
            released
            director {
                name
                born
            }
        }
    }
}
View all (10 more lines)
You then need to create the actor in this example, and connect them to the new Movie node, also specifying which roles they played:
Graphql
Copy to Clipboard
mutation CreateActor {
    createPeople(input: [
        {
            name: ""Tom Hanks""
            born: 1956
            actedInMovies: {
                connect: {
                    where: {
                        node: { title: ""Forrest Gump"" }
                    }
                    edge: {
                        roles: [""Forrest""]
                    }
                }
            }
        }
    ]) {
        movies {
            title
            released
            director {
                name
                born
            }
            actorsConnection {
                edges {
                    roles
                    node {
                        name
                        born
                    }
                }
            }
        }
    }
}
View all (21 more lines)
Note the selection of the actorsConnection field in order to query the roles relationship property.
As you can see, these nested mutations are very powerful, and in the second Mutation you ran, you were able to return the entire graph which was created in this example. In fact, these mutations can actually be compressed down into a single Mutation which inserts all of the data needed:
Graphql
Copy to Clipboard
mutation CreateMovieDirectorAndActor {
    createMovies(input: [
        {
            title: ""Forrest Gump""
            released: 1994
            director: {
                create: {
                    node: {
                        name: ""Robert Zemeckis""
                        born: 1951
                    }
                }
            }
            actors: {
                create: [
                    {
                        node: {
                            name: 
                            born: 
                        }
                        edge: {
                            roles: []
                        }
                    }
                ]
            }
        }
    ]) {
        movies {
            title
            released
            director {
                name
                born
            }
            actorsConnection {
                edges {
                    roles
                    node {
                        name
                        born
                    }
                }
            }
        }
    }
}
View all (32 more lines)
Once you get your head around this, you’ll be creating giant sub-graphs in one Mutation in no time!
Fetching your data
Now that you have the Movie information in your database, you can query all of the information which you just inserted as follows:
Graphql
Copy to Clipboard
query {
    movies(where: { title: ""Forrest Gump"" }) {
        title
        released
        director {
            name
            born
        }
        actorsConnection {
            edges {
                roles
                node {
                    name
                    born
                }
            }
        }
    }
}
View all (4 more lines)
Cardinality
The Neo4j GraphQL Library has type definition requirements for ""many"" relationships, so given this example:
Graphql
Copy to Clipboard
type User {
    name: String!
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}

type Post {
    name: String!
}
The relationship at User.posts is considered a ""many"" relationship. Relationships such as the one above should always be of type NonNullListType and NonNullNamedType, meaning both the array and the type inside of it should have a !.
Custom Directives
Access Control
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/custom-directives;"Custom Directives
Contents
Example
As of @graphql-tools version 8, the mechanism for defining and applying custom directives has changed significantly, and this is reflected in the Neo4j GraphQL Library.
It comes highly recommended to read and follow the @graphql-tools documentation on schema directives for comprehensive documentation on this feature.
Example
This example will work towards the implementation of a field directive to uppercase field values, with the following definition:
Graphql
Copy to Clipboard
directive @uppercase on FIELD_DEFINITION
As per the @graphql-tools documentation, a function will be created which returns both the definition and the transformer which provides the behaviour:
Typescript
Copy to Clipboard
function upperDirective(directiveName: string) {
    return {
        upperDirectiveTypeDefs: `directive @${directiveName} on FIELD_DEFINITION`,
        upperDirectiveTransformer: (schema: GraphQLSchema) =>
            mapSchema(schema, {
                [MapperKind.OBJECT_FIELD]: (fieldConfig) => {
                    const fieldDirective = getDirective(schema, fieldConfig, directiveName)?.[0];
                    if (fieldDirective) {
                        const { resolve = defaultFieldResolver } = fieldConfig;
                        fieldConfig.resolve = async (source, args, context, info) => {
                            const result = await resolve(source, args, context, info);
                            if (typeof result === ""string"") {
                                return result.toUpperCase();
                            }
                            return result;
                        };
                    }
                    return fieldConfig;
                },
            }),
    };
}
View all (8 more lines)
On calling the function, the type definition and the transformer will be returned for the directive:
Typescript
Copy to Clipboard
const { upperDirectiveTypeDefs, upperDirectiveTransformer } = upperDirective(""uppercase"");
On construction of a Neo4jGraphQL instance, the directive definition can be passed into the typeDefs array alongside the rest of the type definitions:
Typescript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs: [
        upperDirectiveTypeDefs,
        gql`
            type Movie {
                name: String @uppercase
            }
        `,
    ],
    driver,
});
Finally, the Neo4j GraphQL schema must be transformed using the transformer returned from the directive function:
Typescript
Copy to Clipboard
const schema = upperDirectiveTransformer(await neoSchema.getSchema());
This schema object is an instance of a GraphQLSchema which can be used in any GraphQL tools, such as in Apollo Server.
Interface Types
Relationships
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/interfaces;"Interface Types
Contents
Type definitions
Directive inheritance
Querying an interface
Creating using an interface field
Nested interface operations
The Neo4j GraphQL Library supports the use of interfaces on relationship fields. This chapter will walk through their definition and usage.
Type definitions
The following schema defines a Actor type, that has a relationship ACTED_IN, of type [Production!]!. Production is an interface type with Movie and Series implementations. Note in this example that relationship properties have also been used with the @relationshipProperties directive as syntactic sugar, so that interfaces representing relationship properties can be easily distinguished.
Graphql
Copy to Clipboard
interface Production {
    title: String!
    actors: [Actor!]!
}

type Movie implements Production {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    runtime: Int!
}

type Series implements Production {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    episodes: Int!
}

  {
    role:!
}

 {
    name:!
    actedIn: !]! (: , direction:, properties: ""ActedIn"")
}
View all (10 more lines)
These type definitions will be used for the rest of the examples in this chapter.
Directive inheritance
Any directives present on an interface or its fields will be ""inherited"" by any object types implementing it. For example, the type definitions above could be refactored to have the @relationship directive on the actors field in the Production interface instead of on each implementing type as it is currently:
Graphql
Copy to Clipboard
interface Production {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
}

type Movie implements Production {
    title: String!
    actors: [Actor!]!
    runtime: Int!
}

type Series implements Production {
    title: String!
    actors: [Actor!]!
    episodes: Int!
}

  {
    role:!
}

 {
    name:!
    actedIn: !]! (: , direction:, properties: ""ActedIn"")
}
View all (10 more lines)
Overriding
In addition to inheritance, directives can be overridden on a per-implementation basis. Say you had an interface defining some Content, with some basic authorization rules:
Graphql
Copy to Clipboard
interface Content
    @auth(rules: [{ operations: [CREATE, UPDATE, DELETE], allow: { author: { username: ""$jwt.sub"" } } }]) {
    title: String!
    author: [Author!]! @relationship(type: ""HAS_CONTENT"", direction: IN)
}

type User {
    username: String!
    content: [Content!]! @relationship(type: ""HAS_CONTENT"", direction: OUT)
}
You might implement this once for public content and once for private content which has additional rules in place:
Graphql
Copy to Clipboard
type PublicContent implements Content {
    title: String!
    author: [Author!]!
}

type PrivateContent implements Content
    @auth(rules: [{ operations: [CREATE, READ, UPDATE, DELETE], allow: { author: { username: ""$jwt.sub"" } } }]) {
    title: String!
    author: [Author!]!
}
The PublicContent type will inherit the auth rules from the Content interface, whilst the PrivateContent type will use the auth rules specified there.
In summary, there are three choices for the application of directives when using interfaces:
Directives specified on the interface and inherited by all implementing types when the directives for every type are the same.
Directives specified on the interface and overridden by certain implementing types when directives are broadly the same with a few discrepancies.
Directives specified on implementing types alone when there is very little commonality between types, or certain types need a directive and others don’t.
Querying an interface
Which implementations are returned by a Query are dictated by the where filter applied.
For example, the following will return all productions with title starting ""The "" for every actor:
Graphql
Copy to Clipboard
query GetProductionsStartingWithThe {
    actors {
        name
        actedIn(where: { node: { title_STARTS_WITH: ""The "" } }) {
            title
            ... on Movie {
                runtime
            }
            ... on Series {
                episodes
            }
        }
    }
}
Whilst the query below will only return the movies with title starting with ""The "" for each actor.
Graphql
Copy to Clipboard
query GetMoviesStartingWithThe {
    actors {
        name
        actedIn(where: { node: { _on: { Movie: { title_STARTS_WITH: ""The "" } } } }) {
            title
            ... on Movie {
                runtime
            }
        }
    }
}
This is to prevent overfetching, and you can find an explanation of this here.
Alternatively, these implementation specific filters can be used to override filtering for a specific implementation. For example, if you wanted all productions with title starting with ""The "", but movies with title starting with ""A "", you could achieve this using the following:
Graphql
Copy to Clipboard
query GetProductionsStartingWith {
    actors {
        name
        actedIn(where: { node: { title_STARTS_WITH: ""The "", _on: { Movie: { title_STARTS_WITH: ""A "" } } } }) {
            title
            ... on Movie {
                runtime
            }
            ... on Series {
                episodes
            }
        }
    }
}
Creating using an interface field
The below mutation creates an actor and some productions they’ve acted in:
Graphql
Copy to Clipboard
mutation CreateActorAndProductions {
    createActors(
        input: [
            {
                name: ""Chris Pratt""
                actedIn: {
                    create: [
                        {
                            edge: {
                                role: ""Mario""
                            }
                            node: {
                                Movie: {
                                    title: ""Super Mario Bros""
                                    runtime: 90
                                }
                            }
                        }
                        {
                            edge: {
                                role: 
                            }
                            node: {
                               : {
                                    title: 
                                    runtime: 
                                }
                            }
                        }
                        {
                            edge: {
                                role: 
                            }
                            node: {
                               : {
                                    title: 
                                    episodes: 
                                }
                            }
                        }
                    ]
                }
            }
        ]
    ) {
        actors {
            name
            actedIn {
                title
            }
        }
    }
}
View all (38 more lines)
Nested interface operations
Operations on interfaces are abstract until you instruct them not to be. Take the following example:
Graphql
Copy to Clipboard
mutation CreateActorAndProductions {
    updateActors(
        where: { name: ""Woody Harrelson"" }
        connect: {
            actedIn: {
                where: { node: { title: ""Zombieland"" } }
                connect: { actors: { where: { node: { name: ""Emma Stone"" } } } }
            }
        }
    ) {
        actors {
            name
            actedIn {
                title
            }
        }
    }
}
View all (3 more lines)
The above Mutation will:
Find any Actor nodes with the name ""Woody Harrelson""
Connect those nodes to any Production (Movie or Series) nodes with the title ""Zombieland""
Connect the connected Production nodes to any Actor nodes with the name ""Emma Stone""
As you can see, this is abstract all the way down. If you wanted to only connect Movie nodes to Actor nodes with name ""Emma Stone"", you could instead do:
Graphql
Copy to Clipboard
mutation CreateActorAndProductions {
    updateActors(
        where: { name: ""Woody Harrelson"" }
        connect: {
            actedIn: {
                where: { node: { title: ""Zombieland"" } }
                connect: { _on: { Movie: { actors: { where: { node: { name: ""Emma Stone"" } } } } } }
            }
        }
    ) {
        actors {
            name
            actedIn {
                title
            }
        }
    }
}
View all (3 more lines)
Likewise, you could move this up a level to make sure you only connect to Movie nodes with title ""Zombieland"":
Graphql
Copy to Clipboard
mutation CreateActorAndProductions {
    updateActors(
        where: { name: ""Woody Harrelson"" }
        connect: {
            actedIn: {
                where: { node: { _on: { Movie: { title: ""Zombieland"" } } } }
                connect: { actors: { where: { node: { name: ""Emma Stone"" } } } }
            }
        }
    ) {
        actors {
            name
            actedIn {
                title
            }
        }
    }
}
View all (3 more lines)
Union Types
Custom Directives
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/type-definitions/access-control;"Access Control
Contents
@exclude
Definition
Usage
@readonly
Definition
@writeonly
Definition
This page addresses controlling schema generation output through the inclusion/exclusion of fields.
For fine-grained and role-based access control, see Auth.
@exclude
This directive skips the generation of queries and/or subscriptions and/or particular/all mutations for the specified type.
Definition
Graphql
Copy to Clipboard
enum ExcludeOperation {
    CREATE
    READ
    UPDATE
    DELETE
    SUBSCRIBE
}

""""""Instructs @neo4j/graphql to exclude the specified operations from query, mutation and subscription generation. If used without an argument, no queries, mutations or subscriptions will be generated for this type.""""""
directive @exclude(
    operations: [ExcludeOperation!]! = [CREATE, READ, UPDATE, DELETE, SUBSCRIBE]
) on OBJECT
Usage
Disable Query field generation
Graphql
Copy to Clipboard
type User @exclude(operations: [READ]) {
    name: String
}
Disable single Mutation field generation
Graphql
Copy to Clipboard
type User @exclude(operations: [CREATE]) {
    name: String
}
Disable multiple Mutation field generation
Graphql
Copy to Clipboard
type User @exclude(operations: [CREATE, DELETE]) {
    name: String
}
Disable Subscription field generation
Graphql
Copy to Clipboard
type User @exclude(operations: [SUBSCRIBE]) {
    name: String
}
Disable all Query, Mutation and Subscription field generation
The following two type definitions are equivalent in the fact that no queries, mutations or subscriptions will be generated for either of them:
Graphql
Copy to Clipboard
type User @exclude {
    name: String
}
Graphql
Copy to Clipboard
type User @exclude(operations: [CREATE, READ, UPDATE, DELETE, SUBSCRIBE]) {
    name: String
}
@readonly
The field will only feature in mutations for creating, and object types for querying, and will not be mutable after creation.
Definition
Graphql
Copy to Clipboard
""""""Instructs @neo4j/graphql to only include a field in generated input type for creating, and in the object type within which the directive is applied.""""""
directive @readonly on FIELD_DEFINITION
@writeonly
This field will only feature in input types, and will not be available for querying the object type through a Query or through a Mutation response.
Definition
Graphql
Copy to Clipboard
""""""Instructs @neo4j/graphql to only include a field in the generated input types for the object type within which the directive is applied, but exclude it from the object type itself.""""""
directive @writeonly on FIELD_DEFINITION
Relationships
Autogeneration
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/migration-guide/server;"Server
Contents
Schema Generation
Schema Configuration
Database Configuration
Driver
Multiple Databases
Schema Generation
In your server codebase, the process of creating an executable schema has changed. For a simple application, what used to be:
JavaScript
Copy to Clipboard
const { makeAugmentedSchema } = require(""neo4j-graphql-js"");

const typeDefs = require(""./type-definitions"");

const schema = makeAugmentedSchema({ typeDefs });
Has become:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");

const typeDefs = require(""./type-definitions"");

const neo4jGraphQL = new Neo4jGraphQL({ typeDefs });

const schema = await neo4jGraphQL.getSchema();
Additionally, the Neo4jGraphQL constructor allows you to pass in a driver instance instead of passing one in the context of each request.
Schema Configuration
The neo4j-graphql-js library would allow a user to configure the GraphQL schema via the makeAugmentedSchema() function.
For example, to exclude all queries and all mutations:
JavaScript
Copy to Clipboard
const schema = makeAugmentedSchema({
  typeDefs,
  config: {
    query: false, // exclude all queries
    mutation: false // exclude all mutations
  }
});
Or to exclude queries for a specific type like so:
JavaScript
Copy to Clipboard
const schema = makeAugmentedSchema({
  typeDefs,
  config: {
    query: {
      exclude: [""NameOfTypeToExclude""] // exclude query for type NameOfTypeToExclude
    },
    mutation: false // exclude all mutations
  }
});
To achieve the same behaviour with the new @neo4j/graphql library, the GraphQL schema has to be extended instead. Note, no additional configuration or parameters need to be passed to the getSchema() function.
To exclude all mutations for a specific type:
Graphql
Copy to Clipboard
type NameOfType @exclude(operations: [CREATE, UPDATE, DELETE]) {
  name: String
}
Or to exclude all queries and all mutations for a specific type like so:
Graphql
Copy to Clipboard
type NameOfTypeToExclude @exclude {
  name: String
}
For more information regarding the above used @exclude directive, see @exclude.
Database Configuration
Driver
Once a schema has been generated, it can be passed into a GraphQL server instance with the driver in the context, identical to using the old library. For example, using Apollo Server and using the schema generated above:
JavaScript
Copy to Clipboard
const { ApolloServer } = require(""apollo-server"");

const driver = require(""./driver"");
const schema = require(""./schema"");

const server = new ApolloServer({ schema, context: { driver } });

server.listen().then(({ url }) => {
    console.log(`@neo4j/graphql API ready at ${url}`);
});
Multiple Databases
Multiple databases were supported in neo4j-graphql-js by passing a context key neo4jDatabase with the name of a database, for example for database called ""sanmateo"":
JavaScript
Copy to Clipboard
const { ApolloServer } = require(""apollo-server"");

const driver = require(""./driver"");
const schema = require(""./schema"");

const server = new ApolloServer({ schema, context: { driver, neo4jDatabase: ""sanmateo"" } });

server.listen().then(({ url }) => {
    console.log(`@neo4j/graphql API ready at ${url}`);
});
In @neo4j/graphql, this has now become:
JavaScript
Copy to Clipboard
const { ApolloServer } = require(""apollo-server"");

const driver = require(""./driver"");
const schema = require(""./schema"");

const server = new ApolloServer({ schema, context: { driver, driverConfig: { database: ""sanmateo"" } } });

server.listen().then(({ url }) => {
    console.log(`@neo4j/graphql API ready at ${url}`);
});
Database bookmarks are also supported. See Driver Configuration for more information.
Migration Guide
Type Definitions
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/custom-resolvers;"Custom Resolvers
Contents
Custom object type field resolver
@customResolver
@computed
Custom Query/Mutation type field resolver
The library will autogenerate Query and Mutation resolvers, so you don’t need to implement those resolvers yourself. However, if you would like additional behaviours besides the autogenerated CRUD operations, you can specify custom resolvers for these scenarios.
Custom object type field resolver
If you would like to add a field to an object type which is resolved from existing values in the type, rather than storing new values, you should mark it with the @customResolver directive (see below) and define a custom resolver for it. Take for instance a simple schema:
JavaScript
Copy to Clipboard
const typeDefs = `
    type User {
        firstName: String!
        lastName: String!
        fullName: String! @customResolver(requires: [""firstName"", ""lastName""])
    }
`;

const resolvers = {
    User: {
        fullName(source) {
            return `${source.firstName} ${source.lastName}`;
        },
    },
};

 neoSchema =  Neo4jGraphQL({
    typeDefs,
    resolvers,
});
View all (5 more lines)
Here fullName is a value that is resolved from the fields firstName and lastName. Specifying the @customResolver directive on the field definition keeps fullName from being included in any Query or Mutation fields and hence as a property on the :User node in the database.
The inclusion of the fields firstName and lastName in the requires argument means that in the definition of the resolver, the properties firstName and lastName will always be defined on the source object. If these fields are not specified, this cannot be guaranteed.
@customResolver
This field will essentially be completely ignored during the generation of Query and Mutation fields, and will require a custom resolver to resolve the field.
Any fields that the custom resolver depends on should be passed to the requires argument to ensure that during the Cypher generation process those properties are selected from the database. Allowable fields are any returning a Scalar or Enum type including those defined using the @cypher directive.
Definition
Graphql
Copy to Clipboard
""""""Informs @neo4j/graphql that a field will be resolved by a custom resolver, and allows specification of any field dependencies.""""""
directive @customResolver(
    """"""Fields that the custom resolver will depend on.""""""
    requires: [String!]
) on FIELD_DEFINITION
Note that any field marked with the @customResolver directive, requires a custom resolver to be defined. If the directive is marked on an interface, any implementation of that interface requires a custom resolver to be defined. Take for example this schema:
Graphql
Copy to Clipboard
interface UserInterface {
    fullName: String! @customResolver
}

type User implements UserInterface {
    id: ID!
    fullName: String!
}
The following resolvers definition would be invalid:
JavaScript
Copy to Clipboard
const resolvers = {
    UserInterface: {
        fullName() {
            return ""Hello World!"";
        },
    },
};
Instead, the following resolvers definition would be required:
JavaScript
Copy to Clipboard
const resolvers = {
    User: {
        fullName() {
            return ""Hello World!"";
        },
    },
};
@computed
The @computed directive has been deprecated and will be removed in version 4.0. Please use the @customResolver directive instead.
This field will essentially be completely ignored during the generation of Query and Mutation fields, and will require another way to resolve the field, such as through the use of a custom resolver.
Any fields that the custom resolver depends on should be passed to the from argument to ensure that during the Cypher generation process those properties are selected from the database. Allowable fields are any returning a Scalar or Enum type including those defined using the @cypher directive.
Definition
Graphql
Copy to Clipboard
""""""Informs @neo4j/graphql that a field will be resolved by a custom resolver, and allows specification of any field dependencies.""""""
directive @computed(
    """"""Fields that the custom resolver will depend on.""""""
    from: [String!]
) on FIELD_DEFINITION
Custom Query/Mutation type field resolver
You can define additional custom Query and Mutation fields in your type definitions and provide custom resolvers for them. A prime use case for this is using the OGM to manipulate types and fields which are not available through the API. You can find an example of it being used in this capacity in the Custom Resolvers example.
Array methods
Auth
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/array-methods;"Array methods
Contents
Examples
Array pop
Array push
Array push and pop in one update
Array methods allow us to modify existing property arrays in Update mutations within these entities:
Node
Nested Nodes
Relationship properties
Interfaces
The following operators are available:
_POP
_PUSH
The POP operator expects a single Int value as input
The PUSH operator conforms to the type of input defined in the type definition.
Examples
Array pop
Suppose we have the following type definition, a Movie with a property array called tags:
Graphql
Copy to Clipboard
type Movie {
    title: String
    tags: [String]
}
We can pop from this tags property array.
Before: ['a', 'b', 'c']
After: ['a', 'b']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_POP: 1 }) {
        movies {
            title
            tags
        }
    }
}
Or, for more than one property from the array:
Before: ['a', 'b', 'c']
After: ['a']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_POP: 2 }) {
        movies {
            title
            tags
        }
    }
}
Similarly, you can have multiple array property fields and update them in the same query:
Graphql
Copy to Clipboard
type Movie {
    title: String
    tags: [String]
    moreTags: [String]
}
We can pop from both the tags and moreTags property arrays.
Before:
None
Copy to Clipboard
    tags: ['a', 'b', 'c']
    moreTags: ['x', 'y', 'z']
After:
None
Copy to Clipboard
    tags: ['a', 'b']
    moreTags: ['x']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_POP: 1, moreTags_POP: 2 }) {
        movies {
            title
            tags
            moreTags
        }
    }
}
Array push
Suppose we have the following type definition, a Movie with a property array called tags:
Graphql
Copy to Clipboard
type Movie {
    title: String
    tags: [String]
}
We can push to this tags property array.
Before: ['some tag']
After: ['some tag', 'another tag']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_PUSH: ""another tag"" }) {
        movies {
            title
            tags
        }
    }
}
Or push multiple elements in a single update:
Before: ['some tag']
After: ['some tag', 'another tag', 'one more tag']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_PUSH: [""another tag"", ""one more tag""] }) {
        movies {
            title
            tags
        }
    }
}
Similarly, you can have multiple array property fields and update them in the same query:
Graphql
Copy to Clipboard
type Movie {
    title: String
    tags: [String]
    moreTags: [String]
}
We can push to both the tags and moreTags property arrays.
Before:
None
Copy to Clipboard
    tags: ['some tag']
    moreTags: []
After:
None
Copy to Clipboard
    tags: ['some tag', 'another tag']
    moreTags ['a different tag']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_PUSH: ""another tag"", moreTags_PUSH: ""a different tag"" }) {
        movies {
            title
            tags
            moreTags
        }
    }
}
Array push and pop in one update
It is possible to perform both a push and pop operation in one Update mutation.
Suppose we have the following type definition, a Movie with a property array called tags:
Graphql
Copy to Clipboard
type Movie {
    title: String
    tags: [String]
    moreTags: [String]
}
We can then update both property arrays with either _POP or _PUSH operators.
Before:
None
Copy to Clipboard
    tags: ['some tag']
    moreTags: []
After:
None
Copy to Clipboard
    tags: []
    moreTags ['a different tag']
Graphql
Copy to Clipboard
mutation {
    updateMovies (update: { tags_POP: 1, moreTags_PUSH: ""a different tag"" }) {
        movies {
            title
            tags
            moreTags
        }
    }
}
Mathematical operators
Custom Resolvers
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/mathematical-operators;"Mathematical operators
Contents
Int and BigInt operators
Float operators
Examples
The social platform schema
Simple increment operation
Nested example
Optional fields
Mathematical operators are a handy way to update numerical fields based on their original values in a single DB transaction.
Specific operators are available on different numerical types (Int, Float, BigInt).
Mathematical operators are supported in Update Mutations within these entities:
Node
Nested Nodes
Relationship properties
Interfaces
Int and BigInt operators
For Int and BigInt types, the following operators are available:
_DECREMENT
_INCREMENT
Float operators
For Float type, the following operators are available:
_ADD
_SUBTRACT
_MULTIPLY
_DIVIDE
Examples
The social platform schema
In this section, we use the following GraphQL schema:
Graphql
Copy to Clipboard
type Video {
  id: ID @id
  views: Int
  ownedBy: User @relationship(type: ""OWN_VIDEO"", properties: ""OwnVideo"", direction: IN)
}
type User {
  id: ID @id
  ownVideo: [Video!]! @relationship(type: ""OWN_VIDEO"", properties: ""OwnVideo"", direction: OUT)
}
interface OwnVideo @relationshipProperties {
  revenue: Float
}
Simple increment operation
Let’s say that a user views a video, so we want to increment viewersCount for that video by 1.
Graphql
Copy to Clipboard
mutation incrementViewCountMutation {
  updateVideos(
    where: { id: ""VideoID"" }
    update: { views_INCREMENT: 1 }
  ) {
    videos {
      id
      views
    }
  }
}
Nested example
Now, let’s say that the video platform wants to reward the user with 0.01 dollars for viewing the video. To do that, we have to update the relationship property revenue.
Graphql
Copy to Clipboard
mutation addRevenueMutation {
  updateUsers(
    where: { id: ""UserID"" },
    update: { ownVideo: [{ update: { edge: { revenue_ADD: 0.01 } } }] }
  ) {
    users {
      id
      ownVideoConnection {
        edges {
          revenue
        }
      }
    }
  }
}
Optional fields
Operators remain available for optional fields, this means that if a mathematical operator has been used in a field not defined then a GraphQL error is raised.
Cursor-based pagination
Array methods
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/pagination/cursor-based;"Cursor-based pagination
Contents
totalCount
On relationship fields, you are able to take advantage of cursor-based pagination, which is often associated with infinitely-scrolling applications.
Using the following type definition:
Graphql
Copy to Clipboard
type User {
    name: String!
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}

type Post {
    content: String!
}
If you wanted to fetch the posts of user ""John Smith"" 10 at a time, you would first fetch 10:
Graphql
Copy to Clipboard
query {
    users(where: { name: ""John Smith"" }) {
        name
        postsConnection(first: 10) {
            edges {
                node {
                    content
                }
            }
            pageInfo {
                endCursor
                hasNextPage
            }
        }
    }
}
In the return value, if hasNextPage is true, you would pass endCursor into the next query of 10. You might do this using a variable as in the following example:
Graphql
Copy to Clipboard
query Users($after: String) {
    users(where: { name: ""John Smith"" }) {
        name
        postsConnection(first: 10, after: $after) {
            edges {
                node {
                    content
                }
            }
            pageInfo {
                endCursor
                hasNextPage
            }
        }
    }
}
You would continue doing this until hasNextPage if false - this is when you have reached the end of the data.
totalCount
The Connection fields also offer a totalCount field which can be used to calculate page numbers, which is useful if you want to page by cursors but use page number in your application. Using the example above, you would simply add the totalCount field which will return the total number of results matching the filter used, which in this example would just be all posts:
Graphql
Copy to Clipboard
query Users($after: String) {
    users(where: { name: ""John Smith"" }) {
        name
        postsConnection(first: 10) {
            edges {
                node {
                    content
                }
            }
            pageInfo {
                endCursor
                hasNextPage
            }
            totalCount
        }
    }
}
Offset-based pagination
Mathematical operators
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/migration-guide/mutations;"Mutations
Contents
Creating
Updating
Deleting
Connecting
Disconnecting
This section will walk through each operation available through GraphQL Mutations, and how to migrate each from neo4j-graphql-js to @neo4j/graphql.
The examples in this section will be based off the following type definitions (which have been migrated over to @neo4j/graphql syntax):
Graphql
Copy to Clipboard
type Actor {
    name: String!
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    title: String!
    averageRating: Float
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}
A summary of migration points is as follows:
Mutations which were previously in the singular and in PascalCase are now pluralized and in camelCase - for example CreateMovie has become createMovies
Connect and disconnect Mutations are no longer present, these operations are accessed through an update Mutation
The object(s) being mutated are returned as a nested field, to allow for metadata about the operation to be added in future
Mutation arguments are now commonly named between different types, but with different input types - such as where and input
Note that Mutations in @neo4j/graphql are incredibly powerful, and it is well worthwhile reading about them in full. You might find that you can collapse multiple current mutations down into one!
Creating
For creating nodes, the input arguments of neo4j-graphql have been moved inside an input argument in @neo4j/graphql.
For example, creating a movie using the old library:
Graphql
Copy to Clipboard
mutation {
    CreateMovie(title: ""Forrest Gump"") {
        title
    }
}
Looks like the following using @neo4j/graphql:
Graphql
Copy to Clipboard
mutation {
    createMovies(input: { title: ""Forrest Gump"" }) {
        movies {
            title
        }
    }
}
Note that movies must also be first selected in the selection set.
Updating
An update Mutation using neo4j-graphql-js had all of the arguments at the root of the Mutation, including the filter and fields to change.
This has all changed in @neo4j/graphql, with a where argument to select the node, and then an update argument (amongst many others) to select what to update.
For example, updating the average rating of the Movie Forrest Gump:
Graphql
Copy to Clipboard
mutation {
    UpdateMovie(title: ""Forrest Gump"", averageRating: 5.0) {
        title
        averageRating
    }
}
Will look like the following using the new library:
Graphql
Copy to Clipboard
mutation {
    updateMovies(where: { title: ""Forrest Gump"" }, update: { averageRating: 5.0 }) {
        movies {
            title
            averageRating
        }
    }
}
Deleting
The arguments for selecting which node to delete have now been moved into a where argument.
Additionally, the return value is now a DeleteInfo object informing how many nodes and relationships were deleted.
For example, deleting a movie:
Graphql
Copy to Clipboard
mutation {
    DeleteMovie(title: ""Forrest Gump"") {
        title
    }
}
Looks like the following using @neo4j/graphql:
Graphql
Copy to Clipboard
mutation {
    deleteMovies(where: { title: ""Forrest Gump"" }) {
        nodesDeleted
        relationshipsDeleted
    }
}
Connecting
Using neo4j-graphql-js, connecting two of the nodes in this example would have been achieved by executing either the AddMovieActors or AddActorMovies Mutation.
In @neo4j/graphql, this is achieved by specifying the connect argument on either the updateMovies or updateActors Mutation.
For example:
Graphql
Copy to Clipboard
mutation {
    AddMovieActors(from: { name: ""Tom Hanks"" }, to: { title: ""Forrest Gump"" }) {
        from {
            name
        }
        to {
            title
        }
    }
}
Would become the following using @neo4j/graphql:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: { title: ""Forrest Gump"" }
        connect: { actors: { where: { node: { name: ""Tom Hanks"" } } } }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
Note, there are many ways to achieve the same goal using the powerful Mutation ability of @neo4j/graphql, so do what feels best for your data!
Disconnecting
Similarly to connecting, using neo4j-graphql-js, disconnecting two of the nodes in this example would have been achieved by executing either the RemoveMovieActors or RemoveActorMovies Mutation.
In @neo4j/graphql, this is achieved by specifying the disconnect argument on either the updateMovies or updateActors Mutation.
For example:
Graphql
Copy to Clipboard
mutation {
    RemoveMovieActors(from: { name: ""Tom Hanks"" }, to: { title: ""Forrest Gump"" }) {
        from {
            name
        }
        to {
            title
        }
    }
}
Would become the following using @neo4j/graphql:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: { title: ""Forrest Gump"" }
        disconnect: { actors: { where: { node: { name: ""Tom Hanks"" } } } }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
In the result field actors, Tom Hanks should no longer be present.
Queries
2.0.0 Migration
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v2-migration;"2.0.0 Migration
Contents
How to Upgrade
Version 2.0.0 of @neo4j/graphql adds support for relationship properties, with some breaking changes to facilitate these new features. All of the required changes will be on the client side, and this guide will walk through what has changed.
How to Upgrade
Simply update @neo4j/graphql using npm or your package manager of choice:
Bash
Copy to Clipboard
npm update @neo4j/graphql
From this point on, it is primarily Mutations which will form the bulk of the migration:
Mutations for how you need to change your Mutations to work with the new schema
Unions for how querying union fields has changed in version 2.0.0
Miscellaneous for other changes in version 2.0.0
Mutations
Mutations
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v2-migration/miscellaneous;"Miscellaneous
Contents
skip renamed to offset
Count queries
Schema validation
_IN and _NOT_IN filters on relationships removed
skip renamed to offset
In the release of Apollo Client 3.0, it became a bit more opinionated about pagination, favouring offset and limit over skip and limit. Acknowledging that the majority of users will be using Apollo Client 3.0, the page-based pagination arguments have been updated to align with this change.
For example, fetching page 3 of pages of 10 movies would have looked like the following in version 1.x:
Graphql
Copy to Clipboard
query {
    movies(options: { skip: 20, limit: 10 }) {
        title
    }
}
This will now need to queried as follows:
Graphql
Copy to Clipboard
query {
    movies(options: { offset: 20, limit: 10 }) {
        title
    }
}
Count queries
Whilst not a necessary migration step, if you are using page-based pagination, it’s important to note the addition of count queries in version 2.0.0. These will allow you to calculate the total number of pages for a particular filter, allowing you to implement much more effective pagination.
Schema validation
In version 2.0.0, there are greater levels of schema validation. However, upon upgrading, you might find that validation is too strict (for example if using certain generated types in your definitions). You can temporarily disable this new validation on construction:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs,
    config: {
        skipValidateTypeDefs: true,
    },
})
If you need to do this, please report the scenario as an issue on GitHub.
_IN and _NOT_IN filters on relationships removed
There were previously _IN and _NOT_IN filters for one-to-many and one-to-one relationships, but these were surplus to requirements, and didn’t match for all cardinalities (many-to-many relationships don’t have _INCLUDES and _NOT_INCLUDES). These may be added back in the future if and when we look more holistically at distinguishing between different relationship cardinalities.
You can still achieve identical filters through different routes. For example, if you had the following schema:
Graphql
Copy to Clipboard
type Movie {
    title: String!
    director: Director! @relationship(type: ""DIRECTED"", direction: IN)
}

type Director {
    name: String!
    movies: [Movie!]! @relationship(type: ""DIRECTED"", direction: OUT)
}
You would have been able to run the following query:
Graphql
Copy to Clipboard
query {
    movies(where: { director_IN: [{ name: ""A"" }, { name: ""B"" }] }) {
        title
    }
}
You can still achieve exactly the same filter with the following:
Graphql
Copy to Clipboard
query {
    movies(where: { director: { OR: [{ name: ""A"" }, { name: ""B"" }]} }) {
        title
    }
}
Unions
3.0.0 Migration
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v3-migration;"3.0.0 Migration
Contents
How to upgrade
Asynchronous schema generation
Relationship changes
Many-to-* relationships
Relationship cardinality
Count query no longer supported
Relationship filters
@ignore directive renamed to @computed
Auth plugin system
JWT auth
JWKS decoding
Types plurals changes
Custom Directives
Types changes
Removal of nested operation fields for connectOrCreate
Non Nullable Aggregation Results
ConnectionWhere types renamed
Neo4j support
GraphQL support
How to upgrade
Simply update @neo4j/graphql using npm or your package manager of choice:
Bash
Copy to Clipboard
npm update @neo4j/graphql
Asynchronous schema generation
Schema generation is now asynchronous. Instead of using the property schema, now the method getSchema will return the schema as a Promise. This means that creating a server now requires awaiting for that method:
Instead of
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
const server = new ApolloServer({
    schema: neoSchema.schema,
});
Now you’ll need to do the following:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
neoSchema.getSchema().then((schema) => {
    const server = new ApolloServer({
        schema: schema
    });
});
Relationship changes
This release contains an overhaul of our relationship validations, which will require a few changes to the schema.
Many-to-* relationships
To improve consistency and validation, all ""many-to-*"" relationships need to be defined as required in the schema:
Graphql
Copy to Clipboard
type Movie {
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
    director: Director @relationship(type: ""DIRECTED"", direction: IN)
}
Note that any other notation, such as [Actor] or [Actor!] will not be valid. ""One-to-one"" relationships such as Director remain unchanged.
Relationship cardinality
Runtime checks for ""one-to*"" relationships have been added in this release, ensuring that the correct number of relationships exist. This means that some databases with inconsistent relationships between the schema definition and the actual data may now fail in some queries. This may have happened due to different reasons such as direct changes in the database or changes to the type definitions. Previous versions of @neo4j/graphql did not have any consistency check, so normal use of these versions may have lead to inconsistent relationships.
For these cases, please ensure that the database is following your schema definition or update the schema to reflect the actual existing relationships, taking care of which relationships are 1-to-* or many-to-many.
Count query no longer supported
Queries using count at the root level are no longer supported. For example:
Graphql
Copy to Clipboard
query {
    usersCount
}
The same operation, can now be achieved with a count aggregation query:
Graphql
Copy to Clipboard
query {
    usersAggregate {
        count
    }
}
Relationship filters
where filters for relationship queries now explicitly state ALL, NONE, SINGLE, and SOME as part of filter name.
Queries using old relationship filters, will now need to use {relationship}_SOME. For example:
Graphql
Copy to Clipboard
query {
  movies(where: {
    actors: {
      name: ""John""
    }
  }) {
    title
  }
}
Should be:
Graphql
Copy to Clipboard
query {
  movies(where: {
    actors_SOME: {
      name: ""John""
    }
  }) {
    title
  }
}
And, instead of _NOT, _NONE should be used.
Old queries will still work in this release, but are marked as @deprecated and will not be available in the future.
@ignore directive renamed to @computed
To better reflect its intended usage, the @ignore directive is now named @computed. Behaviour is unchanged, so you just need to rename this directive in your schema.
Auth plugin system
Auth setup now relies on plugins to setup the configuration. You’ll need to install @neo4j/graphql-plugin-auth or a custom plugin as shown in the auth setup page.
JWT auth
For JWT authorization, instead of the previous configuration:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs,
    config: {
        jwt: {
            secret
        }
    }
});
Now the configuration should be passed through Neo4jGraphQLAuthJWTPlugin:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWTPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWTPlugin({
            secret: ""super-secret""
        })
    }
});
JWKS decoding
JSON Web Key Sets are now supported through Neo4jGraphQLAuthJWKSPlugin.
Instead of setting the endpoint directly:
JavaScript
Copy to Clipboard
const neoSchema = new Neo4jGraphQL({
    typeDefs,
    config: {
        jwt: {
            jwksEndpoint: ""https://YOUR_DOMAIN/.well-known/jwks.json""
        }
    }
});
Now the Neo4jGraphQLAuthJWKSPlugin would take care of that:
JavaScript
Copy to Clipboard
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import { Neo4jGraphQLAuthJWKSPlugin } from ""@neo4j/graphql-plugin-auth"";

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    plugins: {
        auth: new Neo4jGraphQLAuthJWKSPlugin({
            jwksEndpoint: ""https://YOUR_DOMAIN/well-known/jwks.json"",
        })
    }
});
Please, refer to auth setup before setting up auth.
Types plurals changes
To improve consistency, some automatically generated plurals (e.g. createActors) have changed. This may cause issues if your types use conventions such as snake_case.
Because of this, you may find generated queries and mutations may have different names. If you encounter this problem, please update your clients to use the new query names or use the plural option in the @node directive to force a custom plural value.
Custom Directives
Defining and applying custom directives has changed significantly, if you are using or plan to use custom directives, make sure to check the up-to-date documentation on custom directives.
Types changes
Some automatically generated types have changed to improve consistency. These should not require any changes from most developers, unless types names are directly used.
Some automatically generated types have changed to improve consistency. These should not require any changes from the developer in most cases, unless in cases where types names are directly used.
Removal of nested operation fields for connectOrCreate
Input types for onCreate in connectOrCreate operations no longer accept relationship fields. They were originally added in error and did not function as one would expect, so there is no regression in functionality.
Non Nullable Aggregation Results
Aggregation results may now be non-nullable for required fields, yielding more accurate types.
For example, for the following types:
Graphql
Copy to Clipboard
type User {
    name: String!
    lastName: String
}
Will yield different types for aggregations over name and lastName:
Graphql
Copy to Clipboard
type UserAggregateSelection {
  count: Int!
  name: StringAggregateSelectionNonNullable!
  lastName: StringAggregateSelectionNullable!
}
ConnectionWhere types renamed
ConnectionWhere types renamed to improve consistency with other similarly named types.
Neo4j support
Neo4j 4.1 is no longer supported in 3.0.0, inline with the supported versions list.
GraphQL support
graphql@^15.0.0 is no longer supported, please upgrade to graphql@^16.0.0 using npm or the package manager of your choice.
Miscellaneous
4.0.0 Migration
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v4-migration;"4.0.0 Migration
Contents
How to upgrade
Updated Directives
@callback renamed to @populatedBy
@computed renamed to @customResolver
plural argument removed from @node and replaced with @plural
@fulltext changes
@cypher changes
Version 4.0.0 of the library has not yet been released. However, we recommend making these changes early in order to avoid issues in the future.
This document lists all breaking changes from version 3.x.y to 4.0.0 and how to update.
How to upgrade
Simply update @neo4j/graphql using npm or your package manager of choice:
Bash
Copy to Clipboard
npm update @neo4j/graphql
Updated Directives
We have renamed a number of directives and their arguments, in order to make using @neo4j/graphql more intuitive.
@callback renamed to @populatedBy
Previously, there was ambiguity over the behaviour of @callback. As the directive is used to populate a value on input, it has been renamed @populatedBy to reflect this. Additionally, the name argument was previously used to specify the callback used to populate the field’s value. This has been renamed to callback to make it clear that it refers to a callback.
Therefore, the following usage of the directive would be invalid:
Graphql
Copy to Clipboard
type User {
  id: ID! @callback(name: ""nanoid"", operations: [CREATE])
  firstName: String!
  surname: String!
}
It would instead need to be updated to use the new directive and argument as below:
Graphql
Copy to Clipboard
type User {
  id: ID! @populatedBy(callback: ""nanoid"", operations: [CREATE])
  firstName: String!
  surname: String!
}
Note that before and after these changes, a callback named nanoid would need to be defined as below:
JavaScript
Copy to Clipboard
new Neo4jGraphQL({
  typeDefs,
  config: {
    callbacks: {
      nanoid: () => { return nanoid(); }
    }
  }
});
@computed renamed to @customResolver
Previously, there was ambiguity over the behaviour of @computed and it wasn’t clear that it was intended to be used with a custom resolver. In order to make this clear, @computed has been renamed to @customResolver. Furthermore, the behaviour of the from argument was not clear. The argument is used to specify which fields other fields are required by the custom resolver. As a result, from has been renamed to requires.
These changes mean that the following type definition is invalid in version 4.0.0:
Graphql
Copy to Clipboard
type User {
  firstName: String!
  lastName: String!
  fullName: String! @computed(from: [""firstName"", ""lastName""])
}
Instead, it would need to be updated to use the new directive and argument as below:
Graphql
Copy to Clipboard
type User {
  firstName: String!
  lastName: String!
  fullName: String! @customResolver(requires: [""firstName"", ""lastName""])
}
Note that before and after these changes, a custom resolver would need to be defined as below:
JavaScript
Copy to Clipboard
new Neo4jGraphQL({
  typeDefs,
  resolvers: {
    User: {
      fullName: ({ firstName, lastName }, args, context, info) => (`${firstName} ${lastName}`),
    }
  }
});
Checks for custom resolvers
Previously, if no custom resolver was specified for a @computed field when creating an instance of Neo4jGraphQL, no errors would be thrown when generating the schema. However, it is likely that the lack of a custom resolver would lead to errors at runtime. It is preferable to fail fast in this case as it is easier to debug and makes it less likely that bugs will make it into production.
As a result, checks are now performed to ensure that every @customResolver field has a custom resolver provided. If not the library will throw an error during schema generation.
plural argument removed from @node and replaced with @plural
How a type name is pluralised has nothing to do with nodes in the database. As a result, having a plural argument on the @node directive did not make sense. As a result, the plural argument of @node has been removed and replaced with a new @plural directive. The @plural directive takes the pluralised type name using the value argument.
This means that the following type definition is invalid:
Graphql
Copy to Clipboard
type Tech @node(label: ""TechDB"", plural: ""Techs"") {
  name: String
}
It would need to be updated to use the new directive as below:
Graphql
Copy to Clipboard
type Tech @node(label: ""TechDB"") @plural(value: ""Techs"") {
  name: String
}
@fulltext changes
In version 4.0.0, a number of improvements have been made to full-text queries. These include the ability to return the full-text score, filter by the score and sorting by the score.
However, these improvements required a number of breaking changes.
Query changes
Full-text queries now need to be performed using a top-level query, instead of being performed using an argument on a node query.
As a result, the following query is now invalid:
Graphql
Copy to Clipboard
query {
  movies(fulltext: { movieTitleIndex: { phrase: ""Some Title"" } }) {
    title
  }
}
The new top-level queries can be used to return the full-text score, which indicates the confidence of a match, as well as the nodes that have been matched.
The new top-level queries accept the following arguments:
phrase which specifies the string to search for in the full-text index.
where which accepts a min/max score as well as the normal filters available on a node.
sort which can be used to sort using the score and node attributes.
limit which is used to limit the number of results to the given integer.
offset which is used to offset by the given number of results.
The new top-level queries means that for the following type definition:
Graphql
Copy to Clipboard
type Movie @fulltext(indexes: [{ indexName: ""MovieTitle"", fields: [""title""] }]) { # Note that indexName is the new name for the name argument. More about this below.
  title: String!
}
The following top-level query and type definitions would be generated by the library:
Graphql
Copy to Clipboard
type Query {
  movieFulltextMovieTitle(phrase: String!, where: MovieFulltextWhere, sort: [MovieFulltextSort!], limit: Int, offset: Int): [MovieFulltextResult!]!
}

""""""The result of a fulltext search on an index of Movie""""""
type MovieFulltextResult {
  score: Float
  movies: Movie
}

""""""The input for filtering a fulltext query on an index of Movie""""""
input MovieFulltextWhere {
  score: FloatWhere
  movie: MovieWhere
}


input {
  score:
  movie:
}


input {
  min:
  max:
}
View all (12 more lines)
This query can be used to perform a full-text query as below:
Graphql
Copy to Clipboard
query {
  movieFulltextMovieTitle(
    phrase: ""Full Metal Jacket"",
    where: { score: min: 0.4 },
    sort: [{ movie: { title: ASC } }],
    limit: 5,
    offset: 10
  ) {
    score
    movies {
      title
    }
  }
}
The above query would be expected to return results in the following format:
Json
Copy to Clipboard
{
  ""data"": {
    ""movieFulltextMovieTitle"": [
      {
        ""score"": 0.44524085521698,
        ""movie"": {
          ""title"": ""Full Moon High""
        }
      },
      {
        ""score"": 1.411118507385254,
        ""movie"": {
          ""title"": ""Full Metal Jacket""
        }
      }
    ]
  }
}
Argument changes
The following changes have been made to @fulltext arguments:
queryName has been added to specify a custom name for the top-level query that is generated.
name has been renamed to indexName to avoid ambiguity with the new queryName argument.
These changes means that the following type definition is now invalid:
Graphql
Copy to Clipboard
type Movie @fulltext(indexes: [{ name: ""MovieTitle"", fields: [""title""] }]) {
  title: String!
}
The name argument would need to be replaced with indexName as below:
Graphql
Copy to Clipboard
type Movie @fulltext(indexes: [{ indexName: ""MovieTitle"", fields: [""title""] }]) {
  title: String!
}
The queryName argument can be used as below:
Graphql
Copy to Clipboard
type Movie @fulltext(indexes: [{ queryName: ""moviesByTitle"", indexName: ""MovieTitle"", fields: [""title""] }]) {
  title: String!
}
This means the top-level query would now be moviesByTitle instead of movieFulltextMovieTitle:
Graphql
Copy to Clipboard
type Query {
  moviesByTitle(phrase: String!, where: MovieFulltextWhere, sort: [MovieFulltextSort!], limit: Int, offset: Int): [MovieFulltextResult!]!
}
@cypher changes
The default behaviour of the @cypher directive regarding the translation will change: Instead of using apoc.cypher.runFirstColumnMany it will directly wrap the query within a CALL { } subquery. This behvaiour has proven to be much more performant for the same queries, however, it may lead to unexpected changes, mainly when using Neo4j 5.x, where the subqueries need to be aliased.
On top of that, to improve performance, it is recommended to pass the returned alias in the property columnName, to ensure the subquery is properly integrated into the larger query.
For example:
The graphql query:
Graphql
Copy to Clipboard
type query {
    test: String! @cypher(statement: ""RETURN 'hello'"")
}
Would get translated to:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL {
    RETURN 'hello'
}
WITH 'hello' AS this
RETURN this
Which is invalid in Neo4j 5.x.
To fix it we just need to ensure the RETURN elements are aliased:
Graphql
Copy to Clipboard
type query {
    test: String! @cypher(statement: ""RETURN 'hello' as result"")
}
This will be a breaking change, but this new behaviour can be used, as an experimental option with the columnName flag in the @cypher directive:
Graphql
Copy to Clipboard
type query {
    test: String! @cypher(statement: ""RETURN 'hello' as result"", columnName: ""result"")
}
Additionally, escaping strings is no longer needed.
3.0.0 Migration
Troubleshooting
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v2-migration/unions;"Unions
Contents
Input types
Filtering union fields
In this release, the decision was made to take the opportunity to overhaul the existing support for unions on relationship fields, laying down the foundations for adding top-level union support in the future.
All examples in this section will be based off the following type definitions:
Graphql
Copy to Clipboard
type Actor {
    name: String!
    actedIn: [Production!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}

type Series {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}

union Production = Movie | Series
Input types
The structure of input types for union queries and mutations have been changed for user friendliness, and a more consistent API.
Essentially, field names which were previously of template <unionFieldName>_<concreteType> (for example, ""actedIn_Movie"") are now an object, with the field name at the top, and the member types under it.
For example, a Mutation which would have previously been:
Graphql
Copy to Clipboard
mutation {
    createActors(
        input: [
            {
                name: ""Tom Hiddleston""
                actedIn_Movie: {
                    create: [
                        {
                            title: ""The Avengers""
                        }
                    ]
                }
                actedIn_Series: {
                    create: [
                        {
                            title: 
                        }
                    ]
                }
            }
        ]
    )
}
View all (9 more lines)
Will now be:
Graphql
Copy to Clipboard
mutation {
    createActors(
        input: [
            {
                name: ""Tom Hiddleston""
                actedIn: {
                    Movie: {
                        create: [
                            {
                                node: {
                                    title: ""The Avengers""
                                }
                            }
                        ]
                    }
                   : {
                        create: [
                            {
                                node: {
                                    title: 
                                }
                            }
                        ]
                    }
                }
            }
        ]
    )
}
View all (15 more lines)
Note the change in structure for union input, but also the additional node level which enables the use of relationship properties. These changes are consistent across all operations, including where.
Filtering union fields
There has been a slight change to how you filter union fields, adding a where level above each union member. For example, for a query which would have used to have looked like:
Graphql
Copy to Clipboard
query {
    actors {
        name
        actedIn(Movie: { ""The Avengers"" }) {
            ... on Movie {
                title
            }
        }
    }
}
This will now be written like:
Graphql
Copy to Clipboard
query {
    actors {
        name
        actedIn(where: { Movie: { ""The Avengers"" }}) {
            ... on Movie {
                title
            }
        }
    }
}
Furthermore, the where argument used now dictates which union members are returned from the database, to prevent overfetching. Please see this page for background and explanation of this decision.
Mutations
Miscellaneous
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/v2-migration/mutations;"Mutations
Contents
Create
Update
Update
Disconnect
Delete
The most broadly affected area of functionality by the 2.0.0 upgrade are the nested operations of Mutations, to faciliate the mutation of and filtering on relationship properties.
The examples in this section will be based off the following type definitions:
Graphql
Copy to Clipboard
type Actor {
    name: String!
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    title: String!
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}
The theme that you will notice during this section is that as a general rule of thumb, a node field will need adding to your inputs where it will also be possible to filter on relationship properties.
Create
Focussing on the createMovies Mutation, notice that the definition of the createMovies Mutation is unchanged:
Graphql
Copy to Clipboard
input MovieCreateInput {
    title: String!
    actors: MovieActorsFieldInput
}

type Mutation {
    createMovies(input: [MovieCreateInput!]!): CreateMoviesMutationResponse!
}
There are no changes to any of the arguments or types at this level. However, within its nested operations, type modifications have taken place to allow for relationship properties.
In practice, take a Mutation that creates the film ""The Dark Knight"" and then:
Creates a new actor ""Heath Ledger""
Connects to the existing actor ""Christian Bale""
In the previous version of the library, this would have looked like this:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                title: ""The Dark Knight""
                actors: {
                    create: [
                        {
                            name: ""Heath Ledger""
                        }
                    ]
                    connect: [
                        {
                            where: {
                                name: ""Christian Bale""
                            }
                        }
                    ]
                }
            }
        ]
    ) {
        movies {
            title
        }
    }
}
View all (12 more lines)
This will now have to look like this in order to function in the same way:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                title: ""The Dark Knight""
                actors: {
                    create: [
                        {
                            node: {
                                name: ""Heath Ledger""
                            }
                        }
                    ]
                    connect: [
                        {
                            where: {
                                node: {
                                    name: 
                                }
                            }
                        }
                    ]
                }
            }
        ]
    ) {
        movies {
            title
        }
    }
}
View all (16 more lines)
Note the additional level ""node"" before specifying the actor name for the create operation and in the connect where. This additional level allows for the setting of relationship properties for the new relationship, and filtering on existing relationship properties when looking for the node to connect to. See the page Mutations for details on this.
Update
Focussing on the updateMovies Mutation, notice that the definition of the updateMovies Mutation is unchanged:
Graphql
Copy to Clipboard
type Mutation {
    updateMovies(
        where: MovieWhere
        update: MovieUpdateInput
        connect: MovieConnectInput
        disconnect: MovieDisconnectInput
        create: MovieRelationInput
        delete: MovieDeleteInput
    ): UpdateMoviesMutationResponse!
}
The create and connect nested operations are primarily the same as in the createMovies Mutation, so please see the Create section for the difference for these operations.
The delete nested operation is primarily the same as in the deleteMovies Mutation, so please see the Delete section for that.
Update
For example, say that you accidentally misspelt Christian Bale’s surname and wanted to fix that. In the previous version, you might have achieved that by:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: {
            title: ""The Dark Knight""
        }
        update: {
            actors: [
                {
                    where: {
                        name_ENDS_WITH: ""Bail""
                    }
                    update: {
                        name: ""Christian Bale""
                    }
                }
            ]
        }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
View all (11 more lines)
This will now have to look like this in order to function in the same way:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: {
            title: ""The Dark Knight""
        }
        update: {
            actors: [
                {
                    where: {
                        node: {
                            name_ENDS_WITH: ""Bail""
                        }
                    }
                    update: {
                        node: {
                            name: 
                        }
                    }
                }
            ]
        }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
View all (15 more lines)
Note the added layer of abstraction of node in both the where and update clauses.
Disconnect
For example, say you mistakenly put Ben Affleck as playing the role of Batman in ""The Dark Knight"", and you wanted to disconnect those nodes. In the previous version, this would have looked like:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: {
            title: ""The Dark Knight""
        }
        disconnect: {
            actors: [
                {
                    where: {
                        name: ""Ben Affleck""
                    }
                }
            ]
        }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
View all (9 more lines)
This will now have to look like this in order to function in the same way:
Graphql
Copy to Clipboard
mutation {
    updateMovies(
        where: {
            title: ""The Dark Knight""
        }
        disconnect: {
            actors: [
                {
                    where: {
                        node: {
                            name: ""Ben Affleck""
                        }
                    }
                }
            ]
        }
    ) {
        movies {
            title
            actors {
                name
            }
        }
    }
}
View all (10 more lines)
Delete
Focussing on the deleteMovies Mutation, notice that the definition of the deleteMovies Mutation is unchanged:
Graphql
Copy to Clipboard
input MovieDeleteInput {
    actors: [MovieActorsDeleteFieldInput!]
}

type Mutation {
    deleteMovies(where: MovieWhere, delete: MovieDeleteInput): DeleteInfo!
}
There are no changes to any of the arguments or types at this level, but there are some details to note in the MovieActorsDeleteFieldInput type.
Previously, you would have expected this to look like:
Graphql
Copy to Clipboard
input MovieActorsDeleteFieldInput {
    delete: ActorDeleteInput
    where: ActorWhere
}
This allowed you to filter on fields of the Actor type and delete based on that. However, following this upgrade, you will find:
Graphql
Copy to Clipboard
input MovieActorsDeleteFieldInput {
    delete: ActorDeleteInput
    where: MovieActorsConnectionWhere
}
This means that not only can you filter on node properties, but also relationship properties, in order to find and delete Actor nodes.
In practice, a Mutation that deletes the film ""The Dark Knight"" and the related actor ""Christian Bale"" would have previously looked like this:
Graphql
Copy to Clipboard
mutation {
    deleteMovies(
        where: {
            title: ""The Dark Knight""
        }
        delete: {
            actors: {
                where: {
                    name: ""Christian Bale""
                }
            }
        }
    ) {
        nodesDeleted
        relationshipsDeleted
    }
}
This will now have to look like this in order to function in the same way:
Graphql
Copy to Clipboard
mutation {
    deleteMovies(
        where: {
            title: ""The Dark Knight""
        }
        delete: {
            actors: {
                where: {
                    node: {
                        name: ""Christian Bale""
                    }
                }
            }
        }
    ) {
        nodesDeleted
        relationshipsDeleted
    }
}
View all (4 more lines)
Note the additional level ""node"" before specifying the actor name.
2.0.0 Migration
Unions
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/mutations;"Mutations
Contents
A note on nested Mutations
Several Mutations are automatically generated for each type defined in type definitions, which are covered in the following chapters:
Create - create nodes, and recursively create or connect further nodes in the graph
Update - update nodes, and recursively perform any operations from there
Delete - delete nodes, and recursively delete or disconnect further nodes in the graph
A note on nested Mutations
You will see some basic examples of nested Mutations in this chapter, which barely scratch the surface of what can be achieved with them. It’s encouraged to explore the power of what you can do with them!
However, it has to be noted that in order to provide the abstractions available in these Mutations, the output Cypher can end up being extremely complex, which can result in your database throwing out-of-memory errors depending on its configuration.
If out-of-memory errors are a regular occurrence, you can adjust the dbms.memory.heap.max_size parameter in the DBMS settings.
If you need to perform major data migrations, it may be best to manually write the necessary Cypher and execute this directly in the database.
Queries
Create
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/mutations/create;"Create
Contents
Single create
Nested create
connectOrCreate relationships
Using the following type definitions for these examples:
Graphql
Copy to Clipboard
type Post {
    id: ID! @id
    content: String!
    creator: User! @relationship(type: ""HAS_POST"", direction: IN)
}

type User {
    id: ID! @id
    name: String
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}
The following create Mutations and response types will be generated for the above type definitions:
Graphql
Copy to Clipboard
type CreatePostsMutationResponse {
    posts: [Post!]!
}

type CreateUsersMutationResponse {
    users: [User!]!
}

type Mutation {
    createPosts(input: [PostCreateInput!]!): CreatePostsMutationResponse!
    createUsers(input: [UsersCreateInput!]!): CreateUsersMutationResponse!
}
The CreateInput types closely mirror the object type definitions, allowing you to create not only the type in question, but to recurse down and perform further operations on related types in the same Mutation.
The id field will be absent from both create input types as the @id directive has been used.
Single create
A single user can be created by executing the following GraphQL statement:
Graphql
Copy to Clipboard
mutation {
    createUsers(input: [
        {
            name: ""John Doe""
        }
    ]) {
        users {
            id
            name
        }
    }
}
This will create a User with name ""John Doe"", and that name plus the autogenerated ID will be returned.
Nested create
A User and an initial Post can be created by executing the following:
Graphql
Copy to Clipboard
mutation {
    createUsers(input: [
        {
            name: ""John Doe""
            posts: {
                create: [
                    {
                        node: {
                            content: ""Hi, my name is John!""
                        }
                    }
                ]
            }
        }
    ]) {
        users {
            id
            name
            posts {
                id
                content
            }
        }
    }
}
View all (10 more lines)
This will create a User with name ""John Doe"", an introductory Post, both of which will be returned with their autogenerated IDs.
connectOrCreate relationships
If a related node has a @unique or @id directive defined, connectOrCreate can be used in a nested create to perform a MERGE operation on the related node, creating a new relationship and the related node if it doesn’t exist.
Consider the following type definitions:
Graphql
Copy to Clipboard
type Actor {
    name: String!
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
}

type Movie {
    title: String
    id: ID! @id
    actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
}
Because a movie ID is unique, connectOrCreate can be used in an Actor mutation to ensure a movie exists before connecting. Note that only @unique or @id fields can be used in where:
Graphql
Copy to Clipboard
mutation {
  createActors(input: {
    name: ""Tom Hanks"",
    movies: {
      connectOrCreate: {
        where: { node: { id: ""1234"" } }
        onCreate: { node: { title: ""Forrest Gump"" } }
      }
    }
  }) {
    info {
      nodesCreated
    }
  }
}
This will ensure that a movie with ID 1234 exists and it is connected to ""Tom Hanks"". If the movie does not exist, it will be created with the title ""Forrest Gump"". Note that if the movie with the given ID already exists, it will be connected to it, regardless of the title.
Mutations
Update
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/guides/frameworks/nextjs;"Usage with Next.js
Contents
Creating a Next.js application
Create and configure the API route
Add dependencies
Configure secrets (Neo4j credentials)
Set up the GraphQL API endpoint
Start the server
This page describes the basics on how to use @neo4j/graphql as part of a Next.js application.
The official documentation on how to setup a GraphQL in Next.js is located here.
Creating a Next.js application
The recommended way to create a Next.js application is to use the Next.js CLI.
Bash
Copy to Clipboard
npx create-next-app neo4j-graphql-nextjs && cd neo4j-graphql-nextjs
With the command to start the development server yarn dev an index page should now be available on http://localhost:3000.
Create and configure the API route
To have a GraphQL API started when the application starts, dependencies are needed and a file pages/api/graphql.js should be created and configured.
Add dependencies
At this point it’s time to add the dependencies needed to run @neo4j/graphql inside Next.js.
Bash
Copy to Clipboard
yarn add apollo-server-micro micro graphql@^16.0.0 @neo4j/graphql neo4j-driver
Configure secrets (Neo4j credentials)
Next.js supports .env files for storing secrets secrurely, so create a .env.local file with the following contents to set it up.
Make sure you have a Neo4j DBMS running on the configured URI below. Download Neo4j Desktop for easy local Neo4j DBMS management.
Bash
Copy to Clipboard
NEO4J_URI=neo4j://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=mypassword
Set up the GraphQL API endpoint
Place all of the following in a new file pages/api/graphql.js.
JavaScript
Copy to Clipboard
import { gql, ApolloServer } from ""apollo-server-micro"";
import { Neo4jGraphQL } from ""@neo4j/graphql"";
import neo4j from ""neo4j-driver"";

const typeDefs = gql`
    type Movie @exclude(operations: [CREATE, UPDATE, DELETE]) {
        title: String!
        actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
    }
    type Actor @exclude(operations: [CREATE, UPDATE, DELETE]) {
        name: String!
        actedIn: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
    }
`;

 driver = neo4j.driver(
    process.env.NEO4J_URI,
    neo4j.auth.basic(process.env.NEO4J_USER, process.env.NEO4J_PASSWORD)
);

   {
    res.setHeader(, );
    res.setHeader(, );
    res.setHeader(, );
     (req.method === ) {
        res.end();
         ;
    }

     neoSchema =  Neo4jGraphQL({ typeDefs, driver });
     apolloServer =  ApolloServer({ :  neoSchema.getSchema() });
     apolloServer.start();
     apolloServer.createHandler({
        : ,
    })(req, res);
}

  config = {
    : {
        : ,
    },
};
View all (27 more lines)
Start the server
That is all that needs to be done for @neo4j/graphql to work in a Next.js application. The dev server starts wtih yarn dev and Apollo Studio should be loaded on http://localhost:3000/api/graphql and the front-end part of the Next.js application should be able to query the API.
Guides
Migration Guide
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/toolbox;"Neo4j GraphQL Toolbox
Contents
Example
Link
Usage
Requirements
Experiment with your Neo4j GraphQL API using the purpose-built web IDE.
This tool is currently for development purposes only!
Example
Figure 1. Query editor view
Link
Access the Neo4j GraphQL Toolbox here: https://graphql-toolbox.neo4j.io/
Usage
Connect to the database with your credentials
Define (or Introspect) the Type definitions
Build the Neo4j GraphQL schema
Experiment, query and play
Requirements
A Neo4j database, see Neo4j Desktop or use a Neo4j AuraDB
Make sure the database fulfills the requirements stated here, including the necessary plugins.
Introspector
Driver Configuration
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/introduction;"Introduction
Contents
How does it work?
Features
Interaction
Deployment
Versioning
Requirements
Resources
Licence
The Neo4j GraphQL Library is a highly flexible, low-code, open source JavaScript library that enables rapid API development for cross-platform and mobile applications by tapping into the power of connected data.
With Neo4j as the graph database, the GraphQL Library makes it simple for applications to have application data treated as a graph natively from the front-end all the way to storage, avoiding duplicate schema work and ensuring flawless integration between front-end and backend developers.
Written in TypeScript, the library’s schema-first paradigm lets developers focus on the application data they need, while taking care of the heavy lifting involved in building the API.
Just want to get moving with the Neo4j GraphQL Library? Check out the Getting Started guide!
How does it work?
By supplying the Neo4j GraphQL Library with a set of type definitions describing the shape of your graph data, it can generate an entire executable schema with all of the additional types needed to execute queries and mutations to interact with your Neo4j database.
For every query and mutation that is executed against this generated schema, the Neo4j GraphQL Library generates a single Cypher query which is executed against the database. This eliminates the infamous N+1 Problem which can make GraphQL implementations slow and inefficient.
Features
The Neo4j GraphQL Library presents a large feature set for interacting with a Neo4j database using GraphQL:
Automatic generation of Queries and Mutations for CRUD interactions
Various Types, including temporal and spatial types
Support for both node and relationship properties
Extensibility through the @cypher directive and/or Custom Resolvers
Extensive Filtering and Sorting options
Options for value Autogeneration and Default Values
Multiple Pagination options
Comprehensive authentication and authorisation options (Auth), and additional Access Control options
An OGM (Object Graph Mapper) for programmatic interaction with your GraphQL API
A Toolbox (UI) to experiment with your Neo4j GraphQL API on Neo4j Desktop.
Interaction
In the Getting Started guide, Apollo Server is used to host the GraphQL schema. This bundles Apollo Sandbox which can be used to interact directly with your GraphQL API with no front-end.
There are a variety of front-end frameworks with clients for interacting with GraphQL APIs:
React - support through Apollo Client
Vue.js - support through Vue Apollo
AngularJS - support through Apollo Angular
Deployment
There are a variety of methods for deploying GraphQL APIs, the details of which will not be in this documentation.
However, Apollo has documented a subset in their Deployment documentation, which will be a good starting point.
Versioning
The Neo4j GraphQL Library uses Semantic Versioning. Given a version number MAJOR.MINOR.PATCH, the increment is based on:
MAJOR - incompatible API changes compared to the previous MAJOR version, for which you will likely have to migrate.
MINOR - new features have been added in a backwards compatible manner.
PATCH - bug fixes have been added in a backwards compatible manner.
Additionally, prerelease version numbers may have additional suffixes, for example MAJOR.MINOR.PATCH-PRERELEASE.NUMBER, where PRERELEASE is one of the following:
alpha - unstable prerelease artifacts, and the API may change between releases during this phase.
beta - feature complete prerelease artifacts, which will be more stable than alpha releases but will likely still contain bugs.
rc - release candidate release artifacts where each could be promoted to a stable release, in a last effort to find trailing bugs.
NUMBER in the suffix is simply an incrementing release number in each phase.
Requirements
Neo4j Database version 4.3 and newer with APOC plugin:
Node.js 16+
For help installing the APOC plugin, see this page.
Resources
GitHub
Issue Tracker
npm package
Licence
Documentation: Creative Commons 4.0
Source: Apache 2.0
Neo4j GraphQL Library
Getting Started
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/getting-started;"Getting Started
Contents
Create a new project
Install dependencies
Define your GraphQL type definitions
Create an instance of Neo4jGraphQL
Create an instance of ApolloServer
Start the server
Create your first nodes in the database
This tutorial walks you through:
Installing the Neo4j GraphQL Library and its dependencies
Defining type definitions that represent the structure of your graph database
Instantiating an instance of the library, which will generate a GraphQL schema
Running an instance of a server which will let you execute queries and mutations against your schema
This tutorial assumes familiarity with the command line and JavaScript, and also that you have a recent version of Node.js installed. These examples will use the default npm package manager, but feel free to use your package manager of choice.
This tutorial walks through creating a new project with the Neo4j GraphQL Library. If you are not familiar, it will be worthwhile reading up on Neo4j and GraphQL.
Create a new project
Create a new directory and cd into it:
Bash
Copy to Clipboard
mkdir neo4j-graphql-example
cd neo4j-graphql-example
Create a new Node.js project:
Bash
Copy to Clipboard
npm init --yes
Whilst you’re there, create an empty index.js file which will contain all of the code for this example:
Bash
Copy to Clipboard
touch index.js
Install dependencies
The Neo4j GraphQL Library and it’s dependencies must be installed:
@neo4j/graphql is the official Neo4j GraphQL Library package, which takes your GraphQL type definitions and generates a schema backed by a Neo4j database for you.
graphql is the package used by the Neo4j GraphQL Library to generate a schema and execute queries and mutations.
neo4j-driver is the official Neo4j Driver package for JavaScript, of which an instance must be passed into the Neo4j GraphQL Library.
Additionally, you will need to install a GraphQL server package which will host your schema and allow you to execute queries and mutations against it. For this example, use the popular Apollo Server package:
apollo-server is the default package for Apollo Server, which you will pass the Neo4j GraphQL Library generated schema into.
Bash
Copy to Clipboard
npm install @neo4j/graphql graphql neo4j-driver apollo-server
Make sure the database fulfills the requirements stated here, including the necessary plugins.
Define your GraphQL type definitions
The Neo4j GraphQL Library is primarily driven by type definitions which map to the nodes and relationships in your Neo4j database. To get started, use a simple example with two node types, one with label ""Actor"" and the other ""Movie"".
Open up the previously created index.js in your editor of choice and write out your type definitions. You should also add all of the necessary package imports at this stage:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const { ApolloServer, gql } = require(""apollo-server"");
const neo4j = require(""neo4j-driver"");

const typeDefs = gql`
    type Movie {
        title: String
        actors: [Actor!]! @relationship(type: ""ACTED_IN"", direction: IN)
    }

    type Actor {
        name: String
        movies: [Movie!]! @relationship(type: ""ACTED_IN"", direction: OUT)
    }
`;
These type definitions are incredibly simple, defining the two previously described node labels, and a relationship ""ACTED_IN"" between the two. When generated, the schema will allow you to execute queries actors and movies to read data from the database.
You can also automatically generate type definitions from an existing database by introspecting the schema.
Create an instance of Neo4jGraphQL
Now that you have your type definitions, you need to create an instance of the Neo4j GraphQL Library. To do this, you also need a Neo4j driver to connect to your database. For a database located at ""bolt://localhost:7687"", with a username of ""neo4j"" and a password of ""password"", add the following to the bottom of your index.js file:
JavaScript
Copy to Clipboard
const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const neoSchema = new Neo4jGraphQL({ typeDefs, driver });
Create an instance of ApolloServer
The final section of code you need to add is to instantiate an Apollo Server instance using the generated schema, which will allow you to execute queries against it.
Add the following to the bottom of index.js:
JavaScript
Copy to Clipboard
neoSchema.getSchema().then((schema) => {
  const server = new ApolloServer({
      schema,
  });

  server.listen().then(({ url }) => {
      console.log(`🚀 Server ready at ${url}`);
  });
})
Start the server
Finally, you’re ready to start up your GraphQL server! Back in the command line, run the following command:
Bash
Copy to Clipboard
node index.js
All going well, you should see the following output:
Bash
Copy to Clipboard
🚀 Server ready at http://localhost:4000/
Where http://localhost:4000/ is the default URL which Apollo Server starts at.
Create your first nodes in the database
Now it’s time to add some data to your Neo4j database using your GraphQL API!
Visit http://localhost:4000/ in your web browser and you’ll see the following landing page:
Figure 1. Apollo Server Landing Page
Click ""Query your server"" which will open the Sandbox.
Figure 2. First Mutation
At the moment your database is empty! To get some data in there, you can create a movie and an actor in that movie, all in one Mutation. The Mutation in the screenshot above can also be found below:
Graphql
Copy to Clipboard
mutation {
  createMovies(
    input: [
      {
        title: ""Forrest Gump""
        actors: { create: [{ node: { name: ""Tom Hanks"" } }] }
      }
    ]
  ) {
    movies {
      title
      actors {
        name
      }
    }
  }
}
Put this Mutation into the Operations panel and hit the blue ""Run"" button in the top right. When you execute the Mutation, you’ll receive the following response, confirmation that the data has been created in the database!
Json
Copy to Clipboard
{
  ""data"": {
    ""createMovies"": {
      ""movies"": [
        {
          ""title"": ""Forrest Gump"",
          ""actors"": [
            {
              ""name"": ""Tom Hanks""
            }
          ]
        }
      ]
    }
  }
}
You can now go back and query the data which you just added:
Figure 3. First Query
The query in the screenshot above is querying for all movies and their actors in the database:
Graphql
Copy to Clipboard
query {
  movies {
    title
    actors {
      name
    }
  }
}
Of course, you only have the one of each, so you will see the result below:
Json
Copy to Clipboard
{
  ""data"": {
    ""movies"": [
      {
        ""title"": ""Forrest Gump"",
        ""actors"": [
          {
            ""name"": ""Tom Hanks""
          }
        ]
      }
    ]
  }
}
Introduction
Type Definitions
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/sorting;"Sorting
A sorting input type is generated for every object type defined in your type definitions, allowing for Query results to be sorted by each individual field.
Using the following example type definition:
Graphql
Copy to Clipboard
type Movie {
    title: String!
    runtime: Int!
}
The following sorting input type and query will be generated:
Graphql
Copy to Clipboard
type Movie {
    title: String!
    runtime: Int!
}

enum SortDirection {
    ASC
    DESC
}

input MovieSort {
    title: SortDirection
    runtime: SortDirection
}

input {
    """"
    sort: !]
    limit:
    offset:
}

 {
    movies(where:, options:): !]!
}
View all (10 more lines)
The following query would then allow you to fetch all movies sorted by runtime in ascending order:
Graphql
Copy to Clipboard
query {
    movies(options: {
        sort: [
            {
                runtime: ASC
            }
        ]
    }) {
        title
        runtime
    }
}
Additionally, say there was a relationship between the Movie and an Actor type, sorting can also be applied when fetching the actors field:
Graphql
Copy to Clipboard
query {
    movies {
        title
        runtime
        actors(options: {
            sort: [
                {
                    surname: ASC
                }
            ]
        }) {
            surname
        }
    }
}
Filtering
Pagination
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/filtering;"Filtering
Contents
Operators
Equality operators
Numerical operators
String comparison
Array comparison
AND, OR operators
Usage
At the root of a Query
Combining operators
Filtering relationships
Relationship Filtering
Available Filters
Relationship Filtering Usage Examples
n..1 Relationships
n..m Relationships
Aggregation Filtering
Aggregation Filtering Usage Examples
Aggregation Filtering Operators
Operators
When querying for data, a number of operators are available for different types in the where argument of a Query or Mutation.
Equality operators
All types can be tested for either equality or non-equality. For the Boolean type, these are the only available comparison operators.
Numerical operators
The following comparison operators are available for numeric types (Int, Float, BigInt), Temporal Types and Spatial Types:
_LT
_LTE
_GTE
_GT
Filtering of spatial types is different to filtering of numerical types and also offers an additional filter - see Spatial Types.
String comparison
The following case-sensitive comparison operators are only available for use on String and ID types:
_STARTS_WITH
_NOT_STARTS_WITH
_ENDS_WITH
_NOT_ENDS_WITH
_CONTAINS
_NOT_CONTAINS
The following operators are disabled by default:
_LT
_LTE
_GT
_GTE
They can be enabled by explicitly adding them in the features options:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL } = require(""@neo4j/graphql"");
const neo4j = require(""neo4j-driver"");

const typeDefs = `
    type User {
        name: String
    }
`;

const driver = neo4j.driver(
    ""bolt://localhost:7687"",
    neo4j.auth.basic(""neo4j"", ""password"")
);

const features = {
    : {
        : {
            : ,
            : ,
            : ,
            : 
        }
    }
};

 neoSchema =  Neo4jGraphQL({ features, typeDefs, driver });
View all (11 more lines)
RegEx matching
The filter _MATCHES is also available for comparison of String and ID types, which accepts a RegEx string as an argument and returns any matches. Note that RegEx matching filters are disabled by default.
To enable the inclusion of this filter, set the config option enableRegex to true.
The nature of RegEx matching means that on an unprotected API, this could potentially be used to execute a ReDoS attack (https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS) against the backing Neo4j database.
Array comparison
The following two comparison operators are available on non-array fields, and accept an array argument:
_IN
_NOT_IN
Conversely, the following operators are available on array fields, and accept a single argument:
_INCLUDES
_NOT_INCLUDES
These four operators are available for all types apart from Boolean.
AND, OR operators
Complex combinations of operators are possible using the AND/ OR operators. These are stand-alone operators - that is, they are used as such and not appended to field names, and they accept an array argument with items of the same format as the where argument.
Usage
Using the type definitions from Queries, below are some example of how filtering can be applied when querying for data.
At the root of a Query
By using the where argument on the Query field in question, you can return a User with a particular ID:
Graphql
Copy to Clipboard
query {
    users(where: { id: ""7CF1D9D6-E527-4ACD-9C2A-207AE0F5CB8C"" }) {
        name
    }
}
Combining operators
All above-mentioned operators can be combined using the AND/OR operators. They accept an array argument with items of the same format as the where argument, which means they can also be nested to form complex combinations. As an example, the below query matches all actors by the name of either ""Keanu"" or belonging to the ""Pantoliano"" family, that played in ""The Matrix"" movie.
Graphql
Copy to Clipboard
query {
    actors(where: {
        AND: [
            {
                OR: [
                    { name_CONTAINS: ""Keanu"" },
                    { name_ENDS_WITH: ""Pantoliano"" }
                ]
            },
            {
                movies_SOME: { title: ""The Matrix"" }
            }
        ]}
    ) {
        name
        movies {
            title
        }
    }
}
View all (5 more lines)
Filtering relationships
By using the where argument on a relationship field, you can filter for a Post with a particular ID across all Users:
Graphql
Copy to Clipboard
query {
    users {
        id
        name
        posts(where: { id: ""2D297425-9BCF-4986-817F-F06EE0A1D9C7"" }) {
            content
        }
    }
}
Relationship Filtering
For each relationship field, field, a set of filters are available depending on whether the relationship is n..1 or n..m. In the case of n..1, filtering is done on equality or inequality of the related node by specifying a filter on field or field_NOT, respectively. In the case of n..m, filtering is done on the list of related nodes and is based on the List Predicates available in Cypher.
Available Filters
n..1
field - equality
field_NOT - inequality
n..m
field_ALL - all
field_NONE - none
field_SOME - any
field_SINGLE - single
Relationship Filtering Usage Examples
For this section take as type definitions the following:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String
    posts: [Post!]! @relationship(type: ""HAS_POST"", direction: OUT)
}

type Post {
    id: ID!
    content: String
    author: User! @relationship(type: ""HAS_POST"", direction: IN)
    likes: [User!]! @relationship(type: ""LIKES"", direction: IN)
}
n..1 Relationships
In the above, an author represents a n..1 relationship on Post where a given Post is authored by one, and only one, author. The available filters here will be author and author_NOT.
Find all posts by a desired author
Graphql
Copy to Clipboard
query {
    posts(where: { author: { id: ""7CF1D9D6-E527-4ACD-9C2A-207AE0F5CB8C"" } }) {
        content
    }
}
Find all posts not by an undesired author
Graphql
Copy to Clipboard
query {
    posts(where: { author_NOT: { id: ""7CF1D9D6-E527-4ACD-9C2A-207AE0F5CB8C"" } }) {
        content
    }
}
n..m Relationships
In the above, posts represents a n..m relationship on User where a given User can have any number of posts.
Find all users where all of their posts contain search term: ""neo4j""
Graphql
Copy to Clipboard
query {
    users(where: { posts_ALL: { content_CONTAINS: ""neo4j"" } }) {
        name
    }
}
Find all users where none of their posts contain search term: ""cypher""
Graphql
Copy to Clipboard
query {
    users(where: { posts_NONE: { content_CONTAINS: ""cypher"" } }) {
        name
    }
}
Find all users where some of their posts contain search term: ""graphql""
Graphql
Copy to Clipboard
query {
    users(where: { posts_SOME: { content_CONTAINS: ""graphql"" } }) {
        name
    }
}
Find all users where only one of their posts contain search term: ""graph""
Graphql
Copy to Clipboard
query {
    users(where: { posts_SINGLE: { content_CONTAINS: ""graph"" } }) {
        name
    }
}
Aggregation Filtering
This library offers, for each relationship, an aggregation key inside the where argument. You can use the aggregation key to satisfy questions such as:
Find the posts where the number of likes are greater than 5
Find flights where the average age of passengers is greater than or equal to 18
Find movies where the shortest actor screen time is less than 10 minutes
You can use this where aggregation on both the node and edge of a relationship.
Aggregation Filtering Usage Examples
Find the posts where the number of likes are greater than 5
Given the schema:
Graphql
Copy to Clipboard
type User {
    name: String
}

type Post {
    content: String
    likes: [User!]! @relationship(type: ""LIKES"", direction: IN)
}
Answering the question:
Graphql
Copy to Clipboard
query {
    posts(where: { likesAggregate: { count_GT: 5 } }) {
        content
    }
}
Find flights where the average age of passengers is greater than or equal to 18
Given the schema:
Graphql
Copy to Clipboard
type Passenger {
    name: String
    age: Int
}

type Flight {
    code: String
    passengers: [Passenger!]! @relationship(type: ""FLYING_ON"", direction: IN)
}
Answering the question:
Graphql
Copy to Clipboard
query {
    flights(where: { passengersAggregate: { node: { age_AVERAGE_GTE: 18 } } }) {
        code
    }
}
Find movies where the shortest actor screen time is less than 10 minutes
Given the schema:
Graphql
Copy to Clipboard
type Movie {
    title: String
    actors: [Person!]! @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
}

type Person {
    name: String
}

interface ActedIn {
    screenTime: Int
}
Answering the question:
Graphql
Copy to Clipboard
query {
    movies(where: { actorsAggregate: { edge: { screenTime_MIN_LT: 10 } } }) {
        title
    }
}
Aggregation Filtering Operators
Below you will learn more about the autogenerated filters available on the aggregate key and for each type on the node and edge of the specified relationship.
Count
This is a special 'top level' key inside the where aggregation and will be available for all relationships. This is used to count the amount of relationships the parent node is connected to. The operators count has are as follows:
count_EQUAL
count_GT
count_GTE
count_LT
count_LTE
Example
Graphql
Copy to Clipboard
query {
    posts(where: { likesAggregate: { count_GT: 5 } }) {
        content
    }
}
ID
You can only use the _EQUAL operator on types of ID.
String
Fields of type String have the following operators:
_EQUAL
_GT
_GTE
_LT
_LTE
_AVERAGE_EQUAL
_AVERAGE_GT
_AVERAGE_GTE
_AVERAGE_LT
_AVERAGE_LTE
_SHORTEST_EQUAL
_SHORTEST_GT
_SHORTEST_GTE
_SHORTEST_LT
_SHORTEST_LTE
_LONGEST_EQUAL
_LONGEST_GT
_LONGEST_GTE
_LONGEST_LT
_LONGEST_LTE
These operators are calculated against the length of each string.
Example
Graphql
Copy to Clipboard
query {
    posts(where: { likesAggregate: { node: { name_LONGEST_GT: 5 } } }) {
        content
    }
}
Numerical Types
Numerical types include the following:
Int
Float
BigInt
The types in the list above have the following operators:
_EQUAL
_GT
_GTE
_LT
_LTE
_AVERAGE_EQUAL
_AVERAGE_GT
_AVERAGE_GTE
_AVERAGE_LT
_AVERAGE_LTE
_SUM_EQUAL
_SUM_GT
_SUM_GTE
_SUM_LT
_SUM_LTE
_MIN_EQUAL
_MIN_GT
_MIN_GTE
_MIN_LT
_MIN_LTE
_MAX_EQUAL
_MAX_GT
_MAX_GTE
_MAX_LT
_MAX_LTE
Example
Graphql
Copy to Clipboard
query {
    movies(where: { actorsAggregate: { edge: { screenTime_MIN_LT: 10 } } }) {
        title
    }
}
Temporal Types
Temporal types include the following:
DateTime
LocalDateTime
LocalTime
Time
Duration
The types listed above have the following aggregation operators:
_EQUAL
_GT
_GTE
_LT
_LTE
_MIN_EQUAL
_MIN_GT
_MIN_GTE
_MIN_LT
_MIN_LTE
_MAX_EQUAL
_MAX_GT
_MAX_GTE
_MAX_LT
_MAX_LTE
Whilst the Duration type also has the following additional operators:
_AVERAGE_EQUAL
_AVERAGE_GT
_AVERAGE_GTE
_AVERAGE_LT
_AVERAGE_LTE
AMQP
Sorting
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/plugins/amqp;"AMQP Plugin
Contents
Usage
API
close(): Promise<void>
The @neo4j/graphql-plugin-subscriptions-amqp plugin connects to brokers through AMQP 0-9-1 protocol such as:
RabbitMQ
Apache Qpid
Apache ActiveMQ
It can be installed with npm:
Sh
Copy to Clipboard
npm install @neo4j/graphql-plugin-subscriptions-amqp
AMQP 1.0 is not supported by this plugin.
Usage
JavaScript
Copy to Clipboard
const { Neo4jGraphQLSubscriptionsAMQPPlugin } = require(""@neo4j/graphql-plugin-subscriptions-amqp"");

const plugin = new Neo4jGraphQLSubscriptionsAMQPPlugin({
    connection: {
        hostname: ""localhost"",
        username: ""guest"",
        password: ""guest"",
    }
});

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    driver,
    plugins: {
        subscriptions: plugin,
    },
});
API
The following options can be passed to the contructor:
connection: An AMQP uri as a string or a configuration object:
hostname: Hostname to be used, defaults to localhost.
username: defaults to guest.
password: defaults to guest.
port: Port of the AMQP broker, defaults to 5672.
exchange: The exchange to be used in the broker. Defaults to neo4j.graphql.subscriptions.fx.
version: The AMQP version to be used. Currently only 0-9-1 is supported.
Additionally, any option supported by amqplib can be passed to connection.
close(): Promise<void>
Closes the connection and channel created and unbinds the event emitter.
Single Instance
Filtering
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/plugins/single-instance;"Single Instance Plugin
The @neo4j/graphql library provides a zero-dependency plugin to be used during development to quickly deploy a subscriptions server locally in a single instance. If can be imported directly:
JavaScript
Copy to Clipboard
const { Neo4jGraphQL, Neo4jGraphQLSubscriptionsSingleInstancePlugin } = require('@neo4j/graphql');

const neoSchema = new Neo4jGraphQL({
    typeDefs,
    driver,
    plugins: {
        subscriptions: new Neo4jGraphQLSubscriptionsSingleInstancePlugin(),
    },
});
For a full example, check the Getting started guide.
This plugin is not recommended for production environments unless running a single instance.
Plugins
AMQP
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/plugins;"Subscription Plugins
Contents
Official plugins
Create a custom plugin
Using Typescript
Note about event orders
Plugins are used to enable subscriptions in @neo4j/graphql and to allow easy connection to different message brokers. This is required to run a production system with horizontal scaling.
Official plugins
The following plugins are supported officially by @neo4j/graphql:
Single Instance - A plugin for use within a single instance of the GraphQL library, exported directly from the library.
AMQP - Connect to AMQP brokers such as RabbitMQ.
Create a custom plugin
If none of the existing plugins is valid for your use case, you can create a new plugin to connect to any broker you may need. To do this you need to create a new class defining your plugin. This class needs to contain the following:
An EventEmitter property called events that should emit an event everytime the broker sends a message.
A publish method that will publish a new event to the broker.
Optionally, a init method returning a promise, that will be called on getSchema. This is useful for setting up the connection to a broker.
For instance, if we wanted to subscribe using redis:
JavaScript
Copy to Clipboard
// Note: This is an example of a custom plugin and not a production ready redis plugin
class CustomRedisPlugin {
    constructor(redisClient) {
        this.client = redisClient;
        this.events = new EventEmitter();
    }

    // This method connects to Redis and sends messages to the eventEmitter when receiving events.
    async init(){
        await this.client.connect();
        this.subscriber = this.client.duplicate()
        this.publisher = this.client.duplicate();
        await this.subscriber.connect();
        await this.publisher.connect();

         .subscriber.subscribe(, (message) => {
           eventMeta = .parse(message);
          .events.emit(eventMeta.event, eventMeta); 
        });
    }

     publish(eventMeta) {
         .publisher.publish(, .stringify(eventMeta)); // Sends a message to redis
    }
}

 client = createClient(); 
 redisSubscriptions =  CustomRedisPlugin(client)

 neoSchema =  Neo4jGraphQL({
    typeDefs,
    driver,
    : {
        : redisSubscriptions,
    },
});
View all (21 more lines)
Note that, like in the previous example, extra properties and methods are often needed to handle the connection to the broker. As long as the messages are sent to the broker in the publish method and that these messages are received and then emitted through the events property, the subscriptions will be properly handled.
Using Typescript
If using Typescript, you may import the interface Neo4jGraphQLSubscriptionsPlugin to implement your own plugin:
Typescript
Copy to Clipboard
class CustomRedisPlugin implements Neo4jGraphQLSubscriptionsPlugin {}
Note about event orders
Events are sent to the plugin in order, however, order is not guaranteed once these events have been broadcasted through a broker. For cases when ordering is important, the subscriptions payload contains a field timestamp.
Horizontal Scaling
Single Instance
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/scaling;"Horizontal Scaling
Contents
The Problem
Using PubSub
The Problem
Horizontal scaling of any real time system can be tricky. Especially when dealing with long lived connections such as WebSockets. Consider the following example, in which Client A is subscribed to a certain event, that is triggered by Client B:
Figure 1. Simple subscriptions setup
In the previous example, the server running the GraphQL service, will do the following:
Receive the mutation by Client B.
Run the Cypher Query on Neo4j.
Trigger the subscription event to Client A.
This setup works fine for a single instance of @neo4j/graphql. However, when trying to scale horizontally, by adding more GraphQL servers, we may encounter the following situation:
Figure 2. Subscriptions with 2 servers
In this case, Client B is subscribed to one server, however, when Client A triggers the mutation, it queries a different server.
The change happens successfully in the database, and any client connected to the same server will receive the subscription event, however, Client A will not receive any update, as the server it’s connected to will not get notified of any mutation.
This is the behaviour of the single instance plugin provided by the library, so it is not suitable for use in a horizontally scaled environment.
Using PubSub
One solution to this problem, and how @neo4j/graphql is intended to work, is to use a PubSub pattern with an external broker to broadcast events through multiple instances. This can be achieved through subscription plugins.
Following the previous example, using an intermediate broker to broadcast the events across all instances, the infrastructure would look like:
Figure 3. Subscriptions with 2 servers and message broker
In this example, the events are as follow:
Client B will query the first server.
The server performs the mutation in the database.
The same server sends an event to the broker.
The broker will then notify every server (broadcast), including the server that originally triggered the event.
Both servers will receive the notification and will trigger any event to their subscribed clients.
You can find examples of usage with supported brokers in plugins.
Filtering
Plugins
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/getting-started;"Getting Started with Subscriptions
Contents
Example using Apollo and WebSockets
Setting up the server
GraphQL subscriptions
To get started with subscriptions you need a GraphQL server with subscription capabilities.
Example using Apollo and WebSockets
For this example, we will use Apollo and graphql-ws.
Setting up the server
Install the following dependencies:
Bash
Copy to Clipboard
npm i --save ws graphql-ws neo4j-driver @neo4j/graphql express apollo-server-express apollo-server-core
The following code implements a simple apollo-server-express server with subscriptions. You can find more examples and documentation on subscriptions in Apollo’s documentation.
JavaScript
Copy to Clipboard
const { createServer } = require(""http"");
const { EventEmitter } = require('events');
const neo4j = require('neo4j-driver');
const { Neo4jGraphQL, Neo4jGraphQLSubscriptionsSingleInstancePlugin } = require('@neo4j/graphql');
const { WebSocketServer } = require(""ws"");
const { useServer } = require(""graphql-ws/lib/use/ws"");
const express = require('express');
const  { ApolloServer } = require(""apollo-server-express"");
const { ApolloServerPluginDrainHttpServer } = require(""apollo-server-core"");

const typeDefs = `
    type Movie {
        title: String
    }

    type Actor {
        name: String
    }
`;

 driver = neo4j.driver(, neo4j.auth.basic(, ));

 neoSchema =  Neo4jGraphQL({
    typeDefs,
    driver,
    : {
        :  Neo4jGraphQLSubscriptionsSingleInstancePlugin(),
    },
});

 {
    
     app = express();
     httpServer = createServer(app);
     wsServer =  WebSocketServer({
        : httpServer,
        : ,
    });

    
     schema =  neoSchema.getSchema();
     serverCleanup = useServer({
        schema
    }, wsServer);

     server =  ApolloServer({
        schema,
        : [
            ApolloServerPluginDrainHttpServer({
                httpServer
            }),
            {
                 serverWillStart() {
                     {
                         drainServer() {
                             serverCleanup.dispose();
                        },
                    };
                },
            },
        ],
    });
     server.start();
    server.applyMiddleware({
        app
    });

     PORT = ;
    httpServer.listen(PORT, () => {
        .log();
    });
}

main();
View all (59 more lines)
The example above uses the single instance plugin and cannot scale horizontally.
GraphQL subscriptions
With the previous server running, we have subscriptions available for Movie and Actor. We can subscribe to new movies created with the following statement:
Graphql
Copy to Clipboard
subscription {
    movieCreated(where: { title: ""The Matrix"" }) {
        createdMovie {
            title
        }
    }
}
Any new movie created with the matching title will trigger a subscription. You can try this with the following query:
Graphql
Copy to Clipboard
mutation {
    createMovies(input: [{ title: ""The Matrix"" }]) {
        movies {
            title
        }
    }
}
This example uses the graphql-ws implementation, if you are using Apollo Studio, make sure to select ""graphql-ws"" implementation in connection settings.
Subscriptions
Create
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/events/create;"Create Subscriptions
Contents
CREATE event
Example
Subscriptions to CREATE events will listen to newly created nodes. A new event will be triggered for each new node. The event will contain the node’s properties.
Only nodes created will trigger this event, new relationships will not trigger the event.
CREATE event
A subscription to a type can be made with the top-level subscription [type]Created. The subscription will contain the following fields:
event: The event triggering this subscription, in this case it will always be ""CREATE"".
created<typename>: The properties of the newly created node, only top-level properties, without relationships, are available.
timestamp: The timestamp in which the mutation was made. Note that multiple events may come with the same timestamp if triggered by the same query.
Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
}
A subscription to any Movie created would look like:
Graphql
Copy to Clipboard
subscription {
    movieCreated {
        createdMovie {
            title
            genre
        }
        event
        timestamp
    }
}
Getting Started
Update
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/events/update;"Update Subscriptions
Contents
UPDATE event
Example
Subscription to UPDATE events will listen to node properties changes. A new event will be triggered for each mutation that modifies the node top-level properties.
Update events will only be triggered if any of the properties have changed. An update that doesn’t modify the properties will be ignored.
UPDATE event
A subscription to a type can be made with the top-level subscription [type]Updated. The subscription will contain the following fields:
event: The event triggering this subscription, in this case it will always be ""UPDATE"".
updated<typename>: The properties of the updated node, after modification. Only top-level properties, without relationships, are available.
previousState: The old properties of the node, right before the update event. Only top-level properties are available.
timestamp: The timestamp in which the mutation was made. Note that multiple events may come with the same timestamp if triggered by the same query.
Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
}
A subscription to any Movie updated could look like:
Graphql
Copy to Clipboard
subscription MovieUpdated {
    movieUpdated {
        event
        previousState {
            title
            genre
        }
        updatedMovie {
            title
        }
        timestamp
    }
}
Create
Delete
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/events/delete;"Delete Subscriptions
Contents
DELETE event
Example
Subscriptions to DELETE events will trigger on deleted nodes.
Only deleted nodes will trigger this event, deleted relationships will not trigger any event.
DELETE event
A subscription to a type can be made with the top-level subscription [type]Deleted. The subscription will contain the following fields:
event: The event triggering this subscription, in this case it will always be ""DELETE"".
deleted<typename>: The top-level properties of the deleted node, these will be the properties right before the node was deleted. Relationships are not available.
timestamp: The timestamp in which the mutation was made. Note that multiple events may come with the same timestamp if triggered by the same query.
Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
}
A subscription to any deleted Movie would look like:
Graphql
Copy to Clipboard
subscription {
    movieDeleted {
        deletedMovie {
            title
        }
        event
        timestamp
    }
}
Update
Create Relationship
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/subscriptions/events/create_relationship;"Create Relationship Subscriptions
Contents
CREATE_RELATIONSHIP event
Examples
Create Relationship with Standard Types
Create Relationship with Abstract Types
Non-reciprocal relationships
Special Considerations
Types using the same Neo4j label
Subscriptions to CREATE_RELATIONSHIP events will listen for newly created relationships to a node of the specified type.
This subscription operation is only available for types that define relationship fields.
As relationship-specific information, the event will contain the relationship field name, as well as an object containing all relationship field names of the specified type. This object will be populated with properties according to the newly created relationship.
A new event will be triggered for each new relationship.
This means that, if the type targeted for the subscriptions defines two or more relationships in the schema and one of each relationships are created following a mutation operation, the number of events triggered will be equivalent to the number of relationships created.
Each event will have the relationships object populated with the created relationship’s properties for one single relationship name only - all other relationship names will have a null value.
The event will also contain the properties of the nodes at both ends of the relationship, as well as the properties of the new relationship, if any.
The CREATE_RELATIONSHIP events represent new relationships being created and contain information about the nodes at each end of the new relationship. However, the connected nodes may or may not have previously existed. To subscribe to the node’s updates, you need to use one of the CREATE or UPDATE subscriptions.
CREATE_RELATIONSHIP event
A subscription to a type can be made with the top-level subscription [type]RelationshipCreated. The subscription will contain the following fields:
event: The event triggering this subscription, in this case it will always be ""CREATE_RELATIONSHIP"".
timestamp: The timestamp in which the mutation was made. Note that multiple events may come with the same timestamp if triggered by the same query.
<typename>: The properties of the node target to the subscription. Only top-level properties, without relationships, are available. Note these are the properties before the operation that triggered the CREATE_RELATIONSHIP took place.
relationshipFieldName: The field name of the newly created relationship, as part of the node target to the subscription.
createdRelationship: An object having as keys all field names of the node target to the subscription which represent its relationships. For any given event, all field names except the one corresponding to relationshipFieldName will be null. The field name equal to relationshipFieldName will contain the relationship properties if defined, and a node key containing the properties of the node on the other side of the relationship. Only top-level properties, without relationships, are available. Note these are the properties before the operation that triggered the CREATE_RELATIONSHIP took place.
Irrespective of the relationship direction in the database, the CREATE_RELATIONSHIP event is bound to the type targeted for the subscription. The consequence is that - given a relationship between types A and B that is not reciprocal (that is, in the GraphQL schema type A defines a relationship to B but B does not define a relationship to A) and a GraphQL operation that creates the relationship between them - even though the two nodes will be connected in the database, the CREATE_RELATIONSHIP event will only be returned to the subscription to type A. Check out the Non-reciprocal Relationships section below for more details.
For example, considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    reviewers: [Reviewer] @relationship(type: ""REVIEWED"", direction: IN, properties: ""Reviewed"")
}

type Actor {
    name: String
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}

 {
    name:
    reputation:
}

  {
    score:!
}
View all (9 more lines)
An ongoing subscription to created relationships on the Movie type, upon a mutation creating an Actor named Tom Hardy and a Reviewer named Jane to a Movie titled Inception would receive the following events:
Graphql
Copy to Clipboard
{
    # 1  - relationship type `ACTED_IN`
    event: ""CREATE_RELATIONSHIP"",
    timestamp,
    movie: {
        title: ""Inception"",
        genre: ""Adventure""
    },
    relationshipFieldName: ""actors"", # notice the field name specified here is populated below in the `createdRelationship` object
    createdRelationship: {
        actors: {
            screenTime: 1000, # relationship properties for the relationship type `ACTED_IN`
            node: { # top-level properties of the node at the other end of the relationship, in this case `Actor` type
                name: ""Tom Hardy""
            }
        },
        reviewers:  
    }
}
{
    
    event: ,
    timestamp,
    movie: {
        title: ,
        genre: 
    },
    relationshipFieldName: , 
    createdRelationship: {
        actors: , 
        reviewers: { 
            score: ,
            node: {
                name: ,
                reputation: 
            }
        }
    }
}
View all (24 more lines)
Examples
Create Relationship with Standard Types
For example, considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
}

type Actor {
    name: String
}

interface ActedIn @relationshipProperties {
    screenTime: Int!
}
A subscription to any Movie created relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        createdRelationship {
            actors {
                screenTime
                node {
                    name
                }
            }
        }
    }
}
View all (4 more lines)
Create Relationship with Abstract Types
When using Abstract Types with relationships, you will need to specify one or more of the corresponding Concrete Types when performing the subscription operation.
These types are generated by the library and conform to the format [type]EventPayload, where [type] is a Concrete Type.
Union Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    directors: [Director!]! @relationship(type: ""DIRECTED"", properties: ""Directed"", direction: IN)
}

union Director = Person | Actor

type Actor {
    name: String
}

type Person {
    name: String
    reputation: Int
}

  {
    year:!
}
View all (5 more lines)
A subscription to any Movie created relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        createdRelationship {
           directors {
                year
                node {
                    ... on PersonEventPayload { # generated type
                        name
                        reputation
                    }
                      { 
                        name
                    }
                }
            }
        }
    }
}
View all (10 more lines)
Interface Example
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    reviewers: [Reviewer!]! @relationship(type: ""REVIEWED"", properties: ""Review"", direction: IN)
}

interface Reviewer {
    reputation: Int!
}

type Magazine implements Reviewer {
    title: String
    reputation: Int!
}

 implements {
    name:
    reputation:!
}

 {
    score:!
}
View all (9 more lines)
A subscription to any Movie created relationships would look like:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        createdRelationship {
            reviewers {
                score
                node {
                    reputation
                    ... on MagazineEventPayload { # generated type
                        title
                        reputation
                    }
                      { 
                        name
                        reputation
                    }
                }
            }
        }
    }
}
View all (12 more lines)
Non-reciprocal relationships
Considering the following type definitions:
Graphql
Copy to Clipboard
type Movie {
    title: String
    genre: String
    actors: [Actor] @relationship(type: ""ACTED_IN"", direction: IN, properties: ""ActedIn"")
    directors: [Director!]! @relationship(type: ""DIRECTED"", properties: ""Directed"", direction: IN)
}

type Actor {
    name: String
    movies: [Movie!]! @relationship(type: ""ACTED_IN"", properties: ""ActedIn"", direction: OUT)
}

type Person {
    name: String
    reputation: Int
}

 = |

  {
    screenTime:!
}

  {
    year:!
}
View all (11 more lines)
The type definitions contain 2 relationships: types ACTED_IN and DIRECTED.
It can be observed that the ACTED_IN relationship has a corresponding field defined in both the Movie and Actor types. As such, we can say that ACTED_IN is a reciprocal relationship.
DIRECTED on the other hand is only defined in the Movie type. The Director type does not define a matching field. As such, we can say DIRECTED is not a reciprocal relationship.
Let us now take a look at how we can subscribe to created relationships for the 3 types defined above:
Movie
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        createdRelationship {
           actors { # corresponds to the `ACTED_IN` relationship type
                screenTime
                node {
                    name
                }
           }
           directors { 
                year
                node {
                      {
                        name
                        reputation
                    }
                      {
                        name
                    }
                }
            }
        }
    }
}
View all (16 more lines)
Person
As the Person type does not define any relationships, it is not possible to subscribe to CREATE_RELATIONSHIP events for this type.
Actor
Graphql
Copy to Clipboard
subscription {
    actorRelationshipCreated {
        event
        timestamp
        actor {
            name
        }
        relationshipFieldName
        createdRelationship {
           movies { # corresponds to the `ACTED_IN` relationship type
                screenTime
                node {
                    title
                    genre
                }
           }
           
        }
    }
}
View all (5 more lines)
The presence of the movie field inside of createdRelationship for the actorRelationshipCreated subscription reflects the fact that the ACTED_IN typed relationship is reciprocal.
Therefore, when a new relationship of this type is made, such as by running a mutation as follows:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                actors: {
                    create: [
                        {
                            node: {
                                name: ""Keanu Reeves""
                            },
                            edge: {
                                screenTime: 420
                            }
                        }
                    ]
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}
View all (12 more lines)
Two events will be published (given that we subscribed to CREATE_RELATIONSHIP events on both types):
Graphql
Copy to Clipboard
{
    # from `movieRelationshipCreated`
    event: ""CREATE_RELATIONSHIP""
    timestamp
    movie {
        title: ""John Wick"",
        genre: ""Action""
    }
    relationshipFieldName: ""actors"",
    createdRelationship {
        actors: {
            screenTime: 420,
            node: {
                name: ""Keanu Reeves""
            }
        },
        directors: 
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    createdRelationship {
        movies: {
            screenTime: ,
            node: {
                title: ,
                genre: 
            }
        }
    }
}
View all (22 more lines)
Since the DIRECTED relationship between types Movie and Director is not reciprocal, executing a mutation as follows:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                directors: {
                    Actor: { # relationship 1
                        create: [
                            {
                                node: {
                                    name: ""Woody Allen""
                                },
                                edge: {
                                    year: 1989
                                }
                            }
                        ]
                    },
                   : { 
                        create: [
                            {
                                node: {
                                    name: ,
                                    reputation: 
                                },
                                edge: {
                                    year: 
                                }
                            }
                        ]
                    }
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}
View all (27 more lines)
Two events will be published (given that we subscribed to CREATE_RELATIONSHIP events on the Movie type):
Graphql
Copy to Clipboard
{
    # relationship 1 - from `movieRelationshipCreated`
    event: ""CREATE_RELATIONSHIP""
    timestamp
    movie {
        title: ""New York Stories"",
        genre: ""Comedy""
    }
    relationshipFieldName: ""directors"",
    createdRelationship {
        actors: null,
        directors: {
            year: 1989,
            node: {
                name: ""Woody Allen""
            }
        }
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    createdRelationship {
        actors: ,
        directors: {
            year: ,
            node: {
                 name: ,
                reputation: 
            }
        }
    }
}
View all (24 more lines)
Special Considerations
Types using the same Neo4j label
One case that deserves special consideration is overriding the label in Neo4j for a specific GraphQL type. This can be achieved using the @node directive, by specifying the label argument.
While this section serves an informative purpose, it should be mentioned that, in the majority of cases, this is not the recommended approach of designing your API.
Consider the following type definitions:
Graphql
Copy to Clipboard
type Actor @node(label: ""Person"") {
    name: String
    movies: [Movie!]! @relationship(type: ""PART_OF"", direction: OUT)
}

typePerson {
    name: String
    movies: [Movie!]! @relationship(type: ""PART_OF"", direction: OUT)
}

type Movie {
    title: String
    genre: String
    people: [Person!]!  @relationship(type: ""PART_OF"", direction: IN)
    actors: [Actor!]!  @relationship(type: ""PART_OF"", direction: IN)
}
Although we have 3 GraphQL types, in Neo4j there will only ever be 2 types of nodes: labeled Movie or labeled Person.
At the database level there is no distinction between Actor and Person. Therefore, when creating a new relationship of type PART_OF, there will be one event for each of the 2 types.
Considering the following subscriptions:
Graphql
Copy to Clipboard
subscription {
    movieRelationshipCreated {
        event
        timestamp
        movie {
            title
            genre
        }
        relationshipFieldName
        createdRelationship {
           people { # corresponds to the `PART_OF` relationship type
                node {
                    name
                }
           }
           actors { 
                node {
                    name
                }
           }
        }
    }
}

 {
    actorRelationshipCreated {
        event
        timestamp
        actor {
            name
        }
        relationshipFieldName
        createdRelationship {
           movies { 
                node {
                    title
                    genre
                }
           }
        }
    }
}
View all (27 more lines)
Running a mutation as follows:
Graphql
Copy to Clipboard
mutation {
    createMovies(
        input: [
            {
                people: { # relationship 1
                    create: [
                        {
                            node: {
                                name: ""John Logan""
                            }
                        }
                    ]
                },
                actors: {  # relationship 2
                    create: [
                        {
                            node: {
                                name: 
                            }
                        }
                    ]
                },
                title: ,
                genre: 
            }
        ]
    ) {
        movies {
            title
            genre
        }
    }
}
View all (18 more lines)
Results in the following events:
Graphql
Copy to Clipboard
{
    # relationship 1 `people` - for GraphQL types `Movie`, `Person`
    event: ""CREATE_RELATIONSHIP""
    timestamp
    movie {
        title: ""Sweeney Todd"",
        genre: ""Horror""
    }
    relationshipFieldName: ""people"",
    createdRelationship {
        people: {
            node: {
                name: ""John Logan""
            }
        },
        actors: 
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    createdRelationship {
        people: ,
        actors: {
            node: {
                name: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    createdRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    createdRelationship {
        people: {
            node: {
                name: 
            }
        },
        actors: 
    }
},
{
    
    event: 
    timestamp
    movie {
        title: ,
        genre: 
    }
    relationshipFieldName: ,
    createdRelationship {
        people: ,
        actors: {
            node: {
                name: 
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    createdRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
View all (91 more lines)
Had we subscribed to Person as well, we would have received two more events:
Graphql
Copy to Clipboard
{
    # relationship 1 `movies` - for GraphQL types `Person`, `Movie`
    event: ""CREATE_RELATIONSHIP""
    timestamp
    actor {
        name: ""John Logan""
    }
    relationshipFieldName: ""movies"",
    createdRelationship {
        movies: {
            node: {
                title: ""Sweeney Todd"",
                genre: ""Horror""
            }
        }
    }
},
{
    
    event: 
    timestamp
    actor {
        name: 
    }
    relationshipFieldName: ,
    createdRelationship {
        movies: {
            node: {
                title: ,
                genre: 
            }
        }
    }
},
View all (20 more lines)
Delete
Delete Relationship
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0;"Neo4j GraphQL Library
Documentation license: Creative Commons 4.0
This is the documentation for the Neo4j GraphQL Library, authored by the Neo4j GraphQL Team.
Are you a GRANDstack user? We have deprecated the GRANDstack starter app, find more information here.
This documentation covers the following topics:
Introduction - Introduction to the Neo4j GraphQL Library.
Getting Started - Start here if you want to quickly get up and running with the library.
Type Definitions - Define your nodes and relationships using type definitions as documented here.
Queries - GraphQL Queries allow you to read data in your Neo4j database.
Mutations - GraphQL Mutations allow you to change data in your Neo4j database.
Subscriptions - GraphQL Subscriptions for real-time data updates.
Filtering - This chapter covers how to filter your data in Queries and Mutations.
Sorting - This chapter covers how to sort the data being returned.
Pagination - This chapter covers the pagination options offered by the Neo4j GraphQL Library.
Mathematical operators - This chapter covers how to use the Mathematical operators.
Array methods - This chapter covers how to use the Array methods.
Custom Resolvers - Learn how to implement custom functionality accessible through your API.
Auth - Covers the authentication and authorization options offered by this library.
Directives - An index of all of the directives offered by the Neo4j GraphQL Library.
API Reference - API reference for constructing an instance of the library.
OGM - This chapter covers the OGM (Object Graph Mapper), a programmatic way of using your API.
Introspector - This chapter covers how you can introspect an existing Neo4j database and automatically generate GraphQL type definitions from that.
GraphQL Toolbox - Purpose-built Developer UI for your Neo4j GraphQL API.
Driver Configuration - How to configure a database driver for use with this library.
Guides - Guides for usage of the library, including migration guides for moving between versions.
Troubleshooting - Having problems with the library? See if your problem has been found and solved before.
Deprecations - Overview and information regarding deprecated products and applications.
This manual is primarily written for software engineers building an API using the Neo4j GraphQL Library.
Introduction
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/directives;"Directives
Contents
@alias
@auth
@callback
@coalesce
@computed
@customResolver
@cypher
@default
@exclude
@fulltext
@id
@node
@plural
@populatedBy
@private
@queryOptions
@readonly
@relationship
@relationshipProperties
@timestamp
@unique
@writeonly
@alias
The @alias directive will map a GraphQL schema field to a Neo4j property on a node or relationship.
Reference: @alias
@auth
The @auth directive is used to define complex fine-grained and role-based access control for object types and fields.
Reference: @auth directive
@callback
The @callback directive has been deprecated and will be removed in version 4.0. Please use the @populatedBy directive instead.
The @callback directive is used to specify a function that will be invoked when updating or creating the properties on a node or relationship.
Reference: @callback
@coalesce
The @coalesce directive exposes a mechanism for querying against non-existent, null values on a node.
Reference: @coalesce
@computed
The @computed directive has been deprecated and will be removed in version 4.0. Please use the @customResolver directive instead.
The @computed directive specifies that a field will be resolved by a custom resolver, and allows the specification of any field dependencies.
Reference: @computed
@customResolver
The @customResolver directive specifies that a field will be resolved by a custom resolver, and allows the specification of any required fields that will be passed as arguments to the custom resolver.
Reference: @customResolver
@cypher
The @cypher directive overrides field resolution (including Query and Mutation fields), instead resolving with the specified Cypher.
Reference: @cypher directive
@default
The @default directive allows for the setting of a default value for a field on object creation.
Reference: @default
@exclude
The @exclude directive is used on object types to instruct them to be skipped during Query, Mutation and Subscription generation.
Reference: @exclude
@fulltext
The @fulltext directive indicates that there should be a Fulltext index inserted into the database for the specified Node and its properties.
Reference: Fulltext indexes
@id
The @id directive marks a field as the unique ID for an object type, and allows for autogeneration of IDs.
Reference: @id
@node
The plural argument of the @node directive has been deprecated and will be removed in version 4.0. Please use the @plural directive instead.
The @node directive is used to specify the configuration of a GraphQL object type which represents a Neo4j node.
Reference: @node
@plural
The @plural directive redefines how to compose the plural of the type for the generated operations. This is particularly useful for types that are not correctly pluralized or are non-English words.
Reference: @plural
@populatedBy
The @populatedBy directive is used to specify a callback function that gets executed during GraphQL query parsing, to populate fields which have not been provided within the input.
Reference: @populatedBy
@private
The @private directive protects fields which should only be available through the OGM.
Reference: @private Directive
@queryOptions
The @queryOptions is to be used on nodes, where applied will inject values into a query such as the limit.
Reference: @queryOptions
@readonly
The @readonly directive marks fields as read-only.
Reference: @readonly
@relationship
The @relationship directive is used to configure relationships between object types.
Reference: Relationships
@relationshipProperties
Optional syntactic sugar to help you distinguish between interfaces which are used for relationship properties, and otherwise.
Can only be used on interfaces, as per its definition:
Graphql
Copy to Clipboard
""""""Syntactic sugar to help differentiate between interfaces for relationship properties, and otherwise.""""""
directive @relationshipProperties on INTERFACE
@timestamp
The @timestamp directive flags fields to be used to store timestamps on create/update events.
Reference: @timestamp
@unique
The @unique directive indicates that there should be a uniqueness constraint in the database for the fields that it is applied to.
Reference: Unique node property constraints
@writeonly
The @writeonly directive marks fields as write-only.
Reference: @writeonly
Subscriptions
API Reference
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/subscriptions;"Subscriptions
Contents
Authentication
Roles
Bind
Where
Allow
Subscriptions can be used along with @auth, however, some operations are not supported. To setup rules, use the SUBSCRIBE operation.
Graphql
Copy to Clipboard
type Movie {
    title: String!
}

extend type Movie @auth(rules: [{ isAuthenticated: true, operations: [SUBSCRIBE] }])
Authentication
If the authentication rules isAuthenticated and allowUnauthenticated are not met, the subscription request will fail and no events will be sent.
Roles
Roles can be set for subscriptions. Only requests matching the roles set will be accepted.
Bind
Not Supported
Where
Not Supported
Allow
Not Supported
Where
Directives
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authorization/where;"Where
Contents
Combining where with roles
Use the where argument on types to conceptually append predicates to the Cypher WHERE clause. Given the current user ID is ""123"" and the following schema:
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

extend type User @auth(rules: [{ where: { id: ""$jwt.id"" } }])
Then the user executes a GraphQL query for all users:
Graphql
Copy to Clipboard
query {
    users {
        id
        name
    }
}
Behind the scenes the user’s ID is conceptually added to the query:
Graphql
Copy to Clipboard
query {
    users(where: { id: ""123"" }){
        id
        name
    }
}
Where is used on the following operations;
READ
UPDATE
CONNECT
DISCONNECT
DELETE
Combining where with roles
The where argument can be combined with roles within auth rules to support rule based filtering of results.
Revising the early example schema, if you update the auth rules to instead provide two sets of rules for two different roles, you can specify that JWTs with the user role can only see their own User node, as before, but now, those with the admin role can see all users:
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

extend type User @auth(rules: [
    {
        roles: [""user""]
        where: { id: ""$jwt.id"" }
    }
    {
        roles: [""admin""]
    }
])
For those with an admin role, there is a conceptual where: ""*"" rule which is applied, allowing admins to see all User nodes.
These rules can alternatively be expressed using an OR within the top parent of a single auth rule, for example:
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

extend type User @auth(rules: [
    {
        OR: [
            {
                roles: [""user""]
                where: { id: ""$jwt.id"" }
            },
            {
                roles: [""admin""]
            }
        ]
    }
])
Both ways of expressing the rules are valid, and will return the same results.
Roles
Subscriptions
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authorization/roles;"Roles
Contents
RBAC
Use the roles property to specify the allowed roles for an operation. Use the Neo4jGraphQL config option rolesPath to specify a object path for JWT roles otherwise defaults to jwt.roles.
The following type definitions show that an admin role is required for all update operations against Users.
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

extend type User @auth(rules: [{ operations: [UPDATE], roles: [""admin""] }])
If there are multiple possible roles you can add more items to the array, of which users only need one to satisfy a rule:
Graphql
Copy to Clipboard
extend type User @auth(rules: [{ operations: [UPDATE], roles: [""admin"", ""super-admin""] }])
RBAC
Here is an example of RBAC (Role-Based Access Control) using roles:
Graphql
Copy to Clipboard
type CatalogItem @auth(rules: [{ operations: [READ], roles: [""read:catalog""] }]) {
    id: ID
    title: String
}

type Customer @auth(rules: [{ operations: [READ], roles: [""read:customer""] }]) {
    id: ID
    name: String
    password: String @auth(rules: [{ operations: [READ], roles: [""admin""] }])
}

type Invoice @auth(rules: [{ operations: [READ], roles: [""read:invoice""] }]) {
    id: ID
    csv: String
    total: Int
}
Bind
Where
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authorization/bind;"Bind
Contents
bind across relationships
Field-level bind
Use bind to ensure that on creating or updating nodes, there is equality between a value on the JWT and a property on a matched node. This validation is done after the operation but inside a transaction. Taking a closer look, create a user in your database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:User { id:""user1"", name: ""one"" })
For the label and properties of the node created above, the corresponding GraphQL type definitions would be:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}
Given the above GraphQL type definition - you could restrict user1 from changing their own ID:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}

extend type User @auth(
    rules: [
        {
            operations: [UPDATE],
            bind: { id: ""$jwt.sub"" }
        }
    ]
)
After the update or creation of the node, it is validated that the property id on the node is equal to the jwt.sub property.
Given user1 has the following decoded JWT:
Json
Copy to Clipboard
{
    ""sub"": ""user1"",
    ""iat"": 1516239022
}
When the user makes a request using this JWT to change their ID:
Graphql
Copy to Clipboard
mutation {
    updateUsers(where: { id: ""user1"" }, update: { id: ""user2"" }) {
        users {
            name
        }
    }
}
The generated cypher for this query would look like the below, throwing you out of the operation because the id property no longer matches.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (u:User { id: ""user1"" })
SET u.id = ""user2""
CALL apoc.util.validate(NOT (u.id = ""user1""), ""Forbidden"")
RETURN u
Bind is available for the following operations;
READ
UPDATE
CONNECT
DISCONNECT
DELETE
bind across relationships
There may be a reason where you need to traverse across relationships to satisfy your authorization implementation. One use case could be ""ensure that users only create Posts related to themselves"":
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

type Post {
    content: String
    creator: User! @relationship(type: ""HAS_POST"", direction: IN)
}

extend type Post @auth(rules: [
    { operations: [CREATE], bind: { creator: { id: ""$jwt.sub"" } } }
])
When you specify bind on a relationship you can select fields on the related node. It’s worth pointing out that bind on a relationship field will perform an all on the matched nodes to see if there is a match, or any if the bindPredicate option of the plugin has been set to ""any"".
Field-level bind
You can use bind on a field, and the root is still considered the node itself. Taking the example at the start of this chapter, you could do the following to implement the same behaviour:
Graphql
Copy to Clipboard
type User {
    id: ID! @auth(rules: [{ operations: [UPDATE], bind: { id: ""$jwt.sub"" } }])
    name: String!
}
Allow
Roles
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authorization/allow;"Allow
Contents
allow across relationships
Field-level allow
Use allow to ensure that on matched nodes, there is equality between a value on the JWT and a property on each matched node. Taking a closer look, create two users in a hypothetical empty database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:User { id: ""user1"", name: ""one"" })
CREATE (:User { id: ""user2"", name: ""two"" })
For the label and properties of the nodes created above, the corresponding GraphQL type definition would be:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}
Now that there are two users in the database, and a simple type definition - it might be desirable to restrict user1 from accessing user2. This is where allow comes in:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}

extend type User @auth(
    rules: [
        {
            operations: [READ],
            allow: { id: ""$jwt.sub"" }
        }
    ]
)
After a match is made against a node, it is validated that the property id on the node is equal to the jwt.sub property.
Given user1 has the following decoded JWT:
Json
Copy to Clipboard
{
    ""sub"": ""user1"",
    ""iat"": 1516239022
}
If ""user1"" used this JWT in a request for ""user2"":
Graphql
Copy to Clipboard
query {
    users(where: { id: ""user2"" }) {
        name
    }
}
The generated cypher for this query would look like the following and throw you out the operation:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (u:User { id: ""user2"" })
CALL apoc.util.validate(NOT (u.id = ""user1""), ""Forbidden"")
RETURN u
Allow is available on the following operations:
READ
UPDATE
CONNECT
DISCONNECT
DELETE
allow across relationships
There may be a reason where you need to traverse across relationships to satisfy your authorization implementation. One example use case could be ""grant update access to all Moderators of a Post"":
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

type Post {
    content: String
    moderators: [User!]! @relationship(type: ""MODERATES_POST"", direction: IN)
}

extend type Post @auth(rules: [
    { operations: [UPDATE], allow: { moderators: { id: ""$jwt.sub"" } } }
])
When you specify allow on a relationship you can select fields on the referenced node. It’s worth pointing out that allow on a relationship will perform an ANY on the matched nodes to see if there is a match.
Given the above example - There may be a time when you need to give update access to either the creator of a post or a moderator, you can use OR and AND inside allow:
Graphql
Copy to Clipboard
type User {
    id: ID
    name: String
}

type Post {
    content: String
    moderators: [User!]! @relationship(type: ""MODERATES_POST"", direction: IN)
    creator: User! @relationship(type: ""HAS_POST"", direction: IN)
}

extend type Post
    @auth(
        rules: [
            {
                operations: ],
                allow: {: [{ moderators: { id:  } }, { creator: { id: ""$jwt.sub"" } }] }
            }
        ]
    )
View all (5 more lines)
Field-level allow
allow works the same as it does on Types although its context is the Field. So instead of enforcing auth rules when the node is matched and/or modified, it would instead be called when the Field is match and/or modified. Given the following, it is hiding the password to all users but the user themselves:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
    password: String! @auth(rules: [{ allow: { id: ""$jwt.sub"" } }])
}
Authorization
Bind
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/auth/authorization;"Authorization
You specify authorization rules inside the @auth directive. This section looks at each option available and explains how to use it to implement authorization.
Allow
Bind
Roles
Where
Note that authorization rules are not supported when applied over nested unions or interfaces.
Authentication
Allow
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/api-reference;"API Reference
Neo4jGraphQL
@neo4j/graphql-ogm
Directives
Neo4jGraphQL
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/api-reference/ogm;"@neo4j/graphql-ogm
See OGM.
Neo4jGraphQL
OGM
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/deprecations;"Deprecations
Contents
Why have we deprecated the GRANDstack starter app?
What has happened to the GRANDstack starter app?
Why have we deprecated the GraphQL Architect Graph App?
What has happened to the GraphQL Architect?
The following products and applications are deprecated:
GRANDstack starter app
GraphQL Architect (a Neo4j Desktop Graph App)
Why have we deprecated the GRANDstack starter app?
The GRANDstack starter app has been a marketing and Neo4j Labs effort to drive user adoption of the Neo4j Labs GraphQL library at its early stages.
Its main purpose was to demonstrate how the Neo4j Labs GraphQL library could be used in the context of a full-stack application using React and Apollo client. It was extremely useful when building proof of concept applications.
It was very appealing to developers who didn’t want to have additional boiler plate when setting up their application, speeding up development time and helped focussing on building the functionality of the application.
It was also attractive to junior developers with very little experience in building applications, and it was a great channel to bring a new audience to Neo4j.
Finally, it was helpful for users who had an existing front end and needed a new backend. They needed a way to initiate a server, so the value we offered was by providing an opinionated mechanism that can help users get started with Neo4j with GraphQL.
Over time, the GRANDstack starter grew to support other frameworks such as Flutter and Angular. With hindsight, this massively increased the support burden and technical debt of the product, and it is time to revisit the scope of the product.
The intention for the future is to replace this Labs project with a new starter application product, which will focus on the backend and the configuration of the GraphQL library, and we will consider options on how we might help developers with their front-end.
What has happened to the GRANDstack starter app?
From a technical perspective the create-grandstack-app npm package has been marked as deprecated - it can still be used to skeleton a GRANDstack app, however the user will be warned that the package is deprecated. The associated GRANDstack starter GitHub repository has been archived, meaning that it is still available as a reference, but is now read-only. The associated npm packages (such as graphql-auth-directives and the grandstack-cli) have also been deprecated and archived on GitHub.
Why have we deprecated the GraphQL Architect Graph App?
The main purpose of the Neo4j GraphQL Architect was to provide users with a Low-Code way to build GraphQL APIs powered by Neo4j. GraphQL Architect was a Graph App for Neo4j Desktop that enabled developers to build, query, and deploy GraphQL APIs backed by the Neo4j graph database, all from within Neo4j Desktop.
We decided it was time to give this tool a new purpose and expand its potential to attract our target audience. Successor of GraphQL Architect Graph App, the new Neo4j GraphQL Toolbox (the name is a placeholder) will be part of the GraphQL for Neo4j holistic product offering. It is currently available at https://graphql-toolbox.neo4j.io/, however we haven’t publicized it yet and we’re still writing documentation and marketing pieces on it.
The vision for this is to build an embeddable tool that we can integrate into the Neo4j workspace which will help onboarding developers into GraphQL. It’s meant to be a Low-Code GraphQL solution to get started for developers who are either new to Neo4j, or GraphQL, or both, and they’re seeking a way to get started easily and quickly with their project from scratch.
We want to make it easily configurable so that it’s at developers' fingertips ready and available for users without requiring them to have credentials to access a live Neo4j instance when they are in a prototyping stage. It’s also a great way to discover the GraphQL library capabilities. It’s very useful for debugging errors and problems users may encounter using the library so they can use the GraphQL Toolbox to reproduce the problem in GitHub issues.
We can communicate to the developers market that there is no mismatch between the API model and the data model (in the database). We are graph from top to bottom. GraphQL developers already think in graphs about their application data and features, but we need to help them understand that they can store that information in graphs (using a graph DB).
What has happened to the GraphQL Architect?
From a technical perspective we have deprecated and removed the GraphQL Architect Graph App from npm and the Graph App gallery, it is no longer available to be installed in Neo4j Desktop. The associated GitHub repositories have been archived.
Preventing overfetching
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/installation;"Installation
The OGM is very easy to install into a new or existing Node.js project. However it does have a couple of dependencies. The OGM depends on the Neo4j GraphQL Library, which will be installed when you install the OGM, so you will require the following dependencies:
@neo4j/graphql-ogm is the OGM package.
graphql is the package used by the Neo4j GraphQL Library to generate a schema and execute queries and mutations.
neo4j-driver is the official Neo4j Driver package for JavaScript, necessary for interacting with the database.
Bash
Copy to Clipboard
npm install @neo4j/graphql-ogm graphql neo4j-driver
To use the OGM, it will need to be imported wherever you want to use it:
JavaScript
Copy to Clipboard
const { OGM } = require(""@neo4j/graphql-ogm"");
It’s recommended to check out the Examples to see where you might go from here.
OGM
Examples
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/current/auth;"Auth
Contents
Quickstart examples
In this chapter you will learn more about how to secure your GraphQL API using the Neo4j GraphQL Library’s built-in auth mechanics.
Setup
@auth directive
Global authentication
Authentication
Authorization
Subscriptions
Quickstart examples
Only authenticated users can create Post nodes:
Graphql
Copy to Clipboard
type Post @auth(rules: [
    { operations: [CREATE], isAuthenticated: true }
]) {
    title: String!
}
Use extend to avoid large and unwieldy type definitions:
Graphql
Copy to Clipboard
type Post {
    title: String!
}

extend type Post @auth(rules: [
    { operations: [CREATE], isAuthenticated: true }
])
You can use the directive types as seen in the example above, but you can also apply the directive on any field so as long as it’s not decorated with @relationship. In the following example, the password field is only accessible to users with role ""admin"", or the user themselves:
Graphql
Copy to Clipboard
type User {
    id: ID!
    name: String!
}

extend type User {
    password: String! @auth(rules: [
        {
            OR: [{ roles: [""admin""] }, { allow: { id: ""$jwt.sub"" } }]
        }
    ])
}
Custom Resolvers
Setup
Was this page helpful?"
https://neo4j.com/developer/kb/import-csv-locations;"Importing CSV Files: Neo4j Aura, Desktop and Sandbox
Author Jennifer Reif Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load csv import cypher
Loading various kinds of files into Neo4j requires different locations depending on the tool you are using.
Import methods we will cover:
Remote: Neo4j Aura and Neo4j Sandbox
Local: Neo4j Server and Neo4j Desktop
Neo4j Aura and Neo4j Sandbox
Cloud hosted versions of Neo4j can only access remote http(s) URLs. Because they are hosted in the cloud, the security settings do not allow sandboxes to access local file settings on a desktop. Any files that need to be imported must be stored or placed in a remote location that the instance can access
GitHub
Pastebin
Cloud Provider Storage
a website
Google Drive
Dropbox.
We will look at examples for some of the locations for importing into a Cloud hosted Neo4j Instance.
GitHub
If you find or place a file in a GitHub repository or GitHub Gist, others can access the content in a raw format. You just need to navigate to the place that contains the file and go to the file. Once there, you should see a menu bar like the one below right above the file contents.
Click on the Raw button in the button list on the right and copy the url path when the page loads (url should start like https://raw.githubusercontent.com/…;). Now you should be able to use the data in your Neo4j Browser session with a statement like this one.
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV FROM 'https://raw.githubusercontent.com/<yourFileRepositoryPath>' AS row
RETURN row
LIMIT 20
Website
If the file is hosted on a website, Neo4j can access it there with a public URL. For example, in the Neo4j Cypher Manual, the LOAD CSV page uses a csv file on neo4j.com.
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV FROM 'http://data.neo4j.com/northwind/products.csv' AS row
RETURN row
The same is true for any cloud providers storage
AWS S3
GCP Buckets
Azure Blob storage
You can upload the files there using your credentials and the UI or CLI and make them (temporarily) publicly accessible and then use the HTTPS URL of the file.
Google Sheets
You can access files uploaded to Google Sheets, if they are published to the web. Once the file is imported into a tab of a Google Sheet, you can follow the screenshots below to walk through the rest of the process.
The red boxes and numbering show where to click and what order to do the steps.
Step 1 - Publish to Web
Step 2 - Select Tab Name and Format CSV
Step 3 - Confirm Publication and Copy the Link
Cypher
Step 4 - Run Cypher LOAD CSV command
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSx5-mHPUs7hQ3292zrLL_FeNzo85iC83TiezRcPl_SUv4NpW0e2VZilCUH9KbCWExAfE7OAELgdCW8/pub?gid=0&single=true&output=csv' AS row
RETURN row
Dropbox
A file uploaded to Dropbox works similarly to the process with Google Drive. Again, you will need to ensure permissions are set appropriately. Screenshots below step through the rest of the steps.
Step 1 - Review file permissions
Step 2 - Ensure permissions are open
Step 3 - Download Dropbox file
Step 4 - Go to browser downloads and copy link address
Cypher
Step 5 - Run Cypher LOAD CSV command
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM 'https://<fileId>.dl.dropboxusercontent.com/cd/0/get/<yourFilePath>/file#' AS row
RETURN row
Local Neo4j Install and Neo4j Desktop
Your local Neo4j installations can of course also access the remote files via URL as described above.
If you want to import files from the local disk for privacy or performance reasons you have to place them into the import folder. It is generally located relative to your Neo4j server installation.
Those files can then be accessed via file:///filename.csv URLs, e.g.
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM 'file:///products.csv' AS row
RETURN row
Neo4j Desktop
In Neo4j Desktop you can open the folder in your file-manager (explorer, finder, etc) via the UI by clicking on the ""Open (Folder)"" dropdown or menu.
Then place the files there and access them directly from Neo4j.
The CSV import developer guide walks through loading local CSV files to Neo4j Desktop.
Custom Import Folder
If you require a file location different from the default, you can update the following setting in the neo4j.conf file. We recommend specifying a directory path, rather than commenting out the setting, to avoid the security issue mentioned in the configuration comment.
Properties
Copy to Clipboard
# This setting constrains all `LOAD CSV` import files to be under the `import` directory. Remove or comment it out to
# allow files to be loaded from anywhere in the filesystem; this introduces possible security problems. See the
# `LOAD CSV` section of the manual for details.
dbms.directories.import=import
Resources
You can find the full list of file locations by operating system (does not include Sandbox) in the operations manual.
Andy Jefferson explores different methods of loading files (securely) into a remote Neo4j instance * Part 1 - ngrok and python webserver * Part 2 - Cloud Storage
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/algorithms/community;"Community detection
Community detection algorithms are used to evaluate how groups of nodes are clustered or partitioned, as well as their tendency to strengthen or break apart. The Neo4j GDS library includes the following community detection algorithms, grouped by quality tier:
Production-quality
Louvain
Label Propagation
Weakly Connected Components
Triangle Count
Local Clustering Coefficient
Beta
K-1 Coloring
Modularity Optimization
Alpha
Strongly Connected Components
Speaker-Listener Label Propagation
Approximate Maximum k-cut
Conductance metric
Modularity metric
K-Means Clustering
Leiden
Greedy
Louvain
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank;"PageRank
Contents
1. Introduction
2. Considerations
3. Syntax
4. Examples
4.1. Memory Estimation
4.2. Stream
4.3. Stats
4.4. Mutate
4.5. Write
4.6. Weighted
4.7. Tolerance
4.8. Damping Factor
4.9. Personalised PageRank
4.10. Scaling centrality scores
Supported algorithm traits:
Directed
Undirected
Homogeneous
Heterogeneous
Weighted
1. Introduction
The PageRank algorithm measures the importance of each node within the graph, based on the number incoming relationships and the importance of the corresponding source nodes. The underlying assumption roughly speaking is that a page is only as important as the pages that link to it.
PageRank is introduced in the original Google paper as a function that solves the following equation:
where,
we assume that a page A has pages T1 to Tn which point to it.
d is a damping factor which can be set between 0 (inclusive) and 1 (exclusive). It is usually set to 0.85.
C(A) is defined as the number of links going out of page A.
This equation is used to iteratively update a candidate solution and arrive at an approximate solution to the same equation.
For more information on this algorithm, see:
The original google paper
An Efficient Partition-Based Parallel PageRank Algorithm
PageRank beyond the web for use cases
Running this algorithm requires sufficient memory availability. Before running this algorithm, we recommend that you read Memory Estimation.
2. Considerations
There are some things to be aware of when using the PageRank algorithm:
If there are no relationships from within a group of pages to outside the group, then the group is considered a spider trap.
Rank sink can occur when a network of pages is forming an infinite cycle.
Dead-ends occur when pages have no outgoing relationship.
Changing the damping factor can help with all the considerations above. It can be interpreted as a probability of a web surfer to sometimes jump to a random page and therefore not getting stuck in sinks.
3. Syntax
This section covers the syntax used to execute the PageRank algorithm in each of its execution modes. We are describing the named graph variant of the syntax. To learn more about general syntax variants, see Syntax overview.
PageRank syntax per mode
Stream mode
Stats mode
Mutate mode
Write mode
Cypher
Run PageRank in stream mode on a named graph.
Copy to Clipboard
CALL gds.pageRank.stream(
  graphName: String,
  configuration: Map
)
YIELD
  nodeId: Integer,
  score: Float
Table 1. Parameters
Name Type Default Optional Description
graphName
String
n/a
no
The name of a graph stored in the catalog.
configuration
Map
{}
yes
Configuration for algorithm-specifics and/or graph filtering.
Table 2. Configuration
Name Type Default Optional Description
nodeLabels
List of String
['*']
yes
Filter the named graph using the given node labels.
relationshipTypes
List of String
['*']
yes
Filter the named graph using the given relationship types.
concurrency
Integer
4
yes
The number of concurrent threads used for running the algorithm.
jobId
String
Generated internally
yes
An ID that can be provided to more easily track the algorithm’s progress.
dampingFactor
Float
0.85
yes
The damping factor of the Page Rank calculation. Must be in [0, 1).
maxIterations
Integer
20
yes
The maximum number of iterations of Page Rank to run.
tolerance
Float
0.0000001
yes
Minimum change in scores between iterations. If all scores change less than the tolerance value the result is considered stable and the algorithm returns.
relationshipWeightProperty
String
null
yes
Name of the relationship property to use as weights. If unspecified, the algorithm runs unweighted.
sourceNodes
List or Node or Number
[]
yes
The nodes or node ids to use for computing Personalized Page Rank.
scaler
String
None
yes
The name of the scaler applied for the final scores. Supported values are None, MinMax, Max, Mean, Log, L1Norm, L2Norm and StdScore.
Table 3. Results
Name Type Description
nodeId
Integer
Node ID.
score
Float
PageRank score.
4. Examples
In this section we will show examples of running the PageRank algorithm on a concrete graph. The intention is to illustrate what the results look like and to provide a guide in how to make use of the algorithm in a real setting. We will do this on a small web network graph of a handful nodes connected in a particular pattern. The example graph looks like this:
Cypher
The following Cypher statement will create the example graph in the Neo4j database:
Copy to Clipboard
CREATE
  (home:Page {name:'Home'}),
  (about:Page {name:'About'}),
  (product:Page {name:'Product'}),
  (links:Page {name:'Links'}),
  (a:Page {name:'Site A'}),
  (b:Page {name:'Site B'}),
  (c:Page {name:'Site C'}),
  (d:Page {name:'Site D'}),

  (home)-[:LINKS {weight: 0.2}]->(about),
  (home)-[:LINKS {weight: 0.2}]->(links),
  (home)-[:LINKS {weight: 0.6}]->(product),
  (about)-[:LINKS {weight: 1.0}]->(home),
  (product)-[:LINKS {weight: 1.0}]->(home),
  (a)-[: {weight: }]->(home),
  (b)-[: {weight: }]->(home),
  (c)-[: {weight: }]->(home),
  (d)-[: {weight: }]->(home),
  (links)-[: {weight: }]->(home),
  (links)-[: {weight: }]->(a),
  (links)-[: {weight: }]->(b),
  (links)-[: {weight: }]->(c),
  (links)-[: {weight: }]->(d);
View all (9 more lines)
This graph represents eight pages, linking to one another. Each relationship has a property called weight, which describes the importance of the relationship.
In the examples below we will use named graphs and native projections as the norm. However, Cypher projections can also be used.
Cypher
The following statement will project a graph using a native projection and store it in the graph catalog under the name 'myGraph'.
Copy to Clipboard
CALL gds.graph.project(
  'myGraph',
  'Page',
  'LINKS',
  {
    relationshipProperties: 'weight'
  }
)
4.1. Memory Estimation
First off, we will estimate the cost of running the algorithm using the estimate procedure. This can be done with any execution mode. We will use the write mode in this example. Estimating the algorithm is useful to understand the memory impact that running the algorithm on your graph will have. When you later actually run the algorithm in one of the execution modes the system will perform an estimation. If the estimation shows that there is a very high probability of the execution going over its memory limitations, the execution is prohibited. To read more about this, see Automatic estimation and execution blocking.
For more details on estimate in general, see Memory Estimation.
Cypher
The following will estimate the memory requirements for running the algorithm:
Copy to Clipboard
CALL gds.pageRank.write.estimate('myGraph', {
  writeProperty: 'pageRank',
  maxIterations: 20,
  dampingFactor: 0.85
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
Table 13. Results
nodeCount relationshipCount bytesMin bytesMax requiredMemory
8
14
696
696
""696 Bytes""
4.2. Stream
In the stream execution mode, the algorithm returns the score for each node. This allows us to inspect the results directly or post-process them in Cypher without any side effects. For example, we can order the results to find the nodes with the highest PageRank score.
For more details on the stream mode in general, see Stream.
Cypher
The following will run the algorithm in stream mode:
Copy to Clipboard
CALL gds.pageRank.stream('myGraph')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 14. Results
name score
""Home""
3.215681999884452
""About""
1.0542700552146722
""Links""
1.0542700552146722
""Product""
1.0542700552146722
""Site A""
0.3278578964488539
""Site B""
0.3278578964488539
""Site C""
0.3278578964488539
""Site D""
0.3278578964488539
The above query is running the algorithm in stream mode as unweighted and the returned scores are not normalized. Below, one can find an example for weighted graphs. Another example shows the application of a scaler to normalize the final scores.
While we are using the stream mode to illustrate running the algorithm as weighted or unweighted, all the algorithm modes support this configuration parameter.
4.3. Stats
In the stats execution mode, the algorithm returns a single row containing a summary of the algorithm result. For example PageRank stats returns centrality histogram which can be used to monitor the distribution of PageRank score values across all computed nodes. This execution mode does not have any side effects. It can be useful for evaluating algorithm performance by inspecting the computeMillis return item. In the examples below we will omit returning the timings. The full signature of the procedure can be found in the syntax section.
For more details on the stats mode in general, see Stats.
Cypher
The following will run the algorithm and returns the result in form of statistical and measurement values
Copy to Clipboard
CALL gds.pageRank.stats('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85
})
YIELD centralityDistribution
RETURN centralityDistribution.max AS max
Table 15. Results
max
3.2156810760498047
The centrality histogram can be useful for inspecting the computed scores or perform normalizations.
4.4. Mutate
The mutate execution mode extends the stats mode with an important side effect: updating the named graph with a new node property containing the score for that node. The name of the new property is specified using the mandatory configuration parameter mutateProperty. The result is a single summary row, similar to stats, but with some additional metrics. The mutate mode is especially useful when multiple algorithms are used in conjunction.
For more details on the mutate mode in general, see Mutate.
Cypher
The following will run the algorithm in mutate mode:
Copy to Clipboard
CALL gds.pageRank.mutate('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85,
  mutateProperty: 'pagerank'
})
YIELD nodePropertiesWritten, ranIterations
Table 16. Results
nodePropertiesWritten ranIterations
8
20
4.5. Write
The write execution mode extends the stats mode with an important side effect: writing the score for each node as a property to the Neo4j database. The name of the new property is specified using the mandatory configuration parameter writeProperty. The result is a single summary row, similar to stats, but with some additional metrics. The write mode enables directly persisting the results to the database.
For more details on the write mode in general, see Write.
Cypher
The following will run the algorithm in write mode:
Copy to Clipboard
CALL gds.pageRank.write('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85,
  writeProperty: 'pagerank'
})
YIELD nodePropertiesWritten, ranIterations
Table 17. Results
nodePropertiesWritten ranIterations
8
20
4.6. Weighted
By default, the algorithm is considering the relationships of the graph to be unweighted, to change this behaviour we can use configuration parameter called relationshipWeightProperty. In the weighted case, the previous score of a node send to its neighbors, is multiplied by the relationship weight and then divided by the sum of the weights of its outgoing relationships. If the value of the relationship property is negative it will be ignored during computation. Below is an example of running the algorithm using the relationship property.
Cypher
The following will run the algorithm in stream mode using relationship weights:
Copy to Clipboard
CALL gds.pageRank.stream('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85,
  relationshipWeightProperty: 'weight'
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 18. Results
name score
""Home""
3.53751028396339
""Product""
1.9357838291651097
""About""
0.7452612763883698
""Links""
0.7452612763883698
""Site A""
0.18152677135466103
""Site B""
0.18152677135466103
""Site C""
0.18152677135466103
""Site D""
0.18152677135466103
We are using stream mode to illustrate running the algorithm as weighted or unweighted, all the algorithm modes support this configuration parameter.
4.7. Tolerance
The tolerance configuration parameter denotes the minimum change in scores between iterations. If all scores change less than the configured tolerance value the result stabilises, and the algorithm returns.
Cypher
The following will run the algorithm in stream mode using bigger tolerance value:
Copy to Clipboard
CALL gds.pageRank.stream('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85,
  tolerance: 0.1
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 19. Results
name score
""Home""
1.5812450669583336
""About""
0.5980194356381945
""Links""
0.5980194356381945
""Product""
0.5980194356381945
""Site A""
0.23374955154166668
""Site B""
0.23374955154166668
""Site C""
0.23374955154166668
""Site D""
0.23374955154166668
In this example we are using tolerance: 0.1, so the results are a bit different compared to the ones from stream example which is using the default value of tolerance. Note that the nodes 'About', 'Link' and 'Product' now have the same score, while with the default value of tolerance the node 'Product' has higher score than the other two.
4.8. Damping Factor
The damping factor configuration parameter accepts values between 0 (inclusive) and 1 (exclusive). If its value is too high then problems of sinks and spider traps may occur, and the values may oscillate so that the algorithm does not converge. If it’s too low then all scores are pushed towards 1, and the result will not sufficiently reflect the structure of the graph.
Cypher
The following will run the algorithm in stream mode using smaller dampingFactor value:
Copy to Clipboard
CALL gds.pageRank.stream('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.05
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 20. Results
name score
""Home""
1.2487309425844906
""About""
0.9708121818724536
""Links""
0.9708121818724536
""Product""
0.9708121818724536
""Site A""
0.9597081216238426
""Site B""
0.9597081216238426
""Site C""
0.9597081216238426
""Site D""
0.9597081216238426
Compared to the results from the stream example which is using the default value of dampingFactor the score values are closer to each other when using dampingFactor: 0.05. Also, note that the nodes 'About', 'Link' and 'Product' now have the same score, while with the default value of dampingFactor the node 'Product' has higher score than the other two.
4.9. Personalised PageRank
Personalized PageRank is a variation of PageRank which is biased towards a set of sourceNodes. This variant of PageRank is often used as part of recommender systems.
The following examples show how to run PageRank centered around 'Site A'.
Cypher
The following will run the algorithm and stream results:
Copy to Clipboard
MATCH (siteA:Page {name: 'Site A'})
CALL gds.pageRank.stream('myGraph', {
  maxIterations: 20,
  dampingFactor: 0.85,
  sourceNodes: [siteA]
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 21. Results
name score
""Home""
0.39902290442518784
""Site A""
0.16890325301726694
""About""
0.11220151747374331
""Links""
0.11220151747374331
""Product""
0.11220151747374331
""Site B""
0.01890325301726691
""Site C""
0.01890325301726691
""Site D""
0.01890325301726691
Comparing these results to the ones from the stream example (which is not using sourceNodes configuration parameter) shows that the 'Site A' node that we used in the sourceNodes list now scores second instead of fourth.
4.10. Scaling centrality scores
To normalize the final scores as part of the algorithm execution, one can use the scaler configuration parameter. A common scaler is the L1Norm, which normalizes each score to a value between 0 and 1. A description of all available scalers can be found in the documentation for the scaleProperties procedure.
Cypher
The following will run the algorithm in stream mode and returns normalized results:
Copy to Clipboard
CALL gds.pageRank.stream('myGraph', {
  scaler: ""L1Norm""
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
Table 22. Results
name score
""Home""
0.4181682554824872
""About""
0.1370975954128506
""Links""
0.1370975954128506
""Product""
0.1370975954128506
""Site A""
0.04263473956974027
""Site B""
0.04263473956974027
""Site C""
0.04263473956974027
""Site D""
0.04263473956974027
Comparing the results with the stream example, we can see that the relative order of scores is the same.
Centrality
Article Rank
Was this page helpful?"
https://neo4j.com/developer/kb/protecting-against-ssrf;"Protecting against Server Side Request Forgery (SSRF)
Author Irene Michlin Applicable versions 3.5 4.1 4.2 4.3 4.4 5.0 Tags cypher security
What is SSRF?
Server-side request forgery (SSRF) vulnerabilities let an attacker send crafted requests from the back-end server of a vulnerable web application. Criminals usually use SSRF attacks to target internal systems that are behind firewalls and are not accessible from the external network.
SSRF vulnerabilities occur when an attacker has full or partial control of the request sent by the backend application. SSRF is not limited to the HTTP protocol. Generally the input that the attacker controls is HTTP, but the backend request could use different protocols.
You can practice attacking a vulnerable application and learn about mitigations in this interactive lesson from Snyk.
Why SSRF attacks are relevant to the Neo4j ecosystem
Neo4j is a graph database that is used to analyse data. To enable the users easy onboarding of the existing data, we have to provide ways to load files (typically CSV files) locally or from the network via http. With that functionality comes the ability of a potentially malicious user to manipulate the initial request - step one of SSRF.
How to protect my environment
Given that SSRF is an OWASP Top 10 issue, OWASP has a comprehensive guide to prevention and mitigation.
The use case ""users should be able to load the data from anywhere on the internet"" falls into Case 2, which is more complex to defend against.
But with a defence in depth approach, it is possible.
Neo4j does input validation as much as possible, which is your application layer defence. And if you build custom applications on top of Neo4j, it’s a good idea to limit the ability to upload data and to run raw Cypher queries to your authenticated users. But to ensure defence in depth, you should do more on the network layer.
The detection and prevention are highly specific to your infrastructure and network environment.
Running on AWS cloud
Use IMDSv2.
Running on Google cloud
Google has advisories for preventing access to metadata, Compute Engine resources and how to utilize workload identity to minimize access.
Generic mitigation
Segment your network and configure your firewall to prevent access from Neo4j to the metadata subnet (if running on cloud) and any other sensitive backend subnets. In most cases you want to prevent access to internal IP addresses originating from the backend service in general.
Configuration option
In addition to the external network-level restriction mechanisms listed above, Neo4j has an internal control mechanism which allows users to provide IP address ranges for the DBMS to block. This control is activated via a configuration setting which must be added to neo4j.conf and requires restarting the DBMS to be applied.
unsupported.dbms.cypher_ip_blocklist
Description
IP address ranges used by the DBMS to block IP requests
Valid values
Comma separated list of IPv4 and IPv6 CIDR-notation IP ranges
Default value
When the DBMS attempts to make an IP request to a URL, after resolving the URL to an IP address, it ensures this address doesn’t collide with any of the blocked IP ranges provided by the configuration setting. Because the control mechanism is applied at the IP network level, it will be applied to any HTTP and FTP requests made by Cypher features such as LOAD CSV.
There are several helpful resources one could use to help calculate their required blocklist. One such resource is ipaddressguide.com which has calculators for both IPv4 CIDR and IPv6 CIDR ranges.
Use cases
This section includes some example to help illustrate how the setting can be used in practice.
unsupported.dbms.cypher_ip_blocklist=
Blocks no traffic (default behaviour).
unsupported.dbms.cypher_ip_blocklist=0.0.0.0/0,::/0
Blocks all IPv4 and IPv6 network traffic.
unsupported.dbms.cypher_ip_blocklist=10.0.0.0/8,ff:f::/64
Blocks IPv4 traffic between 10.0.0.0 and 10.255.255.255.
Blocks IPv6 traffic between ff:f:0:0:0:0:0:0 and ff:f:0:0:ffff:ffff:ffff:ffff.
unsupported.dbms.cypher_ip_blocklist=10.0.0.0/8,10.0.0.0/24
Blocks IPv4 traffic between 10.0.0.0 and 10.255.255.255.
Blocks IPv4 traffic between 255.0.0.0 and 255.0.0.255.
Blocks no IPv6 traffic.
Supported Versions
In Neo4j, the setting is available from versions 4.4.4, 4.3.17, 4.2.19, 4.1.12, and 3.5.35.
In APOC, the setting is available from versions 4.4.0.3, 4.3.0.8, 4.2.0.12, 4.1.0.12, and 3.5.0.20.
Although the name will change to internal.dbms.cypher_ip_blocklist, the setting will also be supported in the upcoming 5.0 releases for both Neo4j and APOC.
Was this page helpful?"
https://neo4j.com/labs/apoc/4.4/overview/apoc.util/apoc.util.sha512;"apoc.util.sha512
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha512([values]) | computes the sha512 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha512([""Michael""]) AS output;
Table 1. Results
output
""e70bdf701bd91b2357ec83bd6fb74d602f2883beb6934de21c9bffa0fc0717a9ee6ef9327387ac2b3735a3be9796754a03941059405955999e2302b0ae7efeb6""
Was this page helpful?"
https://neo4j.com/labs/apoc/4.4/overview/apoc.util/apoc.util.sha256;"apoc.util.sha256
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.sha256([values]) | computes the sha256 hash of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.sha256([""Michael""]) AS output;
Table 1. Results
output
""f089eaef57aba315bc0e1455985c0c8e40c247f073ce1f4c5a1f8ffde8773176""
Was this page helpful?"
https://neo4j.com/labs/apoc/4.4/overview/apoc.util/apoc.util.md5;"apoc.util.md5
Contents
Signature
Input parameters
Usage Examples
Function APOC Core
apoc.util.md5([values]) | computes the md5 of the concatenation of all string values of the list MD5 is a weak hashing algorithm which is unsuitable for cryptographic use-cases.
Signature
None
Copy to Clipboard
apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Usage Examples
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN apoc.util.md5([""Michael""]) AS output;
Table 1. Results
output
""3e06fa3927cbdf4e9d93ba4541acce86""
More documentation of apoc.util.md5
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-string-to-date;"Neo4j: Convert string to date
Author Mark Needham Applicable versions 3.5 Tags cypher
Neo4j 3.4 saw the introduction of the temporal date type, and while there is now powerful in built functionality, converting strings to dates is still a challenge.
If our string is in the format yyyy-MM-dd we can call the date function with that string and have it converted to a date automatically:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN date(""2019-06-04"") AS date
Executing this query will return the following result:
date
""2019-06-04""
But what if our string is in a different format, say dd/MM/yyyy? Let’s try and create a date from such a string:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN date(""04/06/2019"") AS date
Executing this query will return the following result:
Text cannot be parsed to a Date
""04/06/2019""
 ^
One way we can solve this problem is by manually parsing our string into its different components using the split function. We can then create a date from those components:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH [item in split(""20/07/2018"", ""/"") | toInteger(item)] AS dateComponents
RETURN date({day: dateComponents[0], month: dateComponents[1], year: dateComponents[2]}) AS date
Executing this query will return the following result:
date
""2018-07-20""
Alternatively we can use the APOC library’s apoc.date.parse function to massage our data into a supported format. This function gives us a flexible way for handling different date and time patterns.
The following query:
Uses the apoc.date.parse function to convert our dd/MM/yyyy date string into a timestamp in milliseconds
Creates a datetime from that timestamp
Creates a date from that datetime
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.parse(""31/05/2019"", ""ms"", ""dd/MM/yyyy"") AS ms
RETURN date(datetime({epochmillis: ms})) AS date
Executing this query will return the following result:
date
""2019-05-31""
We could also use this function to parse a longer date format:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH apoc.date.parse(""Tue, 10 September 2019"", ""ms"", ""EEE, dd MMMMM yyyy"") AS ms
RETURN date(datetime({epochmillis: ms})) AS date
Executing this query will return the following result:
date
""2019-09-10""
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model/find;"find
Contents
Example
Arguments
This method can be used to find nodes, and maps to the underlying schema Queries.
Returns a Promise which resolvers to an array of objects matching the type of the Model.
Example
To find all user nodes in the database:
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

const users = await User.find();
To find users with name ""Jane Smith"":
JavaScript
Copy to Clipboard
const User = ogm.model(""User"");

const users = await User.find({ where: { name: ""Jane Smith"" }});
Arguments
Name and Type Description
where

Type: GraphQLWhereArg
A JavaScript object representation of the GraphQL where input type used for Filtering.
options

Type: GraphQLOptionsArg
A JavaScript object representation of the GraphQL options input type used for Sorting and Pagination.
selectionSet

Type: string or DocumentNode or SelectionSetNode
Selection set for the Mutation, see Selection Set for more information.
args

Type: any
The args value for the GraphQL Mutation.
context

Type: any
The context value for the GraphQL Mutation.
rootValue

Type: any
The rootValue value for the GraphQL Mutation.
create
update
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model/create;"create
Contents
Example
Arguments
This method can be used to update nodes, and maps to the underlying Create Mutation.
Returns a Promise that resolves to the equivalent of the Mutation response for this operation.
Example
To create a Movie with title ""The Matrix"":
JavaScript
Copy to Clipboard
const Movie = ogm.model(""Movie"");

await Movie.create({ input: [{ title: ""The Matrix"" }] })
Arguments
Name and Type Description
input

Type: any
JavaScript object representation of the GraphQL input input type used for Create mutations.
selectionSet

Type: string or DocumentNode or SelectionSetNode
Selection set for the Mutation, see Selection Set for more information.
args

Type: any
The args value for the GraphQL Mutation.
context

Type: any
The context value for the GraphQL Mutation.
rootValue

Type: any
The rootValue value for the GraphQL Mutation.
Model
find
Was this page helpful?"
https://neo4j.com/docs/graphql-manual/3.0/ogm/api-reference/model;"Model
Contents
create
find
update
delete
aggregate
create
See create.
find
See find.
update
See update.
delete
See delete.
aggregate
See aggregate.
generate
create
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-non-existent-properties-and-null-values;"Understanding non-existent properties and working with nulls
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
In Neo4j, since there is no table schema or equivalent to restrict possible properties, non-existence and null are equivalent for node and relationship properties. That is, there really is no such thing as a property with a null value; null indicates that the property doesn’t exist at all.
This is in contrast with a relational db with a table schema, where a field exists for a row of a table even if the value for that column is null.
As an example, if we had a graph of :Person nodes, the following two queries are considered the same:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.id = $personId
RETURN NOT EXISTS(p.email)
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.id = $personId
RETURN p.email IS NULL
It does not matter if the property in question is one that is used on other nodes (just missing on this one), or if it is a nonsensical or never-used property in the graph (such as p.pinkElephant). If the property doesn’t exist, a NULL check as above will return true.
Likewise, the following two queries result in the removal of the property:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.id = $personId
SET p.email = null
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.id = $personId
REMOVE p.email
This can be useful if you need a way to clear several properties dynamically from nodes, using a map to update node properties:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH {email:null, dob:null} as clearProps
MATCH (p:Person)
WHERE p.id = $personId
SET p += clearProps
NULL map values
This also demonstrates that although non-existence and null node and relationship properties are equivalent, this does not hold true for maps or collections. A map with an entry with a null value, as above, is different than a map that is missing the entry.
This differentiation can be especially useful when using map projection. Map projection is a map view of a node’s properties, and can be used to force the display of a property for the returned data, even if the property doesn’t exist on that node.
For example, in this query, the email property in the returned node data may or may not be returned, depending on if the property exists on each returned node:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN p
But if we wanted the email property to always display, showing NULL if the property doesn’t exist, we would use map projection like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN p {.*, .email}
NULL list values
NULLs are also allowed in lists:
Cypher
Copy to Clipboard
Run in Neo4j Browser
RETURN [1,2,3,null,5]
However, aggregations over node or relationship properties skip or disregard null values:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN count(p.email) as emailCount
The count does not include null values.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN collect(p.email) as emails
This skips null values; the returned collection does not contain any nulls.
Working with NULL in logical expressions and other contexts
The Neo4j developers manual has an extensive section on working with NULL in logical expressions and details when expressions will return NULL.
Use COALESCE() to use a default for a null value
In some cases we may want to display a fallback default value when a property doesn’t exist on a node or relationship. Or we may want to perform an equality or inequality comparison against a possible null value, and use a default if the value happens to be null.
COALESCE() allows handling of these cases. It accepts any number of parameters, and returns the first non-null value encountered.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN collect(COALESCE(p.email, 'NOT SET')) as emails
Rather than ignoring the null values as before, we see 'NOT SET' included in the list.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE COALESCE(p.optedIn, false) <> true
RETURN p
With COALESCE() we can treat a null as a different value for the purpose of comparison. Note that equality or inequality comparisons against null, such as null <> true, results in null, not a boolean, so COALESCE() is especially helpful here.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
RETURN COALESCE(p.email, p.backupEmail, p.backupBackupEmail, 'NOT SET') as email
Multiple fallbacks are allowed, the first non-null value will be used.
Matching and Merging with NULL
Null node variables
While you can perform a MATCH where a node variable in the match is null (such as from a failed OPTIONAL MATCH), you cannot CREATE or MERGE a pattern with a null node variable.
When there are no :PinkElephant nodes, this works, but won’t return records:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (node1:PinkElephant)
WITH node1
MATCH (node1)-[:ACTED_IN]->(m:Movie)
RETURN node1
However both of these will throw errors:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (node1:PinkElephant)
WITH node1
MERGE (node1)-[:ACTED_IN]->(m:Movie)
RETURN node1
and
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (node1:PinkElephant)
WITH node1
CREATE (node1)-[:ACTED_IN]->(m:Movie)
RETURN node1
Null property values
When we instead use null property values, we can MATCH or CREATE using a null property value, but we cannot use MERGE:
These work:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (ele:PinkElephant)
WITH ele
MATCH (node1:Person {name:ele.name})-[:ACTED_IN]->(m:Movie)
RETURN node1
and
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (ele:PinkElephant)
WITH ele
CREATE (node1:Person {name:ele.name})-[:ACTED_IN]->(m:Movie)
RETURN node1
but this throws an error:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (ele:PinkElephant)
WITH ele
MERGE (node1:Person {name:ele.name})-[:ACTED_IN]->(m:Movie)
RETURN node1
Was this page helpful?"
https://neo4j.com/developer/kb/configure-haproxy-to-send-write-requests-to-master-node-only;"Configure HAProxy to Send Write Requests to Leader Node Only
Author Stefan Armbruster Applicable versions 3.5 Tags cluster master writes load balancer
There are a few options regarding implementation of a proxy server to direct writes to a Master node and reads to the Slave nodes in a Neo4j cluster. Commonly, it is recommended to handle this logic in the application code. However, there is another way.
By using the following configuration for HAProxy, you can direct GET requests (reads) to the Slave nodes, while directing everything else (DELETE, POST, PUT) to the Master.
Haproxy
Copy to Clipboard
global
daemon
maxconn 256

defaults
mode http
timeout connect 5000ms
timeout client 50000ms
timeout server 50000ms

frontend http-in
bind *:80
acl write_methods method POST DELETE PUT
#Only POST and DELETE methods are used according to the documentation
use_backend neo4j-write if write_methods
default_backend  neo4j-read-only

backend neo4j-read-only
balance roundrobin
option httpchk GET /db/manage/server/causalclustering/read-only
server s1 10.0.1.10:7474 maxconn 32 check
server s2 10.0.1.11:7474 maxconn 32 check
server s3 10.0.1.12:7474 maxconn 32 check

backend neo4j-write
balance roundrobin
option httpchk GET /db/manage/server/causalclustering/writable
server s1 10.0.1.10:7474 maxconn 32 check
server s2 10.0.1.11:7474 maxconn 32 check
server s3 10.0.1.12:7474 maxconn 32 check
View all (15 more lines)
The logic here says that by default a request is routed to a follower and if it is a write request (POST, DELETE, PUT), route it to a Master instead.
See the product documentation for more info on this topic: https://neo4j.com/docs/operations-manual/3.5/ha-cluster/haproxy/
The first step in configuring Basic Authentication in HAProxy is to get the base64 representation of username:password.
To do this at the command line, for username neo4j and password neo4j:
Shell
$ echo -n ""neo4j:neo4j"" | base64
bmVvNGo6bmVvYWRtaW4=
Please note that this username-password combination is not valid and only used for demonstration purposes.
Then append HTTP/1.0\r\nAuthorization:\ Basic\ base64_username_password as following:
option httpchk GET /db/manage/server/causalclustering/writable HTTP/1.0\r\nAuthorization:\ Basic\ bmVvNGo6bmVvYWRtaW4=
Was this page helpful?"
https://neo4j.com/developer/kb/modifying-the-httplog-format-on-neo4j-2x;"Retired: Modifying the http.log Format on Neo4j 2.x
Author Dave Gordon Applicable versions 2.2 2.3 Tags http logging
Prior to Neo4j 3.0, the http.log format was controlled by neo4j-http-logging.xml. The default format works fine, except when you need to diagnose problematic long-running queries. The HTTP requests to the /db/data/cypher or /db/data/transaction endpoints do not log the json payload with the Cypher query, which might be helpful in some situations.
The format layout options can be found in the source code here.
For example, to log the cypher query, log the full request. To enable this, in the conf/neo4j-http-logging.xml file, you need to modify it as follows:
Xml
Copy to Clipboard
<pattern>%h %l %user [%t{dd/MMM/yyyy:HH:mm:ss Z}] ""%r"" %s %b ""%i{Referer}"" ""%i{User-Agent}"" %fullRequest %D</pattern>
Note: Only change this during debugging, and then set the pattern back to the default. Otherwise, logging every full request will increase the I/O on the storage and could result in a performance impact.
Was this page helpful?"
https://neo4j.com/developer/kb/minimalistic-local-webserver-for-load-csv;"How do I establish a simple HTTP Server local to my Neo4j Instance to serve CSV files
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 yudx Tags load csv http webserver
When using LOAD CSV one can define the source file to be either at a local file system (i.e load csv from 'file:///…' ) or a webserver ( i.e. load csv from 'http://…'). Usage of a webserver might be a preferable approach when in a Causal Cluster, since the webserver would be available regardless of which member was the leader.
If you are in need of setting up a minimalistic webserver this can be accomplished, provided one has installed Python and by running:
Shell
Copy to Clipboard
$ python -m SimpleHTTPServer
The above command would start a web server at port: 8000, and the web server’s root directory would be the same as where the command was run. For example if you ran the above command in /home/neo4j/load-csv-files then https://<IP of the Neo4j Instance>:8000 would list all the files at /home/neo4j/load-csv-files. And thus your LOAD CSV cypher statement would be:
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv from 'http://192.168.97.215:8000/movies.csv' as row
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-load-csv-error-of-couldnt-load-the-external-resource;"Explanation of error LOAD CSV error of ""Couldn’t load the external resource …""
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load csv user-agent
When running a LOAD CSV Cypher statement, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM ""http://10.12.1.2/Neo4j/cities.csv"" AS row WITH row create (c:cities {name:row.city});
whether through bin/neo4j-shell or the browser at http://localhost:7474 this may result in an error as follows
couldn't load the external resource at: http://10.12.1.2/Neo4j/cities.csv. See debug.log for more details, reference 8a28b268-948d-43fa-8d6d-b1afb0130276
And the data/graph.db/messages.log (2.x) or $NEO4J_HOME/log/debug.log (3.x) will include a stack trace similar to
2016-05-11 13:50:32.508+0000 ERROR [o.n.b.v.r.i.ErrorReporter] Client triggered an unexpected error [ExternalResourceFailed]: Couldn't load the external resource at: http://10.12.1.2/Neo4j/cities.csv. See debug.log for more details, reference 8a28b268-948d-43fa-8d6d-b1afb0130276.
2016-05-11 13:50:32.508+0000 ERROR [o.n.b.v.r.i.ErrorReporter] Client triggered an unexpected error [ExternalResourceFailed]: Couldn't load the external resource at: http://10.12.1.2/Neo4j/cities.csv, reference 8a28b268-948d-43fa-8d6d-b1afb0130276. Couldn't load the external resource at: http://10.12.1.2/Neo4j/cities.csv
org.neo4j.kernel.impl.query.QueryExecutionKernelException: Couldn't load the external resource at: http://mvabl.com/Neo4j/languages.csv
        at org.neo4j.cypher.internal.javacompat.ExecutionEngine.executeQuery(ExecutionEngine.java:69)
        at org.neo4j.bolt.v1.runtime.internal.CypherStatementRunner.run(CypherStatementRunner.java:73)
        at org.neo4j.bolt.v1.runtime.internal.StandardStateMachineSPI.run(StandardStateMachineSPI.java:110)
        at org.neo4j.bolt.v1.runtime.internal.SessionStateMachine$State$2.runStatement(SessionStateMachine.java:122)
        at org.neo4j.bolt.v1.runtime.internal.SessionStateMachine.run(SessionStateMachine.java:653)
        at org.neo4j.bolt.v1.runtime.internal.concurrent.SessionWorkerFacade.lambda$run$3(SessionWorkerFacade.java:68)
        at org.neo4j.bolt.v1.runtime.internal.concurrent.SessionWorker.execute(SessionWorker.java:116)
        at org.neo4j.bolt.v1.runtime.internal.concurrent.SessionWorker.executeBatch(SessionWorker.java:102)
        at org.neo4j.bolt.v1.runtime.internal.concurrent.SessionWorker.run(SessionWorker.java:82)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.neo4j.cypher.LoadExternalResourceException: Couldn't load the external resource at: http://10.12.1.2/Neo4j/cities.csv
        at org.neo4j.cypher.internal.compatibility.exceptionHandlerFor3_0$.loadExternalResourceException(CompatibilityFor3_0.scala:84)
        at org.neo4j.cypher.internal.compatibility.exceptionHandlerFor3_0$.loadExternalResourceException(CompatibilityFor3_0.scala:61)
        at org.neo4j.cypher.internal.frontend.v3_0.LoadExternalResourceException.mapToPublic(CypherException.scala:110)
        at org.neo4j.cypher.internal.compatibility.exceptionHandlerFor3_0$.runSafely(CompatibilityFor3_0.scala:122)
        at org.neo4j.cypher.internal.compatibility.CompatibilityFor3_0$ExecutionPlanWrapper.run(CompatibilityFor3_0.scala:199)
        at org.neo4j.cypher.internal.PreparedPlanExecution.execute(PreparedPlanExecution.scala:27)
        at org.neo4j.cypher.internal.ExecutionEngine.execute(ExecutionEngine.scala:111)
        at org.neo4j.cypher.internal.javacompat.ExecutionEngine.executeQuery(ExecutionEngine.java:65)
        ... 9 more
Caused by: org.neo4j.cypher.internal.frontend.v3_0.LoadExternalResourceException
        at org.neo4j.cypher.internal.compiler.v3_0.spi.CSVResources.openStream(CSVResources.scala:117)
        at org.neo4j.cypher.internal.compiler.v3_0.spi.CSVResources.getCsvIterator(CSVResources.scala:55)
        at org.neo4j.cypher.internal.compiler.v3_0.pipes.LoadCSVPipe$$anonfun$internalCreateResults$1.apply(LoadCSVPipe.scala:108)
        at org.neo4j.cypher.internal.compiler.v3_0.pipes.LoadCSVPipe$$anonfun$internalCreateResults$1.apply(LoadCSVPipe.scala:103)
        at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
        at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
        at org.neo4j.cypher.internal.compiler.v3_0.pipes.EmptyResultPipe.internalCreateResults(EmptyResultPipe.scala:31)
        at org.neo4j.cypher.internal.compiler.v3_0.pipes.PipeWithSource.createResults(Pipe.scala:126)
        at org.neo4j.cypher.internal.compiler.v3_0.pipes.PipeWithSource.createResults(Pipe.scala:123)
        at org.neo4j.cypher.internal.compiler.v3_0.executionplan.DefaultExecutionResultBuilderFactory$ExecutionWorkflowBuilder.createResults(DefaultExecutionResultBuilderFactory.scala:94)
        at org.neo4j.cypher.internal.compiler.v3_0.executionplan.DefaultExecutionResultBuilderFactory$ExecutionWorkflowBuilder.build(DefaultExecutionResultBuilderFactory.scala:64)
        at org.neo4j.cypher.internal.compiler.v3_0.executionplan.InterpretedExecutionPlanBuilder$$anonfun$getExecutionPlanFunction$1.apply(ExecutionPlanBuilder.scala:164)
        at org.neo4j.cypher.internal.compiler.v3_0.executionplan.InterpretedExecutionPlanBuilder$$anonfun$getExecutionPlanFunction$1.apply(ExecutionPlanBuilder.scala:148)
        at org.neo4j.cypher.internal.compiler.v3_0.executionplan.InterpretedExecutionPlanBuilder$$anon$1.run(ExecutionPlanBuilder.scala:123)
        at org.neo4j.cypher.internal.compatibility.CompatibilityFor3_0$ExecutionPlanWrapper$$anonfun$run$1.apply(CompatibilityFor3_0.scala:200)
        at org.neo4j.cypher.internal.compatibility.CompatibilityFor3_0$ExecutionPlanWrapper$$anonfun$run$1.apply(CompatibilityFor3_0.scala:200)
        at org.neo4j.cypher.internal.compatibility.exceptionHandlerFor3_0$.runSafely(CompatibilityFor3_0.scala:117)
        ... 13 more
Caused by: java.io.IOException: Server returned HTTP response code: 403 for URL: http://10.12.1.2/Neo4j/cities.csv
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1840)
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441)
        at org.neo4j.cypher.internal.compiler.v3_0.spi.CSVResources.openStream(CSVResources.scala:109)
        ... 30 more
From the stack trace the reference to
Server returned HTTP response code: 403 for URL: http://10.12.1.2/Neo4j/cities.csv
is indicating that the WebServer at 10.12.1.2 received the request but returned status code 403 (Permission Denied).
When a request is submitted to the WebServer, the user-agent of that request is defined as ""Java/1.8.0_91"". Below is the single line logging for said request in a Apache WebServer Common Log Format. The last field represents the user-agent of the request.
192.168.1.176 - - [16/May/2016:08:34:15 -0400] ""GET /Neo4j/cities.csv HTTP/1.1"" 404 511 ""-"" ""Java/1.8.0_91""
In the above case, the WebServer was explicitly blocking any request with the user-agent ""Java/1.8.0_91"". Once this was addressed the LOAD CSV command was then successful.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-unrecognized-transaction-id-transaction-may-have-timed-out-and-been-rolled-back;"Explanation of error ""Unrecognized transaction id. Transaction may have timed out and been rolled back""
Author Dana Canzano Applicable versions 3.5 Tags cypher http
When submitting a request via the Neo4j Transactional Cypher HTTP endpoint, one may encounter the following error
Unrecognized transaction id.
Transaction may have timed out and been rolled back
This error may occur as a result of the transactions expiration date/time being met. By default, org.neo4j.server.transaction.timeout describes the number of seconds whereby inactivity in a transaction will result in the transaction automatically rolling back. The default is 60 seconds but can be overridden by adding
Properties
Copy to Clipboard
org.neo4j.server.transaction.timeout=XXX
where XXX represents number of seconds, to the conf/neo4j-server.properties and then restarting neo4j via bin/neo4j restart.
Alternatively one can either, keep the transaction open by periodically performing a keep-alive via the REST API and as described via  /db/data/transaction/XXX, or committing the transaction sooner by /db/data/transaction/XXX/commit where XXX represents the transaction number
Note bin/neo4j-shell does not utilize the REST API and as such the org.neo4j.server.transaction.timeout has no effect on transactions created within a begin commit within neo4j-shell.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-display-the-rest-code-from-the-3-0-browser;"How do I display the REST code from the 3.0 Browser
Author Dana Canzano Applicable versions 3.5 Tags browser rest bolt
In Neo4j 3.0 and its implementation of the Bolt protocol, requests submitted via the browser (http://localhost:7474) are submitted using Bolt. From the results frame, on the bottom left, you can click on the </> Code icon to see the response submission. Below is a depiction when Bolt is enabled:
To revert to a REST API request you need to disable Bolt via the ""gears"" icon in the bottom left of the browser. Upon clicking the ""gears"" icon, you would then need to uncheck the checkbox for the field Use Bolt protocol when available (shown below):
With Bolt disabled, the Cypher results frame </> Code icon will now display as follows:
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-zoom-in-out-within-the-graph-visualization-of-the-browser;"How do I zoom in/out within the graph visualization of the browser?
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags browser zoom
Within the graph visualization pane of the browser (reached locally at http://localhost:7474), to zoom in/out of the graph display one first needs to select Full Screen mode. The zoom in/out controls are located in the bottom-right corner.
To enter Full Screen mode, within the graph visualization pane click the icon depicted in the example below:
To zoom in/out, click the icon depicted in the example below:
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-produce-a-profile-explain-through-cypher-shell-and-pipeing-query-file;"How do I produce a profile/explain through cypher-shell and pipeing query file
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher-shell explain profile
If you prepare a file with a Cypher statement that includes either a profile or explain clause and then want to pipe that file to bin/cypher-shell, to produce the profile/explain output you must include --format verbose on the command line.
For example, when your file, mycypher.cql, contains
Cypher
Copy to Clipboard
Run in Neo4j Browser
profile match (n:Movies) return count(n);
if you run:
Shell
Copy to Clipboard
$ cat mycypher.cql | ./cypher-shell
the output will be
Plan: ""PROFILE""
Statement: ""READ_ONLY""
Version: ""CYPHER 3.2""
Planner: ""COST""
Runtime: ""COMPILED""
Time: 42
DbHits: 0
Rows: 1
count(n)
0
However, when running:
Shell
Copy to Clipboard
$ cat mycypher.cql | ./cypher-shell --format verbose
the output will now be:
+--------------------------------------------------------------------------------------+
| Plan      | Statement   | Version      | Planner | Runtime    | Time | DbHits | Rows |
+--------------------------------------------------------------------------------------+
| ""PROFILE"" | ""READ_ONLY"" | ""CYPHER 3.2"" | ""COST""  | ""COMPILED"" | 0    | 0      | 1    |
+--------------------------------------------------------------------------------------+

+--------------------------+----------------+------+---------+-----------+-----------+-------------+---------------------------------------+
| Operator                 | Estimated Rows | Rows | DB Hits | Cache H/M | Time (ms) | Identifiers | Other                                 |
+--------------------------+----------------+------+---------+-----------+-----------+-------------+---------------------------------------+
| +ProduceResults          |              1 |    1 |       0 |       0/0 |     0.019 | count(n)    | 19237                                 |
| |                        +----------------+------+---------+-----------+-----------+-------------+---------------------------------------+
| +NodeCountFromCountStore |              1 |    0 |       1 |       0/0 |     0.029 | count(n)    | 29320; count( (:Movies) ) AS count(n) |
+--------------------------+----------------+------+---------+-----------+-----------+-------------+---------------------------------------+

+----------+
| count(n) |
+----------+
| 0        |
+----------+
Was this page helpful?"
https://neo4j.com/developer/kb/favorites-for-cypher-shell;"Favorites for cypher-shell?
Author Dana Canzano Applicable versions 4.0 4.1 4.2 Tags cypher-shell favorites
The Neo4j Browser has always had the ability to record favorites, i.e. a bookmark to saved cypher that you may want to run sometime in the future. bin\cypher-shell has somewhat similar functionality in that once connected one can run
Connected to Neo4j using Bolt protocol version 4.2 at neo4j://localhost:7687 as user neo4j.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.

neo4j> :source favorite1.cyp
and to which this will cause cypher-shell to run all the cypher statements that are defined in favorite1.cyp. Note you can fully qualify the filename, and thus
neo4j> :source /home/neo4j/favorites/fav1.cyp
and to which this will then cause cypher-shell to execute all the cypher statements in the file namd fav1.cyp as found at /home/neo4j/favorites
Was this page helpful?"
https://neo4j.com/developer/kb/consideration-about-routing-tables-on-multi-data-center-deployments;"Consideration about routing tables on multi-data center deployments
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags drivers routing
Using the official Neo4j drivers means that you can take advantage of the full cluster routing capabilities of the drivers. This means your requests will be routed automatically to the appropriate instance:
If your request is a write: it will be routed to the Leader instance
If your request is a read: it will be routed to a Follower/Read Replica instance
Community drivers also exist for many languages, but vary greatly in terms of feature sets, maturity, and support. To find out more about community drivers, visit https://neo4j.com/developer/language-guides/.
Routing drivers with routing context are an available option when using drivers of version 1.3 or above together with a Neo4j Causal Cluster of version 3.2 or above. In such a setup, a routing driver can include a preferred routing context via the query part of the bolt+routing URI. In the standard Neo4j configuration, routing contexts are defined on server side by means of server policies. Thus the driver communicates the routing context to the cluster in the form of a server policy. It then obtains refined routing information back from the cluster, based on the server policy.
When deploying a multi-data center cluster we often wish to take advantage of locality to reduce latency and improve performance. We therefore highly recommend configuring the server groups in a way they can map to data centers, availability zones, or any other significant topological elements from the operator’s domain.
However, even after you correctly configure your server groups, you may observe a higher latency in some requests. If you’re experiencing this, probably it’s due to the routing table population. When we get the routing table from the Core servers we do so in a random way, not obeying server policies. The reason behind this design is because we want to prevent situations where an instance repeatedly sends stale routing information.
The drivers pull new routing information in 3 occasions:
Driver object creation:
driver driverObj = new driver( ""bolt+routing://server:7687?policy=EU"" )
Failed connections
When there’s a failed connection, the driver marks the routing table as stale and pulls a new one from a random Core.
TTL
When the TTL expires. The default value is 300s but you can adjust this by setting causal_clustering.cluster_routing_ttl in neo4j.conf
Was this page helpful?"
https://neo4j.com/developer/kb/a-demonstration-of-causal-cluster-routing;"A demonstration of causal cluster routing
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster routing cypher-shell
The following will demonstrate how to use cypher-shell to get a better understanding of a Neo4j Causal Cluster instance and its implementation of routing.
The initial scenario is described with local cluster setup with 3 core instances, 1 LEADER and 2 FOLLOWERS. Using dbms.cluster.overview() The output reports
$ ./cypher-shell -a bolt://192.168.0.97:7617
Connected to Neo4j 3.2.2 at bolt://192.168.0.97:7617.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j> call dbms.cluster.overview() yield addresses, role;
+-----------------------------------------------------------------------------------------------+
| addresses                                                                    | role           |
+-----------------------------------------------------------------------------------------------+
| [""bolt://localhost:7617"", ""http://localhost:7414"", ""https://localhost:7413""] | ""LEADER""       |
| [""bolt://localhost:7627"", ""http://localhost:7424"", ""https://localhost:7423""] | ""FOLLOWER""     |
| [""bolt://localhost:7637"", ""http://localhost:7434"", ""https://localhost:7433""] | ""FOLLOWER""     |
+-----------------------------------------------------------------------------------------------+
The above detail is also available through the browser by running :sysinfo
if a connection is made to the 3rd instance (i.e. a FOLLOWER) and the routing attribute is not included, then writes are not possible on the FOLLOWER and this is expected, for example
$ ./cypher-shell -a bolt://192.168.0.97:7637
Connected to Neo4j 3.2.2 at bolt://192.168.0.97:7637.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j> create (m:Person {id:123});
No write operations are allowed directly on this database. Writes must pass through the leader. The role of this server is: FOLLOWER
neo4j> :exit
however if a connection is made to this same FOLLOWER instance and the bolt+routing attribute is included, then Writes are possible, for example
$ ./cypher-shell -a bolt+routing://192.168.0.97:7637
Connected to Neo4j 3.2.2 at bolt://192.168.0.97:7637.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j> create (m:Person {id:123});
0 rows available after 791 ms, consumed after another 3 ms
neo4j> :exit
in this case although cypher-shell was initiated and described to connect to the FOLLOWER on port :7637, as a result of the bolt+routing, the connection was actually redirected to the LEADER, for example
$ ./cypher-shell -a bolt+routing://192.168.0.97:7637
Connected to Neo4j 3.2.2 at bolt+routing://192.168.0.97:7637.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j> call dbms.cluster.role();
+----------+
| role     |
+----------+
| ""LEADER"" |
+----------+
Finally, if the LEADER fails after the intial cypher-shell connection has been established, and thus re-eleection has resulted in the FOLLOWER from instance 3 being reported as the new LEADER, as evidence
neo4j> call dbms.cluster.overview();
+-------------------------------------------------------------------------------------------------------------------------------------------------+
| id                                     | addresses                                                                    | role           | groups |
+-------------------------------------------------------------------------------------------------------------------------------------------------+
| ""0ec70285-5f4a-4a4a-97ce-916592525944"" | [""bolt://localhost:7627"", ""http://localhost:7424"", ""https://localhost:7423""] | ""FOLLOWER""     | []     |
| ""06c1399d-ec17-4cf5-a31e-fb0db135f543"" | [""bolt://localhost:7637"", ""http://localhost:7434"", ""https://localhost:7433""] | ""LEADER""       | []     |
+-------------------------------------------------------------------------------------------------------------------------------------------------+
the cypher-shell connection is able to continue, for example
neo4j> create (n:Person {id:456});
0 rows available after 133 ms, consumed after another 1 ms
Added 1 nodes, Set 1 properties, Added 1 labels
In this case the cypher-shell client has been updated with a new routing table and thus sends WRITEs to the NEW leader at :7637.
If connection had not been established with `bolt+routing' then the connection would have gone to the instance defined by its :port and if that Neo4j instance exits, then future submissions via cypher-shell will results in:
SSL Connection terminated while receiving data. This can happen due to network instabilities, or due to restarts of the database.
Was this page helpful?"
https://neo4j.com/developer/kb/resolve-tls-certificate-errors;"Resolve TLS certificate errors
Author Jeremie Phoulchand Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags tls ssl configuration
TLS encryption is required everywhere. This is a compilation of few errors you can expect while configuring your server. openssl command is required to diagnose or manipulate the certificates.
Check the permission on the folder
neo4j might run as a systemd service with a non-priviledged user. The folder ""$NEO4J_HOME/certificates/<POLICY_NAME>"" specified in your configuration has to be writable by the neo4j user.
Check the private key
The private key has to be in PKCS8 in 3.5.x, PEM format without any passphrase. PKCS12 will be supported in future releases. The command below should return the certificate without prompting for any password.
Shell
Copy to Clipboard
$ openssl rsa -in private.key -check
You can remove the passphrase with:
Shell
Copy to Clipboard
$ openssl rsa -in private.key -out private_key_without_passphrase.key
The folder ""certificates/<POLICY_NAME>/trusted"" can only contains valid certificates in DER format
If you come across signed overrun errors. You might want to review each file including hidden ones in the trusted/revoked folder.
2019-10-24 15:17:36.595+0200 ERROR Failed to start Neo4j: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@6f36c2f0' was successfully initialized, but failed to start. Please see the attached cause exception ""signed overrun, bytes = 918"". Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@6f36c2f0' was successfully initialized, but failed to start. Please see the attached cause exception ""signed overrun, bytes = 918"".
org.neo4j.server.ServerStartupException: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@6f36c2f0' was successfully initialized, but failed to start. Please see the attached cause exception ""signed overrun, bytes = 918"".
at org.neo4j.server.exception.ServerStartupErrors.translateToServerStartupError(ServerStartupErrors.java:45)
at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:187)
at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:124)
at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:91)
at com.neo4j.server.enterprise.CommercialEntryPoint.main(CommercialEntryPoint.java:22)
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.server.database.LifecycleManagingDatabase@6f36c2f0' was successfully initialized, but failed to start. Please see the attached cause exception ""signed overrun, bytes = 918"".
at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:473)
at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:111)
at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:180)
... 3 more
Caused by: java.lang.RuntimeException: Failed to create trust manager based on: /neo4j/certificates/xxx/trusted
at org.neo4j.kernel.configuration.ssl.SslPolicyLoader.load(SslPolicyLoader.java:222)
at org.neo4j.kernel.configuration.ssl.SslPolicyLoader.create(SslPolicyLoader.java:99)
at org.neo4j.graphdb.factory.module.edition.CommunityEditionModule.<init>(CommunityEditionModule.java:98)
at org.neo4j.kernel.impl.enterprise.EnterpriseEditionModule.<init>(EnterpriseEditionModule.java:55)
at com.neo4j.commercial.edition.CommercialEditionModule.<init>(CommercialEditionModule.java:48)
at org.neo4j.graphdb.facade.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:181)
at com.neo4j.commercial.edition.CommercialGraphDatabase.<init>(CommercialGraphDatabase.java:20)
at com.neo4j.server.database.CommercialGraphFactory.newGraphDatabase(CommercialGraphFactory.java:40)
at org.neo4j.server.database.LifecycleManagingDatabase.start(LifecycleManagingDatabase.java:90)
at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:452)
... 5 more
Caused by: java.security.cert.CertificateException: Error loading certificate file: /neo4j/certificates/xxx/private.key
at org.neo4j.kernel.configuration.ssl.SslPolicyLoader.createTrustManagerFactory(SslPolicyLoader.java:363)
at org.neo4j.kernel.configuration.ssl.SslPolicyLoader.load(SslPolicyLoader.java:218)
... 14 more
Caused by: java.security.cert.CertificateParsingException: signed overrun, bytes = 918
at sun.security.x509.X509CertImpl.parse(X509CertImpl.java:1788)
at sun.security.x509.X509CertImpl.<init>(X509CertImpl.java:195)
at sun.security.provider.X509Factory.engineGenerateCertificate(X509Factory.java:102)
at java.security.cert.CertificateFactory.generateCertificate(CertificateFactory.java:339)
at org.neo4j.kernel.configuration.ssl.SslPolicyLoader.createTrustManagerFactory(SslPolicyLoader.java:358)
... 15 more
2019-10-24 15:17:36.597+0200 INFO Neo4j Server shutdown initiated by request
Self-signed certificate
You can generate a key and a public certificate with the following command.
Shell
Copy to Clipboard
$ openssl req -x509 -newkey rsa:2048 -keyout private_key.pem -out public_cert.pem -days 30
You need to set the `dbms.ssl.policy.<policyname>.trust_all=true in neo4j.conf. Please note that this is insecure.
CA signed certificate
All certificates should be in DER encoded format in the trusted directory. The certificate chain has to be complete to allow the communication.
Was this page helpful?"
https://neo4j.com/developer/kb/tls-ssl-configuration-for-specific-ciphers;"TLS/SSL Configuration for Specific Ciphers
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags ssl tls cipher security unix operations
Per documentation: dbms.ssl.policy.<policyname>.ciphers is by default set to the Java platform default allowed cipher suites, which can also be explicitly set to any specific ciphers (separated by "","") to further restrict list of allowed ciphers, thus enabling us to enforce a particular single strong cipher (if needed) and remove any doubt about which cipher gets negotiated and chosen.
Also, alternatively and/or additionally, we can also disable ciphers by using the instructions referenced here: https://lightbend.github.io/ssl-config/CipherSuites.html where as an example, you would add the following into neo4j.conf:
Properties
Copy to Clipboard
dbms.jvm.additional=-Djava.security.properties=<$NEO4J_HOME>/neo4j-enterprise-3.5.x/conf/disabledAlgorithms.properties
with the content of the file including the following(as an example):
Properties
Copy to Clipboard
# disabledAlgorithms.properties
jdk.tls.disabledAlgorithms=EC keySize < 160, RSA keySize < 2048, DSA keySize < 2048
jdk.certpath.disabledAlgorithms=MD2, MD4, MD5,  EC keySize < 160, RSA keySize < 2048, DSA keySize < 2048
To debug further in case of any issues, you can use the following steps:
You can assess the handshake between the client and neo4j by including the following setting in neo4j.conf (and restart):
Properties
Copy to Clipboard
dbms.jvm.additional=-Djavax.net.debug=ssl:handshake
Run the following to investigate list of available ciphers (example)
Shell
Copy to Clipboard
$ nmap --script ssl-enum-ciphers -p 7473 localhost

Starting Nmap 7.70 ( https://nmap.org ) at 2019-07-17 17:54 PDT
Nmap scan report for localhost (127.0.0.1)
Host is up (0.00033s latency).
Other addresses for localhost (not scanned): ::1

PORT     STATE SERVICE
7473/tcp open  rise
| ssl-enum-ciphers:
|   TLSv1.2:
|     ciphers:
|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A
|       TLS_RSA_WITH_AES_128_CBC_SHA256 (rsa 2048) - A
|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (dh 2048) - A
|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A
|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A
|       TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (dh 2048) - A
|     compressors:
|       NULL
|     cipher preference: server
|_  least strength: A

Nmap done: 1 IP address (1 host up) scanned in 0.66 seconds
View all (9 more lines)
As well as the following:
Shell
Copy to Clipboard
$ openssl s_client -connect <server-name-ip>:7473
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-list-and-install-neo4j-versions-using-yum;"How to List and Install Neo4j Versions Using yum
Author Dave Gordon Applicable versions 2.0 2.1 2.2 2.3 Tags unix installation
Prior to Neo4j 3.2, the rpm distribution of Neo4j was experimental at this time. Use with caution and we advise installing from the linux tarball in production environments. For Neo4j 3.2 please follow the instructions here
Neo4j 3.0 does NOT provide an rpm, and it is unlikely 3.1 will either. This is on the roadmap to be done soon, but presently it is not an official method of installing Neo4j. Also note that the ""current"" version installed by yum might be a milestone or release candidate, and thus does not support an upgrade to an official GA release. If you do install Neo4j using yum, be sure to follow these instructions to specify the version you would like to install.*
By default, using yum install neo4j allows you to install the current release (which might be a non-GA release). However, if you would like to install an older version, you can specify that.
For reference, the Yum repo is located here: http://yum.neo4j.com/
After following the instructions found in the link above, run the following command as root at the command line:
Shell
Copy to Clipboard
$ yum list --show-duplicates neo4j
To get the Enterprise package of Neo4j:
Shell
Copy to Clipboard
$ yum list --show-duplicates neo4j-enterprise
Example output:
Shell
Copy to Clipboard
$ yum list --show-duplicates neo4j-enterprise
Loaded plugins: fastestmirror, langpacks
Loading mirror speeds from cached hostfile
 * base: mirror.cc.columbia.edu
 * extras: mirror.es.its.nyu.edu
 * rpmforge: repoforge.mirror.constant.com
 * updates: mirrors.greenmountainaccess.net
Installed Packages
neo4j-enterprise.noarch                   2.2.5-1                         @neo4j
Available Packages
neo4j-enterprise.noarch                   1.9.3-1                         neo4j
neo4j-enterprise.noarch                   1.9.4-1                         neo4j
neo4j-enterprise.noarch                   1.9.6-1                         neo4j
neo4j-enterprise.noarch                   1.9.7-1                         neo4j
neo4j-enterprise.noarch                   1.9.8-1                         neo4j
neo4j-enterprise.noarch                   1.9.9-1                         neo4j
neo4j-enterprise.noarch                   2.0.0-1                         neo4j
neo4j-enterprise.noarch                   2.0.1-1                         neo4j
neo4j-enterprise.noarch                   2.0.2-1                         neo4j
neo4j-enterprise.noarch                   2.0.3-1                         neo4j
neo4j-enterprise.noarch                   2.0.4-1                         neo4j
neo4j-enterprise.noarch                   2.0.5-1                         neo4j
neo4j-enterprise.noarch                   2.1.0-M01_1                     neo4j
neo4j-enterprise.noarch                   2.1.0-M02_1                     neo4j
neo4j-enterprise.noarch                   2.1.0-RC1_1                     neo4j
neo4j-enterprise.noarch                   2.1.0-RC2_1                     neo4j
neo4j-enterprise.noarch                   2.1.0-1                         neo4j
neo4j-enterprise.noarch                   2.1.1-1                         neo4j
neo4j-enterprise.noarch                   2.1.2-1                         neo4j
neo4j-enterprise.noarch                   2.1.3-1                         neo4j
neo4j-enterprise.noarch                   2.1.4-1                         neo4j
neo4j-enterprise.noarch                   2.1.5-1                         neo4j
neo4j-enterprise.noarch                   2.1.6-1                         neo4j
neo4j-enterprise.noarch                   2.1.7-1                         neo4j
neo4j-enterprise.noarch                   2.1.8-1                         neo4j
neo4j-enterprise.noarch                   2.2.0-M01_1                     neo4j
neo4j-enterprise.noarch                   2.2.0-M02_1                     neo4j
neo4j-enterprise.noarch                   2.2.0-M03_1                     neo4j
neo4j-enterprise.noarch                   2.2.0-M04_1                     neo4j
neo4j-enterprise.noarch                   2.2.0-RC01_1                    neo4j
neo4j-enterprise.noarch                   2.2.0-1                         neo4j
neo4j-enterprise.noarch                   2.2.1-1                         neo4j
neo4j-enterprise.noarch                   2.2.2-1                         neo4j
neo4j-enterprise.noarch                   2.2.3-1                         neo4j
neo4j-enterprise.noarch                   2.2.4-1                         neo4j
neo4j-enterprise.noarch                   2.2.5-1                         neo4j
neo4j-enterprise.noarch                   2.2.6-1                         neo4j
neo4j-enterprise.noarch                   2.2.7-1                         neo4j
neo4j-enterprise.noarch                   2.2.8-1                         neo4j
neo4j-enterprise.noarch                   2.2.9-1                         neo4j
neo4j-enterprise.noarch                   2.2.10-1                        neo4j
neo4j-enterprise.noarch                   2.3.0-M01_1                     neo4j
neo4j-enterprise.noarch                   2.3.0-M02_1                     neo4j
neo4j-enterprise.noarch                   2.3.0-M03_1                     neo4j
neo4j-enterprise.noarch                   2.3.0-RC1_1                     neo4j
neo4j-enterprise.noarch                   2.3.0-1                         neo4j
neo4j-enterprise.noarch                   2.3.1-1                         neo4j
neo4j-enterprise.noarch                   2.3.2-1                         neo4j
neo4j-enterprise.noarch                   2.3.3-1                         neo4j
neo4j-enterprise.noarch                   2.3.4-1                         neo4j
neo4j-enterprise.noarch                   2.3.5-1                         neo4j
neo4j-enterprise.noarch                   2.3.6-1                         neo4j
neo4j-enterprise.noarch                   2.3.7-1                         neo4j
neo4j-enterprise.noarch                   3.0.0-M01_1                     neo4j
neo4j-enterprise.noarch                   3.0.0-M02_1                     neo4j
neo4j-enterprise.noarch                   3.0.0-M03_1                     neo4j
neo4j-enterprise.noarch                   3.0.0-M04_1                     neo4j
neo4j-enterprise.noarch                   3.0.0-M05_1                     neo4j
View all (53 more lines)
Choose from the available packages, and decide whether you want Enterprise or Community. To install neo4j 2.3.7:
Shell
Entreprise
Copy to Clipboard
$ yum install neo4j-enterprise-2.3.7
Shell
Community
Copy to Clipboard
$ yum install neo4j-2.3.7
Was this page helpful?"
https://neo4j.com/developer/kb/setup-neo4j-service-with-different-service-id;"Setup Neo4j Service to run with different service ID
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags installation service id service
By default when neo4j is installed as an RPM via yum or apt-get, it creates a user neo4j and group neo4j and runs as neo4j user. However it might be required to run Neo4j service as another service id other than neo4j. So in this article we will take a look at how to go about configuring Service id to run Neo4j service.
For simplicity lets assume the activity is performed on Redhat Release 7.x
Follow instructions as specified in the Neo4j Operations Manual Documentation to install Neo4j Enterprise. https://neo4j.com/docs/operations-manual/current/installation/linux/rpm/
Once the Neo4j service is installed, a new user and group are created called neo4j. When the Neo4j service is started using sudo systemctl start neo4j, the service is started by user neo4j.
To setup and start the Neo4j service as a different user we must follow the below outlined steps.
We will use the user testuser and group testuser to setup neo4j service.
First step is to edit the neo4j.service and change the user and group as testuser so the service can start as that user and group.
Shell
Copy to Clipboard
 sudo vi /usr/lib/systemd/system/neo4j.service
Edit as show below by changing the User and Group.
Ini
Copy to Clipboard
[Unit]
Description=Neo4j Graph Database
After=network-online.target
Wants=network-online.target

[Service]
ExecStart=/home/rohan_kharwar/neo4j-enterprise-3.5.5/bin/neo4j console
Restart=on-failure
User=testuser
Group=testuser
Environment=""NEO4J_CONF=/home/rohan_kharwar/neo4j-enterprise-3.5.5/conf"" ""NEO4J_HOME=/home/rohan_kharwar/neo4j-enterprise-3.5.5""
LimitNOFILE=60000
TimeoutSec=120

[Install]
WantedBy=multi-user.target
Second step is to change the ownership of the below files to testuser:testuser. For RPM install:
/etc/neo4j
/etc/neo4j/jmx.access
/etc/neo4j/jmx.password
/etc/neo4j/neo4j.conf
/var/lib/neo4j
/var/lib/neo4j/data
/var/lib/neo4j/data/databases
/var/lib/neo4j/import
/var/lib/neo4j/plugins
/var/log/neo4j
/var/run/neo4j
Steps documented as :
Shell
Copy to Clipboard
$ sudo chown testuser:testuser -R /etc/neo4j
$ sudo chown testuser:testuser -R /var/lib/neo4j
$ sudo chown testuser:testuser -R /var/log/neo4j
$ sudo chown testuser:testuser -R /var/run/neo4j
Once the above steps are completed, the file ownership should be changed to testuser. Then start the neo4j service as:
Shell
Copy to Clipboard
$ sudo systemctl start neo4j
and this should start as the service user that was setup.
To verify if the neo4j service is started as user testuser execute ps -ef | grep -i neo4j
and the output should show testuser as given below
testuser  3296     1 26 18:00 ?        00:00:19 /usr/bin/java -cp /var/lib/neo4j/plugins:/etc/neo4j:/usr/share/neo4j/lib/*:/var/lib/neo4j/plugins/* -server -XX:+UseG1GC -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:+UnlockExperimentalVMOptions -XX:+TrustFinalNonStaticFields -XX:+DisableExplicitGC -Djdk.tls.ephemeralDHKeySize=2048 -Djdk.tls.rejectClientInitiatedRenegotiation=true -Dunsupported.dbms.udc.source=rpm -Dfile.encoding=UTF-8 com.neo4j.server.enterprise.CommercialEntryPoint --home-dir=/var/lib/neo4j --config-dir=/etc/neo4j
Was this page helpful?"
https://neo4j.com/developer/kb/using-apt-get-to-download-a-specific-neo4j-debian-package;"Using apt to download a specific Neo4j debian package
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags linux installation enterprise debian
By default, using apt-get to install Neo4j allows you to grab the current and previous stable releases. However, if you would like to install an older version, you can specify that.
For reference, the Debian repo is located here: http://debian.neo4j.org/
From the command line, run the following as root:
Shell
Copy to Clipboard
$ apt-cache madison neo4j
     neo4j |    1:3.5.5 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.5.4 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.5.3 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.5.2 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.5.1 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.5.0 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |   1:3.4.13 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |   1:3.4.12 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |   1:3.4.11 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |   1:3.4.10 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.9 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.8 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.7 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.6 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.5 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.4 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.3 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.2 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.1 | https://debian.neo4j.org/repo stable/ Packages
     neo4j |    1:3.4.0 | https://debian.neo4j.org/repo stable/ Packages
View all (6 more lines)
Choose from the available packages, and decide whether you want Enterprise or Community. To install neo4j 3.5.5:
Shell
Enterprise
Copy to Clipboard
$ apt-get install neo4j-enterprise=1:3.5.5
Shell
Community
Copy to Clipboard
$ apt-get install neo4j=3.5.5
For more information, you can refer to the following section of the product documentation: Install Neo4j on Debian and Debian-based distributions.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-properly-shutdown-a-neo4j-database;"How to properly shutdown a Neo4j database after receiving the message took more than 120 seconds to stop
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags installation server
The neo4j script under the bin/ directory of any standard Neo4j install is the primary means of shutting down a running Neo4j instance. That script accepts a stop argument that will try to shutdown the running instance by sending a SIGTERM signal that the JVM interprets as a shutdown command and runs the installed shutdown hooks, which Neo4j implements to ensure a clean shutdown.
When running bin/neo4j stop a message appears saying that the process is stopping. Then it waits for the process to exit, by default for 2 minutes, controlled by the environmental variable $NEO4J_SHUTDOWN_TIMEOUT (with the timeout set in seconds). The shell script will exit with a status code of 0 if the process exits before the $NEO4J_SHUTDOWN_TIMEOUT period or it will print a failure message with the PID of the Neo4j process and will return status code 1.
It is important to note that in either case, the Neo4j process will continue running. The reason is usually a checkpoint operation that takes longer than usual. If this happens, then the current state of the Neo4j process can still be inquired through use of the bin/neo4j status command. This will return status code 0 if the process is running and print its PID or it will return 3 if it’s not running.
The above allow two methods of checking the state of a Neo4j process that has been asked to shutdown.
One is to set the $NEO4J_SHUTDOWN_TIMEOUT environment variable to something larger than 120 seconds. This is preferred if the expected time to shutdown is roughly known and the simplicity of a terminating command is desired.
The other is to use the exit code of the bin/neo4j status command to execute a control loop after the bin/neo4j stop command returns with a non 0 status (indicating a still running process). In this case, it may make sense to set the $NEO4J_SHUTDOWN_TIMEOUT to something small, to jump to the control loop as soon as possible. For example
Bash
Copy to Clipboard
export NEO4J_SHUTDOWN_TIMEOUT=2 # in seconds

if [[! ""${bin/neo4j stop}""]]; then
  while [[""${bin/neo4j status}""]];
    sleep 1
    echo ""Still waiting...""
  done;
fi

else, echo ""Done, process is now shutdown, continue with whatever you want to do""
Was this page helpful?"
https://neo4j.com/developer/kb/proper-file-permissions-on-neo4j-server;"Proper File Permissions on Neo4j Server
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags file-system permissions operations server startup unix installation
When installing Neo4j Server, keep in mind that the bin/neo4j executable will need to be run by some OS system user, and that user will need write permissions to some files/directories, specifically to the data directory. That user will also need execute permissions on other files, such as those in /bin.
It is recommended to either choose or create a user who will own and manage the Neo4j Server. This user should own the entire neo4j directory, so make sure to untar/unzip it as this user, and not with sudo (UNIX/Linux/OSx), etc.
What happens if data is not writable by the neo4j user?
Neo4j won’t be able to write anything either to the store or its log files. As a result any logs would be appended to the console.log. The following error message would indicate a possible permission issue:
2015-05-19 19:32:16.220+0000 INFO [Cluster] Write transactions to database disabled
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-define-my-graphdb-at-a-path-other-than-under-neo4j-home-for-windows;"How do I define my graph.db at a path other than under NEO4J_HOME for Windows
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags installation
Commencing with Neo4j 3.0, the default location for your graph.db directory is under $NEO4J_HOME\databases\. To change the path for the location of the database directory, edit the following parameters in the $NEO4J_HOME\conf\neo4j.conf file
Properties
Copy to Clipboard
# The name of the database to mount
dbms.active_database=graph.db

# Paths of directories in the installation.
dbms.directories.data=C:/MyNeoDB/
The usage of the forward slash character (/) in the value for dbms.directories.data is to be used and not the backslash (\) character which is what is typically used in Windows path names.
Using the above example the graph.db will be recorded in C:\MyNeoDB\databases and the directory will be named graph.db.
Was this page helpful?"
https://neo4j.com/developer/kb/installing-neo4j-on-debian-or-ubuntu-fails-with-packages-have-unmet-dependencies;"Installing Neo4j Database on Debian or Ubuntu fails with ""The following packages have unmet dependencies""
Author Daniel Terlizzi Applicable versions 3.5 Tags installation
Installing Neo4j Database on Debian or Ubuntu fails with the error:
The following packages have unmet dependencies:
 neo4j-enterprise : Depends: cypher-shell (< 1.2.0) but it is not going to be installed
E: Unable to correct problems, you have held broken packages.
Why is this happening?
The apt package manager is not handling multiple versions of a package, in this case Cypher Shell 1.1.12 and 4.0.
How to circumvent this issue?
Until we find a solution to this issue we suggest the following workaround:
Add cypher-shell=1.1.12 to the end of your apt install command, eg:
Shell
Copy to Clipboard
sudo apt install neo4j cypher-shell=1.1.12
This way you ensure the lastest supported Cypher Shell version will be installed for the Neo4j Database version 3.x.
Was this page helpful?"
https://neo4j.com/developer/kb/extracting-java-error-during-neo4j-desktop-install;"Extracting Java Error When Installing Neo4j Desktop
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags installation
In rare cases, Neo4j Desktop install might fail during the Java extract phase with the following message on Windows:
Initialization Error: error: end of central directory record not found (see below)
If encountering this message, it is probably due to a corrupted JVM download.
To resolve the issue, simply remove the currently downloaded JVM copy which can be found at:
%APPDATA%/Neo4j Desktop/Application/distributions/java/
Was this page helpful?"
https://neo4j.com/developer/kb/debian-ubuntu-version-apt-pinning;"Debian / Ubuntu: How to enforce a certain version of neo4j when using debian packages
Author Stefan Armbruster Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags unix installation
If you want to run a specific version of Neo4j and install the software via a debian repository you need to use a technique called apt pinning. Otherwise, any system update will also update Neo4j to its latest stable version.
As an example assume you want to make sure to stay on 3.5.x versions - effectively preventing an upgrade to 4.x or higher. To use apt pinning create a file /etc/apt.d/preferences.d/neo4j with these contents:
Package: neo4j-enterprise
Pin: version 1:3.5.*
Pin-Priority: 1000
Recently the versioning scheme for neo4j debian packages changed and a 1: is used as a prefix.
Was this page helpful?"
https://neo4j.com/developer/kb/can-i-use-nfs-as-my-filesystem-or-datastore-storage;"Can I use NFS as my filesystem or datastore storage?
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags storage disk filesystem unix operations
The short answer is no. Although this may seem harmless, the reason for this is not performance related, but rather for control over locking files.
NFS and other filesystems that don’t offer locking should not be used to install Neo4j or store the datastore. If we can’t lock the store files, others can concurrently access them, resulting in corruption.
Refer to the Neo4j documentation on recommended filesystem storage formats: https://neo4j.com/docs/operations-manual/current/installation/requirements/#deployment-requirements-software
Was this page helpful?"
https://neo4j.com/developer/kb/capacity-planning-example;"Capacity Planning Example
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags storage disk filesystem unix capacity
Here is a back of the napkin example of capacity planning for a Neo4j workload for the following list of requirements:
Requirements
Requirement Value
Number of total users
100-200 (end users, most likely accessing via front end applications)
Number of visits (read/queries) per day per user
5
Number of Nodes
50-75 MM
Number of Relationships
100 – 150 MM
Number of Properties per Node
Min 1, Max 50, Avg 5
Number # of Properties per Relationship
Min 0, Max: 20, Avg: 2
Average request time
500 ms
Queries per second at peak
200/second
Frequency of batch inserts and updates
4-5 times daily
Batch size assume 10% of volumes provided
~ 20 GB a day , 5 million nodes
Max processing/ingest for delta volumes
One hour
RR
in US + EU AWS
DR
DR In 2 US availability zones
Analysis
1) Estimating an initial database size of about 38GB (see table below) - assuming:
20% for indexes
Max # of nodes and relationships with Avg props per node & relations
Number
Bytes/Object
Space(GBs)
Properties subtotal
Nodes
75000000
15
1.048
Relationships
150000000
34
4.750
Props / node
5
41
14.319
Props / rel
2
41
11.455
25.774
Index (percentage)
20
6.314
Total
37.886
2) Assuming daily loads of 5M nodes per day (or 10% - and let’s assume, we need to accommodate future growth of another 50% for the next year.)
3) We then arrive of an estimating about 100GB of total memory per instance [ 5 GB(OS) + 60 GB(data + indexes + 50%growth) + 30GB(Heap) ~ 100GB of total memory ]
4) Lastly, we estimate we will need about 10 CPU cores(or 20 vCPU cores) to accommodate peak demand of 200 queries/second with a response time of 500ms, among a cluster with 3 cores and 2 RRs(see below):
Number of concurrent requests per second 200/sec
Workload/Query processing time (w=0.50 sec)
CPU load factor 0.5 ( c=.5 ; Tha is CPU’s will be 50% busy on average)
Number of instance failures to design for F=1
Core count = r x w / c = 200 x .5 / .5 = 200
Cluster size = 3 cores + 2 RR
Core count per machine = 200/5 = 40 (or 80 vCPU cores)
Estimate:
Cluster configuration (5 Instances) x (80 vCPU cores per instance with 100GB of RAM)
Was this page helpful?"
https://neo4j.com/developer/kb/setting-up-ssl-with-docker;"How to set up SSL communcation when running Neo4j within a Docker Container
Author Dave Shiposh, Sandeep Reehall Applicable versions 3.2 3.3 3.4 4.1 4.2 4.3 Tags docker security ssl tls
Neo4j 3.2 added a Unified SSL Framework to setup secure connections for Bolt, HTTPS and Intra-Cluster Encryption. Details on this framework can be found at: https://neo4j.com/docs/operations-manual/current/security/ssl-framework/
Setting up secure Bolt and HTTPS communications when running Neo4j within a Docker Container requires some specific steps and configuration settings.
The below steps assume the processes outlined in the above documentation link have been followed. In addition, public certificates and private keys have already been created.
The steps listed below are for example purposes only. It must be made sure these are suitable for the environment before deployment.
The configuration steps for Neo4j 3.5 and Neo4j 4.x are different. Both are listed below.
Neo4j 4.x
1. Create Neo4j Scope Directory Structure
Neo4j 4.x requires directories are created with a specific structure. The following is an example for https and bolt scopes
ssl/
├── bolt
│   ├── revoked
│   └── trusted
└── https
    ├── revoked
    └── trusted
Create the above directory structure in $HOME/neo4j. It is possible to use any directory of your choice, making sure to adjust the below paths accordingly.
2. Copy SSL Certificates and Correct Permissions
A copy of the public certificate and private key files will need to be placed in each scopes directory. The public key will also need to be copied into the respective scopes trusted directory.
Once copied, the directory and file layout in $HOME/neo4j/ssl should look like the following:
$HOME/neo4j/ssl/
├── bolt
│   ├── private.key
│   ├── public.crt
│   ├── revoked
│   └── trusted
│       └── public.crt
└── https
    ├── private.key
    ├── public.crt
    ├── revoked
    └── trusted
        └── public.crt
The container will run Neo4j as user neo4j. The uid and gid is 7474. Use the following command to adjust the permissions on the ssl directory:
Shell
Copy to Clipboard
sudo chgrp -R 7474 $HOME/neo4j/ssl && \
sudo chmod -R g+rx $HOME/neo4j/ssl
3. Configure Neo4j
There are two approaches for configuring Neo4j running as a Docker container: externalize neo4j.conf using Docker host volumes, OR configure Docker environment variables. You should only choose one of the approaches (not both)
Externalize neo4j.conf
It is possible to use a Docker host volume to mount a neo4j.conf file. This is achieved by mounting into the container’s /conf directory.
Create a conf directory and neo4.conf file in $HOME/neo4j
Shell
Copy to Clipboard
mkdir $HOME/neo4j/conf && \
touch $HOME/neo4j/conf/neo4j.conf
Insert the following configuration into neo4j.conf making sure to substitute host.domain.com with the required DNS name for the server/ application.
Properties
Copy to Clipboard
dbms.default_advertised_address=host.domain.com

# Bolt SSL configuration
dbms.ssl.policy.bolt.enabled=true
dbms.ssl.policy.bolt.base_directory=certificates/bolt
dbms.ssl.policy.bolt.private_key=private.key
dbms.ssl.policy.bolt.public_certificate=public.crt
dbms.ssl.policy.bolt.client_auth=NONE
dbms.connector.bolt.tls_level=REQUIRED

# Https SSL configuration
dbms.connector.https.enabled=true
dbms.ssl.policy.https.enabled=true
dbms.ssl.policy.https.base_directory=certificates/https
dbms.ssl.policy.https.private_key=private.key
dbms.ssl.policy.https.public_certificate=public.crt
dbms.ssl.policy.https.client_auth=NONE
The above will be mounted at deployment using --volume=$HOME/neo4j/conf:/conf
Docker Environment Variables
The following collection of Docker environment variables can be used instead of the above Docker host volume configuration. These should be specified at deployment making sure to substitute host.domain.com with the required DNS name for the server/ application.
Bash
Copy to Clipboard
--env NEO4J_dbms_default__advertised__address=host.domain.com \
--env NEO4J_dbms_ssl_policy_bolt_enabled=true \
--env NEO4J_dbms_ssl_policy_bolt_base__directory=certificates/bolt \
--env NEO4J_dbms_ssl_policy_bolt_private__key=private.key \
--env NEO4J_dbms_ssl_policy_bolt_public__certificate=public.crt \
--env NEO4J_dbms_ssl_policy_bolt_client__auth=NONE \
--env NEO4J_dbms_connector_bolt_tls__level=REQUIRED \
--env NEO4J_dbms_connector_https_enabled=true \
--env NEO4J_dbms_ssl_policy_https_enabled=true \
--env NEO4J_dbms_ssl_policy_https_base__directory=certificates/https \
--env NEO4J_dbms_ssl_policy_https_private__key=private.key \
--env NEO4J_dbms_ssl_policy_https_public__certificate=public.crt \
--env NEO4J_dbms_ssl_policy_https_client__auth=NONE \
4. Run Neo4j
With a host volume for neo4j.conf, the following command will deploy Neo4j 4.3.2:
Bash
Copy to Clipboard
docker run --name=neo4j-4.3.2 \
--publish=7474:7474 --publish=7687:7687 --publish=7473:7473 \
--volume=$HOME/neo4j/ssl:/ssl \
--volume=$HOME/neo4j/conf:/conf \
--env NEO4J_dbms_memory_pagecache_size=512m \
--env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
neo4j:4.3.2-enterprise
Neo4j 3.5
Add Docker Volume for storing of Certs
The Neo4j Docker image exposes a /ssl volume for mounting a directory on the host machine for storage of the certs:
--volume=$HOME/neo4j/ssl:/ssl
In the above example, a local folder ($HOME/neo4j/ssl) will be used to store the cert and key.
Setup Configuration Settings within Neo4j to use above /ssl Volume
The Neo4j Docker container allows for use of a /conf volumn so that you are able to setup configuration settings in a Neo4j.conf file:
--volume=$HOME/neo4j/conf:/conf
Using the above setting, we can modify the settings in a the Neo4j.conf file and place that file in the $HOME/neo4j/conf folder.
Alternatively, Environment variables can be used to set the configuration settings, as outlined here:
https://neo4j.com/docs/operations-manual/current/installation/docker/#docker-environment-variables
To configure secure Bolt and HTTPs communication, the following configuration parameters are required:
bolt.ssl_policy=client_policy
https.ssl_policy=client_policy
dbms.ssl.policy.client_policy.base_directory=/ssl/client_policy
dbms.ssl.policy.client_policy.client_auth=NONE
A key note here is that base_directory setting starts with /ssl - this will be mapped to the mounted drive and look for client_policy directory in the $HOME/neo4j/ssl folder.
Copy Cert/Key to Host Folders
With the above settings, the following folder structure and files on the host will be required:
$HOME/neo4j/ssl/client_policy/
$HOME/neo4j/ssl/client_policy/private.key
$HOME/neo4j/ssl/client_policy/public.crt
$HOME/neo4j/ssl/client_policy/trusted/
$HOME/neo4j/ssl/client_policy/revoked/
If the key/crt files are named something other then the default, the following settings will be required:
Properties
Copy to Clipboard
dbms.ssl.policy.client_policy.private_key=/ssl/client_policy/neo4j_prod.key
dbms.ssl.policy.client_policy.public_certificate=/ssl/client_policy/neo4j_prod.crt
Sample Docker Run Command
The following is a sample Command to start the Docker container with the above settings:
Shell
Copy to Clipboard
$ docker run --publish=7473:7473 --publish=7687:7687 --volume=$HOME/neo4j/ssl:/ssl  --volume=$HOME/neo4j/conf:/conf --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes neo4j:3.4-enterprise
Was this page helpful?"
https://neo4j.com/developer/kb/backup-failed-unexpected-error-base-directory-for-ssl-policy-with-name-default-does-not-exist;"Backup Failed. Unexpected error: Base directory for SSL policy with name 'default' does not exist.
Author Daniel Terlizzi Applicable versions 3.5 Tags backup error encryption
This article is based on a defect report with a suggested workaround until a fix becomes available.
When running backup (full or incremental) you may encounter the following error in the output, and as a result, the backup is not working:
unexpected error: Base directory '/users/neo4j/neo4j-enterprise-3.5.8/backups/certificates/ssl_policy' for SSL policy with name 'default' does not exist.
You may encounter this issue when using SSL and regardless of using encryption for backups or not.
The configuration that is exposing this issue is:
Properties
Copy to Clipboard
dbms.ssl.policy.default.base_directory=certificates/ssl_policy
The key to this issue is if you are using relative paths instead of absolute paths. With a relative path, the backup will fail with the shown error.
Workaround: To resolve this issue, use an absolute path instead for the SSL configuration setting:
Properties
Copy to Clipboard
dbms.ssl.policy.default.base_directory=/users/neo4j/neo4j-enterprise-3.5.8/certificates/ssl_policy
Additionally this issue is resolved by upgrading to Neo4j 3.5.9 or later
Was this page helpful?"
https://neo4j.com/developer/kb/are-my-cluster-transactions-messages-encrypted;"Are my cluster transactions/messages encrypted.
Author Dana Canzano Applicable versions 3.0 3.1 3.2 3.3 3.4 Tags causal-cluster encryption
For all versions prior to 3.3, there is no encryption done specifically on the contents being transferred. Furthermore, since it doesn’t use REST or Bolt, there is no SSL/https configuration either. Transactions are propagated via transaction logs, which are a binary representation of the data and are not human-readable. However, that does not equate to encryption.
A common way to solve this problem is to implement VPN tunneling between instances, such that the data is transferred through a secure tunnel.
Commencing with 3.3 we would recommend Intra-Cluster Encryption
Was this page helpful?"
https://neo4j.com/developer/kb/a-demonstration-of-intracluster-ssl-encryption;"A demonstration of IntraCluster SSL Encryption
Author Umar Muzammil, Sandeep Reehall Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags ssl tls certificate causal-cluster encryption
This document provides a step-by-step demonstration of the process to deploy a Self-Signed SSL Certificate, to member instances of a Causal Cluster, aimed at achieving intra-cluster encryption. The steps can be outlined as:
Generate and install cryptographic objects
Create an SSL policy
Configure Causal Clustering with the SSL policy
Validate the secure operation of the cluster
These are further described in the Neo4j operations manual: https://neo4j.com/docs/operations-manual/current/clustering/intra-cluster-encryption/#intra-cluster-encryption-example-deployment
Lets go through the demonstration of creation, deployment and verification of the SSL certificate.
Install OpenSSL
A certificate can be signed by a trusted Certificate Authority (CA) or, as in this case, be a self-signed one. We will create a self-signed certificate using OpenSSL. We’ll first need to install OpenSSL in order to create a self-signed certificate.
Windows
OpenSSL can be installed using a Windows binary. Some sample binaries are available at the below links:
https://wiki.openssl.org/index.php/Binaries
Linux
Many Linux distributions has OpenSSL installed. If this is not the case, use a package manager to install openssl, for example:
Shell
Copy to Clipboard
$ sudo apt-get install openssl
Mac
On OSX, OpenSSL can be installed using macports, as described here: https://www.macports.org/install.php
Or alternatively via homebrew package manager as below:
Shell
Copy to Clipboard
$ brew install openssl
Verify Installation
Once installed, the version and installation directory, amongst other installation features, can be checked by running brew info openssl, or openssl version -a:
$ openssl version -a
LibreSSL 2.8.3
built on: date not available
platform: information not available
options:  bn(64,64) rc4(16x,int) des(idx,cisc,16,int) blowfish(idx)
compiler: information not available
OPENSSLDIR: ""/private/etc/ssl""
Create a Neo4j SSL Framework directory structure
Neo4j SSL Framework requires the following directory structure be created:
<NEO4J_HOME>/certificates
                └── cluster
                    ├── revoked
                    └── trusted
From <NEO4J_HOME> run the following commands to create the above structure:
Shell
Copy to Clipboard
---
$ mkdir certificates/cluster
$ mkdir certificates/cluster/trusted
$ mkdir certificates/cluster/revoked
---
Create the SSL Certificate and Key
Use the following command to create a certificate cert.pem and a key key.pem making sure to change xxx to the number of days the certificates should be valid for:
Shell
Copy to Clipboard
$ sudo openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days XXX
or, for a relatively smaller key length:
Shell
Copy to Clipboard
$ sudo openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days XXX
Below describes each parameter used in the openssl command above:
req: PKCS#10 certificate request and certificate generating utility.
x509: outputs a self signed certificate instead of a certificate request.
newkey: creates a new certificate request and a new private key. Note the rsa:nbits, where nbits is the number of bits, generates an RSA key nbits in size.
keyout: gives the filename to write the newly created private key to.
out: specifies the output filename to write to or standard output by default.
days: when the -x509 option is being used this specifies the number of days to certify the certificate for (default is 30 days).
Below is the output of the executed openssl generation command:
$ sudo openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365
Password:
Generating a 4096 bit RSA private key
..................................................................................................................................................++
................................................................................................++
writing new private key to 'key.pem'
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
Country Name (2 letter code) [AU]:UK
State or Province Name (full name) [Some-State]:London
Locality Name (eg, city) []:London
Organization Name (eg, company) [Internet Widgits Pty Ltd]:Neo4j
Organizational Unit Name (eg, section) []:CS
Common Name (e.g. server FQDN or YOUR name) []:CS
Email Address []:myemail@email.com
View all (6 more lines)
The below commands then generate the public.crt and private.key files, using the .pem files created above:
Shell
Copy to Clipboard
$ sudo openssl x509 -outform pem -in cert.pem -out public.crt
$ openssl rsa -in key.pem -out private.key
DEPLOYING THE SSL CERTIFICATE AND KEY
Place the above created private.key and public.crt in $NEO4J_HOME/certificates/cluster. Then place public.crt in $NEO4J_HOME/certificates/cluster/trusted:
certificates
└── cluster
    ├── private.key
    ├── public.crt
    ├── revoked
    └── trusted
        └── public.crt
Then add the following to neo4j.conf of each instance in the cluster, making sure to replace [Absolute_Path_Of_$NEO4J_HOME] appropriately:
Properties
Copy to Clipboard
dbms.ssl.policy.cluster.enabled=true
dbms.ssl.policy.cluster.base_directory=<<Absolute_Path_Of_$NEO4J_HOME>>/certificates/cluster
dbms.ssl.policy.default.base_directory=<<Absolute_Path_Of_$NEO4J_HOME>>/certificates/cluster
dbms.ssl.policy.default.trusted_dir=<<Absolute_Path_Of_$NEO4J_HOME>>/certificates/cluster/trusted
dbms.ssl.policy.default.revoked_dir=<<Absolute_Path_Of_$NEO4J_HOME>>/certificates/cluster/revoked
dbms.ssl.policy.cluster.ciphers=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384
dbms.ssl.policy.cluster.client_auth=REQUIRE
Validate the Intra-cluster Encryption
We’re now ready to initialise all cluster instances. Once these are initialised and available, we can then verify our SSL encryption by using the nmap tool (sometimes deployed alongside openssl otherwise it will need to be installed separately), to check the available SSL ciphers as below:
$ nmap --script ssl-enum-ciphers -p 5000 localhost
Starting Nmap 7.80 ( https://nmap.org ) at 2022-07-07 14:18 UTC
Nmap scan report for localhost (127.0.0.1)
Host is up (0.000049s latency).
Other addresses for localhost (not scanned): ::1

PORT     STATE SERVICE
5000/tcp open  upnp
| ssl-enum-ciphers:
|   TLSv1.2:
|     ciphers:
|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A
|     compressors:
|       NULL
|     cipher preference: indeterminate
|     cipher preference error: Too few ciphers supported
|     warnings:
|       Key exchange (secp256r1) of lower strength than certificate key
|_  least strength: A

Nmap done: 1 IP address (1 host up) scanned in 0.31 seconds
View all (6 more lines)
Where port 5000 is the default Causal Cluster Discovery Management. The above configuration will also enable SSL on port 6000 and 7000 which are Causal Cluster Transaction and Causal Cluster RAFT ports respectively. Details on Neo4j port usages can be found on the following link:
https://neo4j.com/docs/operations-manual/current/configuration/ports/
An additional confirmation would be to find debug messages similar to the following, in the Neo4j debug.log:
2022-07-08 09:30:28.006+0000 INFO  [o.n.s.c.SslPolicyLoader] Loaded SSL policy 'CLUSTER' = SslPolicy{keyCertChain=Subject: EMAILADDRESS=myemail@email.com, CN=neo4j.local, OU=Support, O=Neo4j, L=London, ST=London, C=UK, Issuer: EMAILADDRESS=myemail@email.com, CN=neo4j.local, OU=Support, O=Neo4j, L=London, ST=London, C=UK, ciphers=[TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384], tlsVersions=[TLSv1.2], clientAuth=REQUIRE}
References:
https://neo4j.com/docs/operations-manual/current/security/ssl-framework/#term-ssl-cryptographic-objects
https://www.macports.org/install.php
https://wiki.openssl.org/index.php/Binaries
https://www.cloudinsidr.com/content/how-to-install-the-most-recent-version-of-openssl-on-windows-10-in-64-bit/
Was this page helpful?"
https://neo4j.com/developer/kb/executing-neo4j-etl-from-an-rdbms-database-running-on-docker;"Executing Neo4j ETL from an RDBMS database running on Docker
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags import export etl rdbms docker sql
Following provides some examples of importing a test csv data into Neo4j, using the Neo4j ETL tool’s command line interface with the source RDBMS database running on docker. Examples herein are specific to tests conducted on a MAC OSX host machine, but processes for other OS’s will be similar.
Step 1: Setup
Get the ETL CLI Tool as a zip or tar.gz. The command-line tool is available at https://github.com/neo4j-contrib/neo4j-etl/releases/latest. If using ETL as a Neo4j Desktop application, add the ETL license key available from dev-rel, to the Neo4j Desktop Application.
Get the latest mssqljdbc driver version: https://docs.microsoft.com/en-us/sql/connect/jdbc/download-microsoft-jdbc-driver-for-sql-server?view=sql-server-2017,relevant to the source rdbms database. Sql-jdbc versions 6.0, 6.2 and 6.4 were successfully used for this testing.
Step 2: Setup a test RDBC database.
In this case, MSSQL Server is used. Others are very similar.
Either run MSSQL server as a docker container, or as a standalone application. This document’s scope is limited to docker. Server appliacation UIs present a much straightforward process, however, availability and installation of these may not always be desired.
Install docker. Here’s the installation process:
https://docs.docker.com/docker-for-mac/install/#install-and-run-docker-for-mac
Pull the mssql server container image: sudo docker pull microsoft/mssql-server-linux:2017-latest
Run the mssql server container:
Shell
Copy to Clipboard
$ sudo docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=Neo4j1234' \
   -p 1433:1433 --name sql1 \
   -d microsoft/mssql-server-linux:2017-latest
This should create and initialize a mssql server container called sql1 on localhost:1433. The password should follow MSSQL Server default password policy, (unless a different policy is specified) otherwise the container won’t start.
Check that the container is up and running: sudo docker ps -a. Logs can be viewed by docker logs sql1
Connect to the mssql server within the sql1 container created above: sudo docker exec -it sql1 ""bash"" you’ll have to enter your bash password.
Launch the sqlcmd utility to execute TSQL queries within the container: /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P Neo4j1234
Once within sqlcmd, issue tsql to create a database, a schema and a temp table using the schema.
Sql
Copy to Clipboard
CREATE DATABASE TestDB;
-- created
SELECT Name from sys.Databases;
Verify that TestDB created above is in the list of dbs
Sql
Copy to Clipboard
CREATE SCHEMA testschema;
Confirm that schema has been created:
Sql
Copy to Clipboard
SELECT * FROM sys.schemas;
Create a temporary table using the testschema created above. Columns within the table will be determined by what data is to be imported within this table before it eventually gets exported to Neo4j using the ETL tool. In this case, a csv with random weather data was uploaded to the following table (this article later explains how to do that).
Sql
Copy to Clipboard
CREATE TABLE testschema.weather
(ID int,
StationCode nvarchar(50),
Date date,
StationName nvarchar(50),
Tmax float,
Tmin float,
Tobs float,
Latitude float,
Longitude float,
Fy int);
Some test data (or your actual data) now needs to be imported to the weather table (or your desired table) created above. To do this in docker, from outside of the sqlcmd prompt, (perhaps from a separate terminal window), execute: docker cp /Users/user/Desktop/weather.txt sql1:/ where weather.txt in this case is the file name of the csv to be imported, /Users/user/Desktop/ is the directory path of that file and sql1 is the name of the docker container. This should copy over the weather.txt file from the host OS into the docker container.
SQL’s Bulk Insert procedure can then be used to map and import the csv to the weather table in our TestDB. To do so, execute the following from the sqlcmd prompt within the sql1 container:
Sql
Copy to Clipboard
BULK INSERT testschema.weather from '/weather.txt' with (FIRSTROW=2, fieldterminator = ',', rowterminator = '0x0a');
Step 3: Export the relational data to Neo4j using the Neo4j ETL cli
Use Neo4j ETL to import contents of the testschema.weather sql table into the Neo4j graph.db. The correct version of the jdbc driver will additionally be required for this step. Following was tested using mssql-jdbc versions 6.0, 6.2 and 6.4. The ETL process essentially requires the jdbc jar file (mssql-jdbc-6.2.2.jre8.jar in this case) and its path to be specified.
Using the Neo4j ETL CLI tool, first, a mapping file needs to be generated. In this case, its named mssql_TestDB_mapping and chosen to be located at /$NEO4j_HOME/import. Additional options e.g. ""Multiline support"" can be specified for the import, just so neo4j-import can deal with csv lines with newlines in fields. The path to that options file must be specified in the import command. Here’s an example command used to generate the import mapping file:
Shell
Copy to Clipboard
$ ./neo4j-etl generate-metadata-mapping \
--rdbms:url ""jdbc:sqlserver://localhost:1433;databaseName=TestDB"" \
--rdbms:schema ""TestDB.testschema"" \
--rdbms:user sa \
--rdbms:password Neo4j1234 \
--output-mapping-file ""/$NEO4j_HOME/import/mssql_TestDB_mapping.json"" \
--debug \
--force \
--using ""bulk:neo4j-import"" \
--options-file ""/$NEO4j_HOME/import/import-tool-options.json"" \
--driver ""/$NEO4j_HOME/import/jdbc drivers/6.2/sqljdbc_6.2/enu/mssql-jdbc-6.2.2.jre8.jar"" \
--mapping-file ""/$NEO4j_HOME/import/mssql_TestDB_mapping""
This is followed by executing the actual import, based on the mapping file generated in the previous step:
Shell
Copy to Clipboard
$ ./neo4j-etl export \
--rdbms:url ""jdbc:sqlserver://localhost:1433;databaseName=TestDB"" \
--rdbms:user ""sa"" \
--rdbms:password ""Neo4j1234"" \
--destination ""/$NEO4j_HOME/data/databases/graph.db"" \
--import-tool ""/$NEO4j_HOME/bin"" \
--csv-directory ""/$NEO4j_HOME/import/csv-008"" \
--debug \
--force \
--using ""bulk:neo4j-import"" \
--options-file ""/$NEO4j_HOME/import/import-tool-options.json"" \
--driver ""/$NEO4j_HOME/drivers/jdbc drivers/6.2/sqljdbc_6.2/enu/mssql-jdbc-6.2.2.jre8.jar""\
--mapping-file ""/$NEO4j_HOME/import/mssql_TestDB_mapping.json"" \
--rdbms:schema ""TestDB.testschema""
That should be it!
Additional resources are below:
Resources:
https://neo4j-contrib.github.io/neo4j-etl/
https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-docker?view=sql-server-linux-2017
https://docs.microsoft.com/en-us/sql/connect/jdbc/download-microsoft-jdbc-driver-for-sql-server?view=sql-server-2017
https://docs.microsoft.com/en-gb/sql/t-sql/statements/statements?view=sql-server-2017
Was this page helpful?"
https://neo4j.com/developer/kb/export-sub-graph-to-cypher-and-import;"Export a (sub)graph to Cypher script and import it again
Author Michael Hunger Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher export import
Oftentimes you want to export a full (or partial) database to a file and import it again without copying the actual database files. If you want to do the latter, use neo4j-admin dump/load.
Here are two ways on how to create a Cypher script file from your database or Cypher statement. This can also be used to downgrade (smaller) databases.
Format
Some notes on the format written from these tools:
recreate indexes and constraints
simple statements per node (CREATE) / relationship (2x MATCH + CREATE)
optionally you can configure the export to use MERGE instead of CREATE
data creation in batches (by default 40k) optionally surrounded with :begin, :commit
uses existing constraints for node-lookup
if no constraint on that label exist, use an artificial constraint + property (UNIQUE IMPORT LABEL.UNIQUE IMPORT ID) where the property value is the node-id, on node creation
clean up artificial label + property + constraint at the end in batches
APOC
You can install the APOC procedure library.
And then use the apoc.export.cypher.* procedures to create the export.cypher file from your graph or data. There is more in the documentation but below are some examples.
Those procedures have config options to generate formats for different outputs and also to split nodes, relationships and schema scripts into different files.
Please note that you have to enable the capability to write and read files first in neo4j.conf.
Properties
Copy to Clipboard
apoc.export.file.enabled=true
apoc.import.file.enabled=true
Cypher
Copy to Clipboard
Run in Neo4j Browser
// exports the whole database incl. indexes as cypher statements to the provided file
CALL apoc.export.cypher.all('/tmp/export.cypher',{format:'cypher-shell'})

// exports given nodes and relationships incl. indexes as cypher statements to the provided file
MATCH path = (p1:Person)-[r:KNOWS]->(p2:Person)
WITH collect(p1)+collect(p2) as export_nodes, collect(r) as export_rels
CALL apoc.export.cypher.data(export_nodes,export_rels,'/tmp/export.cypher',{format:'cypher-shell'})
YIELD file, source, format, nodes, relationships, properties, time
RETURN nodes, relationships, time;

// exports given graph object incl. indexes as cypher statements to the provided file
...
CALL apoc.graph.fromPaths([paths],'export_graph',{}) YIELD graph
CALL apoc.export.cypher.graph(graph,'/tmp/export.cypher',{format:'cypher-shell'}) YIELD time
RETURN time;


 apoc.export..query(
,
,{format:});
View all (5 more lines)
Import with cypher-shell
If you export the file with the cypher-shell format, it contains the right syntax to use for transactions in the shell.
Then you can import them with cypher-shell too.
Shell
Copy to Clipboard
$ cat /tmp/export.cypher | ./bin/cypher-shell -u neo4j -p password
Example for export file
Cypher
Copy to Clipboard
Run in Neo4j Browser
// create nodes
:begin
CREATE (:`UNIQUE IMPORT LABEL` {`UNIQUE IMPORT ID`:0});
CREATE (:`User` {`age`:43, `name`:""User1""});
:commit

// add schema
:begin
CREATE INDEX ON :`User`(`age`);
CREATE CONSTRAINT ON (node:`User`) ASSERT node.`name` IS UNIQUE;
CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT node.`UNIQUE IMPORT ID` IS UNIQUE;
:commit

// wait for index completion
call db.awaitIndexes();

// create relationships
:begin
MATCH (n1:` IMPORT LABEL IMPORT IDUsernameKNOWS` {`since IMPORT LABEL IMPORT LABELUNIQUE IMPORT ID IMPORT LABEL IMPORT ID
View all (14 more lines)
Was this page helpful?"
https://neo4j.com/developer/kb/multiple-causal-clusters-using-docker;"Run multiple Causal Clusters locally using Docker
Author Stefan Armbruster Applicable versions 3.3 3.4 Tags docker causal cluster
It’s rather easy to run multiple causal clusters on the same server or machine. You need to ensure:
Each cluster needs to run on its own Docker network
Overlapping port mappings must be prevented
causal_clustering.initial_discovery_members needs to contain the list of machines of its cluster only
Advertised hostname + port for bolt needs to be set explicitly
The following example runs 2 separate clusters of 3 core instances each:
Bash
Copy to Clipboard
#!/bin/sh

# cluster 1
docker network create --driver=bridge cluster1

docker run --name=core1 --detach --network=cluster1 \
    --publish=7474:7474 --publish=7473:7473 --publish=7687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core1:5000,core2:5000,core3:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:7687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise

docker run --name=core2 --detach --network=cluster1 \
    --publish=8474:7474 --publish=8473:7473 --publish=8687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core1:5000,core2:5000,core3:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:8687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise

docker run --name=core3 --detach --network=cluster1 \
    --publish=9474:7474 --publish=9473:7473 --publish=9687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core1:5000,core2:5000,core3:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:9687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise


docker network create --driver=bridge cluster2

docker run --name=core21 --detach --network=cluster2 \
    --publish=17474:7474 --publish=17473:7473 --publish=17687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core21:5000,core22:5000,core23:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:17687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise

docker run --name=core22 --detach --network=cluster2 \
    --publish=18474:7474 --publish=18473:7473 --publish=18687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core21:5000,core22:5000,core23:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:18687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise

docker run --name=core23 --detach --network=cluster2 \
    --publish=19474:7474 --publish=19473:7473 --publish=19687:7687 \
    --env=NEO4J_dbms_mode=CORE \
    --env=NEO4J_causal__clustering_expected__core__cluster__size=3 \
    --env=NEO4J_causal__clustering_initial__discovery__members=core21:5000,core22:5000,core23:5000 \
    --env=NEO4J_ACCEPT_LICENSE_AGREEMENT=yes \
    --env=NEO4J_dbms_connector_bolt_advertised__address=localhost:19687 \
    --env=NEO4J_AUTH=none \
    neo4j:3.3-enterprise
View all (52 more lines)
Was this page helpful?"
https://neo4j.com/developer/kb/an-explanation-of-e-count-exceeded;"An explanation of the E_COUNT_EXCEEDED WARNing message in Neo4j’s debug.log.
Author Stephen Levett Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging performance raft causal cluster
The document aims to explain the E_COUNT_EXCEEDED WARNing messages that Neo4j can write to its debug.log. It also provides some monitoring and troubleshooting options.
When running a Neo4j Causal Cluster, you may see the following errors on a FOLLOWER:
None
Copy to Clipboard
021-05-05 20:42:43.349+0530 WARN [o.n.c.c.BatchingMessageHandler] Raft in-queue dropping messages after: E_COUNT_EXCEEDED
2021-05-05 20:42:45.465+0530 INFO [o.n.c.c.BatchingMessageHandler] Raft in-queue not dropping messages anymore. Dropped 771 messages.
2021-05-05 20:42:46.250+0530 WARN [o.n.c.c.BatchingMessageHandler] Raft in-queue dropping messages after: E_COUNT_EXCEEDED
2021-05-05 20:42:48.461+0530 INFO [o.n.c.c.BatchingMessageHandler] Raft in-queue not dropping messages anymore. Dropped 958 messages.
2021-05-05 20:42:49.587+0530 WARN [o.n.c.c.BatchingMessageHandler] Raft in-queue dropping messages after: E_COUNT_EXCEEDED
2021-05-05 20:42:50.829+0530 INFO [o.n.c.c.BatchingMessageHandler] Raft in-queue not dropping messages anymore. Dropped 541 messages.
2021-05-05 20:42:59.392+0530 WARN [o.n.c.c.BatchingMessageHandler] Raft in-queue dropping messages after: E_COUNT_EXCEEDED
2021-05-05 20:42:59.744+0530 INFO [o.n.c.c.BatchingMessageHandler] Raft in-queue not dropping messages anymore. Dropped 163 messages.
You may often see these messages, too:
None
Copy to Clipboard
2021-05-05 20:42:59.392+0530 INFO [o.n.c.c.s.CommandApplicationProcess] BatchSize{min=1.0, max=7.0, avg=1.1328449328449361, count=4096}
2021-05-05 20:42:59.398+0530 INFO [o.n.c.c.s.CommandApplicationProcess] BatchSize{min=15.0, max=15.0, avg=15.0, count=1}
The BatchSize INFOmational messages report that several batches were applied that contain >4000 operations, and the default size of the queue is 4096 (causal_clustering.state_machine_flush_window_size parameter). Whenever we exceed the size of the queue, we will see E_COUNT_EXCEEDED.
Practically, this means that the raft messages are coming into the queue for processing, but the queue is filling up faster than Neo4j can process the raft messages.
The size of this queue is set by causal_clustering.raft_in_queue_size. In the above example, we see that queue filling up. As a result, the messages are dropped, then draining enough to accept messages again, then filling up again. Neo4j is repeating this process constantly.
The problem is equivalent to a temporary network partition. It should be able to recover, but it is a sign that there is a performance problem.
The E_COUNT_EXCEEDED WARN usually means the workload is too high for the cluster.
Furthermore, on the leader, we might expect to observe this situation:
None
Copy to Clipboard
2021-05-05 20:42:59.658+0530 INFO [o.n.c.c.r.RaftReplicator] Replication attempt 2 to leader MemberId{46531432}: DistributedOperation{content=TransactionRepresentationReplicatedTransaction{tx=PhysicalTransactionRepresentation[masterId:-1,authorId:-1,timeStarted:1620227030656,latestCommittedTxWhenStarted:3999325909,timeCommitted:1620227030657,lockSession:2,additionalHeader:[]commands.length:2}, globalSession=GlobalSession{sessionId=2d76658e-cb25-4d33-b46d-4f163c2e04c4, owner=MemberId{46531432}}, operationId=LocalOperationId{localSessionId=821, sequenceNumber=525762}}
2021-05-05 20:42:59.789 INFO [o.n.c.c.r.RaftReplicator] Replication attempt 2 to leader MemberId{46531432}: DistributedOperation{content=TransactionRepresentationReplicatedTransaction{tx=PhysicalTransactionRepresentation[masterId:-1,authorId:-1,timeStarted:1620227030659,latestCommittedTxWhenStarted:3999325909,timeCommitted:1620227030662,lockSession:2,additionalHeader:[]commands.length:2}, globalSession=GlobalSession{sessionId=2d76658e-cb25-4d33-b46d-4f163c2e04c4, owner=MemberId{46531432}}, operationId=LocalOperationId{localSessionId=218, sequenceNumber=569728}}
That set of messages indicates that the LEADER cannot replicate the raft messages to the FOLLOWER(s.)
Again, this is indicative of the workload being too high for the cluster. Transactions are hitting the LEADER, and it, in turn, is replicating those transactions to all the FOLLOWERS. The replication adheres to the raft protocol described here: https://raft.github.io/raft.pdf
However, the workload is too much, which leads to the FOLLOWERs queue filling up, which ultimately causes the replication on the LEADER to drop outbound messages.
Troubleshooting and monitoring:
Firstly, diagnosing this is potentially complex, so I would recommend opening a ticket with Neo4j support.
In advance of working with support, you could probe the following areas looking for signs of a bottleneck:
1) Disks. We are draining the raft queue to disk, so you need to ensure enough I/O capacity to satisfy the writes to the cluster. I would recommend monitoring the disks using iostat. The following command will give the best overview:
iostat -x -c -d -t 1 600 >> $(hostname -i)-iostat.out
The most important metric here is queue depth. Queue depth is the number of pending access operations. I tend to consider anything > 1 over an extended period as indicative of a bottleneck. It means the members are going to be slow writing the transactions and reading data as well.
It is also necessary to determine what the relevant Neo4j directories map, too, though. For example, dbms.directories.data and `dbms.directories.transaction.logs.root`will be stored on some device, but unless we know which devices, we cant determine if the saturated devices are the ones of interest. They may relate to another application or process altogether!
Technical support can advise on this, and it does depend on the type of devices.
2) There are metrics for raft message processing that might provide insight into what is slow or blocked. neo4j.causal_clustering.core.message_processing_delay and neo4j.causal_clustering.core.message_processing_timer are going to be helpful in this scenario.
3) Historic monitoring of transactions. I would recommend using your preferred monitoring tool to graph the numbers of transactions over time. The purpose here is to spot any trends which might coincide with the onset of the problem. Perhaps there is a spike in the number of transactions, which corresponds to the beginning of the E_COUNT_EXCEEDED?
Resolution:
What one does to resolve this is dependent on what the problem is.
If the problem is caused by an I/O bottleneck, then you can isolate the Neo4j directories to use their own devices. For example, you can split out ~data and ~transactions` to separate disks. Neo4j 4.2 and later allows the operator to place the raft logs on separate devices.
Ultimately, though, it may be caused by a workload profile that is too high for the physical resources of the cluster.
Was this page helpful?"
https://neo4j.com/developer/kb/mitigating-causal-cluster-re-elections-caused-by-high-gcs;"Mitigating Causal Cluster re-elections caused by high GCs
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal cluster election garbage-collection timeout
This article describes the effects of JVM stop-the-world GC pauses, on a causal cluster. A brief introduction to garbage collection, heap sizing and memory leak troubleshooting, is followed by a discussion on best practices and configurations to help mitigate the resulting heartbeat timeouts and cluster re-elections.
GC at a glance:
A JVM (java virtual machine, e.g. the Neo4J server) allocates required memory to newly created java objects. This memory is part of the total heap memory allocation configured at startup via neo4j.conf. The JVM periodically checks for unused objects in heap, which are subsequently discarded to reclaim heap memory via a process called Garbage Collection or GC in short.
Assuming heap sizing has been optimally done using Neo4j memory configurations (see https://neo4j.com/developer/kb/understanding-memory-consumption/), spikes in usage/data volume may still lead to increased heap utilisation and consequently longer and/or more frequent garbage collection. Memory leaks are another cause of increased heap utilisation, in many cases leading to a heap out of memory situation. A memory leak in Java is a situation where some objects are no longer used by the application but Garbage Collection fails to recognise this.
In such cases, adding more heap may simply postpone the JVM running out of heap space (throwing the java.lang.OutOfMemoryError: Java heap space error). Additionally, increasing the amount of Java heap space also tends to increase the length of GC pauses. One can execute heap dumps and use e.g. Eclipse MAT (ensure that your machine has sufficient memory for the analysis) to diagnose memory leaks. Other tools like JDK, jconsole, visualvm, jstat and indeed the neo4j gc.log may help identify any outlier transactions.
How does a GC pause effect a Causal Cluster?
One common consequence of the above long GCs or memory leaks, is heartbeat timeouts in a cluster, which is essentially the cluster members not being able to timely reach other members. That is because a full GC enforces a stop-the-world pause, during which time, the JVM halts all other operations, including network communication. In a causal cluster, this often results in a re-election, whereby unreachable members are removed from the cluster and a new cluster leader is elected. Note that there are other factors that may lead to re-elections but they generally benign and are out of the scope of this article.
Re-elections and why their frequency matters under heavy workloads?
Re-election in a Causal Cluster, is a quick, seamless process, which under normal operation, occurs within a few tens/hundreds milliseconds without any noticeable effects on transaction clients. Re-elections are a natural consequence of what is, effectively, the leader becoming unavailable for the duration of the pause, the followers don’t know that the leader is garbage collecting, nor should they care. In high workload situations though, coupled with frequent high GC pauses, re-elections may be undesirable. That is because the number of inbound and therefore, rejected transactions per unit time are high, during a re-election. Also because the newly elected leader may need to commit any pending transactions to store via checkpointing as well as become the new source for followers to catch up from, whilst a high number of newly incoming transactions will again require frequent and possibly long GC pauses, having a cumulative effect on the OS CPU and memory resources. Additionally, the previous leader may rejoin the cluster within a short timespan, still having higher transaction IDs in its logs and therefore becoming the leader again. Importantly, whilst an election itself may last a few milliseconds, during an election, the cluster will not accept writes. These are some of the key factors which may result in cyclic continuous leader switches, especially under heavy workload situations.
Election and Heartbeat timeouts. What are they?
Election timeout refers to the time after which a FOLLOWER will attempt to start an election, becoming a CANDIDATE. These timeouts continue during elections, and a CANDIDATE will either become a FOLLOWER or start another election if it fails to get elected, or hear from a newly elected LEADER, after another causal_clustering.leader_election_timeout period. Long election timeouts are undesirable in general. They represent a greater period of downtime during leader fail over. The aim should not be to increase it, but rather manage the workload to cause less GC. Having a slightly longer period for the second timeout, may reduce the overall downtime caused by elections. The documented definition of causal_clustering.leader_election_timeout does not mention heartbeat timeouts since heartbeats are an implementation detail. Most intra-cluster messages are also treated as heartbeats. If a cluster member receives a message from the leader, it is considered to have heard from that leader and so the election timeout resets the timeout after which a new leader_election will be triggered.
How best to mitigate heartbeat/election timeouts, following long GCs?
Causal Cluster heartbeat timeouts are controlled via the configuration causal_clustering.leader_election_timeout which defaults to 7s and the recommended value is less than 10s. For graphs with large heaps, GC pauses may sometimes be of the order of minutes, in which case, such timeout values wouldn’t prevent re-elections. Note that it is not large heaps per se that cause GC, but allocating far more than the GC is able to collect, eventually causing stop-the-world pauses. If there were numerous smaller pauses which were very occasionally causing leadership elections (so just occasionally missing the 7s timeout), then increasing the causal_clustering.leader_election_timeout by a small value could be a solution, but the only real solution is to generate less garbage, which usually involves rewriting cypher queries and avoiding large data ingest queries etc. Query optimisation is beyond the scope of this article, but is part of the Neo4J cypher manual, available at: https://neo4j.com/docs/cypher-manual/current/query-tuning/.
What is Pre_Voting and how can it help?
Another configuration which helps prevent frequent re-elections, is causal_clustering.enable_pre_voting (added in Neo4j 3.2.9), which controls whether ""pre-elections"" are enabled. Pre_voting is where an instance asks other cluster members: “if I was to call an election, would you vote for me?”. It is an optimistic approach to stop potentially unfruitful elections (which as we know stop writes while they’re happening). “Fruitless” in such case typically means the previous leader remains leader and all we get is election number of seconds of unavailability while the “Fruitless” election happens. Following an election, the cluster member with the highest ""term"" wins and becomes the new leader. Note that members do not increase their term unless another member votes for them, and that leaders must step down if a follower has a higher term, it means the leader is behind.
Pre-voting therefore helps reduce the number of unnecessary elections in two ways:
It ensures that an election is not triggered unless a quorum has lost heartbeat with the leader.
It ensures that a member at a term lesser than others in the cluster, does not trigger an election.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-quickly-identify-long-gc-pauses-via-the-messages-or-debug-logs;"How do I quickly identify long gc pauses via the messages or debug logs
Author Dana Canzano Applicable versions 2.3 3.0 3.1 Tags garbage-collection
Java Garbage Collection (gc) pauses are monitored by the MonitorGc process in Neo4j, and recorded in the $NEO4J_HOME/logs/debug.log ( or $NEO4J_HOME/data/graph.db/messages.log for Neo4j v2.3.x and prior). To quickly find the 10 longest pauses in
Neo4j 3.0 through Neo4j 3.3 one can run:
Shell
Copy to Clipboard
$ grep -n -i blocked debug.log | sort -r -n -k 11 | head -10
which will result in output similar to:
7830:2016-12-05 19:04:23.865+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 707ms.
3283:2016-12-02 13:25:52.264+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 579ms.
6360:2016-12-02 15:38:35.502+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 381ms.
6349:2016-12-02 15:02:33.156+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 285ms.
6361:2016-12-02 15:50:45.560+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 274ms.
6920:2016-12-05 16:57:47.170+0000 WARN  [o.n.k.i.c.MonitorGc] GC Monitor: Application threads blocked for 251ms.
The example grep command will perform a case-insensitive search (as a result of the -i argument) of the debug.log for the string 'blocked' and return the respective line number (as a result of the -n argument). These results are then sorted by way of the field representing the time (as a result of -k 11 and -k 10 respectively) and sorted in numeric order rather than ASCII order (as a result of the -n argument) and then presented in reverse chronological order (as a result of the -r argument). Lastly the head -10 will only display the top 10 results after the sort.
For Neo4j 3.4 and above run
Shell
Copy to Clipboard
$ grep -n ""VM stop-the-world"" debug.log | sort -t= -nrk2 | head -10
which will result in output similar to
27675:2019-04-09 10:39:27.115+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=516, gcTime=508, gcCount=1}
2671:2019-04-08 08:03:12.921+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=483, gcTime=487, gcCount=1}
27885:2019-04-09 11:01:07.033+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=371, gcTime=422, gcCount=1}
16302:2019-04-09 09:53:31.066+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=338, gcTime=372, gcCount=1}
14283:2019-04-08 16:54:03.108+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=272, gcTime=358, gcCount=1}
27904:2019-04-09 11:26:29.463+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=346, gcTime=355, gcCount=1}
4006:2019-04-08 12:14:33.514+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=352, gcTime=349, gcCount=1}
14519:2019-04-08 20:37:12.126+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=253, gcTime=345, gcCount=1}
3983:2019-04-08 11:17:23.039+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=301, gcTime=322, gcCount=1}
16110:2019-04-09 07:19:25.626+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=318, gcTime=314, gcCount=1}
Was this page helpful?"
https://neo4j.com/developer/kb/when-to-use-bookmarks;"When to use bookmarks
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster causal leader follower bookmarks drivers
Bookmarks are part of a broader topic: Causal consistency. We recommend reading the introduction to Neo4j Causal Clustering and the lifecycle of a Neo4j Causal Cluster before reading further. Pay special attention to Causal Consistency explained.
Bookmarks ensure than when reading data from the cluster, that data read represents the user’s most recent view of the graph. When using bookmarked transactions, you are effectively saying: ""Use a particular instance, only when its able to honour this bookmark"" (in other words, after they processed and applied the bookmark).
Unfortunately there isn’t a one-size-fits-all scenario when it comes to understanding when it makes sense to use bookmarks. If we look back at all the information about raft and application of transactions to the followers (links above), we know this:
The speed of the data propagation can be seen as (from faster to slower data readiness):
Leader
Majority of followers
Rest of followers and read replicas
Leader has all the transactions and is always the most up-to-date instance
Majority of followers have the transactions due to raft’s nature (but may not have applied them yet)
Rest of followers (and read replicas) will eventually have the transactions at a later period in time
With this information you can make design choices such as:
Use bookmarks for queries where you absolutely need to read your own writes and:
Direct read queries that are latency sensitive to the leader1, making use of bolt for direct connection instead of bolt+routing.
Use bolt+routing for other queries that are not as latency sensitive (these queries will be routed to the followers)
Do not use bookmarks for other queries that do not require a most up-to-date view of the graph (this queries will be routed to a random follower/read-replica)
1 Be careful when making the decision to direct read transactions to the leader. You will want to avoid stressing the leader to a point where it cannot serve more requests. You can read more about this topic here.
This is only an example but all of it is achievable with a mix of direct/routed connections and bookmarks. Remember that bookmarks exist on a transaction level, which means that you can tweak this to your need in order to achieve the optimal throughput and experience. You might have several clients with different consistency and data readiness requirements and adjust the bookmark usage per-client basis.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-monitor-if-a-follower-is-in-sync-with-leader-causal-cluster;"How to monitor if a follower is in sync with Leader (Causal Cluster)
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags server cluster causal cluster leader follower writes
To monitor if a Follower is in sync with its Leader, or know how much it is lagging behind, it is possible to check the Last Commited Transaction Id from Leader and Follower.
Last Commited Transaction Id can be assessed in one of the following ways:
From the Neo4j Browser
Via the Neo4j Metrics
Via the JMX MBeans
1. Checking Last Transaction Id from the Neo4j Web Interface
From the Neo4j Browser:
type :sysinfo and hit enter
from the ""Transactions"" frame, identify the parameter ""Last Tx Id""
You can also call the dbms.queryJmx procedure in the following way:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.queryJmx(""org.neo4j:instance=kernel#0,name=Transactions"") yield attributes
return attributes[""LastCommittedTxId""]
2. Checking Last Commited Transaction Id via the Neo4j Metrics
Assuming Neo4j’s csv metrics are enabled already, you can analyse the following csv file: neo4j.transaction.last_committed_tx_id.csv.
From 3.4 onwards metrics are enabled by default. If you are running any version prior to 3.4, you need to enable the metrics in your neo4j.conf file on all instances. Please refer to https://neo4j.com/docs/operations-manual/current/monitoring/metrics/#metrics-enable in order to do so.
3. Checking Last Commited Transaction Id via the JMX MBeans
Please check:
LastCommittedTxId
You can do this using curl if you prefer:
Shell
Copy to Clipboard
$ curl -v http://localhost:7474/db/manage/server/jmx/domain/org.neo4j/instance%3Dkernel%230%2Cname%3DTransactions
For more information on the supported Neo4j JMX MBeans and how to connect to the JMX monitoring programmatically or via JConsole, please refer to https://neo4j.com/docs/java-reference/current/jmx-metrics/
Determining how much a Follower is lagging behind its Leader
To determine how much a Follower is lagging behind its Leader, you can compare the Last Commited Transaction Id (assessed in any of the methods described above) from Leader and Follower:
(Last Commited Transaction Id)_leader - (Last Commited Transaction Id)_follower
The higher the difference, the more the Follower is lagging behind (in terms of commited transactions). Because data propagation depends on a combination of different factors such as size of transactions, concurrency, hardware, network latency, etc, it’s virtually impossible to correlate all of this into a time unit.
Important Note: One of Neo4j’s Causal Cluster requirement is to safeguard data. The Core Servers do so by replicating all transactions using the Raft protocol. This ensures that the data is safely durable before confirming transaction commit to the end user application. In practice this means once a majority of Core Servers in a cluster (N/2+1) have accepted the transaction, it is safe to acknowledge the commit to the end user application. This safety requirement has an impact on write latency so make sure to take this into consideration when monitoring and determining whether there is an issue or not.
You can read more about Neo4j’s Causal Clustering here: https://neo4j.com/docs/operations-manual/current/clustering/introduction/
Was this page helpful?"
https://neo4j.com/developer/kb/diagnosing-network-latency-in-a-causal-cluster-using-mtr;"Diagnosing network latency in a Causal Cluster using MTR
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster latency monitoring
MTR is a simple ICMP based test combining ping and traceroute. The following demonstrates usage of the MTR trace tool to diagnose network latency and packet loss in a Causal Cluster. The tool is commonly used on Windows via the WinMTR tool (https://sourceforge.net/projects/winmtr/), however this article describes its example usage via the unix terminal. Installation and various usage options are beyond the scope of this article. A good reference for these can be found at the linode website referenced at the end of this article.
OSX Installation
Shell
Copy to Clipboard
$ brew install mtr
this should allow execution as sudo /usr/local/sbin/mtr however, executing the below two commands simplifies execution as sudo mtr:
Shell
Copy to Clipboard
$ sudo ln /usr/local/Cellar/mtr/0.92/sbin/mtr /usr/local/bin/mtr
$ sudo ln /usr/local/Cellar/mtr/0.92/sbin/mtr-packet /usr/local/bin/mtr-packet
To install using MacPorts, run
Shell
Copy to Clipboard
$ port install mtr
Linux (Debian/Ubuntu)
Shell
Copy to Clipboard
$ apt update && apt upgrade
$ apt install mtr-tiny
CentOS/RHEL/Fedora
Shell
Copy to Clipboard
$ yum update
$ yum install mtr
Parameters
Usage Verbose version Description
-F
--filename FILE
read hostname(s) from a file
-4
use IPv4 only
-6
use IPv6 only
-u
--udp
use UDP instead of ICMP echo
-T
--tcp
use TCP instead of ICMP echo
-a
--address ADDRESS
bind the outgoing socket to ADDRESS
-f
--first-ttl NUMBER
set what TTL to start
-m
--max-ttl NUMBER
maximum number of hops
-U
--max-unknown NUMBER
maximum unknown host
-P
--port PORT
target port number for TCP, SCTP, or UDP
-L
--localport LOCALPORT
source port number for UDP
-s
--psize PACKETSIZE
set the packet size used for probing
-B
--bitpattern NUMBER
set bit pattern to use in payload
-i
--interval SECONDS
ICMP echo request interval
-G
--gracetime SECONDS
number of seconds to wait for responses
-Q
--tos NUMBER
type of service field in IP header
-e
--mpls
display information from ICMP extensions
-Z
--timeout SECONDS
seconds to keep probe sockets open
-r
--report
output using report mode
-w
--report-wide
output wide report
-c
--report-cycles COUNT
set the number of pings sent
-j
--json
output json
-x
--xml
output xml
-C
--csv
output comma separated values
-l
--raw
output raw format
-p
--split
split output
-t
--curses
use curses terminal interface
--displaymode MODE
select initial display mode
-n
--no-dns
do not resove host names
-b
--show-ips
show IP numbers and host names
-o
--order FIELDS
select output fields
-y
--ipinfo NUMBER
select IP information in output
-z
--aslookup
display AS number
-h
--help
display this help and exit
-v
--version
output version information and exit
Examples below describe usage on OSX only, but usage on other operating systems is very similar.
Usage
Shell
Copy to Clipboard
sudo mtr <destination domain name or ip>
If a summary, rather than real-time response updates, is desired, execute:
sudo mtr -rwn -i 2 -c 5 <domain name or ip> > /User/<username>/Desktop/mtr.txt where i is the ping interval in seconds and in this case is 2. This outputs the trace report to an mtr.txt file at the above specified location.
Run mtr -P <tcp port> -T -w <destination ip> to generate a report. By default it sends 10 packets to the host. The Loss% column shows the percentage of packet loss at each hop. The Snt column counts the number of packets sent.
The next four columns Last, Avg, Best, and Wrst are all measurements of latency in milliseconds. Last is the latency of the last packet sent, Avg is the average latency of all packets, while Best and Wrst display the best (shortest) and worst (longest) round trip time for a packet to this host. In most cases, the average Avg column should be the focus. The final column, StDev, provides the standard deviation of the latencies to each host. The higher the standard deviation, the greater the difference is between measurements of latency.
When analyzing MTR output, you are looking for two things: loss and latency. An example test result of mtr -P 80 -T -w <ip> is shown below:
The question marks ??? appear when there is no additional route information. In the above example, there isn’t much information available from hops 9 to 16. When variable loss is reported between hops, it is advised to trust response times from later hops.
In the above example, there is 20% packet loss from hop 6 to hop 7 and 80% from hop 7 to hop 8. The destination also has 80% packet loss. This could lead to high latency (10s of seconds) and in this case, it seems to be down to hops 6, 7 and 8. Note that some packet loss is due to rate limiting. If there’s no packet loss on the destination, it means the connectivity is good. Notice the latency above averages at 86.4 ms. Hops 8 to 16 seem to have introduced around 100ms delay in this case.
The ability to specifiy a source address and port, makes this tool particularly useful for testing intra-cluster latency. One can specify a source address and port as well as which protocol to use instead of ICMP, e.g. UDP or TCP.
For example, if one sets dbms.connector.bolt.listen_address=:7688 on the neo4j server side, it may be useful to test the network latency which will be added to query response times by executing the MTR trace from the server towards the client, e.g. as sudo mtr -rwn -i 2 -c 5 -P 7688 -T <ip of the client, or, another cluster member>.
For a sample 3 core causal cluster with dbms.connector.bolt.listen_address=:7688, dbms.connector.bolt.listen_address=:7689 and dbms.connector.bolt.listen_address=:7690, we can test the intra-cluster latency between instances 1 (source) and 2 (destination) as: e.g. sudo mtr -c 5 -T -P 7689 192.168.8.103:
https://www.linode.com/docs/networking/diagnostics/diagnosing-network-issues-with-mtr/
https://support.mulesoft.com/s/article/How-to-use-mtr-to-diagnose-packet-loss-problem-with-a-TCP-port
https://github.com/traviscross/mtr
Was this page helpful?"
https://neo4j.com/developer/kb/upgrading-causal-cluster;"Upgrading your Causal Cluster from 3.1.x to 3.2.x
Author Dave Shiposh Applicable versions 3.1 3.2 Tags upgrade causal cluster
This article outlines possible steps to upgrade your Neo4j 3.1.2+ Causal Cluster to 3.2.2. For this upgrade path, Neo4j does not support rolling upgrades, so downtime is required to complete the process. However, the following procedure tries to minimize the downtime for both, reads and writes while retaining data safety/high availability where possible. This trade-off may not be the best for all setups.
Assumptions
You have a working Neo4j Causal Cluster in Version 3.1.x where x>=2.
You have three core servers and no followers.
Your operating system is Linux.
The installation of Neo4j has been done by extracting the .tar.gz file.
You have licensed multi-data center operations, see http://neo4j.com/docs/operations-manual/current/clustering/causal-clustering/multi-data-center/#multi-dc-licensing.
Your configuration, plugins and files in data/dbms/ are not changed while following the upgrade steps of this article (except for the adjustments described in the steps itself, of course).
Your free disk space is at least double the size of your current installation including your database files.
Upgrade Steps
Before following the below steps, read the complete article thoroughly and test the procedure in a pre-production environment.
Step 0 - Preparation
Make sure you have access to the installation source of Neo4j 3.2.2.
Make sure your client applications have a good error handling in place, since they will receive execeptions during a short period of time. E.g., when using the Java driver, you may want to configure it with Config.build().withMaxTransactionRetryTime( .. ).toConfig().
Make sure your client applications differentiate between read and write transactions. I.e., whenever you only read, use session.readTransaction() or set the access mode of your session to AccessMode.READ.
Make sure that all your plugins are compatible with the new version.
Make a backup of your database.
Step 1 - Install Neo4j 3.2.2
On each server:
Extract the neo4j-enterprise-3.2.2-unix.tar.gz file
Copy all files from the following directories from your old (and running) Neo4j insallation to the newly extracted (and still shutdown) installation (retain the directory structure):
files in conf/
files in data/dbms/
files in plugins/
In the following, we are referring to old and new files or instances. The old files/instances are those of the Neo4j 3.1 installation, the new ones are those of the Neo4j 3.2 installation.
Step 2 - Set Followers as ""Follower Only""
Identify Leader and Follower instances of your old cluster installation. You may use one of the following commands:
:sysinfo in the Neo4j Browser or
CALL dbms.cluster.overview() via Cypher
Pick a Follower instance that is not already in ""Follower Only"" mode:
In the old neo4j.conf file of that instance
set/add causal_clustering.refuse_to_be_leader=true and
set/add causal_clustering.multi_dc_license=true.
Restart the instance, which will not be able to become a Leader any longer.
Wait until this instance is up and running again.
Repeat Step 2 until all Followers (in our szenario two) are in ""Follower Only"" mode.
During this step you may encounter a short (a few ms) delay in processing read requests. However, no downtime is expected if you have configured your application to retry transactions (see Step 0). After this step, we have a three instances cluster where only one instance is allowed to be the Leader. This reduces the high-availability for your writes. E.g., if the Leader now fails, reads are still processed, but no writes are possible.
Step 3 - Shutdown Leader
Stop the old Leader. This step starts the downtime for writes! Reads are still processed through the two Follower instances.
Step 4 - Copy database to the New Leader
On the old Leader instance:
Copy your (old) active database folder (by default: data/databases/graph.db) to the new 3.2.x installation (which has been setup in step 1). By copying the database folder, we still have the latest writes available for fallback.
Step 5 - Configure 3.2.x for the Format Migration
On the Leader box in the new 3.2.x neo4j.conf file, make sure to have the following parameters set:
dbms.allow_format_migration=true
dbms.mode=SINGLE
Step 6 - Upgrade the database files (Format Migration)
On the Leader box in the new installation:
Start up Neo4j 3.2.x. Depending on the size of your database, this step may take a few moments to finish.
Check your logs/neo4j.log file for success. It should have the following line: 2017-07-06 18:08:59.933+0000 INFO Successfully finished upgrade of database
Stop Neo4j 3.2.x. We now have a upgraded database which we use to seed the new cluster.
Step 7 - Revert Configuration from Step 5
On the Leader box in the new conf/neo4j.conf file, make sure to have the following parameters set:
dbms.allow_format_migration=false
dbms.mode=CORE
Step 8 - Seed the Cluster
Copy the newly upgraded database folder (by default: data/databases/graph.db) to the new installation of the Follower instances. I.e.:
Copy your new active database folder from the Leader box to one of the new Follower installations.
Copy your new active database folder from the Leader box to the other new Follower installation.
Step 9 - Switch Versions
Starting with one of the old Follower instances:
Stop the instance.
Repeat this process for the second Follower instance. This is the beginning of the downtime for reads!
Now, start up the new cluster:
Start the new Leader instance.
Start the two new Follower instances.
This procedure stops the downtime for reads and writes.
Step 10 - Validate
Validate that your cluster is healthy. CALL dbms.cluster.overview() may be used as a starting point. If you still have the Neo4j Browser open in a web browser, you may need to refresh the site.
Step 11 - Backup
Take a full backup of your running database including the consistency check to validate the upgraded database.
Step 12 - Remove 3.1.x
Remove your old installation files on all of your three servers.
Fallback Scenarios
The following sections describe the steps to revert your setup to its original state. Depending on when you decide to do the fallback, you will jump into one of the following sections and execute the steps described in there.
Coming from Step 1 above
Remove the new installation files from all servers.
Coming from Step 2 above
Follow the steps from section 'Coming from Step 1 above'.
Coming from Step 3 above
Starting with one of the old Follower instances:
In the old neo4j.conf file of that instance
set causal_clustering.refuse_to_be_leader=false or remove that parameter completely and
revert causal_clustering.multi_dc_license to its originally configured value.
Restart the (old) Follower instance.
Wait until this instance is up and running again. > Repeat this process for the second Follower instance.
Follow the steps from section 'Coming from Step 1 above'.
Coming from Step 4, 5, 6, 7 or 8 above
Start the old Leader
This step forms the end of the downtime for writes!
Follow the steps from section 'Coming from Step 3 above'.
Coming from Step 9 or 10 above
Be aware that you will lose writes, that have been committed to the new cluster when doing the following!
Stop the new Followers.
Stop the new Leader.
Start the old Leader.
Follow the steps from section 'Coming from Step 3 above'.
Was this page helpful?"
https://neo4j.com/developer/kb/upgrading-to-neo4j-3-0-enterprise-step-by-step-linux;"Upgrading to Neo4j 3.0 Enterprise Step-by-Step - Linux
Author Dave Gordon Applicable versions 3.0 Tags upgrade linux
Neo4j 3.0 is a major release that includes both a directory structure reorganization and a configuration file/parameter name overhaul. This means that upgrading to it requires some additional consideration and a couple extra steps. In order to provide you with the best upgrade experience possible, lets walk through the upgrade on each OS platform we support.
We are assuming a single instance in this example. For cluster upgrades, refer to the same steps apply, combined with the additional steps noted in the product documentation.
Linux Upgrade Using tar.gz Distribution
Assumptions:
Neo4j 2.3.7 is already installed at /var/lib/neo4j/neo4j-enterprise-2.3.7
Neo4j 2.3.7 was installed, configured and managed by the neo4j OS user
Steps:
Navigate to the NEO4J_HOME directory:
$ cd /var/lib/neo4j/
Get the 3.0 software:
$ wget http://www.neo4j.com/customer/download/neo4j-enterprise-3.0.4-unix.tar.gz
Backup the existing Neo4j 2.3.7 install:
$ ./neo4j-enterprise-2.3.7/bin/neo4j-backup -to /tmp/neo4j_2.3.7_backup -host 127.0.0.1
Unpack the 3.0 software:
$ tar -xzf neo4j-enterprise-3.0.4-unix.tar.gz
Chown the 3.0 directory:
$ chown -R neo4j:neo4j ./neo4j-enterprise-3.0.4
Stop the Neo4j 2.3.7 server:
$ ./neo4j-enterprise-2.3.7/bin/neo4j stop
Move to the Neo4j 3.0 home directory:
$ cd neo4j-enterprise-3.0.4
Use the new config migrator tool to migrate the configuration from the Neo4j 2.3.7 install to the new Neo4j 3.0:
$ java -jar config-migrator.jar /var/lib/neo4j/neo4j-enterprise-2.3.7 .
Use neo4j-admin to migrate the datastore from its 2.3.7 location to 3.0:
$ ./bin/neo4j-admin import --mode=database --database=graph.db --from=/var/lib/neo4j/neo4j-enterprise-2.3.7/data/graph.db
$ ls data/databases/
graph.db
Edit the conf/neo4j.conf file, and:
Uncomment the line: dbms.allow_format_migration=true
Uncomment the line: dbms.active_database=graph.db Note: Change this to the name of the database if not graph.db
Copy the authentication details from the 2.3.7 install to 3.0 (if you have authentication enabled):
$ cp -R /var/lib/neo4j/neo4j-enterprise-2.3.7/conf/ssl ./conf/ssl
Copy plugins from the 2.3.7 install to 3.0 (if you have any):
$ cp /var/lib/neo4j/neo4j-enterprise-2.3.7/plugins/* ./plugins
Start Neo4j: ./bin/neo4j start or ./bin/neo4j console
$ ./bin/neo4j start
Starting Neo4j.
Started neo4j (pid 39823). By default, it is available at http://localhost:7474/
There may be a short delay until the server is ready.
See /var/lib/neo4j/neo4j-enterprise-3.0.4/logs/neo4j.log for current status.
Tail the neo4j.log to see the progress of the store upgrade, and make sure the database comes online:
2016-04-15 19:58:20.310+0000 INFO  Starting...
2016-04-15 19:58:21.568+0000 INFO  Initiating metrics...
2016-04-15 19:58:21.898+0000 INFO  Starting upgrade of database
2016-04-15 19:58:21.939+0000 INFO  Migrating Indexes (1/3):
2016-04-15 19:58:21.946+0000 INFO    10% completed
2016-04-15 19:58:21.946+0000 INFO    20% completed
2016-04-15 19:58:21.951+0000 INFO    30% completed
2016-04-15 19:58:21.951+0000 INFO    40% completed
2016-04-15 19:58:21.951+0000 INFO    50% completed
2016-04-15 19:58:21.951+0000 INFO    60% completed
2016-04-15 19:58:21.951+0000 INFO    70% completed
2016-04-15 19:58:21.951+0000 INFO    80% completed
2016-04-15 19:58:21.951+0000 INFO    90% completed
2016-04-15 19:58:21.952+0000 INFO    100% completed
2016-04-15 19:58:21.952+0000 INFO  Migrating Legacy indexes (2/3):
2016-04-15 19:58:21.997+0000 INFO    10% completed
2016-04-15 19:58:21.998+0000 INFO    20% completed
2016-04-15 19:58:21.999+0000 INFO    30% completed
2016-04-15 19:58:21.999+0000 INFO    40% completed
2016-04-15 19:58:21.999+0000 INFO    50% completed
2016-04-15 19:58:22.000+0000 INFO    60% completed
2016-04-15 19:58:22.000+0000 INFO    70% completed
2016-04-15 19:58:22.000+0000 INFO    80% completed
2016-04-15 19:58:22.001+0000 INFO    90% completed
2016-04-15 19:58:22.002+0000 INFO    100% completed
2016-04-15 19:58:22.002+0000 INFO  Migrating Store files (3/3):
2016-04-15 19:58:22.727+0000 INFO  Initiating metrics...
2016-04-15 19:58:23.552+0000 INFO    10% completed
2016-04-15 19:58:23.553+0000 INFO    20% completed
2016-04-15 19:58:23.553+0000 INFO    30% completed
2016-04-15 19:58:23.553+0000 INFO    40% completed
2016-04-15 19:58:23.553+0000 INFO    50% completed
2016-04-15 19:58:23.553+0000 INFO    60% completed
2016-04-15 19:58:23.553+0000 INFO    70% completed
2016-04-15 19:58:23.554+0000 INFO    80% completed
2016-04-15 19:58:23.554+0000 INFO    90% completed
2016-04-15 19:58:23.554+0000 INFO    100% completed
2016-04-15 19:58:23.682+0000 INFO  Successfully finished upgrade of database
2016-04-15 19:58:28.447+0000 INFO  Started.
2016-04-15 19:58:28.844+0000 INFO  Mounted REST API at: /db/manage
2016-04-15 19:58:30.920+0000 INFO  Remote interface available at http://localhost:7474/
Linux Upgrade Using Debian (apt-get)
Assumptions:
You are familiar with the instructions at http://debian.neo4j.org/
Neo4j Enterprise 2.3.7 (or another 2.x version) is already installed via debian package
Steps:
Update using apt-get:
$ sudo apt-get update
Install neo4j-enterprise=3.0.4
$ sudo apt-get install neo4j-enterprise=3.0.4
When prompted, select the option N, as we will rectify this later:
Configuration file '/etc/neo4j/neo4j-wrapper.conf'
 ==> Modified (by you or by a script) since installation.
 ==> Package distributor has shipped an updated version.
   What would you like to do about it ?  Your options are:
    Y or I  : install the package maintainer's version
    N or O  : keep your currently-installed version
      D     : show the differences between the versions
      Z     : start a shell to examine the situation
 The default action is to keep your current version.
*** neo4j-wrapper.conf (Y/I/N/O/D/Z) [default=N] ?  N
Stop neo4j:
$ service neo4j stop
Run the config-migrator.jar utility that ships with Neo4j 3.0:
$sudo java -jar /usr/share/neo4j/bin/tools/config-migrator.jar /var/lib/neo4j/ .
Copy the new configuration files into /etc/conf, and move the old ones out, or remove them after you confirm the newly generated config files are correct:
$ mkdir /etc/neo4j_archive
$ mv /etc/neo4j/* /etc/neo4j_archive/
$ cp /var/lib/neo4j/conf/* /etc/neo4j
Copy auth if applicable (need to test this actually)
Update /etc/neo4j/neo4j.conf with allow_format_migration setting to true, and any other required settings.
Start the database:
$ service neo4j start
Where things live after a Debian install:
/var/lib/neo4j
data, certificates
/var/log/neo4j
logs
/usr/share/neo4j/
bin, lib, tools
/etc/neo4j
conf files
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-noclassdeffounderror-org-neo4j-kernel-impl-util-jobscheduler;"Explanation of error NoClassDefFoundError: org/neo4j/kernel/impl/util/JobScheduler
Author Dana Canzano Applicable versions 3.3 Tags apoc upgrade
Upon upgrading to Neo4j 3.3, if you were previously using APOC, and did not download and install the version of APOC for 3.3 bin\neo4j start will fail.
The contents of your $NEO4J_HOME/logs/neo4j.log will appear similar to.
2017-11-07 20:38:38.245+0000 INFO  Bolt enabled on 0.0.0.0:7687.
2017-11-07 20:38:38.265+0000 ERROR Failed to start Neo4j: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@c73c26' was successfully initialized, but failed to start. Please see the attached cause exception ""org.neo4j.kernel.impl.util.JobScheduler"". Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@c73c26' was successfully initialized, but failed to start. Please see the attached cause exception ""org.neo4j.kernel.impl.util.JobScheduler"".
org.neo4j.server.ServerStartupException: Starting Neo4j failed: Component 'org.neo4j.server.database.LifecycleManagingDatabase@c73c26' was successfully initialized, but failed to start. Please see the attached cause exception ""org.neo4j.kernel.impl.util.JobScheduler"".
        at org.neo4j.server.exception.ServerStartupErrors.translateToServerStartupError(ServerStartupErrors.java:68)
        at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:218)
        at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:111)
        at org.neo4j.server.ServerBootstrapper.start(ServerBootstrapper.java:79)
        at org.neo4j.server.enterprise.CommercialEntryPoint.main(CommercialEntryPoint.java:22)
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.server.database.LifecycleManagingDatabase@c73c26' was successfully initialized, but failed to start. Please see the attached cause exception ""org.neo4j.kernel.impl.util.JobScheduler"".
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:466)
        at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:107)
        at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:210)
        ... 3 more
Caused by: java.lang.RuntimeException: Error starting org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory, /home/neo4j/neo4j-enterprise-3.3.0/data/databases/graph.db.out
        at org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:211)
        at org.neo4j.kernel.enterprise.EnterpriseGraphDatabase.<init>(EnterpriseGraphDatabase.java:36)
        at org.neo4j.server.enterprise.EnterpriseNeoServer.lambda$static$1(EnterpriseNeoServer.java:75)
        at org.neo4j.server.database.LifecycleManagingDatabase.start(LifecycleManagingDatabase.java:88)
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.start(LifeSupport.java:445)
        ... 5 more
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.kernel.extension.KernelExtensions@165be2d' failed to initialize. Please see the attached cause exception ""org.neo4j.kernel.impl.util.JobScheduler"".
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.init(LifeSupport.java:427)
        at org.neo4j.kernel.lifecycle.LifeSupport.init(LifeSupport.java:62)
        at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:98)
        at org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory.initFacade(GraphDatabaseFacadeFactory.java:207)
        ... 9 more
Caused by: java.lang.NoClassDefFoundError: org/neo4j/kernel/impl/util/JobScheduler
        at java.lang.Class.getDeclaredMethods0(Native Method)
        at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
        at java.lang.Class.privateGetPublicMethods(Class.java:2902)
        at java.lang.Class.getMethods(Class.java:1615)
        at sun.misc.ProxyGenerator.generateClassFile(ProxyGenerator.java:451)
        at sun.misc.ProxyGenerator.generateProxyClass(ProxyGenerator.java:339)
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:639)
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:557)
        at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:230)
        at java.lang.reflect.WeakCache.get(WeakCache.java:127)
        at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:419)
        at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:719)
        at org.neo4j.kernel.impl.util.DependenciesProxy.dependencies(DependenciesProxy.java:55)
        at org.neo4j.kernel.extension.KernelExtensions.getKernelExtensionDependencies(KernelExtensions.java:125)
        at org.neo4j.kernel.extension.KernelExtensions.init(KernelExtensions.java:58)
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.init(LifeSupport.java:406)
        ... 12 more
Caused by: java.lang.ClassNotFoundException: org.neo4j.kernel.impl.util.JobScheduler
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 28 more
2017-11-07 20:38:38.268+0000 INFO  Neo4j Server shutdown initiated by request
To resolve this error download and install the version of APOC for 3.3 and as detailed here
Was this page helpful?"
https://neo4j.com/developer/kb/fix-error-no-dependefix-error-no-dependency-satisfies-type-interface-org-neo4j-graphdb;"Fix error: No dependency satisfies type interface org.neo4j.graphdb.GraphDatabaseService
Author Daniel Terlizzi Tags upgrade
From Neo4j 3.5 onwards, there are 2 kinds of Extension Factories : global and per database.
Only the database one has access to the GraphDatabaseService.
If you encounter this error, you need to change the call to the parent constructor of the classes that are extending KernelExtensionFactory<ApocKernelExtensionFactory.Dependencies> as following and adjust the import class:
Java
Copy to Clipboard
    import org.neo4j.kernel.extension.ExtensionType;

    //... etc

    public ApocKernelExtensionFactory() {
        super(ExtensionType.DATABASE, ""registerUserDefinedExtension"");
    }
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-db-fails-to-start-with-caused-by-org-neo4j-token-api-nonuniqueyokenexception-the-propertykey-namedtoken;"Explanation of Error: db fails to start with Caused by: org.neo4j.token.api.NonUniqueTokenException: The PropertyKey NamedToken
Author Dana Canzano Applicable versions 4.0 Tags upgrade
When attempting to start Neo4j and one is running a Neo4j 4.0.x release and where x is ⇐2 the following error may be encountered and logged in logs\debg.log
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.internal.recordstorage.RecordStorageEngine$2@783ae61f' failed to initialize. Please see the attached cause exception ""The PropertyKey NamedToken[name:prop1, id:321, internal:false] is not unique, it existed as null."".
        at org.neo4j.kernel.lifecycle.LifeSupport$LifecycleInstance.init(LifeSupport.java:426)
        at org.neo4j.kernel.lifecycle.LifeSupport.init(LifeSupport.java:66)
        at org.neo4j.kernel.lifecycle.LifeSupport.start(LifeSupport.java:102)
        at org.neo4j.kernel.database.Database.start(Database.java:462)
        ... 13 more
Caused by: org.neo4j.token.api.NonUniqueTokenException: The PropertyKey NamedToken[name:prop1, id:321, internal:false] is not unique, it existed as null.
This error has only been reported if your environment was previously on a Neo4j 3.5.x release and then later upgraded to 4.0.x, where x is ⇐2.
This error is addressed in Neo4j 4.0.3 forward. If you have encountered this error the workaround is to utilize neo4j-admin copy which is an offline activity and will read a database and create a new copy of the database without the errors in the underlying data/database/* files.
Was this page helpful?"
https://neo4j.com/developer/kb/manually-merging-neo4jwrapperconf-into-neo4jconf-in-neo4j-31;"Manually Merging neo4j-wrapper.conf into neo4j.conf in Neo4j 3.1
Author Dave Gordon Applicable versions 3.1 Tags configuration upgrade
Neo4j 3.1 takes the configuration changes made in Neo4j 3.0 a step further, and ships with a single configuration file: conf/neo4j.conf. This is the result of merging the contents of conf/neo4j.conf and conf/neo4j-wrapper.conf. The upgrade does not merge these automatically, and conf/neo4j-wrapper.conf is deprecated but still supported until the end of 3.x. This, merging the two is optional at this point, but a good step to take in preparation for future versions.
One can simply copy the entire contents of conf/neo4j-wrapper.conf and paste them at the end of conf/neo4j.conf. Or, use the sample script below. Just copy the script, paste into a new file with execute privileges in $NEO4J_HOME/bin, and run it:
Bash
Copy to Clipboard
#!/usr/bin/env bash
# This script will merge an existing neo4j.conf and neo4j-wrapper.conf
# This script is designed to be run from the bin/ directory of Neo4j, and expects both neo4j.conf
# and neo4j-wrapper.conf to be located in the conf/ directory.
# This is a sample script that is not part of the Neo4j project.
# Please be sure to read, understand and adapt this script as appropriate for your environment

set -o errexit -o nounset -o pipefail
[[ ""${TRACE:-}"" ]] && set -o xtrace

: ""${NEO4J_BIN:=$(dirname ""$0"")}""
readonly NEO4J_BIN
. ""${NEO4J_BIN}/neo4j-shared.sh""

main() {
  setup_environment
  check_java
  build_classpath
   NEO4J_HOME NEO4J_CONF

  NOW=$(date +)
  CONF_CONTAINS_WRAPPER=$(ls  | grep -x  | wc -l | tr -d '[:space:]')
  
   [  =  ]; 
    
     
    cp  
    
     
      >> /neo4j.conf
    cat  >> /neo4j.conf
    mv  
    
     
  
     
  
}

main 
View all (26 more lines)
Was this page helpful?"
https://neo4j.com/developer/kb/add-a-neo4j-instance-to-an-embedded-ha-application;"Add a Neo4j instance to a running embedded HA application
Author Vivek Saran Applicable versions 3.5 Tags embedded ha
There are situations when we would like to use the Neo4j Browser to access an embedded HA cluster.
The documented approach to accomplish that goal requires changing the embedded application code as described in the Neo4j documentation:
Accessing Neo4j embedded via the Bolt protocol
There is another approach that does not require changing application code. This second approach involves adding an additional server mode instance to the cluster. Here are the steps:
Install a new Neo4j Enterprise server mode instance (using tarball/zip or other means) with the same version of Neo4j that is operational in the embedded application.
Edit the neo4j.conf file and update the following parameters:
Properties
Copy to Clipboard
dbms.mode=HA
# this is just a high number to easily identify that it is a server instance
ha.server_id=20
ha.slave_only=true
ha.initial_hosts=<initial hosts to only include the members of the embedded HA cluster>
We don’t need to add the new server instance to ha.initial_hosts unless it is going to be a permanent fixture in the cluster, and will be required for the cluster to startup. We have set ha.slave_only=true because we want to prevent this instance from becoming the Master. It will, however, be able to accept writes.
Start Neo4j on the new instance.
During startup, the new instance will connect to one of the initial hosts and request to join the cluster. Part of the startup process is to discover who else is in the cluster, including instances that may not be in the inital_hosts that joined later, and also to know if any members from the inital_hosts have failed.
We now have a Neo4j instance where we can use the Neo4j Browser to communicate with the graph database as we do in a conventional server mode HA cluster.
Was this page helpful?"
https://neo4j.com/developer/kb/number-of-open-files-on-linux;"Number of open files
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags linux
GNU/Linux and Mac OS operating systems impose an upper limit on the number of concurrent files a user may have open.
This article covers how to configure the number of open files on GNU/Linux that use systemd or sysvinitd.
For Mac OS, please check the following article: Setting Max Open File Limits on Mac OSX
Check the settings for current user and current session
This number is reported for the current user and session with the ulimit -n command:
Shell
Copy to Clipboard
user@localhost:~$ ulimit -n
1024
Check the setting for a running process
To monitor how many open files a user has, you can run:
Shell
Copy to Clipboard
> lsof -u <user>
replacing <user> with the linux username who started the Neo4j process.
To understand the limits for one specific ProcessID one can also run:
Shell
Copy to Clipboard
> cat /proc/<processID>/limits
replacing <processID> with the linux processID for the running Neo4j process.
This will produce output similar to
Shell
Copy to Clipboard
$ cat /proc/5219/limits
Limit                     Soft Limit           Hard Limit           Units
Max cpu time              unlimited            unlimited            seconds
Max file size             unlimited            unlimited            bytes
Max data size             unlimited            unlimited            bytes
Max stack size            8388608              unlimited            bytes
Max core file size        0                    unlimited            bytes
Max resident set          unlimited            unlimited            bytes
Max processes             31357                31357                processes
Max open files            40000                40000                files
Validate the correct settings
Neo4j will report the current setting for number of file descriptors in the debug.log as following:
2019-01-02 13:39:27.003+0000 INFO [o.n.i.d.DiagnosticsManager] Max number of file descriptors: 10000
The usual default is 1024 and is often not enough. We recommend setting this to 40000 to ensure Neo4j works correctly.
It is possible to set the limit with the ulimit -n command, but only for the root user, and it only affects the current session, so it’s not permanent. Also, it will not affect your processes that are already running.
It is necessary to check this before and after changing the file descriptor limit.
Change file descriptor limit
Depending on the System and Service Manager, the configuration steps differ. Since 2015, the majority of Linux distributions have adopted systemd and it is considered a de facto standard.
Table 1. Table Systemd vs SysVinit usage as of 2019
OS SysVinit(deprecated) systemd
RedHat Enterprise Linux >=7, CentOS >=7, fedora >=16
no
yes
RedHat Enterprise Linux ⇐6, CentOS ⇐6, fedora ⇐15
yes
no
Ubuntu >=16.04, Debian >=8
no
yes
If your system is using systemd
neo4j is running as a service
run the following command
Shell
Copy to Clipboard
> sudo systemctl edit neo4j.service
and append the following
Ini
Copy to Clipboard
[Service]
LimitNOFILE=60000
Follow the product documentation
neo4j is as a normal process
run the following command
Shell
Copy to Clipboard
> $ sudo vi /etc/systemd/system.conf
and uncomment and define DefaultLimitNOFILE
Ini
Copy to Clipboard
[Manager]
...
DefaultLimitNOFILE=60000
run the following command
Shell
Copy to Clipboard
> $ sudo vi /etc/systemd/user.conf
and uncomment and define LimitNOFILE
Ini
Copy to Clipboard
[Manager]
#...
DefaultLimitNOFILE=60000
If your system is using SysVinit
The actual way to raise your file limits consists of editing three files:
/etc/security/limits.conf needs to have these lines in it:
Plaintext
Copy to Clipboard
neo4j  soft  nofile  40000
neo4j  hard  nofile  40000
/etc/pam.d/common-session needs to have this line in it:
Plaintext
Copy to Clipboard
session required pam_limits.so
/etc/pam.d/common-session-noninteractive also needs to have this line in it:
Plaintext
Copy to Clipboard
session required pam_limits.so
Keep in mind that limits can be easily modified by anything responsible for execution of your processes. If running ulimit -n (with the correct user) is giving you the number you just set, but cat /proc/{process_id}/limits is still printing the low number, you almost certainly have a process manager, an init script, or something similar overriding your limits. One last thing worth noting is that processes inherit the limits of the parent process.
Related issue: NativeFSLock strange behavior - Lock obtain timed out
Sometimes you’ll see the following error in the logs: LockObtainFailedException: Lock obtain timed out: NativeFSLock
In this case you might want to increase the number of file descriptors to an even higher value.
For example: if you encounter the issue with 40000, try to increase it to 80000 or higher.
Links
For more information, refer to:
why systemd has replaced sysvinitd
Systemd wikipedia article
Was this page helpful?"
https://neo4j.com/developer/kb/getting-a-jvm-heap-dump;"Getting a JVM heap dump
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jvm memory heap dump
This document provides the process of creating a heap-dump on a java machine to investigate potential memory leaks.
Although a heap dump will be auto generated when OutOfMemoryError is thrown by specifying -XX:+HeapDumpOnOutOfMemoryError VM option, we can use the jmap tool to print shared object memory maps or heap memory details of a given process or core file or a remote debug server. If the given process is running on a 64-bit VM, you may need to specify the -J-d64 option, e.g.:
Shell
Copy to Clipboard
$ jmap -J-d64 -heap <pid>
To get a list of Java processes running on a machine, use the jps or jcmd commands.
In Windows Systems where dbgeng.dll is not present, 'Debugging Tools For Windows' needs to be installed to have these tools working. Also, PATH environment variable should contain the location of jvm.dll used by the target process or the location from which the Crash Dump file was produced. For example, set PATH=<jdk>\jre\bin\client;%PATH%
When no option is used jmap prints shared object mappings. An example of whats normally required for our analysis is:
Shell
Copy to Clipboard
$ jmap -dump:[live,]format=b,file=<filename>.bin <pid>
The above will dump the Java heap in binary format to filename. If the optional live suboption is used, live objects in the heap are dumped.
Viewing heap dumps
To browse heap dumps generated as above, one can use jhat (Java Heap Analysis Tool) to read the generated file.
Some useful options to use with jmap are:
-heap prints a heap summary instead of a binary dump.
-histo[:live] prints a histogram of the heap.
-F can be used with jmap -dump or jmap -histo option if the pid does not respond.
We can use the jhat command to parse a java heap dump file and launch a webserver to view heap dumps over a web browser. The default port is 7000, but we can change this by using the -port option
Syntax:
Shell
$ jhat [ options ] <heap-dump-file>
e.g. jhat -port 7001 -debug 1
where -port determines the browser port the output can be viewed and -debug <int> determines the level of debug detail presented.
We can also use the jconsole tool to view cpu, memory and heap utilisation in a graphical format.
Shell
Copy to Clipboard
$ jconsole [ options ] [ connection ... ]
e.g. jconsole -interval=5 <pid> 127.0.0.1:7474
where -interval=n determines the report refresh interval in seconds, <pid> is the process id of the target JVM (the JVM must be running with the same user id as that running the jconsole)
References:
https://docs.oracle.com/javase/7/docs/technotes/tools/share/jmap.html
https://docs.oracle.com/javase/7/docs/technotes/tools/share/jhat.html
https://docs.oracle.com/javase/7/docs/technotes/tools/share/jconsole.html
Was this page helpful?"
https://neo4j.com/developer/kb/changing-your-garbage-collection-method-to-g1;"Retired: Changing your Garbage Collection Method to G1
Author Dave Gordon Applicable versions 2.0 2.1 2.2 Tags garbage collection heap memory jvm
This is already the default Garbage Collector in Neo4j 2.3+. This guide is only intended for previous versions.
When to Use G1:
By default, Neo4j versions 2.2 and earlier use Concurrent Mark and Sweep (CMS) for garbage collection. Customers with large heaps or who are seeing unacceptable garbage collection pauses with the default method should give G1 (Garbage 1st) a try.
G1 trades off a little throughput in the application to ensure the Full GC pauses are predictable and short. It compacts objects on the heap as it runs to avoid the long Full GC associated with CSM.
When setting G1, it is important to consider your target GC pause duration. We recommend that you leave it at the default (200ms) to start with but increase it if you see too many GCs over one to two seconds. For example, you might try 400ms, then 600ms, until you find the right balance. The setting for the target pause is:
Properties
Copy to Clipboard
wrapper.java.additional=-XX:MaxGCPauseMillis=200
Add this line to conf/neo4j-wrapper.conf if you wish to change the default setting.
Making the Switch to G1:
Edit conf/neo4j-wrapper.conf and change:
Properties
Copy to Clipboard
#********************************************************************
# JVM Parameters
#********************************************************************

#wrapper.java.additional=-XX:+UseConcMarkSweepGC
wrapper.java.additional=-XX:+UseG1GC
G1 should only be used with latest Java 7 or Java 8 releases.
Was this page helpful?"
https://neo4j.com/developer/kb/large-delete-transaction-best-practices-in-neo4j;"Large Delete Transaction Best Practices in Neo4j
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher transaction memory garbage collection heap delete
In order to achieve the best performance, and avoid negative effects on the rest of the system, consider these best practices when processing large deletes.
Start by identifying which situation you are in:
Deleting the entire graph database, so you can rebuild from scratch.
Deleting a large section of the graph, or a large number of nodes/relationships that are identified in a MATCH statement.
Depending on the situation, there may be a different recommendation. Going through them in order:
When deleting the entire graph database,
In Neo4j 4.x EE, you can just switch to the system database and issue an DROP DATABASE xxx; and CREATE DATABASE xxx; statements.
For Community Edition and older editions: stop the database, rename/delete the graph store
4.x CE data/databases/neo4j and data/transactions/neo4j
pre 4.x data/databases/graph.db
pre 3.x data/graph.db
directory, and start the database.
This will build a fresh, empty database for you.
If you need to delete some large number of objects from the graph, one needs to be mindful of the not building up such a large single transaction such that a Java OUT OF HEAP Error will be encountered.
Use the following example to delete subsets of the matched records in batches until the full delete is complete:
If your nodes have more than 100 relationships per node ((100+1)*10k=>1010k deletes) reduce the batch size or see the recommendations at the bottom.
With 4.4 and newer versions you can utilize the CALL {} IN TRANSACTIONS syntax.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Foo) where n.foo='bar'
CALL { WITH n
DETACH DELETE n
} IN TRANSACTIONS OF 10000 ROWS;
With 3.x forward and using APOC
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.periodic.iterate(""MATCH (n:Foo) where n.foo='bar' return id(n) as id"", ""MATCH (n) WHERE id(n) = id DETACH DELETE n"", {batchSize:10000})
yield batches, total return batches, total
Pre 3.x
Cypher
Copy to Clipboard
Run in Neo4j Browser
// Find the nodes you want to delete
MATCH (n:Foo) where n.foo = 'bar'

// Take the first 10k nodes and their rels (if more than 100 rels / node on average lower this number)
WITH n LIMIT 10000
DETACH DELETE n
RETURN count(*);
Run this until the statement returns 0 (zero) records.
For versions before Neo4j 2.3 run:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// Find the nodes you want to delete
MATCH (n:Foo) where n.foo = 'bar'

// Take the first 10k nodes and their rels (if more than 100 rels / node on average lower this number)
WITH n LIMIT 10000
MATCH (n)-[r]-()
DELETE n,r
RETURN count(*);
In all of the examples we are performing a delete in batch sizes of 10k. This may still lead to out of heap errors if the nodes eligible for delete have a significant number of relationsips.
For example if a node to be deleted as 1 million :FOLLOWS relationships then the delete of this single node will include the removal of this 1 node and the 1 million :FOLLOWS relationships.
For nodes with many relationships or widely varying degrees of nodes a single DETACH DELETE can still exceed the transaction heap boundaries. In these cases it’s better to delete the relationships first and then the nodes in batches. Here is an example for Neo4j 4.4.x and later
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Foo)-[r]-() where n.foo='bar'

// delete relationships
CALL { WITH r
DELETE r
} IN TRANSACTIONS OF 10000 ROWS

// reduce cardinality
WITH distinct n
// delete nodes
CALL { WITH n
DELETE n
} IN TRANSACTIONS OF 10000 ROWS;
Also, please consider reviewing KB document How to avoid using excessive memory on deletes involving dense nodes for other considerations.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-determine-number-of-nodes-and-relationships-effected-by-detach-delete;"How do I determine the number of nodes and relationships to be effected by a detach delete
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags delete
Prior to running a match …. detach delete n; which will find said nodes and delete all relationships associated with said nodes as well as delete the nodes themselves one might want to run a query to determine how many nodes/relationships will be effected.
For example, using the :play movies database as part of the Neo4j Browser, if one runs
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person) return count(n), sum ( size( (n)-[]->()));
this will report back
which would indicate that if you are to then run match (n:Person) detach delete n; this will effect
133 nodes and 253 relationships and as depicted
In this case the 133 nodes and 253 relationships is not a significantly large number. However, if the query was to return tens of thousands of nodes and relationships to be effected one should reconsider the approach and follow the document entitled Large Delete Transaction Best Practices in Neo4j
Was this page helpful?"
https://neo4j.com/developer/kb/how-deletes-workin-neo4j;"How deletes work in Neo4j
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags delete disk storage
Neo4j uses logical deletes to delete from the database to achieve maximum performance and scalability. To understand how this might appear to an operator of the database, lets take a simple case of loading data into Neo4j. When you start loading data, you can see the nodes are stored in a file called neostore.nodestore.db. As you keep loading, the file will keep growing.
However, once you start deleting nodes, you can verify that the file neostore.nodestore.db does not reduce in size. In fact, not only does the size remain the same, but you will also start to see the file neostore.nodestore.db.id grow - and keep growing for all records deleted.
This happens because of id re-use. Deletes in Neo4j do not physically delete the records, but rather just flip the bit from available to unavailable. We keep the deleted (but available to reuse) IDs in neostore.nodestore.db.id. This means the neostore.nodestore.db.id file acts sort of like a ""recycle bin"" where it stores all the deleted ids.
Now you’ve deleted the data and neostore.nodestore.db is the same size as before the delete, the neostore.nodestore.db.id file is larger than before the delete operation. How do you reclaim this space?
When you start loading new data after the deletes, Neo4j starts using the ids recorded in neostore.nodestore.db.id and thus the neostore.nodestore.db file does not grow in size and the file neostore.nodestore.db.id starts decreasing until it’s completely empty.
If you do not plan to add more nodes but still want to shrink the size of the database on disk, you can use the copy store util. This utility will read an offline database, copy it to a new one, and leave out data that is no longer in use (and also the list of eligible ids to re-use).
Large deletes can generate a lot of transaction logs. You should be aware of this when doing mass delete operations otherwise - ironically - your filesystem can potentially fill up.
Was this page helpful?"
https://neo4j.com/developer/kb/enabling-gc-logging;"Enabling GC Logging
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging garbage collection heap memory jvm
What is Garbage collection and why enabling it?
A garbage collection event is a complete pause of the java application (ie: neo4j-server).
It can be identified in the debug.log as a stop-the-world event.
For example:
If you notice issues with them such as too many pauses, too long of a pause, pauses causing cluster re-election, etc, you can enabling GC logging for easier integration with monitoring parsers.
Keep in mind the following regarding GC logging:
GC log files are cleared out when the database is restarted
They are crucial for the analysis of the Application Performance
It will add minor overhead
You might consider enabling this option on your live environments
Enabling GC logging
As indicated in the product documentation in 3.5 or newer, you can uncomment the following line to enable it:
Properties
Copy to Clipboard
#dbms.logs.gc.enabled=true
Save the file and restart your server.
GC log location
The log file will be written to the logs directory as specified here and named gc.log.<#>
Additional options
You can review our operational manual (3.5 or newer) for additional settings such as the number of rotated files or their size.
dbms.gc.log.options changes
dbms.gc.log.options differs due to the upgrade from Java 8 to 11 in 4.0.x.
We recommend to leave this commented so neo4j starts with working settings in both versions.
You can review those differences in the table below.
Table 1. Differences between 3.5.x and 4.0.x
neo4j version
configuration value
3.5.x
#dbms.logs.gc.options=-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution
4.0.x and higher
#dbms.logs.gc.options=-Xlog:gc*,safepoint,age*=trace
Was this page helpful?"
https://neo4j.com/developer/kb/long-pauses-caused-by-application-code-calling-system-gc;"Long GC Pauses caused by application code calling System.gc()
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging garbage collector heap memory jvm operations
When investigating the cause of long garbage collection cycles, it is often useful to enable GC logging.
You can do so by following the product documentation.
Once this is enabled, you can look through the GC log file for signs of problems.
When looking for Full GC messages, pay special attention to the details of the message.
If you see something like:
2019-05-02 17:53:16.622+0100 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=566, gcTime=596, gcCount=1}
In this case you are likely looking at a situation where the application code is invoking a full garbage collection cycle, whether or not it is needed. It is recommended to allow the JVM to make decisions on how and when to run garbage collection.
Do not to explicitly trigger ""stop the world"" events by calling System.gc().
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-manually-clear-the-node-and-relationship-cache;"Retired: How to manually clear the Node and Relationship Cache
Author Dave Gordon Applicable versions 2.1 2.2 Tags performance cache warmup
This is no longer applicable in Neo4j 2.3+ The second level object cache was removed in favor of a more scalable off-heap page-cache.
When troubleshooting transient issues or testing out queries on warm vs. cold cache, you may want to try clearing out the cache without necessarily restarting the Neo4j database.
To achieve this, you need to trigger the clear() method on the JMX bean for relationship and/or node cache.
See http://neo4j.com/docs/stable/jmx-mxbeans.html#jmx-cache-relationshipcache for details.
You can do this by connecting to your JVM using JConsole or JVisualVM, and navigating to the NodeCache and RelationshipCache JMX beans. Once there, simply invoke the clear() method.
Here is a screen capture of what JConsole looks like when executing this operation:
Was this page helpful?"
https://neo4j.com/developer/kb/warm-the-cache-to-improve-performance-from-cold-start;"Warm the cache to improve performance from cold start
Author Dave Gordon Applicable versions 2.1 2.2 2.3 3.1 3.2 3.3 3.4 3.5 4.0 4.1 4.2 4.3 Tags performance cache warmup
Note: For 3.5.x forward the details below are no longer applicable as Neo4j will keep record of what is in the pagecache at all times and upon restart of Neo4j the pagecache will be auto-warmed with the data which was previously in the pagecache. In 3.5.x forward the logs\debug.log will report similar to
2020-12-14 21:00:08.486+0000 INFO [o.n.k.i.p.PageCacheWarmer] Page cache warmup started.
2020-12-14 21:00:08.659+0000 INFO [o.n.k.i.p.PageCacheWarmer] Page cache warmup completed. 441 pages loaded. Duration: 173ms.
Note: For Neo4j 2.3+ there is no object cache anymore, so this warms up the page-cache which maps the Neo4j store files into memory.
You may find that some queries run much faster the second time they run. This is because on cold boot, a server node has nothing cached yet, and needs to go to disk for all records. Once some/all of the records are cached, you will see greatly improved performance.
One technique that is widely employed is to ""warm the cache"". At its most basic level, we run a query that touches each node and relationship in the graph. Assuming the data store can fit into memory, this will cache the entire graph. Otherwise, it will cache as much as it can. Give it a try and see how it helps you!
Cypher
Cypher (Server,Shell)
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
OPTIONAL MATCH (n)-[r]->()
RETURN count(n.prop) + count(r.prop);
In the above example the reference to count(n.prop) + count(r.prop) is used so as to force the optimizer to search for a node/relationship with a property named 'prop'. Replacing this with count(*) would not be sufficient for it would not load all of the node and relationship properties.
Java
Embedded (Java):
Copy to Clipboard
@GET @Path(""/warmup"")
public String warmUp(@Context GraphDatabaseService db) {
  try ( Transaction tx = db.beginTx()) {
    for ( Node n : GlobalGraphOperations.at(db).getAllNodes()) {
      n.getPropertyKeys();
      for ( Relationship relationship : n.getRelationships()) {
        relationship.getPropertyKeys();
        relationship.getStartNode();
      }
    }
  }
  return ""Warmed up and ready to go!"";
}
With 3.0 forward and the inclusion of APOC one can now warm up the cache by running the stored procedure
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.warmup.run()
This can help in many ways. Aside for pure performance improvement, it can also help alleviate upstream issues resulting from lagging queries. For example if the nodes are busy, and your load balancer/proxy has a very short timeout, it can appear that the cluster is not available initially, if none of the graph is in memory yet. If the cache is warmed, the short timeout shouldn’t be a concern on a cold cluster start.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-admin-load-causes-not-a-valid-neo4j-archive;"neo4j-admin load causes ""Not a valid Neo4j archive""
Author Kambiz Chehresa Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags dump load neo4j-admin linux
When using neo4j-admin load for loading a .dump file, following error is observerd:
Shell
Copy to Clipboard
$ neo4j-admin load --from=/var/lib/neo4j/neo4j.dump --database=neo4j --force --verbose
org.neo4j.cli.CommandFailedException: Not a valid Neo4j archive: /
Caused by: org.neo4j.dbms.archive.IncorrectFormat: /var/lib/neo4j/neo4j.dump
at org.neo4j.dbms.archive.Loader.openArchiveIn(Loader.java:172)
at org.neo4j.dbms.archive.Loader.load(Loader.java:74)
at org.neo4j.commandline.dbms.LoadCommand.load(LoadCommand.java:131)
... 11 more
Caused by: java.util.zip.ZipException: Not in GZIP format
Sometimes this has nothing to do with the formatting of the .dump file as indicate by Not in GZIP format, but an OS setting interfering with a Java System property.
Java uses the System property java.io.tmpdir and on most Linux flavor machines this usually defaults to /tmp. The location is a directory used by the JVM to create and store temporary files. Some system administrators when following security best practices in order to limit their attack surface, make sure that /tmp is mounted with noexec option. This option prompts the kernel to refuse to allow any code execution and or storage performed against this location.
One approach to troubleshoot:
Check if this option set. For example on a RHEL server:
Shell
Copy to Clipboard
$ mount | grep /tmp
tmpfs on /tmp type tmpfs (rw,noexec,relatime,seclabel,size=524288k)
So on this machine /tmp is setup with noexec option.
Fix / Workaround:
Override java.io.tmpdir default setting from /tmp to another location and then running neo4j-admin load.
For example:
Shell
Copy to Clipboard
$ export _JAVA_OPTIONS=""-Djava.io.tmpdir=/var/lib/neo4j/import/temp""
$ neo4j-admin load --from=/var/lib/neo4j/neo4j.dump --database=neo4j --force
Done: 34 files, 971.0KiB processed.
Was this page helpful?"
https://neo4j.com/developer/kb/database-compaction-in-40-using-neo4j-admin-copy;"Database Compaction in 4.0 using Neo4j-admin copy
Author Umar Muzammil Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags store compaction
This article demonstrates using the neo4j-admin copy tool to reclaim un-used space occupied by neo4j store files.
1). Adding 100k nodes: foreach (x in range (1,100000) | create (n:testnode1 {id:x})).
2). Checking allocated ID range: MATCH (n:testnode1) RETURN ID(n) as ID order by ID limit 5.
IDs ascending: 0, 1, 2, 3, 4; IDs descending: 99999, 99998, 99997, 99996, 99995.
3). Execute :sysinfo: Total Store Size=18.6 MiB, ID Allocation: Node ID 100000, Property ID 100000.
4). We may then delete the above created nodes by Match (n) detach delete n.
5). Total store size reported as :sysinfo: Total Store Size=18.6 MiB, ID Allocation: Node ID 100000, Property ID 100000.
6). We may then execute a full neo4j-admin backup (https://neo4j.com/docs/operations-manual/current/backup-restore/online-backup/) to perform an online backup which by default executes a checkpoint (to flush any cached updates in pagecache to store files).
7). From step 6 above, it seems that the allocated IDs remain unchanged and that the store-size has not altered despite deletion. If at this point, or in a production database where numerous load/deletes are frequently performed and may result in significant un-used space occupied by store files, we could use the neo4j-admin copy tool (essentially a merger of store-utils) introduced in 4.0 (https://neo4j.com/docs/operations-manual/current/tools/neo4j-admin/#neo4j-admin-syntax-and-commands). We may then use the backup performed in step 6 to execute the neo4j-admin copy tool. Note that neo4j-admin copy may ONLY be executed ON AN OFFLINE DATABASE OR BACKUP.
8). Execute neo4j-admin copy e.g. as:
Shell
Copy to Clipboard
$./bin/neo4j-admin copy --from-database=neo4j --to-database=1/backups/copy:

Starting to copy store, output will be saved to: /$neo4j_home/logs/neo4j-admin-copy-2020-01-16.12.06.38.log
2020-01-16 12:06:38.777+0000 INFO [StoreCopy] ### Copy Data ###
2020-01-16 12:06:38.778+0000 INFO [StoreCopy] Source: /Users/um/neo4j/4.0/cc/1/data/databases/neo4j
2020-01-16 12:06:38.778+0000 INFO [StoreCopy] Target: /Users/um/neo4j/4.0/cc/1/data/databases/1/backups/copy
2020-01-16 12:06:38.779+0000 INFO [StoreCopy] Empty database created, will start importing readable data from the source.
2020-01-16 12:06:40.159+0000 INFO [o.n.i.b.ImportLogic] Import starting

Import starting 2020-01-16 12:06:40.227+0000
  Estimated number of nodes: 0.00
  Estimated number of node properties: 0.00
  Estimated number of relationships: 0.00
  Estimated number of relationship properties: 0.00
  Estimated disk space usage: 3.922MiB
  Estimated required memory usage: 7.969MiB

(1/4) Node import 2020-01-16 12:06:40.604+0000
  Estimated number of nodes: 0.00
  Estimated disk space usage: 1.961MiB
  Estimated required memory usage: 7.969MiB
(2/4) Relationship import 2020-01-16 12:06:42.804+0000
  Estimated number of relationships: 0.00
  Estimated disk space usage: 1.961MiB
  Estimated required memory usage: 7.969MiB
(3/4) Relationship linking 2020-01-16 12:06:43.046+0000
  Estimated required memory usage: 7.969MiB
(4/4) Post processing 2020-01-16 12:06:43.461+0000
  Estimated required memory usage: 7.969MiB
-......... .......... .......... .......... ..........   5% ∆226ms
.......... .......... .......... .......... ..........  10% ∆1ms
.......... .......... .......... .......... ..........  15% ∆1ms
.......... .......... .......... .......... ..........  20% ∆1ms
.......... .......... .......... .......... ..........  25% ∆0ms
.......... .......... .......... .......... ..........  30% ∆1ms
.......... .......... .......... .......... ..........  35% ∆0ms
.......... .......... .......... .......... ..........  40% ∆1ms
.......... .......... .......... .......... ..........  45% ∆0ms
.......... .......... .......... .......... ..........  50% ∆1ms
.......... .......... .......... .......... ..........  55% ∆0ms
.......... .......... .......... .......... ..........  60% ∆0ms
.......... .......... .......... .......... ..........  65% ∆1ms
.......... .......... .......... .......... ..........  70% ∆0ms
.......... .......... .......... .......... ..........  75% ∆1ms
.......... .......... .......... .......... ..........  80% ∆0ms
.......... .......... .......... .......... ..........  85% ∆0ms
.......... .......... .......... .......... ..........  90% ∆1ms
.......... .......... .......... .......... ..........  95% ∆0ms
.......... .......... .......... .......... .......... 100% ∆1ms

IMPORT DONE in 3s 860ms.
Imported:
  0 nodes
  0 relationships
  0 properties
Peak memory usage: 7.969MiB
2020-01-16 12:06:44.031+0000 INFO [o.n.i.b.ImportLogic] Import completed successfully, took 3s 860ms. Imported:
  0 nodes
  0 relationships
  0 properties
2020-01-16 12:06:44.318+0000 INFO [StoreCopy] Import summary: Copying of 200622 records took 5 seconds (40124 rec/s). Unused Records 200622 (100%) Removed Records 0 (0%)
2020-01-16 12:06:44.318+0000 INFO [StoreCopy] ### Extracting schema ###
2020-01-16 12:06:44.319+0000 INFO [StoreCopy] Trying to extract schema...
2020-01-16 12:06:44.330+0000 INFO [StoreCopy] ... found 0 schema definition. The following can be used to recreate the schema:
2020-01-16 12:06:44.332+0000 INFO [StoreCopy]
View all (50 more lines)
Above example completed in around 6s, and resulted in a compact as well as consistent store (any inconsistent nodes, properties, relationships are not copied over to the newly created store). Another point to note is that the above ""/copy"" of the was created at $neo4j_home/data/databases/neo4j/1/backups/copy, instead of /current-directory/1/backups/copy, since the copy tool prefixes $neo4j_home/data/databases/<database_name> to the specified destination directory.
9). We may then restore the above copy as on a standalone Neo4j 4.0 instance and compare the difference in store size to the previous 61.6MiB: Execute ./sa/bin/neo4j-admin restore --from=cc/1/data/databases/1/backups/copy --verbose --database=sa/data/databases/neo4j --force
Note that the restored neo4j databases got restored to $neo4j_home/data/databases/sa/data/databases, again prefixing the specified destination directory with $neo4j_home/data/databases
10). Finally, compare the total store-size now (following compaction) to that before:
sysinfo on the above restored database now shows a total store size = 800.00 KiB in this example
This shows that neo4j-admin copy tool successfully compacted the store and the OS reclaimed the space reserved by the ID stores for future ID creates.
References:
https://neo4j.com/docs/operations-manual/current/tools/neo4j-admin/#neo4j-admin-syntax-and-commands
https://github.com/jexp/store-utils
https://neo4j.com/docs/operations-manual/current/backup-restore/online-backup/
https://neo4j.com/docs/operations-manual/current/backup-restore/restore-backup/
https://neo4j.com/docs/operations-manual/current/tools/consistency-checker/
Was this page helpful?"
https://neo4j.com/developer/kb/running-copy-store-tool-on-windows;"Running copy store tool on windows
Author José Rocha Applicable versions 3.3 3.4 3.5 Tags performance copy store tools
The copy store utilities is a set of tools to compact, copy, fix and analyse Neo4j stores. You might already know this but if not, you can read more about it here.
You will notice that the execution is done by running a linux script. While we do not have any Windows batch file or Powershell script but we can run the copy store tool on Windows by following these easy steps:
Install OpenJDK or Oracle JDK
Download & Unpack Maven
Clone or download the copy store tool version correspondent that matches your Neo4j version here
You need to be running the correct version of the copy store tool for your Neo4j version. If you are running Neo4j 3.3.x, you should use the copy store version 3.3.4 for example.
Open a command window, browse to GitHub repository contents on your local hard-drive and run the following command:
Shell
Copy to Clipboard
$ ${maven.home}/mvn.cmd clean compile exec:java -Penterprise -e -Dexec.mainClass=""org.neo4j.tool.StoreCopy"" -Ddbms.pagecache.memory=2G -Ddbms.pagecache.memory.source=1G -Dexec.args=""<SOURCE PATH> <DESTINATION PATH>""
such as:
Shell
Copy to Clipboard
$ c:\apache-maven-3.6.0\bin\mvn.cmd clean compile exec:java -Penterprise -e -Dexec.mainClass=""org.neo4j.tool.StoreCopy"" -Ddbms.pagecache.memory=2G -Ddbms.pagecache.memory.source=1G -Dexec.args=""c:\\Users\\headw\\share\\neo4j-enterprise-3.4.9\\data\\databases\\graph.db c:\\sc.db""
You’ll need to set both the source and destination path by changing: -Dexec.args=""<SOURCE PATH> <DESTINATION PATH>"". Also, you can change -Ddbms.pagecache.memory=2G and -Ddbms.pagecache.memory.source=1G to change the memory consumption of this tool. You can get more information on the actual tool in its GitHub repo
This will compile and run the copy store utility on a Windows command line window.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-perform-the-equivalent-of-a-sql-ctas;"How do I perform the equivalent of a SQL Create Table as Select with Cypher
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags copy sql
With a traditional SQL RDBMS one could perform a create table as select (i.e. CTAS) whereby its purpose is to create a new table and copy existing data from the original table to the new copy. If you are looking to achieve the same with Cypher this can be performed via
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
MERGE (m:New_Movie)
SET m=n;
The above will copy all Movie nodes and their properties to a set of new nodes with the label New_Movie. If you have a significant number of Movie nodes you may not want to copy all nodes in a single transaction, for example you may want to run utilize apoc.periodic.iterate
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.periodic.iterate(""MATCH (n:Movie) RETURN properties(n) as props"", ""CREATE (m:New_Movie) SET m = props"",{});
As with a CTAS statement, this does not copy any underlying schema indexes or constraints on said label. Additionally, if the Movie nodes have additional labels they will not be copied to the New_Movie nodes.
Was this page helpful?"
https://neo4j.com/developer/kb/using-the-actual-data-type-with-neo4j-import;"Using the ACTUAL data type with neo4j-import
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags import neo4j-admin csv store
When importing data using neo4j-admin import, make sure to review the required CSV file structure and considerations before moving on.
https://neo4j.com/docs/operations-manual/current/tools/import/
ACTUAL vs. String (default) or Integer:
Each node in the CSV must have an :ID, which can be in the format Integer, String, or ACTUAL. By default it is String, and one can specify Integer explicitly in the header. However, the reality is that performance and memory-wise, both are about equal, and using the default is fine.
Using Integer or String is a bit more memory intensive that using ACTUAL, so one may be tempted to go for that option. However, this is actually not usually the best option, unless you have a specific use case for it.
What is ACTUAL, and why is it special?
ACTUAL refers to the actual node ID, which in Neo4j, means the actual location of that record on disk. When using ACTUAL with neo4j-import, all `:ID`s must be ordered, and they must be ordered across ALL CSV files being imported during the load. This is generally difficult to achieve, particularly in an existing data set, and one that is quite large and complex.
Assuming you have ordered all of the nodes across all CSV files to be imported, one must also consider whether there are gaps in those IDs. Any gaps will yield places on disk where we will not use that area for storage, and will potentially reduce the amount of storage space you have available for the graph data store.
Lastly, avoid using large ids with ACTUAL, as this will greatly increase the size of your store files, which should be avoided for obvious reasons.
Take home message:
If you use low, consecutive, ordered :ID`s, `ACTUAL should work fine for you, but it does require knowledge of the internal storage architecture and can be challenging to keep all of the nodes in order across CSV files.
neo4j-admin import is intended to populate a new, empty database. It cannot be used to import into an existing database.
Was this page helpful?"
https://neo4j.com/developer/kb/store-format-versions;"Store Format Versions Reference Guide
Author Dave Gordon Applicable versions 2.x 3.1 3.2 3.3 3.4 3.5 Tags store version
In some situations, you may see a log message or exception that refers to a store format version, and it is not clear which Neo4j store format it is referring to. Please use the table below to map store format versions to Neo4j Server versions.
Note: Standard is the default in Enterprise and the only format available in Community. It has a limit of 34B nodes, 34B relationships, 68B properties. High Limit is only available in Enterprise and supports virtually unlimited numbers of nodes, relationships and properties.
Standard Store Versions
Store Format Name Store Format Version Neo4j Server Version
STANDARD_V2_0
v0.A.1
2.0.0
STANDARD_V2_1
v0.A.3
2.1.0
STANDARD_V2_2
v0.A.5
2.2.0
STANDARD_V2_3
v0.A.6
2.3.0
STANDARD_V3_0
v0.A.7
3.0.0
STANDARD_V3_2
v0.A.8
3.2.0
STANDARD_V3_4
v0.A.9
3.4.0
High Limit Store Versions
Store Format Name Store Format Version Neo4j Server Version
HIGH_LIMIT_V3_0_0
vE.H.0
3.0.0
HIGH_LIMIT_V3_0_6
vE.H.0b
3.0.6
HIGH_LIMIT_V3_1_0
vE.H.2
3.1.0
HIGH_LIMIT_V3_2_0
vE.H.3
3.2.0
HIGH_LIMIT_V3_4_0
vE.H.4
3.4.0
Inspecting a store’s format
You can use the neo4j-admin store-info against an offline store to find out what format it is using. Example:
Shell
Copy to Clipboard
$ ./bin/neo4j-admin store-info --store=data/databases/mygraph.db
Store format version:         v0.A.9
Store format introduced in:   3.4.0
Was this page helpful?"
https://neo4j.com/developer/kb/cypher-to-determine-version-and-edition-of-neo4j;"Using Cypher how do I determine the version and edition of Neo4j
Author Vivek Saran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags edition version
If you want to determine version and edition of the running Neo4j instance this can be accomplished via running the following cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.components() yield name, versions, edition unwind versions as version return name, version, edition;
The expected output will be:
name        | version   | edition
------------|-----------|-----------
Neo4j Kernel¦  3.5.6    ¦enterprise
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-memory-configurations-for-neo4j-admin-backup;"Understanding memory configurations for neo4j-admin backup
Author Dana Canzano Applicable versions 3.2 Tags neo4j-admin backup
When using bin\neo4j-admin backup to backup a Neo4j database, Neo4j Support recommends explicitly defining the JVM heap size and pagecache memory to be used by the backup JVM process. If these are not defined then when neo4j-admin backup is executed, the JVM will allocate a default heap size and the pagecache will use the value defined in the dbms.memory.pagecache.size setting from conf/neo4j.conf. In most cases the conf/neo4j.conf defines these parameters such that they consume over 60% of total RAM. As such, if neo4j-admin backup were to allocate the same values for heap and pagecache as the running Neo4j process, we would consume all available RAM leading to backup failure and out of memory conditions.
To specify the JVM heap for neo4j-admin backup, set the environment variable HEAP_SIZE, for example:
Shell
Copy to Clipboard
$ export HEAP_SIZE=2G
To specify the pagecache allocation for neo4j-admin backup,
Neo4j 3.3.1 forward As a result of PR 10463, specify the pagecache value on the command line through --pagecache=XXM
replacing XX with the about of megabytes to allocate for the pagecache. The --pagecache command line argument overrides any and all other defined pagecache settings in any neo4j.conf files.
Neo4j 3.2.x through Neo4j 3.3.0
first create a directory specific for the backup config file and then set the environment variable NEO4J_CONF:
Shell
Copy to Clipboard
$ export NEO4J_CONF=/tmp/backup/
+ Then, in /tmp/backup create a file named neo4j.conf with the following content:
Properties
Copy to Clipboard
dbms.memory.pagecache.size=12G
+ For environments that were installed through Debian (i.e. apt-get install neo4j-enterprise) you will also need to add
Properties
Copy to Clipboard
dbms.directories.lib=/usr/share/neo4j/lib
+ to this neo4j.conf file.
Be sure not to exceed the total physical RAM on the server between the Neo4j database plus the backup process.
Was this page helpful?"
https://neo4j.com/developer/kb/troubleshooting-neo4j-desktop-linux;"Troubleshooting Neo4j Desktop Issues on Linux
Author Angelo Gazzola Applicable versions neo4j desktop 1.x Tags desktop linux
This page describes common issues users may encounter when running Neo4j Desktop on Linux.
Error: The SUID sandbox helper binary was found, but is not configured correctly.
The SUID sandbox helper binary was found, but is not configured correctly.
Rather than run without sandboxing I'm aborting now.
You need to make sure that /tmp/.mount_neo4j-0qHCJ1/chrome-sandbox is owned by root and has mode 4755.
Explanation
Neo4j Desktop is an Electron app.
Electron is using a feature from the Linux kernel that is disabled in some distributions (eg. Debian).
They have a fallback binary for these cases but it seems like electron-builder is packaging it with the wrong permissions, hence the permission error you got.
This comment explains the issue more in detail.
Solution
Execute Neo4j Desktop (as a regular user) with the --no-sandbox flag, or run this command to enable the kernel feature Electron is using:
Shell
Copy to Clipboard
$ sysctl kernel.unprivileged_userns_clone=1
Error: The name org.freedesktop.secrets was not provided by any .service files
App initialization error: Error: The name org.freedesktop.secrets was not provided by any .service files {
  constructor: 'Error',
  stack: 'Error: The name org.freedesktop.secrets was not provided by any .service files'
}
Explanation:
Neo4j Desktop uses the system keyring to store credentials. On Linux (regardless of distribution or desktop environment) this is gnome-keyring. On previous versions not having gnome-keyring would make the application fail to start. Now it switches to the built-in keyctl utility if it can’t find gnome-keyring.
Solution:
Update to the latest Neo4j Desktop or install and enable gnome-keyring.
Error: spawn keyctl ENOENT
Error: spawn keyctl ENOENT
Explanation
keyctl is a key management utility used as a fallback when gnome-keyring is not available as the system keyring.
This utility is included in the core packages of most distributions, but if you see this error it means you don’t have it installed.
Solution
Install the keyutils or gnome-keyring.
Error: Neo4j Desktop is not showing in the applications menu.
Neo4j Desktop is not showing in the applications menu.
Explanation
Neo4j Desktop is distributes as an AppImage.
Solution
Install AppImageLauncher and integrate the Neo4j Desktop AppImage.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-desktop-password-change-failure;"Neo4j Desktop password change failure
Author Umar Muzammil Applicable versions 3.3 Tags logging query monitoring desktop
This document provides info and resolution for the error message on a clean install of Desktop 1.0.2x, Neo4j DB version 3.3.x mentioning ""Database failed to create: Error: Could not change password neo4j""
Error:
Error message on a clean install of Desktop 1.0.2x, Neo4j DB version 3.3.x, error says: ""Database failed to create: Error: Could not change password neo4j""
Fix:
Cause is a lack of permissions on the auth files at $NEO4J_HOME/data/dbms/ usually encountered upon an upgrade or a re-install without completely removing previous installation directories. Emptying %NEO4J_HOME%/data/dbms, followed by Neo4j-Desktop restart should fix it.
Was this page helpful?"
https://neo4j.com/developer/kb/resolve-port-conflicts-in-neo4j-desktop;"Resolve Port Conflicts in Neo4j Desktop
Author Umar Muzammil Applicable versions neo4j desktop 1.x Tags desktop
Occasionally upon upgrade or re-install, Neo4j Desktop may throw a repetitive port conflict exception for ports 7474, 7687, 7473, whilst providing a ""Fix Configuration"" option. However, selecting this option does not resolve the port conflict in certain cases. Attempting to start the database with the play button results in a port conflict notification prompting to fix configuration. Clicking on fix configuration changes nothing and the database does not start up.
Database does start up using bin\neo4j console and is accessible via a standalone chrome browser, whilst launching the neo4j browser throws the error suggesting invalid credentials, use :server connect. Issuing :server connect throws the error credentials provided could not be used.
First thing to check is whether the default/configured http, https, bolt ports are allowed in the OS firewall and/or antivirus. The second check is to do an nc -l -p <port> which will check the port availability locally and also whether the port is already in use by another application/process. A variant of this is nc -v <hostname> <port> where neo4j server is on a remote instance. For windows, one can use the built-in telnet tool via the command prompt e.g. as telnet hostname.domain.com 7687.
Following above checks, it is worth attempting taking a backup of the .Neo4jDesktop directory at /Users/user/ /Library/Application Support/ on MacOSX or %USERPROFILE%.Neo4jDesktop\ and %USERPROFILE%\AppData\Roaming\Neo4j Desktop\ on Windows, then removing these directories, followed by a re-install of the desired Neo4j Desktop version and an OS restart.
If port conflict persists, the next step in troubleshooting is to check for potential issues with the OS’s hosts file. Hosts file on Linux and Mac OS is found at (/etc/hosts). Windows has a hosts file as well, on Windows you can find it in \Windows\System32\drivers\etc\. A quick check to test whether the OS is able to correctly resolve hostnames, one can execute in cmd tracert localhost, which should print a single hop. The only line in the hosts file is the following line, and we can comment out, delete or modify this line or file if needed . A sample output is:
Shell
Copy to Clipboard
$ traceroute localhost
traceroute to localhost (127.0.0.1), 64 hops max, 52 byte packets
 1  localhost (127.0.0.1)  1.167 ms  0.112 ms  0.085 ms
If the trace route returns an empty result, try commenting out everything related to localhost in the hosts file. Then try running the command tracert localhost again. Following this, try starting a graph database in Desktop to see if the issue has been resolved. The line in hosts file should be commented out when testing in Desktop.
The above steps have been tested to alleviate port conflict issues encountered.
References: https://www.makeuseof.com/tag/modify-manage-hosts-file-linux/
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-use-activation-keys;"How activation keys work
Author Andreas Kollegger Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags desktop
Summary
Activation keys are mini-contracts that are signed by Neo4j, granting access to a ""feature"". Typically, features are entire applications like ""Neo4j Desktop"" or ""Neo4j Bloom"" but they may be also be used to toggle features within an application, like the experimental ""application drawer"" in Neo4j Desktop.
The content of an activation-key is signed with a private cryptographic key. Applications like Neo4j Desktop contain the paired cryptographic public key, allowing them to validate that the activation-key has not been altered. Neo4j Desktop itself has been code-signed for distribution on Windows and MacOS, forming a chain of trust which allows us to make use of the activation-key.
To be buzzword-friendly, you could say that an activation key is a single-link block chain. :)
Keys in Neo4j Desktop
Neo4j Desktop supports using activation keys for a few features:
registering Neo4j Desktop itself, as a manual alternative to the Social Sign-in registration
activating Graph-Apps: Neo4j Bloom, Neo4j ETL
activating some experimental features
Business rules for keys in Neo4j Desktop:
activating a Graph-App installs that app. Once installed, the app can be used forever.
an expired Graph-App key can not be used for installation.
an expired Graph-App key will be prevent updates from being installed, but will not disable the Graph-App
Installing Activation Keys
Start Neo4j Desktop
Open the ""Software Keys"" drawer
Click on ""+ Add software Key""
Paste in the entire contents of the activation key
Problem solving:
often, users will copy&paste just the ""signature"" field from the key. It is necessary to paste in the entire key
sometimes, keys will get altered in transit by an email server or client, or a virus-protection software. Take a look at the key to see if any fields look funny
Keys for Neo4j Bloom
How to install activation keys
Formats
Version 1 — YAML
Yaml
Copy to Clipboard
########################################
# NEO4J SOFTWARE FEATURE ACTIVATION CODE
activationVersion: 1.0.0
featureName: neo4j-bloom
featureVersion: <2.0
registrant: Neo4j Employee
organization: 'Neo4j, Inc.'
email: andreas@neo4j.com
publisher: neo4j.com
expirationDate: '2019-07-02'
signature: >-
  3a0304b4658bdeb1469aaab512bf13b86f41a0ad4fcb60a5f00e97198bde361830ed00291b82c0bc5d5a24d6b727ea50ce46e2a40c0489d95303881348bb4627a510623e98a1738d32b97064d868597f39abaa52a249fa7df545c374f901a5cb6fdf40ec90c0076d42186152abeaf477095f3b6eb00738c801642028454da93e5211b460cf96216c659225cd64328d6c3513c08dce3f2d7ef6d8a1681f514d650314626003bf9ee863aacab9944de79b3761589dc7b5653bd9d8d36a311de75bdb06390bd0f70b039c5151165c570be252b8760ec5442ae8e3b0402588f9f27515d2dcadc270f6fa4eda89f4cae6fd9d4002e0d8f5035ad7c2d6fe0d6da0529d
Fields:
activationVersion: version of the license format (semver)
featureName: (kebab-case org-featureName, where featureName may be further segmented using camelCase)
featureVersion: valid version range (semver range)
registrant: full name of contact person (Title Case)
organization: official name of registrant’s organization (string)
email: contact address for registrant (email)
publisher: domain name of feature publisher (FQDN)
expirationDate: year-month-day of expiration (string)
signature: cryptographic signature of fields (hex)
Version 2 — JWT
Was this page helpful?"
https://neo4j.com/developer/kb/convert-an-appimage-file-into-executable-on-linux-ubuntu-debian;"Launching Neo4j Desktop in Linux (Ubuntu & Debian) with an .appimage file
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags install desktop
Neo4j installation on Linux using apt-get, as per the process here, distributes installation files across multiple system directories e.g. /etc, /var/log, /home/neo4j, etc…
A quicker way to install is using the .appimage file directly from https://neo4j.com/download/
The download for linux distributions is in the form of a .appimage file. AppImage files can then run without installation or the need for root priviledges.
Example: If the file is downloaded to /home/neo4j/Downloads/neo4j-desktop-1.0.3-x86_64.AppImage, then from terminal run the following commands at this location:
Shell
Copy to Clipboard
$ chmod a+x neo4j-desktop-1.0.3-x86_64.AppImage

$ ./neo4j-desktop-1.0.3-x86_64.AppImage
This creates an executable at /home/neo4j/Downloads/ in this example, which can just be double-clicked to launch the Neo4j Desktop application.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-setup-neo4j-to-startup-on-linux-server-reboot;"How to Setup Neo4j to Startup on Linux Server Reboot
Author Shawn Tozeski Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags startup linux
If you want to emulate the Neo4j RPM service with a tar installation on Linux systems, do the following steps:
As root:
Copy the $NEO4J_HOME/bin/neo4j script file to /etc/init.d
Edit the /etc/init.d/neo4j script file to uncomment the NEO4J_HOME variable and set this to the correct Neo4j home value. The NEO4J_HOME variable setting in the section marked:
# Provides these environment variables:
NEO4J_HOME=<full_path_to_your_NEO4J_HOME>
Once you have made these changes, then you can manually start and start neo4j as service as root.
If you execute the following as root, this will start neo4j as the ""neo4j"" user, so the pid will be owned by this user:
Shell
Copy to Clipboard
# su - neo4j -c ""service neo4j start""
If your neo4j user for example has sudo privileges, you can also perform these commands from the user level:
Shell
Copy to Clipboard
$ sudo service neo4j start
To setup the automation of stop/start of Neo4j when the Linux server is rebooted, follow these steps:
As root:
a) Create the file /etc/init.d/neo4j_ctl with the following contents:
Bash
Copy to Clipboard
#!/bin/sh

        OWNER=neo4j #Set to the owner of the Neo4j installation

        case ""$1"" in
        'start')
            su - $OWNER -c ""service neo4j start""
            ;;
        'stop')
            su - $OWNER -c ""service neo4j stop""
            ;;
        'restart')
            su - $OWNER -c ""service neo4j restart""
            ;;
        *)
             
             1
            ;;
        
         0
View all (5 more lines)
b) Set the permissions for the script:
Shell
Copy to Clipboard
# chmod 744 /etc/init.d/neo4j_ctl
c) Test the script by shutting down the database
Shell
Copy to Clipboard
# /etc/init.d/neo4j_ctl stop
d) Test the script by starting up the database
Shell
Copy to Clipboard
# /etc/init.d/neo4j_ctl start
e) Configure the system to start Neo4j at the correct run level and to stop Neo4j at run level 0.
Run the following to determine the Linux run level to run in:
Shell
Copy to Clipboard
# /sbin/runlevel
If run level is 3 then follow these steps:
Shell
Copy to Clipboard
# cd /etc/rc3.d
# ln -s ../init.d/neo4j_ctl S40neo4j_ctl
# cd /etc/rc0.d
# ln -s ../init.d/neo4j_ctl K30neo4j_ctl
If runlevel is 5 then follow these steps :
Shell
Copy to Clipboard
# cd /etc/rc5.d
# ln -s ../init.d/neo4j_ctl S40neo4j_ctl
# cd /etc/rc0.d
# ln -s ../init.d/neo4j_ctl K30neo4j_ctl
f) Restart the Linux system and check that Neo4j is automatically restarted.
Was this page helpful?"
https://neo4j.com/developer/kb/increasing-systemd-thread-limits;"Increasing Systemd Thread Limits
Author Phil Stott Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags configuration linux systemd
Problem
In some high workload, and large scale multi-database environments, you may find that your Systemd unit configuration limits the maximum number of processes (""tasks"") too low for your use case.
When this problem occurs, you can see the following in the Neo4j debug.log file:
java.lang.OutOfMemoryError: unable to create native thread: possibly out of memory or process/resource limits reached
If you are looking at the output from systemctl status neo4j you will see the number of running tasks is at or near to the limit, 4915 in this example:
● neo4j.service - Neo4j Graph Database
Loaded: loaded (/lib/systemd/system/neo4j.service; enabled; vendor preset: enabled)
Active: active (running) since Thu 1970-01-01 00:00:00 UTC; 48min ago
Main PID: 20000 (java)
Tasks: 4915 (limit: 4915)
CGroup: /system.slice/neo4j.service
  ├─20000 /usr/bin/java     org.neo4j.server.startup.Neo4jCommand console
  └─20047 /usr/lib/jvm/java-11-openjdk-amd64/bin/java     com.neo4j.server.enterprise.EnterpriseEntryPoint
Looking further, you might find this reported in your Linux syslog or messages file as something similar to:
Jan 01 00:48:00 neo4j-core1 kernel: [ TIME ] cgroup: fork rejected by pids controller in /system.slice/neo4j.service
Jan 01 00:48:02 neo4j-core1 neo4j[ PID ]: [ TIME ][warning][os,thread] Failed to start thread - pthread_create failed (EAGAIN) for attributes: stacksize: 1024k, guardsize: 0k, detached.
Jan 01 00:48:02 neo4j-core1 neo4j[ PID ]: Exception in thread ""neo4j.Scheduler-1"" java.lang.OutOfMemoryError: unable to create native thread: possibly out of memory or process/resource limits reached
Systemd may then terminate and restart Neo4j Server.
Workaround
In these cases, you may want to conservatively increase the maximum thread limit as a workaround. This should only need to be temporary in all but the most extreme cases.
First, ensure Neo4j is stopped:
systemctl stop neo4j
Then edit the neo4j.service unit file:
systemctl edit neo4j
and add/increase the TasksMax setting:
Properties
Copy to Clipboard
[Service]
# The user and group which the service runs as.
User=neo4j
Group=neo4j

# If it takes longer than this then the shutdown is considered to have failed.
# This may need to be increased if the system serves long-running transactions.
TimeoutSec=120

# Increase the systemd process / task limit
TasksMax=6500
After uncommenting the above lines, restart neo4j.
systemctl daemon-reload
systemctl start neo4j
Again, be very conservative when increasing the task limit for a system service. High process thread counts can be a strong indicator of poor configuration, sizing issues, or plugins that are misbehaving.
As with all workarounds, they should be used sparingly until a root cause can be fully identified and a more permanent solution put in place.
Was this page helpful?"
https://neo4j.com/developer/kb/debian-apt-get-failing-to-update-neo4j;"Debian: apt-get failing to update Neo4j
Author John Forrest Tags debian ubuntu
The common cause is an out of date gpg key.
To update then run the following command:
Shell
Copy to Clipboard
$ wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
See also the information on: https://debian.neo4j.com
You can get more information about running Neo4j on Debian at: https://neo4j.com/docs/operations-manual/current/deployment/single-instance/debian/.
If you continue to have issues please consult https://community.neo4j.com and contact Neo4j support.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-log-to-neo4jlog-in-a-server-plugin;"How to log to neo4j.log in a Server Plugin
Author Dave Gordon Applicable versions 3.0 3.1 Tags java api logging plugin
As part of the major changes in 3.0, the way to log to the user log, now neo4j.log (in server mode), has changed. To log within a Server Plugin follow these steps:
Include these packages:
Java
Copy to Clipboard
import org.neo4j.logging.Log;
import org.neo4j.logging.LogService;
import org.neo4j.kernel.internal.GraphDatabaseAPI;
+ . In the method for the Server Plugin, you need the following code to use the logger:
Java
Copy to Clipboard
    @PluginTarget(GraphDatabaseService.class)
    public Iterable<String> getAllLabels(@Source GraphDatabaseService graphDb) {
        LogService logService = ((GraphDatabaseAPI)graphDb).getDependencyResolver().resolveDependency( LogService.class );
        Log log = logService.getUserLog( getClass() );
+ . Now log using the appropriate method for the log object:
Java
Copy to Clipboard
log.info( ""Hello world!"" );
log.debug( ""Hello debuggers!"" );
We get a log that contains lines like this:
2016-12-05 17:33:21.223+0000 INFO  Hello world!
2016-12-05 17:33:21.345+0000 DEBUG  Hello debuggers!
Was this page helpful?"
https://neo4j.com/developer/kb/startup-failure-misconfigured-unmanaged-extensions-or-plugins;"Startup failure due to misconfigured unmanaged extensions or plugins
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags unmanaged extension plugin startup
Occasionally, following upgrades, one might encounter Neo4j server initialisation failure due to an exception similar to:
2019-11-14 12:57:40.446+0000 ERROR Failed to start Neo4j:
Starting Neo4j failed: Component 'org.neo4j.server.AbstractNeoServer$ServerComponentsLifecycleAdapter@7f7eeaaf' was successfully
initialized, but failed to start. Please see the attached cause exception ""The ResourceConfig instance does not contain any root
resource classes."". Starting Neo4j failed: Component 'org.neo4j.server.AbstractNeoServer$ServerComponentsLifecycleAdapter@7f7eeaaf'
was successfully initialized, but failed to start. Please see the attached cause exception ""The ResourceConfig instance does not
contain any root resource classes."".
This exception is usually thrown in following situations:
When the plugins directory (by default set to $NEO4J_HOME/plugins), contains an invalid plugin JAR. When the JAR no longer corresponds to the newly upgraded Neo4j version. When the path defined by dbms.unmanaged_extension_classes is invalid or unreachable. When the unmanaged extension hosted at the path does not contain the required resource classes as highlighted by the exception.
If using plugins (Neo4j or custom), e.g. using apoc, ensure that there is only one plugin version compatible with the currently installed Neo4j version.
Further, assuming that the present use of any configured unmanaged extensions is not required. Simplest workaround to achieve server initialisation, halted by the above exception, is to comment this setting in neo4j.conf as #dbms.unmanaged_extension_classes. If the extension is indeed required, the configuration path and permissions must then be verified and finally the presence of the classes required for the extension to work.
Was this page helpful?"
https://neo4j.com/developer/kb/an-approach-to-parsing-the-query-log;"An approach to parsing the query.log
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags query.log logging
When one has enabled query.log through Neo4j Enterprise parameter dbms.logs.query.enabled the included bash shell script can be used to quickly parse the log and identify the top 10 most expensive queries based upon total execution time and if one has enabled dbms.logs.query.time_logging_enabled then the top 10 most expensive queries based upon planning, cpu and waiting time will also be reported.
The bash shell script is as follows:
Bash
Copy to Clipboard
#!/bin/bash
# Copyright (c) 2002-2018 ""Neo Technology,""
# Network Engine for Objects in Lund AB [http://neotechnology.com]
# This file is a commercial add-on to Neo4j Enterprise Edition.

# only parse those lines where the 3rd field is 'INFO'
# count total number of lines in query.log which report INFO in the 3rd field

parse() {
logfile=$1
if [ -e $logfile ]; then
    # log file exits
    awk '$3== ""INFO"" {print ""First Query Reported at: "" $1 "" "" $2}' $logfile | head -1
    awk '$3== ""INFO"" {print "" Last Query Reported at: "" $1 "" "" $2}' $logfile | tail -1


    awk  $logfile

    
     
     
    awk   | sort -n -r -k 5 | head -10

    pcw=`grep   | grep  | head -1`
     [ ! -z  ]; 
          
          
          
          
          
          
          awk  $logfile

          
          awk   | sort -n -r -k 8 | head -10



          
          awk  $logfile
awk   | sort -n -r -k 10 | head -10

          
          awk  $logfile
awk   | sort -n -r -k 12 | head -10
     

    
     
     

}

 [ -z  ]; 
        parse 
  
        parse 
View all (44 more lines)
Upon running the script and passing the query.log file to be analyzed, for example ./parse_querylog.sh query.log output will be similar to
when dbms.logs.query.time_logging_enabled=false
First Query Reported at: 2018-04-10 11:48:36.425+0000
 Last Query Reported at: 2018-04-10 11:49:01.213+0000

*******EXECUTION:*******
Total # of Completed Queries: 6
       Total Duration (msec): 2521
   Avg of all Queries (msec): 420.167

Top 10 Longest Queries longest on top and leading line number:
Note: Queries which are multi-line will only report first line of query !!!


line:1  2018-04-10 11:48:36.425+0000 INFO  2398 ms: embedded-session             - MATCH (a:` Arbitrary label name that really doesn't matter `) RETURN a LIMIT 0 - {} - {}
line:2  2018-04-10 11:48:37.106+0000 INFO  48 ms: bolt-session  bolt            neo4j-java/dev          client/127.0.0.1:35796  server/127.0.0.1:7687>   - RETURN 1 - {} - {}
line:3  2018-04-10 11:48:43.839+0000 INFO  33 ms: bolt-session  bolt            neo4j-java/dev          client/127.0.0.1:35796  server/127.0.0.1:7687>   - match (n) return count(n); - {} - {}
line:9  2018-04-10 11:49:01.213+0000 INFO  21 ms: bolt-session  bolt            neo4j-java/dev          client/127.0.0.1:35796  server/127.0.0.1:7687>   -
line:4  2018-04-10 11:48:47.494+0000 INFO  12 ms: bolt-session  bolt            neo4j-java/dev          client/127.0.0.1:35796  server/127.0.0.1:7687>   -
line:6  2018-04-10 11:48:51.613+0000 INFO  9 ms: bolt-session   bolt            neo4j-java/dev          client/127.0.0.1:35796  server/127.0.0.1:7687>   -
when dbms.logs.query.time_logging_enabled=true
(Note: the listing of 10 queries per section has been reduced to 2 lines for brevity. Additonally the Cypher of the query has been reduced)
First Query Reported at: 2018-01-24 07:58:13.360+0000
 Last Query Reported at: 2018-01-24 15:19:40.897+0000

*******EXECUTION:*******
Total # of Completed Queries: 13655
       Total Duration (msec): 1207191
   Avg of all Queries (msec): 88.4065

Top 10 Longest Queries longest on top and leading line number:
Note: Queries which are multi-line will only report first line of query !!!

line:12100      2018-01-24 08:49:14.144+0000 INFO  10082 ms: (planning: 0, cpu: 81, waiting: 0) - bolt-session  bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.1.3:56870    server/10.0.1.2:7687>        neo4j - MATCH (n:Person............)
line:58883      2018-01-24 12:28:17.472+0000 INFO  2530 ms: (planning: 313, cpu: 2520, waiting: 0) - bolt-session       bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.27:56870        server/10.0.1.2:7687>        neo4j -  MATCH (n:Person)

                *******PLANNING:*******
 Total # of Completed Queries: 13655
        Total Duration (msec): 8798
    Avg of all Queries (msec): 0.644306
Number of Queries NOT Planned: 11448    83.8374%

line:37438      2018-01-24 10:43:28.532+0000 INFO  2255 ms: (planning: 991, cpu: 2239, waiting: 0) - bolt-session       bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.45:56870      server/10.0.1.2:7687>        neo4j -  MATCH (n:Person...............)
line:89641      2018-01-24 15:13:42.191+0000 INFO  513 ms: (planning: 409, cpu: 510, waiting: 0) - bolt-session bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.45:56870       server/10.0.1.2:7687>        neo4j - MATCH (n:Person...........) {}

                *******CPU:*******
Total # of Completed Queries: 13655
       Total Duration (msec): 1194341
   Avg of all Queries (msec): 87.4655

line:58883      2018-01-24 12:28:17.472+0000 INFO  2530 ms: (planning: 313, cpu: 2520, waiting: 0) - bolt-session       bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.27:56870        server/10.0.1.2:7687>       neo4j -  MATCH (n:Person .......)
line:386        2018-01-24 07:59:54.851+0000 INFO  2359 ms: (planning: 256, cpu: 2350, waiting: 0) - bolt-session       bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.27:49536        server/10.0.1.2:7687>        neo4j -  MATCH (n:Person {.......})

                        *******WAITING:*******
 Total # of Completed Queries: 13655
        Total Duration (msec): 27
    Avg of all Queries (msec): 0.0019773
Number of Queries NOT Waiting: 13654      99.9927%

line:81         2018-01-24 07:58:33.168+0000 INFO  67 ms: (planning: 0, cpu: 67, waiting: 27) - bolt-session    bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.27:49536        server/10.0.1.2:7687>        neo4j -  MATCH (n:Person) return n:Deleted
line:9991       2018-01-24 08:40:16.476+0000 INFO  74 ms: (planning: 0, cpu: 74, waiting: 0) - bolt-session     bolt    neo4j   neo4j-java/1.4.2-45c2930bc28fac23dda088b300977b804fedf8bb              client/10.21.21.27:49536        server/10.0.1.2:7687>        neo4j -  MATCH (n:Person..............)
From the output of the 2nd run we see that the log spans First Query Reported at: 2018-01-24 07:58:13.360+0000 through Last Query Reported at: 2018-01-24 15:19:40.897+0000. The script then reports that we found Total # of Completed Queries: 13655 and then provide a listing of the Top 10 most expensive queries based upon Total/Avg Exection time, Total/Avg Time Planning, Total/Avg Time CPU and Total/Avg Time Waiting. Additionally, from the output we can see that 'query planning' is not a significant issue as Number of Queries NOT Planned: 11448 83.8374% indicating 83.8374% of queries were satisfied from the query plan cache. Finally, 'locking' is not a concern as Number of Queries NOT Waiting: 13654 99.9927% indicating 99.9927% of all queries spent no time in a 'waiting' state.
There are certain 'caveats' to the script.
The above script will report the line number of the query in the log file for those queries that meet any of the 'Top 10' results. However if a query is multi-line including carriage returns, only the first line of the query is displayed. One would need to read the query.log at the spcific line number to fully understand the query in question.
Times reported can be inflated if run against a query.log which is immediately after a cold start of Neo4j. This is as a result of queries not being in the query plan cache or the pagecache.
One can configure query.log logging to only log queries longer than X duration through parameter dbms.logs.query.threshold. If you set to 0 then everything is logged. If you set to 2s then only queries longer than 2 seconds will be logged and this will effect the results above.
Was this page helpful?"
https://neo4j.com/developer/kb/displaying-cpu-utilization-and-allocated-bytes-in-query-log;"Displaying Query CPU Utilization and Allocated Bytes in Query log
Author Rohan Kharwar Applicable versions 3.4 Tags cpu query.log configuration
In Neo4j 3.3 and prior versions, when query logging is enabled with the following configuration parameters:
Properties
Copy to Clipboard
# Log executed queries that takes longer than the configured threshold. Enable by uncommenting this line.
dbms.logs.query.enabled=true

# If the execution of query takes more time than this threshold, the query is logged. If set to zero then all queries
# are logged.
dbms.logs.query.threshold=0

# The file size in bytes at which the query log will auto-rotate. If set to zero then no rotation will occur. Accepts a
# binary suffix ""k"", ""m"" or ""g"".
dbms.logs.query.rotation.size=20m

# Maximum number of history files for the query log.
dbms.logs.query.rotation.keep_number=7

# Include parameters for the executed queries being logged (this is enabled by default).
=

=

=

=
View all (10 more lines)
The log is written with output as shown below:
2018-10-29 21:07:37.219+0000 INFO  31 ms: (planning: 0, cpu: 29, waiting: 0) - 1969624 B - 0 page hits, 6 page faults - bolt-session bolt neo4j neo4j-javascript/1.5.3  client/127.0.0.1:65274 server/127.0.0.1:7687> neo4j - match (n:Person {name:""Keanu Reeves""})-[:ACTED_IN]->(m) return m - {} - {}
Note that it displays CPU - cpu: 29 and Allocated Bytes - 1969624 B.
However, starting in Neo4j 3.4, using the above settings will not capture CPU and Allocated Bytes as the tracking is disabled by default. The default behavior was changed for Neo4j 3.4 due to noticeable overhead when capturing CPU and Allocated Bytes to avoid resource contention. Thus, even when query logging is enabled with dbms.logs.query.time_logging_enabled=true and dbms.logs.query.allocation_logging_enabled=true, the output in the query log will be missing CPU and allocated bytes as shown below:
2018-10-29 21:17:29.222+0000 INFO  30 ms: (planning: 0, waiting: 0) - 9 page hits, 0 page faults - bolt-session bolt neo4j neo4j-javascript/1.5.3  client/127.0.0.1:65383 server/127.0.0.1:7687> neo4j - match (n:Person {name:""Keanu Reeves""})-[:ACTED_IN]->(m) return m - {} - {}
In order to capture Query CPU utilization and allocated bytes, the following configuration parameters must be set to true to override the default (false).
Properties
Copy to Clipboard
dbms.track_query_allocation=true
dbms.track_query_cpu_time=true
With those settings, the query.log will display as shown below:
2018-10-29 21:21:04.446+0000 INFO  141 ms: (planning: 124, cpu: 139, waiting: 0) - 19388616 B - 10 page hits, 0 page faults - bolt-session bolt neo4j neo4j-javascript/1.6.1  client/127.0.0.1:65482 server/127.0.0.1:7687> neo4j - EXPLAIN match (n:Person {name:""Keanu Reeves""})-[:ACTED_IN]->(m) return m - {} - {}
Was this page helpful?"
https://neo4j.com/developer/kb/an-explanation-of-entries-in-query-log;"An explanation of entries in query.log
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging query.log monitoring
This document aims to provide descriptions of components of the query.log logfile located at $NEO4J_HOME/logs. Note that the following configs in conf/neo4j.conf need to be uncommented for the query log to include mentions of the useful parameters described in this article:
dbms.logs.query.enabled=true
dbms.logs.query.allocation_logging_enabled=true
dbms.logs.query.page_logging_enabled=true
dbms.logs.query.parameter_logging_enabled=true
dbms.logs.query.time_logging_enabled=true
dbms.logs.query.threshold=<appropriate value>
The following sample query was executed on the movies database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person {name:'Tom Hanks'})-[:ACTED_IN]->(n1:Movie)<-[:DIRECTED]-(n2:Person {name:""Tom Hanks""}) return n1.title
The corresponding query log in [.file}_query.log_ is shown below:
2017-11-23 12:44:56.973+0000 INFO  1550 ms: (planning: 20, cpu: 920, waiting: 10) - 13792 B - 15 page hits, 0 page faults - bolt-session bolt neo4j neo4j-javascript/1.4.1  client/127.0.0.1:58189 server/127.0.0.1:7687> neo4j - match (n:Person {name:'Tom Hanks'})-[:ACTED_IN]->(n1:Movie)<-[:DIRECTED]-(n2:Person {name:""Tom Hanks""}) return n1.title; - {} - {}
An obvious but essential point of note when examining parameters of a particular query, is to ensure to analyse only the entries relevant to that to the particular query plan, as opposed to e.g. cpu, time, bytes etc. for each log entry in sequence.
Following is a breakdown of resource usage parameters, with descriptions, corresponding to the above qurey:
2017-11-23 12:44:56.973+0000
log timestamp.
INFO
log category.
1550 ms
Total elapsed cumulative wall time spent in query execution. It is the total of planning time + cpu + waiting (see below for individual descriptions) + any other processing time e.g. taken to acquire execution threads. This figure is cumulative for every time a cpu thread works on executing the query.
Planning
refers to the time taken by the cypher engine to create a query plan. Plans may be cached for repetitive queries and therefore planning times for such queries will be shorter than those for previously unplanned ones. In our example, this contributed 20ms to the total execution time 1550ms.
CPU time
refers to the time taken by individual threads thread executing the query, e.g. a query is submitted at 08:00, it uses CPU for 720ms but then the CPU swaps out to another query, so the first query is no longer using the CPU, but then after 100ms it then gets/uses the cpu again for 200ms, (more results to be loaded, requested by the client via the driver), then the query completes at 08:01:30, so the total duration is 1550ms (includes some round-trip time for 2 round-trips) but CPU is 720+200=920ms.
Waiting
time a query spent waiting prior to execution (in ms) e.g. if an existing query has a lock which the new query must wait on to release. In our example, this contributed 10ms to the total execution time 1550ms.
Importantly, note that the client requests data from the server only when it’s record buffer is empty (one round-trip from the server may end-up with several records), and server stops pushing data into outgoing buffers if client doesn’t read them in a timely fashion. So, it basically depends on the size of the result set, if it is fairly small and will fit in a single round-trip - the client will receive all the results at once and server would have finish processing without any client-side effect. If the result set is large, client side processing time will affect the overall time as it is directly connected to when new data is requested from the server.
A simple test which shows how retrieval and roud-trip times between db and client are reflected in query.log, we can try the following transaction:
Java
Copy to Clipboard
public void iterateWithoutDelay() throws Exception {
  final Session session = driver.session(AccessMode.READ);
  Transaction tx = session.beginTransaction();
  final long startTime = System.currentTimeMillis();
  final StatementResult result = tx.run(""MATCH (n) return n"");
  while (result.hasNext()) {
    result.next();
  }
  tx.close();
}
results in this entry in the log:
… INFO 3896 ms: bolt-session bolt null neo4j-java/dev client/127.0.0.1:52935 server/127.0.0.1:7687> - MATCH (n) return n - {} - {} …
While this code
Java
Copy to Clipboard
public void iterateWithDelay() throws Exception {
  final Session session = driver.session(AccessMode.READ);
  Transaction tx = session.beginTransaction();
  final long startTime = System.currentTimeMillis();
  final StatementResult result = tx.run(""MATCH (n) return n"");
  while (result.hasNext()) {
    result.next();
    Thread.sleep(5);
  }
  tx.close();
}
results in this entry:
INFO 135171 ms: bolt-session bolt null neo4j-java/dev client/127.0.0.1:52935 server/127.0.0.1:7687> - MATCH (n) return n - {} - {}
Notice that the only difference here is the delay added to the client processing hence showing it contributing to logged times.
So based on this, if total time is T, planning time P, CPU time C, waiting time W then:
x = T - (C + W + P)
represents the time spent either transferring results to the client (round-trip time), or time spent waiting for the client to pull results, or both.
13792 B
The allocated bytes for the executed queries being logged. This is the amount of HEAP memory used during the life of the query. The logged number is cumulative over the duration of the query, i.e. for memory intense or long-running queries the value may be larger than the current memory allocation.
15 page hits
Page hit means the result was returned from pagecahce as opposed to disk. In this case, pagecache was hit 15 times.
0 page faults
Page fault means that the query result data wasnt in the dbms.memory.pagecache and therefore had to be fetched from the file system. In this case, query results were returned entirely from the 8 pagecache hits mentioned above therefore there were 0 hits on the disk required.
bolt-session
session type
bolt
browser ← → db communication protocol used by the query
neo4j
process id
neo4j-javascript/1.4.1
driver version
client/127.0.0.1:52935
query client outbound IP:port used
server/127.0.0.1:7687>
server listening IP:port used
neo4j
username of the query executioner
match (n:Person {name:'Tom Hanks'})-[:ACTED_IN]→(n1:Movie)←[:DIRECTED]-(n2:Person {name:""Tom Hanks""}) return n1.title
the executed query.
The last two parenthesis {} {} are for query params and txMetaData. See https://neo4j.com/docs/operations-manual/current/monitoring/logging/#query-log-config.
Was this page helpful?"
https://neo4j.com/developer/kb/amazon-cloudwatch-configuration-for-neo4j-logs;"Using Amazon CloudWatch to monitor Neo4j logs
Author David Fauth Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags aws logging monitoring
This article describes how to set up Amazon CloudWatch. Amazon CloudWatch Logs allows you to monitor, store, and access your Neo4j log files from Amazon EC2 instances, AWS CloudTrail, or other sources. You can then retrieve the associated log data from CloudWatch Logs using the Amazon CloudWatch console, the CloudWatch Logs commands in the AWS CLI, the CloudWatch Logs API, or the CloudWatch Logs SDK. This article will describe how to configure CloudWatch to monitor the neo4j.log file, configure a metric, configure an alert on the metric and show how to view the logs with the CloudWatch console.
Setup
Setting up CloudWatch is a straight forward process that is well-documented on the CloudWatch website. You can configure CloudWatch on an existing EC2 instance or on a new EC2 instance. Note that CloudWatch relies on your IAM or Secret_Key security details.
Configuration
As part of the setup, you will need to configure the agent file to consume Neo4j’s neo4j.log file. In the existing EC2 instance, this is done in the /etc/awslogs/awscli.conf file. In a new EC2 instance, you will need to configure the agent configuration file.
The configuration options are described in the CloudWatch Logs Agent Reference. For Neo4j 3.0, the following configuration will work:
Toml
Copy to Clipboard
[neo4j.log]
datetime_format = %Y-%m-%d %H:%M:%S%f%z
file = /home/ec2-user/neo4j3/neo4j-enterprise-3.0.0/logs/neo4j.log
log_stream_name = {instance_id}
initial_position = start_of_file
log_group_name = /neo4j/logs
Viewing the Logs
CloudWatch provides a user interface to view the log files. Once you log into your Amazon console and select CloudWatch, you will be presented with the following console:
Selecting the /neo4j/logs group brings you to a page to select your logstream:
Finally, you can select on the server id and view the actual log file:
Configuring a Metric
CloudWatch allows you to configure custom metrics to monitor events of interest. The filter and pattern syntax describes how you can configure the metric. Unfortunately for us, you can only do text searches and not regex searches. For our example, we will configure a metric to look for a master failover.
The steps to configure a custom metric are documented here. After selecting our Log Group, you will click on the Create Metric Filter button.
For the filter pattern, use the text: ""unavailable as master"". When you are finished, you will assign the metric.
Configuring an Alert
CloudWatch provides the capability to be alerted when a threshold around a metric. We can create an alarm around our custom metric. The steps are well documented. The custom metric will show under the Custom Metrics section. You are able to name the alert, set thresholds and set the notification options.
Summary
Amazon CloudWatch Logs provides a simple and easy way to monitor your Neo4j log files on an EC2 instance. Setup is straightforward and should take no more than 15 minutes to configure and have logs streaming from your Neo4j instance to CloudWatch.
Was this page helpful?"
https://neo4j.com/developer/kb/using-aws-cli-to-upload-download-files-to-amazon-s3-buck;"Using AWS CLI to upload/download files to Amazon S3 bucket
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags aws s3 upload download
If one has installed the AWS CLI
To download a file from a S3 bucket anonymously run:
Shell
Copy to Clipboard
$ aws s3 cp s3://<AWS instance name>/<bucket_Name>/<file> <file> --no-sign-request
and/or to upload to a Neo4j S3 buck anonymously run:
Shell
Copy to Clipboard
$ aws s3 cp <file> s3://<AWS Instance name>/<file> --acl=bucket-owner-full-control --no-sign-request
replacing <AWS Instance name> with the name of the AWS S3 instance, <file> with the name of the file on your server, and <bucket_Name> with the name of the bucket provided by Neo4j
Was this page helpful?"
https://neo4j.com/developer/kb/load-csv-data-from-csv-files-on-aws-s3-bucket;"Load CSV data in Neo4j from CSV files on Amazon S3 Bucket
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags aws s3 import cli
Neo4j provides LOAD CSV cypher command to load data from CSV files into Neo4j or access CSV files via HTTPS, HTTP and FTP. But how do you load data from CSV files available on AWS S3 bucket as access to files requires login to AWS account and have file access? That is possible by making use of presign URL for the CSV file on S3 bucket.
We will quickly walk through on how to create a presign URL for a file on AWS S3 bucket. We will need aws command line utility for it. Once the aws command line utility is installed, setup the aws command line using aws configure command.
Shell
Copy to Clipboard
Rohans-MacBook-Pro-2:bin rohankharwar$ aws configure
AWS Access Key ID [****************KSRQ]:
AWS Secret Access Key [****************t9gZ]:
Default region name [us-east]: us-east-2
Default output format [None]:
For this example the actors.csv file is available in rohank S3 bucket. Run the below command to create the presign URL for actors.csv file.
Shell
Copy to Clipboard
$ aws s3 presign s3://rohank/actors.csv
The command will create and output the following presign URL: https://rohank.s3.amazonaws.com/actors.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAICM6A3RO53KOKSRQ%2F20190404%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20190404T215301Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=61cb485af12daa60bb8cb7a91fb503797311c8e178d9bfa3c7ff49770e4535b5
Then use the URL to access the file from S3 bucket using LOAD CSV as
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS FROM ""https://rohank.s3.amazonaws.com/actors.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAICM6A3RO53KOKSRQ%2F20190404%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20190404T215301Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=61cb485af12daa60bb8cb7a91fb503797311c8e178d9bfa3c7ff49770e4535b5"" as row return count(row)
Was this page helpful?"
https://neo4j.com/developer/kb/helpful-commands-when-supporting-neo4j;"Helpful Commands When Supporting Neo4j
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cli support
Top 50 Slowest queries from Query log:
$ grep -i ""INFO"" query.log | sort -r -n -k 4 | head -50 > long_queries.log
Find Longest GC Pauses in debug or messages log:
$ grep -n -i blocked debug.log | sort -r -n -k 11 | head -10
Strip all comments / empty lines of neo4j.conf file:
$ grep -v ""^#"" neo4j.conf | sed -e '/^$/d' | sort
Find a class within a directory of jars:
$ for i in *.jar; do jar -tvf ""$i"" | grep -Hsi MyClass && echo ""$i""; done
Take a thread dump:
$ jstack <neo4j process ID>
or to force a thread dump. Use when jstack <pid> does not respond (process is hung)
$ sudo jstack -F <neo4j process ID>
Take a heap dump:
$ jmap -dump:format=b,file=<directory>/heapdump.hprof <neo4j process ID>
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-4-2-x-sec-vuln-fix;"Neo4j 4.2.x Security Vulnerability Fixed in Release 4.2.8
Author Daniel Terlizzi Applicable versions 4.2 Tags support
Affected products
Neo4j 4.2.x Enterprise and Aura Cloud before 2021-06-18
Unaffected versions: Neo4j Community Edition, all Enterprise versions prior to 4.2 and Aura Cloud from 2021-06-18. Additionally Neo4j 4.3.x includes this fix.
Description of the problem
Neo4j engineering and security teams have identified an issue categorized as “unauthorized access” within the Neo4j 4.2 release. Users with any level of access to the database may be able to bypass security and gain full administrator-level access.
A user executing an administrative command in a transaction could retain elevated Cypher permissions used by the command for the duration of the transaction. For read-only administrative commands e.g. SHOW CURRENT USER this would be full read access, and for write system commands e.g. CREATE DATABASE this would be full access to the system.
Resolution
Neo4j has released Neo4j Enterprise 4.2.8 to resolve the issue and advises customers to apply this patch immediately. This patch requires downtime on a single server and can be performed with a rolling upgrade on clusters to ensure there is no downtime. Aura customers do not need to take any further action, as Neo4j has already released the patch to Aura Cloud on 2021-06-18.
Was this page helpful?"
https://neo4j.com/developer/kb/deploy-aws-cloudformation;"Deploying Neo4j on AWS Using CloudFormation
Author David Allen Applicable versions 3.5 Tags cloud aws deployment
This page describes how to use CloudFormation to deploy Neo4j clusters on AWS, using Virtual Machines.
Basics
The Neo4j CloudFormation templates allow deploying causal clusters of any size, with almost any machine type, as Virtual Machines on AWS. The templates are based on top of the Neo4j Cloud VMs which have been made available for Amazon (AMIs).
AWS Marketplace
Neo4j Enterprise Causal Cluster is already available in AWS Marketplace and can be found under this link.
The CloudFormation templates discussed in this article are the same as those that drive this marketplace listing. As a result, if you do not require any modifications to the CloudFormation template, it may be even easier to simply use the Marketplace option, which is BYOL, meaning that it does not charge any additional money per hour.
This article is for those customers who need to customize the default deploy options.
Availability
Templates in JSON format have been made available in the public S3 bucket named s3://neo4j-cloudformation. Two types of templates are available; one for a stand-alone single instance Neo4j install, and one for a causal cluster setup. The remainder of this article will discuss the causal cluster setup. The stand-alone instance follows the same general set of rules and architecture, and differs only in that it creates a single VM instead of a configurable number of VMs.
Templates are made available for many, (but not all) versions of Neo4j. As an example, full public URL of CloudFormation template for 3.5.12 is https://s3.amazonaws.com/neo4j-cloudformation/neo4j-enterprise-stack-3.5.12.json.
The basics of template structure is the same from version to version, the primary difference is the Neo4j version of the AMI used.
Architecture
The deployment architecture that the CloudFormation templates follow can be seen here:
In general, a new AWS VPC is created, with cores and read replicas round-robined across three subnets, each placed in a different availability zone, all within the same region on AWS. A limitation of the CloudFormation template is that it can only be used in regions with >= 3 availability zones to allow for this spreading; in the event of an AZ outage, the database will remain available.
Customer VPCs
The most likely reason you may need to modify the template for your own needs is to place a Neo4j cluster into an existing VPC.
The CloudFormation template does not at present allow (by default) placement of new clusters into existing VPCs, because there are too many factors to consider to make this a reliable operation, including number of free IP addresses in subnets, existing routing rules, and other factors. It is absolutely possible to do this, it just requires your organization’s customization to ensure that these factors have been considered.
Here’s a short checklist of things to check in the template:
Association of Virtual Machines to subnets
Likely no need to create an internet gateway
Usage
To create a cloudformation stack from a JSON file, customize this command, substituting parameters as you see fit:
Shell
Copy to Clipboard
$ aws cloudformation create-stack \
   --stack-name StackyMcGrapherston \
   --template-body file://neo4j-enterprise-stack.json \
   --parameters ParameterKey=ClusterNodes,ParameterValue=3 \
                ParameterKey=InstanceType,ParameterValue=m3.medium \
                ParameterKey=NetworkWhitelist,ParameterValue=0.0.0.0/0 \
                ParameterKey=Password,ParameterValue=s00pers3cret \
                ParameterKey=SSHKeyName,ParameterValue=my-ssh-key-name \
                ParameterKey=VolumeSizeGB,ParameterValue=37 \
                ParameterKey=VolumeType,ParameterValue=gp2 \
  --capabilities CAPABILITY_NAMED_IAM
This command will create a 3-node causal cluster running on m3.medium machines, open to the entire internet (because we allowed a network whitelist of 0.0.0.0/0). It will initialize the database with the given neo4j user password, and allow direct SSH access with the specified SSH key. Each node will be allocated 37GB of GP2 storage.
For further parameters that are available, consult the parameters at the top of the template. Other options include the ability to create a number of read replicas.
Ongoing Management
CloudFormation does not automate operations of the cluster itself, or provide much in the way of autoscaling. As a result, once the infrastructure is deployed, management and custom configuration is left to operators with SSH access.
Backing Code
The code for building any version of Neo4j as an AMI or CloudFormation template is in a private GitHub repository. Customer access may be granted upon request, but the repository will not be made public.
The finished CloudFormation templates themselves can be hard to work with because of how CloudFormation operates. For example, CloudFormation does not natively support creating a variable number of resources (such as a user inputted number of core nodes in your cluster) and so the finished template contains code to create up to 9 core nodes, with conditionals depending on what the user selected. In the GitHub repository, we use a templating language called jinja to generate the CloudFormation templates, making them easier to read and manage in a modular way. If substantial modifications are needed, you may wish to consider working off of these Jinja templates rather than the raw CloudFormation templates.
Was this page helpful?"
https://neo4j.com/developer/kb/data-import-for-cloud;"Importing Data to Neo4j in the Cloud
Author Jennifer Reif Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags import cypher cloud
Loading data in a Neo4j instance that is in the cloud is very similar to running Neo4j using any other method. However, there are a few small things to look out for and keep in mind when importing data to a 'cloud graph'. We will discuss the main ones in this article.
Configuration and access
Using the offline importer
Cloud disk planning
The specifics of differences of running Neo4j in the Cloud are documented in our developer guides. Anything not listed there would indicate is does not differ from other Neo4j implementations.
Configuration and Access
When you set up and deploy a cloud instance, the default, out-of-the-box security settings on some clouds may prevent traffic through the firewall to the data source you intend to use. This means that many external data sources and networks might be locked out from communicating with the Neo4j cloud instance. To remedy that, you will need to adjust the firewall settings on your cloud machine to allow traffic. How to do this varies on your cloud provider. For steps to change firewall settings, please consult your cloud provider’s documentation.
Plugins
Some Neo4j plugins like APOC and graph algorithms are included as defaults in cloud installations. Other plugins can be installed manually, as needed. However, for using data import procedures in APOC, not all images have file imports from a local disk configured. These security settings could prevent you from using some procedures that would load a local file.
If you execute one of these procedures that is blocked, you could see an error message similar to the one below.
Neo.ClientError.Procedure.ProcedureCallFailed: Failed to invoke procedure apoc.load.json: Caused by: java.lang.RuntimeException: Import from files not enabled, please set apoc.import.file.enabled=true in your neo4j.conf
To alter these settings and allow any blocked procedures to run and access files, you can review the APOC documentation for configuration settings and whitelisting options.
Offline Data Import
The neo4j-admin import tool is helpful for loading massive amounts of data into a new, empty database at incredible speeds by ignoring the usual transaction batching that occurs when a database is running and handling other daily requests. Using non-transaction loading makes the tool very fast, but means that the normal ACID process is circumvented for performance’s sake.
If done accurately, this process is very simple and efficient. One small difference running the neo4j-admin import tool on a cloud instance of Neo4j compared with other deployments is how to stop and start the database. The cloud providers use systemd with Neo4j installed as a service, so you will need to stop the systemd service before using the neo4j-admin import. Your command steps to stop and start will look like the ones below.
Shell
Copy to Clipboard
$ systemctl stop neo4j
# run neo4j-admin import command
$ systemctl start neo4j
Further information on how the system service works with Neo4j in Cloud VMs can be found in one of our developer guides.
Running offline data import should be used with caution. As a warning, users should never (ever!) use the offline data import while the database instance is running. Doing so will result in data corruption and error messages that are difficult to diagnose.
For more information on the neo4j-admin import tool, check out the Operations Manual.
Disk Planning for the Cloud
Importing data to Neo4j (especially large quantities of it) requires some disk space. The defaults initiated in your cloud instances may not be enough to handle large file imports or streamed imports from other systems.
If the disk is under-allocated, the disk space will run out during the load, and the database will crash. To avoid this, you’ll need to increase your disk space. But, how much might you need?
You will need some disk space to store any files (if using flat file import) and some space for the loading process. As a safe estimate, we recommend 2-3x the size of the data you are planning to load. For instance, if you have 50GB of CSV, you should likely allocate 100GB+ of disk.
Of course, each data set may have varying complexity, but these numbers should cover most cases. As always, if you have any issues or questions, feel free to reach out to us on the Neo4j Community Site. We are happy to work with you to find the best solution!
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-log-parameter-values-into-the-query-log-file;"How do I log parameter values into the query.log file
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging parameters query-log
Neo4j 3.0 introduced the ability to log the value of query parameters in the log/query.log file. The settings to control this feature are located in the conf/neo4j.conf file. To enable query logging with parameters, one must first enable query logging via the conf/neo4j.conf parameter:
Properties
Copy to Clipboard
dbms.logs.query.enabled=true
Second, to enable the logging of parameters one should set:
Properties
Copy to Clipboard
dbms.logs.query.parameter_logging_enabled=true
By default dbms.logs.query.parameter_logging_enabled is set to true.
Once these two settings are defined/enabled (and Neo4j is restarted to apply the change), when a Cypher statement is submitted using parameters, the parameter values will appear at the end of the line.
For example submitting:
Json
Copy to Clipboard
{
  ""statements"" : [ {
    ""statement"" : ""CREATE (n) RETURN id(n)""
  }, {
    ""statement"" : ""CREATE (n {props}) RETURN n"",
    ""parameters"" : {
      ""props"" : {
        ""name"" : ""My Node""
      }
    }
  } ]
}
will result in the following log entry:
2016-04-29 18:03:31.679+0000 INFO  86 ms: server-session        http    192.168.1.220   /db/data/transaction - CREATE (n {props}) RETURN n - {props: {name: My Node}}
where the trailing {props: {name: My Node}} represents the parameter value(s) passed.
If you were to define dbms.logs.query.parameter_logging_enabled=false, then the above line would appear as:
2016-04-29 18:02:23.868+0000 INFO  2 ms: server-session http    192.168.1.220   /db/data/transaction - CREATE (n {props}) RETURN n
Was this page helpful?"
https://neo4j.com/developer/kb/checkpointing-and-log-pruning-interactions;"Checkpointing and Log Pruning interactions
Author Chris Gioran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags checkpoint pruning logging metrics configuration
Overview
Checkpointing is the process of flushing all pending page updates from the page cache to the store files. This is necessary for ensuring that the number of transactions that are in need of being replayed during recovery is kept to a reasonable number, mostly to reduce recovery time after an improper shutdown. Regardless of the existence of checkpoints, database operations remain safe, since all transactions not confirmed to have had their changes persisted to storage will be replayed on the next database startup. However, that is dependent on the existence of the set of changes these transactions consist of, information that is kept in the transaction logs. Keeping the list of non-applied transactions long (the interval between checkpoints large) will result in accumulation of transaction logs, since they are necessary for recovery. Checkpointing introduces a special “Checkpointing” entry in the transaction log which marks the last transaction at which checkpointing happened. This is used to determine which transaction logs are no longer necessary, since all the transactions they contain have been safely persisted to the store files.
The process of removing transaction logs that are no longer necessary for recovery is called pruning. From the above description it is apparent that pruning is dependent on checkpointing, in the sense that checkpointing determines which logs can be pruned or, put differently, when pruning can happen, since if a checkpoint doesn’t take place the set of prune-able transaction log files cannot have changed. This dependency is expressed through the triggering of pruning (which may or may not include a check for their existence, as discussed below) whenever checkpointing happens. This relationship is invariant and applies to the entirety of the discussion that follows.
Triggering of checkpointing (and pruning) events
Checkpointing, which is the driving event for pruning, can be triggered in a few different ways.
The simplest method, called ""periodic"", checks by default every 15 minutes whether there are changes pending flushing (i.e. transactions that have not been checkpointed yet). If so, it performs a checkpoint and subsequently triggers a log prune. Note that no checkpointing being performed imples no pruning happens. This is the default behaviour and the only one available in community edition.
In the enterprise edition, there are two additional checkpointing policies. The simplest is called ""continuous"" and, as the name implies, it constantly checks if a checkpoint is possible (that is, if any transactions committed since the last successful checkpoint) and if so, it performs it. Pruning is triggered immediately after it completes, just like in the periodic policy.
The third and final checkpointing policy is ""volumetric"". It checks every 10 seconds if any logs are available for pruning and, if so, it triggers a checkpoint and subsequently it prunes the logs. This policy appears to invert the control between checkpointing and pruning, but in reality it only changes the criteria for when checkpointing must happen. Instead of relying on a time trigger, as the previous two, it relies on a pruning check. Pruning will still happen after checkpointing has occured, as with the other two policies. Nevertheless, since the check depends on the existence of prunable transaction log files, this policy depends on pruning configuration, as described in the next session.
The policy to be used is controlled by the setting dbms.checkpoint and it defaults to ""periodic"".
Logging and Metrics
The following details the expected messages to appear in the logs\debug.log upon a checkpoint event
Checkpoint based upon dbms.checkpoint.interval.time
2019-08-28 12:55:05.174+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for time threshold"" @ txId: 49 checkpoint started...
2019-08-28 12:55:05.253+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for time threshold"" @ txId: 49 checkpoint completed in 79ms
Checkpoint based upon dbms.checkpoint.interval.tx
2019-08-28 13:08:51.603+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for tx count threshold"" @ txId: 118 checkpoint started...
2019-08-28 13:08:51.669+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for tx count threshold"" @ txId: 118 checkpoint completed in 66ms
Checkoint when dbms.checkpoint=continuous
2019-08-28 13:17:21.927+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for continuous threshold"" @ txId: 171 checkpoint started...
2019-08-28 13:17:21.941+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Scheduled checkpoint for continuous threshold"" @ txId: 171 checkpoint completed in 13ms
Checkpoint as a result of database shutdown
2019-08-28 12:35:56.272+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Database shutdown"" @ txId: 47 checkpoint started...
2019-08-28 12:35:56.306+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Database shutdown"" @ txId: 47 checkpoint completed in 34ms
Checkpoint as a result of call dbms.checkpoint(); introduced in Neo4j 3.5.6
2019-08-28 12:31:56.463+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Call to dbms.checkpoint() procedure"" @ txId: 47 checkpoint started...
2019-08-28 12:31:56.490+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Call to dbms.checkpoint() procedure"" @ txId: 47 checkpoint completed in 27ms
Checkpoint as a result of a backup run
2019-08-28 12:33:30.489+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Full backup"" @ txId: 47 checkpoint started...
2019-08-28 12:33:30.509+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by ""Full backup"" @ txId: 47 checkpoint completed in 20ms
Checkpoint Metrics are also available and are detailed in metrics/ and the following files
neo4j.check_point.check_point_duration.csv
neo4j.check_point.total_time.csv
neo4j.check_point.events.csv
Controlling transaction log pruning
Transaction log pruning configuration primarily deals with specifing the number of transaction logs that should remain available. The primary reason for leaving more than the absolute minimum amount required for recovery comes from requirements of clustered deployments and online backup. Since database updates are communicated between cluster members and backup clients through the transaction logs, keeping more than the minimum amount necessary allows for transferring just the incremental changes (in the form of transactions) instead of the whole store files, which can lead to substantial savings in time and network bandwidth. This is true for HA deployments, backups and Read Replicas in Causal Clusters. However, in the case of Core members in Causal Clustering it is not the transaction logs that matter, but rather the Raft log contents. That scenario is covered in a separate KB article.
The amount of transaction logs left after a pruning operation is controlled by the setting dbms.tx_log.rotation.retention_policy and it can take a variety of values. They are of the form <numerical value> <measurement>.
<measurement> can be ""files"", ""size"", ""txs"", ""entries"", ""hours"", or ""days"".
""files"" determines the mimumum number of transaction log files left after pruning. That means that once the checkpoint is performed, a number of log files will be deleted to leave at least as many as specified - for example the value ""5 files"" will leave at least 5 files of transaction logs.
""size"" behaves similarly but instead of counting files it counts total file size. For example, ""500M size"" will leave at least 500M worth of files behind.
""txs"" and ""entries"" are synonymous. They behave similarly to the above but they count transactions present in the files, regardless of file count or size. ""100 txs"" will leave at least 100 transactions worth of logs unpruned after every operation.
""hours"" and ""days"" measure time instead of size or transaction count, but otherwise behave similarly. Setting the value to ""20 hours"" will ensure that at least 20 hours worth of transactions will be present in the logs.
Relevant Configuration Settings
dbms.checkpoint
dbms.checkpoint.interval.tx
dbms.checkpoint.interval.time
dbms.checkpoint.iops.limit
dbms.tx_log.rotation.retention_policy
dbms.tx_log.rotation.size
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-monitor-neo4j-with-prometheus;"How to monitor Neo4j with Prometheus
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags monitoring metrics
Commencing with the release of Neo4j Enterprise 3.4, one can now use the open source monitoring tool Prometheus to monitor Neo4j. The following article details a basic Prometheus implementation to demonstrate the connectivity between Prometheus v2.2.1 and Neo4j.
After installing Prometheus, Neo4j needs to be configured via its neo4j.conf file with the following parameters:
Properties
Copy to Clipboard
# Enable the Prometheus endpoint. Default is 'false'.
metrics.prometheus.enabled=true
# The IP and port the endpoint will bind to in the format <hostname or IP address>:<port number>.
# The default is localhost:2004.
metrics.prometheus.endpoint=localhost:2004
and the prometheus.yml file should be configured as follows:
Yaml
Copy to Clipboard
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'Neo4j-prometheus'

    # metrics_path: /metrics
    # scheme defaults to 'http'.

    static_configs:
      - targets: ['localhost:2004']
In the above configuration snippets, Prometheus has been installed on the same server as Neo4j. If you choose to install it on a different server, simply replace references to localhost above with the IP address of the Neo4j instance.
Launching the Prometheus browser at http://<IP of Prometheus Server>:9090 and clicking the menu option Status → Targets should display:
Returning back to the 3rd menu choice of Graphs one can define a graph to monitor a Neo4j metric. For example, in the detail below the graph represents the number of transactions started (neo4j_transaction_started):
Was this page helpful?"
https://neo4j.com/developer/kb/redirect-neo4j-logs-to-sysout-using-rsyslog;"Redirect Neo4j logs to sysout (using rsyslog)
Author Jose Rocha Applicable versions 2.2 2.3 3.0 3.1 3.2 Tags logging
Sometimes - due to organizational requirements, security, indexing or plain convenience - we want to output all of our application logs to Linux’s sysout. While Neo4j doesn’t offer this feature, we can use RSYSLOG (www.rsyslog.com) to achieve that and we can do this in 6 easy steps.
Steps:
Install rsyslog dependencies
Install rsyslog
Edit rsyslog.conf to accept arbitrary files to be added
Create configuration file for rsyslog to read from Neo4j
Restart rsyslog
Check the results
1. Install rsyslog dependencies
Installing rsyslog requires installing a lot of dependencies. In our test environment, we had to install the following dependencies/libraries: libee, libstr, libjson0, libjson0-dev, uuid, libgcrypt11-dev, python-docutils, zlib1g-dev
You should refer to rsyslog’s installation guide (http://www.rsyslog.com/newbie-guide-to-rsyslog) and check the Preliminary actions chapter.
Installing these dependencies may involve following the step-by-step instruction on the Preliminary actions chapter, or use the command sudo apt-get install <dependency>. Nevertheless, for rsyslog to install correctly, all dependencies must be installed.
Since it depends on what you have installed in your machine, you’ll only know if you’re missing some dependencies when actually installing rsyslog. If this happens, install the dependency and try again.
2. Install rsyslog
Now that you’ve installed all required dependencies mentioned in the rsyslog guide, you can proceed to the installation of rsyslog itself. You can again refer to rsyslog’s installation guide (http://www.rsyslog.com/newbie-guide-to-rsyslog) and follow the How to install rsyslog steps. However, to get rsyslog to work with arbitrary files, you need to explicitly install that module. In the step-by-step guide in rsyslog’s website, on step 4 (Type “./configure –prefix=/usr”), you need to run the following command instead:
./configure --prefix=/usr --enable-imfile
Failing to do this will result in a successful installation but the module we will be using won’t be installed so the redirection will not work.
3. Edit rsyslog.conf
Now that rsyslog is intalled, we need to edit rsyslog.conf to work with arbitrary files. To do so, we must edit the file /etc/rsyslog.conf and add the following line to the MODULES section of the file:
$ModLoad imfile
This will enable the usage of rsyslog with any file you define.
Also, make sure the following line is not commented: $IncludeConfig /etc/rsyslog.d/*.conf. We will need this for the next step.
4. Create neo4j.conf file
We are now going to create the configuration file that enables the redirection from Neo4j’s logs to sysout.
Create a new file on /etc/rsyslog.d (ie: neo4j_debug.conf), edit it and add the following to the file (I will use as example the debug.log of version 3.0.7):
Plaintext
Copy to Clipboard
$InputFileName /neo/neo4j-enterprise-3.0.7/logs/debug.log
$InputFileTag neo4j_debug
$InputFileStateFile neo4j_debug
$InputFileSeverity info
$InputFileFacility local7
$InputRunFileMonitor
$InputFilePersistStateInterval 1000
(while I used version 3.0.7 on $InputFileName, you should use the full path to your desired log file)
5. Restart rsyslog
Everything is now configured and we just need to restart rsyslog service:
$ service rsyslog restart
6. Check the results
If everything was successful, we should have Neo4j’s debug.log now being replayed in the sysout file. You can verify this by verifying the sysout file itself (/var/log/syslog).
You can redirect as many files you want. In order to do so, you only need follow step 4 and create a new .conf file for the new log you wish to be redirected.
Was this page helpful?"
https://neo4j.com/developer/kb/sending-neo4j-message-to-slack-channel;"Sending Neo4j messages to a Slack channel
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging operations backup
Although not specific to Neo4j and this knowledge base document is provided as a convenience, if your environment has a Slack implementation, then Slack provides an API to allow you to programmatically send messags to a specific channel. This can be helpful, for example to send a message on success/failure of backup by checking the exit code of backup.
Using the Slack Hello World example as a starting template, one will be guided through the process of creating a Slack app and resultant WEBHOOK_URL to post messages to.
For example on backup failure:
Shell
Copy to Clipboard
$ curl -X POST -H 'Content-type: application/json' --data '{""text"":""Backup Failure""}' YOUR_WEBHOOK_URL
replacing YOUR_WEBHOOK_URL with its actual value, for example the following code on a linux implementations
Bash
Copy to Clipboard
host=`uname -n`
time=`date`
msg=""{   \""text\"":  \""Backup failure on $host at $time\""   }""
curl -X POST -H 'Content-type: application/json' --data ""$msg""  https://hooks.slack.com/services/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
will result in a message to your Slack channel similar to
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-use-cypher-to-connect-to-a-rbms-using-jdbc;"How do I use Cypher to connect to a RDBMS using JDBC
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logging server database
With the inclusion of java stored procedures in Neo4j 3.x, one can run Cypher to connect to a RDBMS using JDBC. To do so one needs to download and install https://github.com/neo4j-contrib/neo4j-apoc-procedures.
After installation of the Neo4j APOC kit, download the respective RDBMS JDBC driver .jar and install into $NEO4J_HOME\plugins\. The respective JDBC driver can be obtained from the RDBMS vendor. For example:
Vendor Download location JDBC jar file
MySQL
https://dev.mysql.com/downloads/connector/j/
mysql-connector-java-5.1.34.jar
Postgres
https://jdbc.postgresql.org/
postgresql-9.4.1209.jar
Oracle
http://www.oracle.com/technetwork/database/features/jdbc/
ojdbc7.jar
After installing APOC and copying the RDBMS vendor .jar to $NEO4J_HOME\plugins\, restart Neo4j.
The apoc.load.jdbc stored procedure is used to connect over JDBC and takes 2 arguments,namely:
connection string
SQL statement or table
The 'connection string' is vendor specific and as such one should consult the RDBMS vendor for syntax. The 'SQL statement or table name' could be for example 'select * from movies' or simply 'movies'. Usage of a single table name would result in 'select * from <table name>'
The following example would connect to a mysql database named proddb1 as user root with password=football and select all movies from the 'movies' table where the studio column was defined to be 'MGM Studios'. Using this data we would then create nodes in Neo4j for all the movies meeting this criteria and define the title property.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('jdbc:mysql://localhost:3306/proddb1?user=root&password=football','select title from movies where studio=\'MGM Studios\'') YIELD row
CREATE (n:Movies {name:row.title})
If running the above results in error message similar to:
No suitable driver found for jdbc:mysql://localhost:3306/proddb1?user=root&password=football
you may need to first manually load the driver by calling:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.driver('com.mysql.jdbc.Driver')
where 'com.mysql.jdbc.Driver' is the class name for the MySQL JDBC driver.
If you want to hide/alias the connection string, this can be accomplished by adding to the conf/neo4j.conf a parameter similar to:
Conf
Copy to Clipboard
apoc.jdbc.myalias.url=jdbc:mysql://localhost:3306/proddb1?user=root&password=football
and now the above Cypher can be rewritten as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.jdbc('myalias','select title from movies where studio=\'MGM Studios\'') YIELD row
CREATE (n:Movies {name:row.title})
It should be noted that the apoc.load.jdbc call is simply providing connectivity back to the RDBMS over JDBC. The second argument can be any SQL statement, and that includes a SQL statement that may modify the source database through an UPDATE, DROP, TRUNCATE, etc. If required, you might want to connect to the RDBMS with a user who only has SELECT privileges.
Also, when loading data from JDBC, be mindful of datatypes and any necessary conversions; for example whereas MySQL supports a native DATE datatype, Neo4j does not. For example, to get the column with DATE data type, convert the value to a String when importing into Neo4j.
Was this page helpful?"
https://neo4j.com/developer/kb/why-does-my-create-constraint-take-so-long-to-complete;"Why does my CREATE CONSTRAINT take so long to complete
Author Dana Canzano Applicable versions 2.3 3.0 Tags logging server
When creating a constraint, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT ON (n:ZipCode) ASSERT n.name IS UNIQUE;
this will require a lock on all nodes with the label the constraint is being created for, in this case ZipCode
If you have another transaction which was opened prior to the CREATE CONSTRAINT Cypher statement and it has a lock on the same Node label, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
Begin
create (n:ZipCode {name:'94401'}) return n;
then the CREATE CONSTRAINT will not progress until the open transaction is committed/rolled back.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-data-log-console-log-error-of-tls-certificate;"Explanation of data/log/console.log error of 'TLS certificate error occurred, unable to start server: Neither RSA, DSA nor EC worked…'
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags server security
On bin/neo4j start the data/log/console.log may log an error similar to
2016-01-04 13:32:44.589-0500 INFO Successfully shutdown database 13:33:06.856 [main] DEBUG i.n.u.i.l.InternalLoggerFactory - Using SLF4J as the default logging framework 2016-01-04 13:33:07.437-0500 ERROR Failed to start Neo4j: TLS certificate error occurred, unable to start server: Neither RSA, DSA nor EC worked TLS certificate error occurred, unable to start server: Neither RSA, DSA nor EC worked org.neo4j.server.ServerStartupException: TLS certificate error occurred, unable to start server: Neither RSA, DSA nor EC worked at org.neo4j.server.AbstractNeoServer.createKeyStore(AbstractNeoServer.java:492) at org.neo4j.server.AbstractNeoServer.init(AbstractNeoServer.java:178) at org.neo4j.server.AbstractNeoServer.start(AbstractNeoServer.java:191) at org.neo4j.server.Bootstrapper.start(Bootstrapper.java:100)
Neo4j allows for the configuration of HTTPS certificates via the parameters in conf/neo4j-server.properties. The following are the default values:
Properties
Copy to Clipboard
# Turn https-support on/off org.neo4j.server.webserver.https.enabled=true
# Certificate location (auto generated if the file does not exist) dbms.security.tls_certificate_file=conf/ssl/snakeoil.cert
# Private key location (auto generated if the file does not exist) dbms.security.tls_key_file=conf/ssl/snakeoil.key
If the above three parameters are modified a bin/neo4j restart would need to be run for the changes to take effect.
On neo4j start, the certificate files will be read and verified that the algorithm used to generate the certificate files was either RSA, DSA or EC format.
In the instance above the conf/ssl/snakeoil* files are autogenerated on start if they do not already exists and they are self signed certificate.
Was this page helpful?"
https://neo4j.com/developer/kb/when-authentication-is-enabled-in-neo4j-how-do-i-call-the-ha-status-rest-api-without-a-username-password;"When authentication is enabled in Neo4j, how do I call the HA Status
Author Dana Canzano Applicable versions 3.5 Tags server configuration
One can enable authentication for the Neo4j database by adding the following to the conf/neo4j-server.properties
Properties
Copy to Clipboard
dbms.security.auth_enabled=true
In doing so any connections to the database will need to provide a username/password.
However, for the REST endpoint for HA Status information a username/password is not required for these endpoints (/db/manage/server/ha/*) if the following parameter is defined in the conf/neo4j.properties
Properties
Copy to Clipboard
dbms.security.ha_status_auth_enabled=false
Was this page helpful?"
https://neo4j.com/developer/kb/will-execution-guard-enabled-work-in-my-release-of-neo4j;"Will execution_guard_enabled work in my release of Neo4j?
Author Dave Gordon Applicable versions 2.0 2.1 2.2 2.3 3.0 3.1 Tags server configuration
Background
From the beginning, the execution guard was never meant to be used by the general public. However, the feature was there in the product, though undocumented, and it did work for the purpose of preventing long running queries from utilizing significant resources and causing other downstream effects. So it was blogged about, and utilized by users looking for that functionality.
Explanation
If you are running Neo4 2.1.x or previous versions it will still work. If you are running 2.2.x through 3.0.x it will not work, unless you are using the core Java API. If you are running 3.1.x please see dbms.transaction.timeout
Why?
Cypher used the core Java API behind the scenes until 2.2, so the execution guard was actually implemented at that layer. When we made a big change in 2.2 to allow Cypher to use the lower level, more efficient Cursor API, Cypher queries were no longer subject to honoring the execution guard. As the execution guard was an undocumented, unsupported ""feature"", it was left alone.
Want to see this feature back in the product? Send us a message at our Public Slack channel for product feedback:
https://neo4j-users.slack.com/messages/product-feedback/
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-logical-logs-and-effects-of-parameters-keep-logical-logs-and-logical-log-rotation-threshold;"Understanding logical logs and effects of parameters keep_logical_logs and logical_log_rotation_threshold
Author Dana Canzano Applicable versions 2.0 Tags server configuration
Neo4j maintains logical logs for incremental backup and cluster consistency. The logical logs are named as follows:
pre 2.2
data/graph.db/nioneo_logical.log*
2.2 forward
data/graph.db/neostore.transaction.db*
When one runs a database backup, via bin/neo4j-backup, if the -to <target directory> has a previous backup, then the backup will be an incremental backup rather than a full backup. If the logical logs have been rotated out since the last full backup, then the backup is forced to be a full backup.
In a cluster environment the logical logs are utilized to ensure that a newly discovered slave is updated with the correct transactions. If the logical logs have been rotated out, then rather than simply updating the new slave from the logical logs, a complete store copy will occur.
Within the conf/neo4j.properties, one can configure the following two parameters:
Conf
Copy to Clipboard
logical_log_rotation_threshold
keep_logical_logs
Each of these parameters are documented in the Neo4j documentation. In summary the logical_log_rotation_threshold determines to what size the current logical log file can grow before it is rotated out. For example the default under 2.3.0 for logical_log_rotation_threshold is 250M. As such, one will expect no files under data/graph.db/neostore.transaction.db to exceed 250M. At the point that the neostore.transaction.db.<N> reaches 250M the neostore.transaction.db.<N> will be rotated to neostore.transaction.db.<N+1> and then the keep_logical_logs parameter will be consulted to determine if prior neostore.transaction.db.<N> files should be automatically removed.
For example if
Properties
Copy to Clipboard
logical_log_rotation_threshold=250M
keep_logical_logs=3 days
then when the neostore.transaction.db.<N> exceeds 250M we will create a neostore.transaction.db.<N+1> and then auto remove any neostore.transaction.db.<N> which are older than 3 days. The important part to remember is that the removal of files per the parameter for keep_logical_logs is only considered when the logical_log_rotation_threshold has been met.
Additionally, if initially
Properties
Copy to Clipboard
logical_log_rotation_threshold=250M
keep_logical_logs=10 days
and then one edits conf/neo4j.properties and changes
Properties
Copy to Clipboard
keep_logical_logs=10 days
to
Properties
Copy to Clipboard
keep_logical_logs=5 days
and then restarts Neo4j, there will still be neostore.transaction.db.<N> for the last 10 days. When the current neostore.transaction.db reaches 250M then we will remove logical logs from all but the last five days.
Was this page helpful?"
https://neo4j.com/developer/kb/proxy-setting-for-neo4j-desktop;"How to Configure Proxy in Neo4j Desktop
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags configuration
Organizations have proxy settings in order to access the internet or external websites.
Neo4j Desktop has a way to setup proxy configuration so one can use their organization’s proxy settings.
To setup Proxy in Neo4j Desktop:
Click on the Settings as identified by the blue arrow:
Click on the No Proxy which will open a drop down menu. Choose from the following as shown in the image below:
HTTP
Local PAC file
Remote PAC file
Enter the proxy information and click on Save. Example shown with HTTP proxy setup in the image below.
Was this page helpful?"
https://neo4j.com/developer/kb/a-demonstration-of-cluster-size-at-formation-and-runtime;"A Demonstration of Cluster Size at Formation and Runtime
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster configuration
Causal Clustering Minimum Core Size At Formation
causal_clustering.minimum_core_cluster_size_at_formation is defined as the minimum number of Core machines initially required to form a cluster. The cluster will form when at least this many Core members have discovered each other.
The following example shows a 5 core cluster with causal_clustering.minimum_core_cluster_size_at_formation=3. Core 1 and 2 are initialised and the first election occurs as below:
2019-03-31 14:14:22.028+0000 INFO [o.n.c.n.Server] raft-server: bound to 127.0.0.1:7000
2019-03-31 14:14:22.038+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:14:30.910+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Cluster discovery service started
2019-03-31 14:14:30.955+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[{memberId=
MemberId{fb0bc6e1}, info=CoreServerInfo{raftServer=localhost:7001, catchupServer=localhost:6001,
clientConnectorAddresses=bolt://localhost:7688,http://localhost:7460,https://localhost:7461, groups=[], database=default,
refuseToBeLeader=false}}, {memberId=MemberId{3811e9ed}, info=CoreServerInfo{raftServer=localhost:7000,
catchupServer=localhost:6000, clientConnectorAddresses=bolt://localhost:7687,http://localhost:7474,https://localhost:7470,
groups=[], database=default, refuseToBeLeader=false}}], removed=[]}
2019-03-31 14:14:30.956+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{fb0bc6e1},
MemberId{3811e9ed}]
2019-03-31 14:14:31.022+0000 INFO [o.n.c.d.CoreMonitor] Discovered core member at localhost:5001
2019-03-31 14:14:32.099+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:14:42.141+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:14:52.188+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:15:02.225+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members..
Core 3 now joins and the cluster forms successfully:
2019-03-31 14:15:02.225+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:15:12.281+0000 INFO [o.n.c.d.CoreMonitor] Waiting for a total of 3 core members...
2019-03-31 14:15:22.287+0000 INFO [o.n.c.d.CoreMonitor] Discovered core member at localhost:5002
2019-03-31 14:15:22.298+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed
{added=[{memberId=MemberId{9274358d}, info=CoreServerInfo{raftServer=localhost:7002, catchupServer=localhost:6002,
clientConnectorAddresses=bolt://localhost:7689,http://localhost:7476,https://localhost:7472, groups=[], database=default,
refuseToBeLeader=false}}], removed=[]}
2019-03-31 14:15:22.568+0000 INFO [o.n.c.d.CoreMonitor] This instance bootstrapped the cluster.
Causal Clustering Minimum Core Size At Runtime
causal_clustering.minimum_core_cluster_size_at_runtime is defined as the minimum size of the dynamically adjusted voting set (which only core members may be a part of). Adjustments to the voting set happen automatically as the availability of core members changes, due to explicit operations such as starting or stopping a member, or unintended issues such as network partitions. Note that this dynamic scaling of the voting set is generally desirable as under some circumstances it can increase the number of instance failures which may be tolerated. A majority of the voting set must be available before voting in or out members.
Let’s try out causal_clustering.minimum_core_cluster_size_at_runtime=2 on a 3-node cluster. If we lose one core, the cluster still has consensus and can scale down to 2. But if we lose 1 more we’re at a single node left and lack consensus so can’t scale down, and we’re waiting for that just-failed node to become available again. At this point, if the first node of 3 that failed comes back online, it can’t be added back to the cluster since we lack consensus to add it back in. We’re stuck waiting on only the last failed node.
In the example below, core 1 (leader) sees core 3 leaving the cluster as below:
2019-03-31 15:10:31.234+0000 WARN [o.n.c.d.CoreMonitor] Lost core member at localhost:5002
At this point, the cluster still has quorum for writes done at leader, core 1. But after a subsequent period of causal_clustering.leader_election_timeout (default 7s), core 3 is removed from the cluster _because of the cluster size at runtime set to 2.
If we then take core 2 offline also, the cluster becomes read only:
2019-03-31 15:11:08.005+0000 INFO [o.n.c.c.c.s.RaftState] Leader changed from MemberId{e7f79e48} to null
2019-03-31 15:11:08.006+0000 INFO [o.n.c.c.c.s.RaftLogShipper] Stopping log shipper MemberId{a2ef543b}[matchIndex: 5,
lastSentIndex: 5, localAppendIndex: 5, mode: PIPELINE]
However, if we now add back core 3 before adding back core 2, we still end up with two cores in follower state, leaving the cluster as read-only and we see the below in core 1’s log:
2019-03-31 15:12:06.251+0000 DEBUG [o.n.c.c.c.RaftMachine] Should vote for raft candidate false: requester log up to date:
false (request last log term: 1, context last log term: 1, request last log index: 1, context last append: 5) voted for other
in same term: false (request term: 1, context term: 1, voted for another: false)
And a write transaction results in the below exception:
Neo.ClientError.Cluster.NotALeader
Neo.ClientError.Cluster.NotALeader: No write operations are allowed directly on this database. Writes must pass through the
leader. The role of this server is: FOLLOWER
It is not until core 2 is added back, that the three cores form a writeable cluster once again:
2019-03-31 15:13:04.377+0000 INFO [o.n.c.c.c.RaftMachine] Election started with vote request: Vote.Request from
MemberId{e7f79e48} {term=2, candidate=MemberId{e7f79e48}, lastAppended=5, lastLogTerm=1} and members: [MemberId{a2ef543b},
MemberId{e7f79e48}]
2019-03-31 15:13:04.377+0000 INFO [o.n.c.c.c.RaftMachine] Moving to CANDIDATE state after successful pre-election stage
2019-03-31 15:13:04.384+0000 INFO [o.n.c.c.c.RaftMachine] Moving to LEADER state at term 2 (I am MemberId{e7f79e48}), voted
for by [MemberId{a2ef543b}]
2019-03-31 15:13:04.384+0000 INFO [o.n.c.c.c.s.RaftState] First leader elected: MemberId{e7f79e48}
If we however, stick with the default cluster size at runtime of 3, then the cluster could not have scaled down to 2 (the first node that failed wouldn’t have been voted out), but we would have kept consensus and write ability. But then when the second node fails and we’re down to 1, we lose consensus and write capability, just like the previous scenario, but we’re able to get back consensus and write capability if either of the two failed nodes comes back online, not just the latest failed node.
In conclusion, the only effective difference between minimum_core_cluster_size_at_runtime at 2 instead of the default of 3 is that when we’re down to 1 operational node (after having scaled down to cluster size of 2), we have to wait until the just-failed node comes back online, the one that failed before that can’t rejoin because adding a ""new"" node to the cluster requires consensus.
Having a smaller minimum_core_cluster_size_at_runtime is therefore a more relevant optimisation when the base/resting cluster size is larger (e.g. 5). In that situation, having a minimum_core_cluster_size_at_runtime of 3, rather than 5, allows the cluster to tolerate 3 failures, rather than 2, before losing write capability, i.e. provided that those 3 failures don’t happen faster than the cluster is able to vote out failing members (causal_clustering.leader_election_timeout). Using 2 instead of the default of 3 doesn’t affect the ability to tolerate 1 failure in 3. There typically however, isn’t a a good reason to have it set to 2. One may however set minimum_core_cluster_size_at_runtime to a smaller than the total number of cores in a cluster of 5 or more.
Was this page helpful?"
https://neo4j.com/developer/kb/geocoding-with-arcgis;"Geocoding with Arcgis
Author Davids Pecollet Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher configuration
Prerequisites
Create/obtain an Arcgis account.
Create application within your account. The application will be assigned a 'client_id' and 'secret'.
APOC
The APOC library provides a apoc.spatial.geocode('address') procedure (as well as reverseGeocode), that supports geocoding against OpenStreetMap and Google Maps. It also supports other providers (ex: opencage) with a more explicit configuration of the API call (in neo4j.conf) :
Properties
Copy to Clipboard
apoc.spatial.geocode.provider=opencage
apoc.spatial.geocode.opencage.key=<api_key>
apoc.spatial.geocode.opencage.url=http://api.opencagedata.com/geocode/v1/json?q=PLACE&key=KEY
apoc.spatial.geocode.opencage.reverse.url=http://api.opencagedata.com/geocode/v1/json?q=LAT+LNG&key=KEY
with KEY gets replaced by the API key, and PLACE by the address to geocode at run time (resp. LAT/LNG by the coordinates to reverse geocode).
For Arcgis, the key would be the application token, and the url would look like that (that’s the public Arcgis API endpoint) : apoc.spatial.geocode.arcgis.url=https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&outFields=Match_addr,Addr_typ&singleLine=PLACE&token=KEY
Unfortunately, the apoc procedures expect the json response from the provider to contain a list of ""results"". That is not the case for the Arcgis API endpoints :
endpoint 'findAddressCandidates' returns a list of ""candidates""
the other bulk geocoding endpoint 'geocodeAddresses' returns a list of ""locations""
So the apoc.spatial procedures can’t help here.
Workaround using apoc.load.json
The apoc.load.json procedure lets you call any HTTP/REST API and process the response directly in cypher.
You can use the apoc.static procedures to read the API key and URL from neo4j.conf, similarly to what apoc.spatial.geocode does. The two following properties would be required for geocoding (this is using the public arcgis server ; replace with your own Arcgis server hostname if necessary) :
Properties
Copy to Clipboard
apoc.static.arcgis.key=<arcgis_token>
apoc.static.arcgis.geocode_url=https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&outFields=Match_addr,Addr_typ&singleLine=
Then run the following cypher query :
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH 'Statue of Liberty, Liberty Island New York, NY 10004' as address
// get the configuration properties
CALL apoc.static.getAll(""arcgis"") yield value AS arcgis
// build the URL
WITH arcgis.geocode_url+apoc.text.urlencode(address)+'&token='+ arcgis.key as url
// extract the top result
CALL apoc.load.json(url, '$.candidates[0].location') YIELD value as location
return location.x, location.y
Temporary Tokens
Arcgis application token may be temporary (by default 2h). That means you may not be able to hardcode a token in your neo4j.conf. To obtain a new token, you’re supposed to call the Authentication API with your application credentials. You can use apoc.load.json again to do that in cypher.
In neo4j.conf, add the building bricks of the token API call:
Properties
Copy to Clipboard
apoc.static.arcgis.client_id=<application_client_id>
apoc.static.arcgis.client_secret=<secret>
apoc.static.arcgis.token_url=https://www.arcgis.com/sharing/rest/oauth2/token?grant_type=client_credentials
And run the following cypher query :
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.static.getAll(""arcgis"") yield value AS arcgis
WITH arcgis.token_url+'&client_id='+arcgis.client_id+'&client_secret='+arcgis.client_secret as tokenUrl
CALL apoc.load.json(tokenUrl) YIELD value as tokenResponse
WITH tokenResponse.access_token as token
// proceed with geocoding using 'token'
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-java-lang-noclassdeffounderror-readsupport;"Explanation of error ""java.lang.NoClassDefFoundError: org/apache/spark/sql/sources/v2/ReadSupport""
Author Stephen Levett Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags spark pyspark databricks neo4j-spark-connector
In Neo4j 4.x, if you are using the Databricks Run-time of Spark and the neo4j-spark-connector. You may encounter either of these errors when trying to read or write to neo4j via the spark-connector:
java.lang.NoClassDefFoundError: org/apache/spark/sql/sources/v2/ReadSupport
Or:
java.lang.ClassNotFoundException: Failed to find data source: org.neo4j.spark.DataSource
One possible explanation is you are using an incompatible connector, or you built it yourself, and something went wrong.
To resolve this, do the following:
Remove all existing neo4j_connector jars from the Databricks UI.
Add the relevant jar that matches both the Spark & Scala runtimes. You don’t need to compile it yourself. Instead, you can download the artefact from here: https://github.com/neo4j-contrib/neo4j-spark-connector/releases
FYI - To help you decide on the correct jar, we have a compatibility matrix here: https://neo4j.com/developer/spark/overview/#_compatibility
Was this page helpful?"
https://neo4j.com/developer/kb/categories/cluster;"Articles tagged as cluster
A demonstration of causal cluster routing
The following will demonstrate how to use cypher-shell to get a better understanding of a Neo4j Causal Cluster instance and its implementation of routing. The initial scenario is described with…
Read more
causal-cluster routing cypher-shell
A Demonstration of Cluster Size at Formation and Runtime
Causal Clustering Minimum Core Size At Formation causal_clustering.minimum_core_cluster_size_at_formation is defined as the minimum number of Core machines initially required to form a cluster. The cluster will form when at least…
Read more
causal-cluster configuration
A demonstration of IntraCluster SSL Encryption
This document provides a step-by-step demonstration of the process to deploy a Self-Signed SSL Certificate, to member instances of a Causal Cluster, aimed at achieving intra-cluster encryption. The steps can…
Read more
ssl tls certificate causal-cluster encryption
A method to replicate a Causal Cluster to new hardware with minimum downtime
If the opportunity arises such that you are in need of replicating your existing Causal Cluster to a new hardware setup, the following can be used to allow for minimal…
Read more
causal-cluster clone
Add a Neo4j instance to a running embedded HA application
There are situations when we would like to use the Neo4j Browser to access an embedded HA cluster. The documented approach to accomplish that goal requires changing the embedded application…
Read more
embedded ha
An example of neo4j-import steps in a Causal Cluster environment
The following steps are provided to describe how to use neo4j-import in a Causal Cluster environment and was run from an environment of a single linux host with 3 copies…
Read more
import causal-cluster ha
Are my cluster transactions/messages encrypted.
For all versions prior to 3.3, there is no encryption done specifically on the contents being transferred. Furthermore, since it doesn’t use REST or Bolt, there is no SSL/https configuration…
Read more
causal-cluster encryption
Causal Cluster FAQ for heavy workloads
Lagging of follower instances and what causes it? The main reason for followers to fall behind is highly concurrent and continuous read/write workloads. This can cause the instances get overwhelmed…
Read more
causal-cluster leader follower writes latency bookmark
Cluster: org.neo4j.kernel.impl.transaction.log.NoSuchTransactionException: Unable to find transaction 1 in any of my logical logs: Couldn’t find any log containing 1
When operating a causal cluster, if ""the store"" (data/databases/graph.db) is removed from a server that was previously a member of the cluster we will get the following exception when that…
Read more
causal-cluster exception
Comparing HA and Causal Clusters
The legacy HA cluster mode has been deprecated as of Neo4j version 3.5, and will be totally removed from the product in version 4.0, with 4.0 expected to be released…
Read more
ha cluster bolt http https load balancer
Configure HAProxy to Send Write Requests to Leader Node Only
There are a few options regarding implementation of a proxy server to direct writes to a Master node and reads to the Slave nodes in a Neo4j cluster. Commonly, it…
Read more
cluster master writes load balancer
How do I resolve inconsistency problems on an instance of a cluster
(if using HA (High Availability, please read Leader and Follower instead of Master and Slave respectively) Sometimes, when running a clustered Neo4j environment, a slave’s store may become inconsistent. On…
Read more
cluster master slave backup consistency
Deploying Neo4j on AWS Using CloudFormation
This page describes how to use CloudFormation to deploy Neo4j clusters on AWS, using Virtual Machines. Basics The Neo4j CloudFormation templates allow deploying causal clusters of any size, with almost…
Read more
cloud aws deployment
Explanation of error ""Failed to obtain connection towards WRITE server. Known routing table is: Ttl…""
In Neo4j 4.0, if you are logged into the READ_REPLICA of a Causal Cluster, and execute the following command to login into cypher-shell: You will encounter this error: The reason…
Read more
cypher-shell bolt
HA Proxy Configuration for Online Backup
What are we trying to achieve? Online backup should be scheduled to run periodically on a production cluster. You only need to run it on one instance, since each has…
Read more
cluster backup ha-proxy
How do I display a hostname rather than IP address in the Causal Clustering Members section of sysinfo
Via the browser one can enter :sysinfo to display data about the Neo4j system. When Neo4j is configured as a causal cluster, the bottom-right corner of the `:sysinfo' output will…
Read more
sysinfo causal cluster ip address hostname
How to monitor if a follower is in sync with Leader (Causal Cluster)
To monitor if a Follower is in sync with its Leader, or know how much it is lagging behind, it is possible to check the Last Commited Transaction Id from…
Read more
server cluster causal cluster leader follower writes
Mitigating Causal Cluster re-elections caused by high GCs
This article describes the effects of JVM stop-the-world GC pauses, on a causal cluster. A brief introduction to garbage collection, heap sizing and memory leak troubleshooting, is followed by a…
Read more
causal cluster election garbage-collection timeout
Planning Data Center Migration
The following KB describes the process that you can use utilizing backup (or Read-Replicas) in order to migrate (and/or upgrade) from one datacenter(DC1) to another(DC2) in a rolling fashion with…
Read more
disk operation storage cluster capacity
Setup Routing Policies for Different User Types To Direct them to Different Servers
Problem statement There is a Causal Cluster Setup with 3 Cores and 1 Read Replica. There are 2 user groups - OLTP users and OLAP users. OLTP user queries should…
Read more
causal cluster multi-datacenter
Understanding causal cluster quorum and cluster recovery
Several major causal cluster operations require a majority of cluster members to be online, a majority quorum. When a causal cluster loses majority quorum, it loses write capability as well…
Read more
cluster
Understanding causal cluster size scaling
The ability to safely scale down the size of a causal cluster affords us more robustness for instance failures, provided we maintain quorum as the failures take place. Prior to…
Read more
cluster scaling
Upgrading your Causal Cluster from 3.1.x to 3.2.x
This article outlines possible steps to upgrade your Neo4j 3.1.2+ Causal Cluster to 3.2.2. For this upgrade path, Neo4j does not support rolling upgrades, so downtime is required to complete…
Read more
upgrade causal cluster
Upstream strategy behaviour change
Starting with version 3.4, we changed in the behaviour of how instances sync with the Leader. This change can potentially affect the behaviour of your cluster when using strategy plugins,…
Read more
network multi-datacenter
When authentication is enabled in Neo4j, how do I call the HA Status
One can enable authentication for the Neo4j database by adding the following to the conf/neo4j-server.properties In doing so any connections to the database will need to provide a username/password. However,…
Read more
server configuration
When to use bookmarks
Bookmarks are part of a broader topic: Causal consistency. We recommend reading the introduction to Neo4j Causal Clustering and the lifecycle of a Neo4j Causal Cluster before reading further. Pay…
Read more
cluster causal leader follower bookmarks drivers"
https://neo4j.com/developer/kb/a-method-to-replicate-a-causal-cluster-to-new-hardware-with-minimum-downtime;"A method to replicate a Causal Cluster to new hardware with minimum downtime
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster clone
If the opportunity arises such that you are in need of replicating your existing Causal Cluster to a new hardware setup, the following can be used to allow for minimal downtime.
Let us first start with an existing 3 instances cluster with the following characteristics:
neo4j> call dbms.cluster.overview
+---------------------------------------------------------------------------------------------------------------------------------------------+
| id                                     | addresses                                                                    | role       | groups |
+---------------------------------------------------------------------------------------------------------------------------------------------+
| ""ffc16977-4ab8-41b5-a4e2-e0e32e8abd6f"" | [""bolt://10.1.1.1:7617"", ""http://10.1.1.1:7474"", ""https://10.1.1.1:7473""] | ""LEADER""   | []     |
| ""f0a78cd1-7ba3-45f6-aba3-0abb60d785ef"" | [""bolt://10.1.1.2:7627"", ""http://10.1.1.2:7474"", ""https://10.1.1.2:7473""] | ""FOLLOWER"" | []     |
| ""2fe26571-6fcc-4d1e-9f42-b81d08579057"" | [""bolt://10.1.1.3:7637"", ""http://10.1.1.3:7474"", ""https://10.1.1.3:7473""] | ""FOLLOWER"" | []     |
+---------------------------------------------------------------------------------------------------------------------------------------------+
Each instance has defined its conf/neo4j.conf with https://neo4j.com/docs/operations-manual/current/reference/configuration-settings/#config_causal_clustering.expected_core_cluster_size and causal_clustering.initial_discovery_members defined as:
Properties
Copy to Clipboard
causal_clustering.expected_core_cluster_size=3
causal_clustering.initial_discovery_members=10.1.1.1:5001,10.1.1.2:5002,10.1.1.3:5003
All other ports referenced are using the default values.
To add 3 new instances, for example at IP address 10.2.2.1, 10.2.2.2 and 10.2.2.3 perform the following steps
install and create the new 3 instances cluster at IP addresses 10.2.2.1, 10.2.2.2 and 10.2.2.3.
in each of these 3 new instances conf/neo4j.conf define their ha.initial_hosts to be defined as:
Properties
Copy to Clipboard
causal_clustering.initial_discovery_members=10.1.1.1:5001,10.1.1.2:5001,10.1.1.3:5001
Start up each instance at 10.2.2.1, 10.2.2.2, and 10.2.2.3. These 3 new instances will then join the initial cluster at 10.1.1.1, 10.1.1.2 and 10.1.1.3 and copy down the databases\graph.db. Running dbms.cluster.overview(); will return output similar to:
+---------------------------------------------------------------------------------------------------------------------------------------------+
| id                                     | addresses                                                                    | role       | groups |
+---------------------------------------------------------------------------------------------------------------------------------------------+
| ""ffc16977-4ab8-41b5-a4e2-e0e32e8abd6f"" | [""bolt://10.1.1.1:7687"", ""http://10.1.1.1:7474"", ""https://10.1.1.1:7473""] | ""LEADER""   | []     |
| ""f0a78cd1-7ba3-45f6-aba3-0abb60d785ef"" | [""bolt://10.1.1.2:7687"", ""http://10.1.1.2:7474"", ""https://10.1.1.2:7473""] | ""FOLLOWER"" | []     |
| ""2fe26571-6fcc-4d1e-9f42-b81d08579057"" | [""bolt://10.1.1.3:7687"", ""http://10.1.1.3:7474"", ""https://10.1.1.3:7473""] | ""FOLLOWER"" | []     |
| ""847b74c2-34a9-4458-b0e2-ea36cf25fdbf"" | [""bolt://10.2.2.1:7687"", ""http://10.2.2.1:7474"", ""https://10.2.2.1:7473""] | ""FOLLOWER"" | []     |
| ""39f92686-f581-4454-b288-a2254d38ea5c"" | [""bolt://10.2.2.2:7687"", ""http://10.2.2.2:7474"", ""https://10.2.2.2:7473""] | ""FOLLOWER"" | []     |
| ""e4114ad2-dcd1-4d22-8f56-a085524c9ed0"" | [""bolt://10.2.2.2:7687"", ""http://10.2.2.3:7474"", ""https://10.2.2.3:7473""] | ""FOLLOWER"" | []     |
+---------------------------------------------------------------------------------------------------------------------------------------------+
Once the 3 new instances have completed the copy of graph.db from master, one can then cleanly stop the 3 initial instances at 10.1.1.1, 10.1.1.2, and 10.1.1.3 via a bin/neo4j stop. The 3 remaining instances will continue to run:
+---------------------------------------------------------------------------------------------------------------------------------------------+
| id                                     | addresses                                                                    | role       | groups |
+---------------------------------------------------------------------------------------------------------------------------------------------+
| ""847b74c2-34a9-4458-b0e2-ea36cf25fdbf"" | [""bolt://10.2.2.1:7687"", ""http://10.2.2.1:7474"", ""https://10.2.2.1:7473""] | ""LEADER""   | []     |
| ""39f92686-f581-4454-b288-a2254d38ea5c"" | [""bolt://10.2.2.2:7687"", ""http://10.2.2.2:7474"", ""https://10.2.2.2:7473""] | ""FOLLOWER"" | []     |
| ""e4114ad2-dcd1-4d22-8f56-a085524c9ed0"" | [""bolt://10.2.2.2:7687"", ""http://10.2.2.3:7474"", ""https://10.2.2.3:7473""] | ""FOLLOWER"" | []     |
+---------------------------------------------------------------------------------------------------------------------------------------------+
If a Load Balancer was in front of the 3 instance cluster, at 10.1.1.1, 10.1.1.2, and 10.1.1.3, it should be updated to now point to 10.2.2.1, 10.2.2.2, and 10.2.2.3.
Since the initial 3 instances have been shut down and to provide ability for the 3 new instances to successfully restart at some later time, update the causal_clustering.initial_discovery_members of the new 3 instances and change:
Properties
Copy to Clipboard
causal_clustering.initial_discovery_members=10.1.1.1:5001,10.1.1.2:5001,10.1.1.3:5001
to:
Properties
Copy to Clipboard
causal_clustering.initial_discovery_members=10.2.2.1:5001,10.2.2.2:5001,10.2.2.3:5001
If you are currently using the Bolt driver to connect to the cluster, you would then need to update the connection string to reference a new url, for example changing bolt+routing://10.1.1.1:7678 to bolt+routing://10.2.2.1:7678.
Was this page helpful?"
https://neo4j.com/developer/kb/planning-data-center-migration;"Planning Data Center Migration
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags disk operation storage cluster capacity
The following KB describes the process that you can use utilizing backup (or Read-Replicas) in order to migrate (and/or upgrade) from one datacenter(DC1) to another(DC2) in a rolling fashion with no zero downtime.
This approach involves utilizing a recent backup from the DC1 cores then slowly adding DC2 cores based on the backup, whilst deleting old DC1 cores.
Specifically, you would want to follow a rolling pattern:
None
Copy to Clipboard
1) Add 2 cores to DC2
2) Remove 1 core from DC1
3) Add one core to DC2
4) Remove 2 remaining cores from DC1
Please note that between each of the above steps, you should monitor the cluster status endpoint on each machine, to make sure that new joiners are adequately caught up and participating in raft before shutting down an old member.
The endpoint, an example response, and how to interpret it are documented here: https://neo4j.com/docs/operations-manual/current/monitoring/causal-cluster/http-endpoints/#causal-clustering-http-endpoints-status
The key points to consider for this approach are the following:
Can you afford some period of reduced write throughput, due to some Cores being outside of DC1 (i.e. inter-DC network hops are required for commits)
How do you get a sufficiently up to date backup on each new Core such that a store copy won’t be required as soon as they join the cluster.
The second point above really depends on your workload. That is if the workload is perhaps very high then perhaps you need to use an alternative approach utilizing Read-Replicas(RR), where you would set up 3 RRs in the DC2 which you eventually switch off and unbind (just before you start your rolling migration).
Now, if you must use RRs, then follow these instructions:
None
Copy to Clipboard
1) Start the 3 RRs some time before migration cut over date
2) Wait until they’re caught up with the Cores (let’s call the Cores dc1.1, dc1.2, dc1.3)
3) Then stop the RRs
4) Run ""$bin/neo4j-admin unbind"" against all RR instances
5) Reconfigure them all to be Cores (call them dc2.4, dc2.5 and dc2.6)
6) Start dc2.4 and dc2.5
7) Use the status endpoint to make sure they’re keeping up with dc1.1, dc1.1 and dc1.1
8) Then shutdown dc1.1
9) Followed by starting dc2.6
10) Lastly, shut down dc1.1 and dc1.2
Again, use the status endpoint to make sure that dc2.6 gets up to date and keeps up with dc1.1, dc.2, dc2.4 and dc2.5
If it all goes well, then you have rolled to the new data center(DC2) with no downtime.
Lastly, you’ll want to update the configs of DC2.4, DC2.5 and DC2.6 later on to remove the DC1 instances from initial_discovery_members etc.
But you don’t need to restart the database to do that - you can just modify the config file and allow that setting to be picked up on the next restart of each instance.
RR Dryrun:
None
Copy to Clipboard
1) Set up a single RR in the On-prem database
2) Try turning it into a Core
3) And making sure it catches up, using the status endpoint
4) That should give you good data on how long things are likely to take on the day of the migration
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-causal-cluster-size-scaling;"Understanding causal cluster size scaling
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster scaling
The ability to safely scale down the size of a causal cluster affords us more robustness for instance failures, provided we maintain quorum as the failures take place.
Prior to 3.4, we used a single config property to define both the minimum core cluster size needed at formation, and the minimum cluster size for scaling down:
causal_clustering.expected_core_cluster_size
With 3.4 the above config property has been deprecated and its behavior separated into 2 config properties:
causal_clustering.minimum_core_cluster_size_at_formation
and
causal_clustering.minimum_core_cluster_size_at_runtime
While the first of these (the core cluster size required for formation) is easy to understand, the minimum core cluster size at runtime is not so simple, and requires some understanding of raft consensus and cluster size scaling.
It should be noted before continuing that the default value of 3 for causal_clustering.minimum_core_cluster_size_at_runtime is sufficient for most cluster deployments and affords the best ability to scale down the cluster size safely. Only for very specific multi-datacenter requirements or special cases would a different value be reasonable.
Consensus operations in Raft
Causal clustering uses the Raft consensus protocol, which requires a majority quorum of core cluster instances for most cluster operations.
Here’s a an easy to understand visual walkthrough of distributed consensus operations in Raft.
While this is usually understood to apply to commits to the cluster, this also applies to voting (in and out) of cluster members:
Quorum is required to accept a new member into the cluster.
Quorum is required to vote out a member of the cluster.
Both of these will change the runtime size of the core cluster members, potentially changing the number of core cluster members required for quorum, and thus the number of failures the cluster can tolerate before losing quorum (and write capability).
Voting in a new member to the cluster
The first point should be fairly easy to understand.
This is also the reason why, if a cluster loses quorum (and write capability) that we cannot restore it by adding new members to the cluster dynamically: a quorum of online cluster members is required to vote in a new cluster member.
The only way to recover quorum is to restore enough of those instances which are offline (but which weren’t voted out of the cluster, due to loss of quorum).
Voting out cluster members and shrinking the cluster
The second point is a little bit more complicated.
The act (or at least attempt) of voting out a member of the cluster happens in all situations, planned or unexpected, when a core cluster instance is no longer participating in the cluster.
This can be in response to Neo4j being shut down or restarted for that instance, where the instance tells the rest of the cluster it is leaving, or a more unexpected case where the instance is killed (or maybe network issues are present), and the instance heartbeat isn’t received over the expected timeout interval and the cluster’s discovery service determines that instance is offline.
At that point, provided we are not currently at the minimum_core_cluster_size_at_runtime, the cluster attempts to vote out the instance from the cluster, and this will only pass if a quorum of core cluster instances is online.
If a quorum is present, the instance is voted out, and the core cluster size shrinks accordingly, changing the number of core instances required for quorum.
If a quorum is not present, or we’re at the minimum_core_cluster_size_at_runtime, the vote will not take place, we cannot vote out the instance, and though it may be offline, we cannot shrink the cluster size as far as Raft is concerned, so the number required for quorum will not change, nor will the number of failures the cluster can tolerate.
Example with a cluster of 3 and minimum cluster size of 3
The default value for causal_clustering.minimum_core_cluster_size_at_runtime is 3.
This means, when we reach a cluster size of 3 and lose an instance, we cannot scale the cluster down further:
If one of those 3 core cluster instances goes offline, no vote to remove the instance will take place even if we have a quorum of 2.
The cluster size will stay at 3 and will not shrink to 2. The offline instance is still considered a member of the cluster even if it’s not available.
With only 2 out of 3 instances online, if another instance fails we lose quorum and write capability.
If a different core instance gets added it can still be voted in, since we still have quorum of 2 instances.
Example with a cluster of 5 and a minimum cluster size of 3
If we started out with a 5 instance cluster, quorum would be 3 of the 5 instances, and we can tolerate 2 simultaneous instance failures while keeping quorum.
In the event of losing up to 2 instances of those 5 (simultaneously or progressively, planned or unplanned), a member vote-out would take place and succeed, since a quorum is present. The cluster size would then scale down accordingly to a 3-instance cluster, with a new quorum size of 2 out of 3 and the ability to tolerate just one more instance failure safely while keeping quorum and write capability.
Basically when we scale down to a 3-instance cluster the behavior for the above section (cluster of 3, min cluster size of 3) applies.
Example with a cluster of 5 and a minimum cluster size of 5
If we started with a 5 instance cluster and minimum cluster size of 5, we would not be able to scale down to a smaller cluster with instance failures.
While we could tolerate up to 2 simultaneous instance failures while keeping quorum, no cluster scaling would occur, and no instances voted out, and no more instances could be lost without losing quorum and write capability.
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-causal-cluster-quorum-and-cluster-recovery;"Understanding causal cluster quorum and cluster recovery
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster
Several major causal cluster operations require a majority of cluster members to be online, a majority quorum. When a causal cluster loses majority quorum, it loses write capability as well as the ability to add or remove members of the cluster.
This article explains the reasoning for this behavior, and how it impacts recovery from certain cluster issues.
Quorum commits and data durability
When we lose quorum, the cluster goes into a read-only state and no longer has a leader to perform writes.
This behavior is part of the Raft protocol that backs causal clustering, and is in place to ensure data durability and maintain database ACIDity.
Since we have quorum commits, when quorum is lost, in the worst case scenario the quorum of nodes with the latest data are all offline, and none of the online nodes have the latest commits.
It would be a mistake to allow writes until we restore quorum and ensure the cluster reflects the latest committed data.
Quorum vote in/out and cluster recovery
Quorum is also needed to vote in and out cluster members, and this affects both cluster size scaling and options available for cluster recovery.
Note that cluster membership is separate from a cluster node’s online or offline state. It is possible for a node to be a member of the cluster yet be unreachable or offline.
While an unreachable or offline node may trigger a vote-out attempt to remove the node from cluster membership, the vote-out operation has two requirements:
That the membership count of cluster members is above causal_clustering.minimum_core_cluster_size_at_runtime.
That there is a majority quorum present to pass the vote.
As discussed in the article on cluster size scaling, a cluster can gracefully scale down in size down to the configured causal_clustering.minimum_core_cluster_size_at_runtime (default 3), provided that quorum is maintained.
As clusters scale down (or up!) in size, the number of online nodes required for majority quorum will change according to the cluster membership size.
When we lose quorum, nodes that went offline/unresponsive that were responsible for the loss of quorum must be restored in order to regain quorum. Remember, even though these members may be offline, they are still counted as members of the cluster, as they were never voted out due to the loss of quorum.
We cannot add in new cluster members in order to recover quorum, since quorum is required to vote in new cluster members.
While this may seem restrictive in that we cannot simply add new nodes to a cluster to restore normal operation, this behavior still supports data durability.
In the worst case scenario as discussed in the previous section, when quorum is lost, there is the possibility that only the offline nodes contain the latest committed data (due to quorum commits).
If we incorrectly allowed new nodes to be added to restore quorum, we could restore write operations, but data would be lost with the offline members. Even if we were to later restore these members, in the meantime the new commits may be in conflict with the lost data, resulting in either duplicated or inconsistent data, with no clear way to resolve the conflict.
Requiring quorum for both commits and cluster vote in/out operations is required to maintain data durability in the cluster.
Example log messages for vote in/out operations
Raft membership operations appear in the debug log, here are a few examples of what you might see.
We’re using a causal cluster with up to 6 core members. For this configuration, we’re using discovery ports 5001 through 5006 for each member accordingly, and raft listen addresses of 7001 through 7006 accordingly.
At this point in time, we have 4 core nodes online, corresponding with nodes 1, 2, 3, and 5. At this point we attempt to start node 6.
In the debug logs, we’ll see multiple debug messages, but these in particular show discovery of new member and a (successful!) attempt to add the new member to the cluster:
2019-03-29 21:57:59.670+0000 INFO [o.n.c.d.CoreMonitor] Discovered core member at localhost:5006
2019-03-29 21:57:59.676+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[{memberId=MemberId{416eca31}, info=CoreServerInfo{raftServer=localhost:7006, catchupServer=localhost:6006, clientConnectorAddresses=bolt://localhost:7667,http://localhost:7464,https://localhost:7463, groups=[], database=default, refuseToBeLeader=false}}], removed=[]}
2019-03-29 21:57:59.676+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{1b45d851}, MemberId{cf17e1cf}, MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{416eca31}]
...
2019-03-29 21:58:14.806+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Getting consensus on new voting member set [MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}, MemberId{416eca31}]
2019-03-29 21:58:14.806+0000 INFO [o.n.c.c.c.m.RaftMembershipChanger] ConsensusInProgress{}
2019-03-29 21:58:14.813+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Appending new member set RaftMembershipState{committed=MembershipEntry{logIndex=5, members=[MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}]}, appended=MembershipEntry{logIndex=6, members=[MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}, MemberId{416eca31}]}, ordinal=7}
If we stop node 6, we’ll see the member set change accordingly as the rest of the cluster votes node 6 out of the cluster:
2019-03-29 22:09:40.191+0000 WARN [o.n.c.d.CoreMonitor] Lost core member at localhost:5006
2019-03-29 22:09:40.203+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[], removed=[{memberId=MemberId{416eca31}, info=CoreServerInfo{raftServer=localhost:7006, catchupServer=localhost:6006, clientConnectorAddresses=bolt://localhost:7667,http://localhost:7464,https://localhost:7463, groups=[], database=default, refuseToBeLeader=false}}]}
2019-03-29 22:09:40.203+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{1b45d851}, MemberId{cf17e1cf}, MemberId{2011b3fb}, MemberId{3e6dbf35}]
2019-03-29 22:09:40.204+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Getting consensus on new voting member set [MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}]
2019-03-29 22:09:40.204+0000 INFO [o.n.c.c.c.m.RaftMembershipChanger] ConsensusInProgress{}
2019-03-29 22:09:40.209+0000 INFO [o.n.c.m.RaftOutbound] No address found for MemberId{416eca31}, probably because the member has been shut down.
2019-03-29 22:09:40.209+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Appending new member set RaftMembershipState{committed=MembershipEntry{logIndex=6, members=[MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}, MemberId{416eca31}]}, appended=MembershipEntry{logIndex=7, members=[MemberId{2011b3fb}, MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}]}, ordinal=9}
In both cases, you can see that membership changes are implemented as consensus commits.
Example log messages when dropping below minimum core size at runtime
In this scenario, nodes 1, 3, and 5 are up for a cluster of 3. We will stop node 3 and observe the log messages:
2019-03-29 22:12:20.280+0000 WARN [o.n.c.d.CoreMonitor] Lost core member at localhost:5003
2019-03-29 22:12:20.281+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[], removed=[{memberId=MemberId{cf17e1cf}, info=CoreServerInfo{raftServer=localhost:7003, catchupServer=localhost:6003, clientConnectorAddresses=bolt://localhost:7637,http://localhost:7434,https://localhost:7433, groups=[], database=default, refuseToBeLeader=false}}]}
2019-03-29 22:12:20.281+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{1b45d851}, MemberId{3e6dbf35}]
2019-03-29 22:12:20.281+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Not safe to remove member [MemberId{cf17e1cf}] because it would reduce the number of voting members below the expected cluster size of 3. Voting members: [MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}]
The target membership of 2 nodes is not achievable, since this would reduce the number of voting members below the runtime cluster size of 3. So even though node 3 is offline, it cannot be removed from the membership set. Quorum size remains at 2/3 nodes for majority, which we maintain since 2 cluster nodes remain online. In the logs we would likely see connection attempts to the offline node, since it’s still considered a cluster member even if offline.
If we remove one more node we will lose quorum:
2019-03-29 22:23:05.055+0000 WARN [o.n.c.d.CoreMonitor] Lost core member at localhost:5005
2019-03-29 22:23:05.056+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[], removed=[{memberId=MemberId{1b45d851}, info=CoreServerInfo{raftServer=localhost:7005, catchupServer=localhost:6005, clientConnectorAddresses=bolt://localhost:7657,http://localhost:7454,https://localhost:7453, groups=[], database=default, refuseToBeLeader=false}}]}
2019-03-29 22:23:05.056+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{3e6dbf35}]
2019-03-29 22:23:05.056+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Not safe to remove members [MemberId{1b45d851}, MemberId{cf17e1cf}] because it would reduce the number of voting members below the expected cluster size of 3. Voting members: [MemberId{3e6dbf35}, MemberId{1b45d851}, MemberId{cf17e1cf}]
We would likely see this accompanied by a stepdown event, as we cannot have a leader or write capability without quorum:
2019-03-29 22:23:20.100+0000 INFO [o.n.c.c.c.s.RaftState] Leader changed from MemberId{3e6dbf35} to null
...
2019-03-29 22:23:20.101+0000 INFO [o.n.c.c.r.RaftReplicator] Lost previous leader 'MemberId{3e6dbf35}'. Currently no available leader
2019-03-29 22:23:20.101+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Step down event detected. This topology member, with MemberId MemberId{3e6dbf35}, was leader in term 2, now moving to follower.
We would likely see this accompanied by connection attempts being made to the two offline cluster members, along with failed elections as quorum isn’t present.
Let’s see what happens if we attempt to start node 6 at this point. Remember, node 6 has already been voted out of the cluster, so it isn’t considered a cluster member, and quorum of cluster members isn’t present, so we should see the join attempt fail:
2019-03-29 22:29:41.003+0000 INFO [o.n.c.d.CoreMonitor] Discovered core member at localhost:5006
2019-03-29 22:29:41.004+0000 INFO [c.n.c.d.SslHazelcastCoreTopologyService] Core topology changed {added=[{memberId=MemberId{416eca31}, info=CoreServerInfo{raftServer=localhost:7006, catchupServer=localhost:6006, clientConnectorAddresses=bolt://localhost:7667,http://localhost:7464,https://localhost:7463, groups=[], database=default, refuseToBeLeader=false}}], removed=[]}
2019-03-29 22:29:41.004+0000 INFO [o.n.c.c.c.m.RaftMembershipManager] Target membership: [MemberId{3e6dbf35}, MemberId{416eca31}]
The topology and target membership messages show that the new node has been detected and wants to join in the cluster, but we do not see the consensus messages on the new voting member set or the appending of the new member set with a commited MembershipEntry.
Since we don’t see the consensus messages or the commit membership entry messages, we know that node 6 was not able to successfully join the cluster.
If we restore one of the offline member nodes and reestablish quorum by having the majority of cluster members online, we will see the consensus and committed membership entry messages resume as quorum would allow the cluster to start voting in and out cluster members once again, and the quorum size would change accordingly as the membership set changes.
How neo4j-admin unbind impacts causal cluster recovery
Several recovery procedures for causal cluster issues require usage of neo4j-admin unbind, which deletes cluster state, and is usually executed in concert with deleting, overwriting (such as from a restore) or moving the graph.db on the instance. Since the graph data is being changed, the cluster state no longer reflects the state of the store, thus the unbind operation is necessary.
It is important to understand how this affects cluster membership, and how in certain situations this may impact cluster recovery:
A node which has had its cluster state unbound cannot be used to restore quorum (and thus write operation) to a cluster.
When you execute neo4j-admin unbind, because that node’s cluster state is being destroyed, its identity in the cluster is also destroyed. When the node is brought back online it will have a new member id and appear as a brand new node to the cluster.
If the cluster currently has a majority quorum of cluster members online, then there should be no negative consequences, as quorum should allow the newly recovered node to be voted into the cluster.
But if the cluster does not have quorum, then the newly recovered node cannot be voted in and cannot contribute to stabilizing the cluster. Even if the recovered node’s previous member id is still counted as a cluster member (has not been voted out of the cluster), the node cannot assume its previous identity, and cannot pass itself off as a current member. And it would not be correct to allow such to happen.
This behavior is intended, and is part of the Raft implementation which contributes to data durability. Without this behavior, then there could be scenarios that could result in data loss or data conflict in the cluster.
When a cluster loses quorum, the only way to restore it is to get one of the current offline members (which hasn’t been voted out) to rejoin the cluster, and neo4j-admin unbind must not have been used on the member.
If quorum has been lost, and there is no way to bring any current offline members back online without usage of neo4j-admin unbind, then you may be forced to fall back to full cluster recovery procedures, which will require bringing the cluster offline.
Was this page helpful?"
https://neo4j.com/developer/kb/categories/neo4j-spark-connector;"Articles tagged as neo4j-spark-connector
Explanation of error ""java.lang.NoClassDefFoundError: org/apache/spark/sql/sources/v2/ReadSupport""
In Neo4j 4.x, if you are using the Databricks Run-time of Spark and the neo4j-spark-connector. You may encounter either of these errors when trying to read or write to neo4j…
Read more
spark pyspark databricks neo4j-spark-connector"
https://neo4j.com/developer/kb/categories/developmnt;"Articles tagged as developmnt
Favorites for cypher-shell?
The Neo4j Browser has always had the ability to record favorites, i.e. a bookmark to saved cypher that you may want to run sometime in the future. bin\cypher-shell has somewhat…
Read more
cypher-shell favorites"
https://neo4j.com/developer/kb/recovering-local-bloom-perspectives;"Recovering Local Bloom Perspectives
Author Jon Harris Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags bloom perspectives recovery
Summary
When Bloom is connected to a Neo4j server that does not have the Bloom plugin installed it stores perspectives locally in the Web Browser or Neo4j Desktop’s local storage.
In some rare instances users may experience trouble starting up Bloom and and it can be necessary to clear this local storage to resume normal functioning, which would result in the loss of all local perspectives.
To remedy this problem, Bloom version 1.3.2 and above provides a command that you can run from the developer tools that will export all local perspectives to a zip file.
The provided command can be run even if the Bloom user interface has not successfully loaded.
Opening Developer Tools in a Web Browser
Chrome
Command+Option+J (Mac)
Control+Shift+J (Windows, Linux)
Firefox / Edge
Command+Option+I (Mac)
Control-Shift+I or F12 (Windows, Linux)
Opening Developer Tools in Neo4j Desktop
To access the developer tools while running Bloom in Neo4j Desktop you need to enable development mode in Neo4j Desktop before starting Bloom.
This can be done by scrolling to the bottom of the Settings page of Neo4j Desktop, and checking the ""Enable development mode"" checkbox under the ""Developer tools"" heading.
Once this is done, restart Bloom and you should see ""Reload App"" and ""App Developer tools"" buttons in a panel across the top.
Click the ""App Developer tools"" button.
Running the command from developer tools
Once you have opened the developer tools via the appropriate steps above, you can type or paste the following command into the Console (may require clicking on the ""Console"" tab first), and then press enter/return key to execute it:
JavaScript
Copy to Clipboard
window.exportLocalPerspectives()
This will trigger a download of a zip file containing all the perspectives stored locally by Bloom.
The individual perspectives inside the zip file can later be imported into Bloom via its user interface.
Was this page helpful?"
https://neo4j.com/developer/kb/bloom-compatibility-neo4j50;"Bloom Compatibility with Neo4j 5.0
Author Jeff Gagnon Applicable versions 4.3+ Tags bloom
Neo4j Bloom makes use of database procedures for identifying indexes and constraints that have been deprecated and will be unavailable in Neo4j 5.0. These changes have been implemented to ensure a higher level of security compliance and to enable administrators better control over which information is available to authorized users.
Bloom will use the supported SHOW INDEXES and SHOW CONSTRAINTS Cypher commands in place of these deprecated procedures on Neo4j 5.0 and above, but starting with Bloom 2.3, it is possible to have Bloom use the supported commands prior to upgrading to Neo4j 5.0, on Neo4j versions 4.3 and above.
To have Bloom use the supported commands, users can activate 'Experimental features' in the Bloom Settings drawer, and then activate 'Use updated commands to access procedures, indexes & constraints' in the Experimental features drawer. After restarting Bloom and logging in, the supported commands will be in use.
The ability to run or receive results from the SHOW INDEXES and SHOW CONSTRAINTS commands may be limited to certain database users based on Neo4j Role Based Access Control settings. In order to confirm that database roles for Bloom users have appropriate permissions for Bloom to run as expected using the supported commands, it is recommended that organizations test Bloom functionality by activating the 'Use updated commands to access procedures, indexes & constraints' experimental feature and logging in with user accounts assigned roles typical of Bloom users in the organization.
If the roles assigned to Bloom users do not have the required permissions to execute and see results from the supported commands, Bloom will return an error at login:
Bloom requires visibility of database indexes and constraints to function. User ""user"" with role(s) roles needs to have permission granted to execute ""index"" procedures. Please contact your database administrator.
Administrators can add privileges to execute SHOW INDEXES and SHOW CONSTRAINTS commands to relavant roles using the following commands:
GRANT SHOW CONSTRAINT ON {HOME DATABASE | DATABASE[S] {* | name[, …]}} TO role[, …]
GRANT SHOW INDEX ON {HOME DATABASE | DATABASE[S] {* | name[, …]}} TO role[, …]
See the Neo4j Role Based Access Control documentation on [Index management](https://neo4j.com/docs/cypher-manual/current/access-control/database-administration/#access-control-database-administration-index) and [Constraint management](https://neo4j.com/docs/cypher-manual/current/access-control/database-administration/#access-control-database-administration-constraints) privileges for further details.
Was this page helpful?"
https://neo4j.com/developer/kb/categories/tools;"Articles tagged as tools
How to use the BI Connector on the Command Line
This article describes how to use the BI Connector integration with SQLLine. Prerequisites Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version 3.5.0.9…
Read more
jdbc sql tableau visualization bi-connector
How to use the BI Connector with Tableau Desktop
This article describes how to use the BI Connector integration with Tableau Desktop. Prerequisites Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version…
Read more
jdbc sql tableau visualization bi-connector
How to use the BI Connector with Tableau Server
This article describes how to use the BI Connector integration with Tableau Server. Prerequisites Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version…
Read more
jdbc sql tableau visualization bi-connector
Neo4j & JDBC: the Neo4j JDBC Driver vs. BI Connector
This page describes the connection between JDBC and Neo4j, and when users should use the BI Connector, vs. when they should use the Neo4j JDBC Driver. To begin with, let’s…
Read more
jdbc sql tableau cypher
Running copy store tool on windows
The copy store utilities is a set of tools to compact, copy, fix and analyse Neo4j stores. You might already know this but if not, you can read more about…
Read more
performance copy store tools
What Works with the BI Connector
This article provides an overview of what third-party applications to expect the BI connector work with. Prerequisites Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed…
Read more
jdbc sql tableau visualization bi-connector"
https://neo4j.com/developer/kb/how-to-use-the-bi-connector-with-sqlline;"How to use the BI Connector on the Command Line
Author Shashi Dookhee Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jdbc sql tableau visualization bi-connector
This article describes how to use the BI Connector integration with SQLLine.
Prerequisites
Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version 3.5.0.9 or 4.0.0.4 of the APOC library respectively.
Building SQLLine
Build the SQLLine package from source:
Shell
Copy to Clipboard
$ git clone https://github.com/julianhyde/sqlline.git
$ cd sqlline
$ mvn package
SQLLine comes with a shell script that knows how to launch it correctly. But before we run it directly, make sure that we have our Neo4j BI Connector JAR file in the right place. In this example, we’ll assume it’s in the SQLLine target folder (where the source build placed its JAR files) because that way it will automatically be on the classpath.
Configuring connection
Set the environment variables for connection:
Bash
Copy to Clipboard
export URL=""jdbc:neo4j://localhost:7687""
export DRIVER=com.simba.neo4j.jdbc.Driver
Connecting to the database
Perform the connection:
Shell
Copy to Clipboard
$ bin/sqlline -d ""$DRIVER"" -u ""$URL""
Enter username for jdbc:neo4j://localhost:7687: neo4j
Enter password for jdbc:neo4j://localhost:7687: *****
Feb 06, 2020 7:56:55 AM com.simba.neo4j.shaded.neo4j.driver.internal.logging.JULogger info
INFO: Direct driver instance 1540374340 created for server address localhost:7687
Verifying connection
Use the ""!tables"" command at the SQL prompt to get a list of tables. Perform a select query to verify the connection:
Things to watch out for
For performance reasons ensure that the Neo4j server has adequate resources. The driver may ""overfetch"" data depending on the query, so adequate resources (especially memory) would make a noticeable impact.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-use-the-bi-connector-with-tableau-server;"How to use the BI Connector with Tableau Server
Author Shashi Dookhee Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jdbc sql tableau visualization bi-connector
This article describes how to use the BI Connector integration with Tableau Server.
Prerequisites
Ensure that you are running Neo4j server 3.5.x or 4.x, and have installed at least version 3.5.0.9 or 4.0.0.4 of the APOC library respectively.
Install BI Connector on Tableau Desktop
The first step is to ensure the JAR file has been installed on Tableau Desktop as the data source must be published from Desktop to Server. Install the plugin by dropping the JDBC JAR file in to the appropriate driver directory depending on the platform:
Windows: C:\Program Files\Tableau\Drivers
Mac: ~/Library/Tableau/Drivers
Linux: /opt/tableau/tableau_driver/jdbc
Create datasource to connect to a Neo4j instance
Using Tableau’s ""Other JDBC Connection"" option, you need to create a datasource connected to a Neo4j instance using the appropriate JDBC connection string. For example:
jdbc:neo4j://10.0.0.50:7687
Connect to Tableau Server
Using the Tableau Desktop menu, select Server → Sign In, and you will be presented with the following dialog:
Once you choose a URL, you will be prompted to login to the Tableau server at that URL:
At this point you can verify you are actually logged in to the Tableau server:
Publish the datasource
Once connected, you must publish the datasource to the server. On the Tableau Desktop menu, select Server → Publish Data Source and fill out the form. Notably some of these fields (like ""Project"") refer to remote resources on the server. The screen should look something like this:
Verify the datasource is on the server
Connect to the Tableau Server URL in a web browser, explore the appropriate project, and ensure that that datasource is available. You should see something similar to this:
Additionally you can check you can actually query for data at this point:
Things to watch out for
When exploring the project on the server, ensure that you enter the correct authentication details as prompted for (i.e. the Neo4j server as opposed to the Tableau Server credentials). If you see the following error it’s a good indication of authentication/credential issues:
For performance reasons ensure that the Neo4j server has adequate resources. The driver may ""overfetch"" data depending on the query, so adequate resources (especially memory) would make a noticeable impact.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-and-jdbc;"Neo4j & JDBC: the Neo4j JDBC Driver vs. BI Connector
Author David Allen Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags jdbc sql tableau cypher
This page describes the connection between JDBC and Neo4j, and when users should use the BI Connector, vs. when they should use the Neo4j JDBC Driver.
To begin with, let’s start that JDBC is a transport; that is, it is a way of moving data from point to point. JDBC itself does not imply graph or tables; ""Java Database Connectivity"" is just concerned with an API for connecting to databases, issuing queries, and getting results.
The BI Connector
The BI Connector is a proprietary JDBC driver developed by Simba/Magnitude, in cooperation with Neo4j. For Neo4j Enterprise customers, professional support is available for the BI Connector.
It provides a JDBC-compatible interface for executing SQL queries against a Neo4j instance. The BI connector exposes a virtual relational schema for software tooling such as Tableau that expects a relational database, and which knows how to build & execute SQL queries.
The BI Connector supports Neo4j version 3.5 forward.
The Neo4j JDBC Driver
The Neo4j JDBC project is an Apache 2.0 licensed open source project that is run as part of Neo4j Labs. Community support via Neo4j’s usual channels is available.
It provides a JDBC-compatible interface for executing Cypher queries against a Neo4j instance and fetching results. On the project page, several examples are provided.
The Neo4j JDBC Driver supports Neo4j 3.0 and forward.
Usage Guidance
The BI Connector is recommended when the situation involves:
Business facing applications such as Tableau, where users may not be knowledgeable about graphs, or where the tool is generating queries automatically on their behalf (typically by SQL)
Enterprise support is needed
Integration with 3rd party tooling that is SQL/JDBC aware.
The Neo4j JDBC driver is recommended when the situation involves:
Developer tooling where the developer is writing the queries themselves, and knows Cypher.
Extract, Transform, and Load scenarios where tight control over the necessary Cypher is required
A custom java program where a driver is needed as a dependency
Was this page helpful?"
https://neo4j.com/developer/kb/categories/import-export;"Articles tagged as import-export
Importing Data to Neo4j in the Cloud
Loading data in a Neo4j instance that is in the cloud is very similar to running Neo4j using any other method. However, there are a few small things to look…
Read more
import cypher cloud
Executing Neo4j ETL from an RDBMS database running on Docker
Following provides some examples of importing a test csv data into Neo4j, using the Neo4j ETL tool’s command line interface with the source RDBMS database running on docker. Examples herein…
Read more
import export etl rdbms docker sql
Export a (sub)graph to Cypher script and import it again
Oftentimes you want to export a full (or partial) database to a file and import it again without copying the actual database files. If you want to do the latter,…
Read more
cypher export import
How do I specify the field and array delimiter to neo4j-import as a ASCII character
neo4j-import allows one to initially load a graph.db via CSV files. There may be times when using a ',' as a field or array delimiter is not appropriate as your…
Read more
neo4j-import delimiter
How do I use Cypher to connect to a RDBMS using JDBC
With the inclusion of java stored procedures in Neo4j 3.x, one can run Cypher to connect to a RDBMS using JDBC. To do so one needs to download and install…
Read more
logging server database
How do I use LOAD CSV to update/set properties of existing nodes
One can use LOAD CSV to perform a bulk update to existing nodes, and create new nodes, as follows. If we have a .csv called Movies.csv and its content is: and…
Read more
cypher import merge
How do I use LOAD CSV with data including quotes
When using LOAD CSV to read a file which includes data with double quote characters (""), the quotes need to be escaped as 2 double quote characters For example if…
Read more
load csv quotes
Importing CSV Files: Neo4j Aura, Desktop and Sandbox
Loading various kinds of files into Neo4j requires different locations depending on the tool you are using. Import methods we will cover: Remote: Neo4j Aura and Neo4j Sandbox Local: Neo4j…
Read more
load csv import cypher
Load CSV data in Neo4j from CSV files on Amazon S3 Bucket
Neo4j provides LOAD CSV cypher command to load data from CSV files into Neo4j or access CSV files via HTTPS, HTTP and FTP. But how do you load data from…
Read more
aws s3 import cli
Parsing of quotes for LOAD CSV and/or Import
When using LOAD CSV or neo4j-admin import if your data contains quotes they must be properly escaped to be imported otherwise one might encounter the error neo4j-admin import error LOAD…
Read more
load-csv quotes csv
Properly escaping input data for neo4j-import
When importing data using neo4j-import, make sure to review the required CSV file structure and considerations before moving on. http://neo4j.com/docs/stable/import-tool.html Escaping commas within the CSV: Consider the following string: Use…
Read more
import neo4j-import csv
How to import a file with LOAD CSV that has a space in file name?
When you try to import data from a file using LOAD CSV where the filename containing spaces for example you get the following error: Statement: Error: To allow for a…
Read more
load-csv
Using apoc.load.jsonParams to load data from Zendesk into Neo4j to learn about article subscribers
The following document describes how to utilize the Zendesk API to load data from Zendesk into Neo4j, specifically data about users who have chosen to subscribe/follow Knowledge Base section(s). This…
Read more
apoc json import
Using APOC to parse JSON results from Trello API
Prior to Neo4j 3.0, if you wanted to parse the JSON results from a call to a Web API, it would require you use one of the database drivers to…
Read more
apoc json import
Using the ACTUAL data type with neo4j-import
When importing data using neo4j-admin import, make sure to review the required CSV file structure and considerations before moving on. https://neo4j.com/docs/operations-manual/current/tools/import/ ACTUAL vs. String (default) or Integer: Each node in…
Read more
import neo4j-admin csv store"
https://neo4j.com/developer/kb/properly-escaping-input-data-for-neo4j-import;"Properly escaping input data for neo4j-import
Author Dave Gordon Applicable versions 2.1 2.2 2.3 3.1 3.2 3.3 3.4 3.5 Tags import neo4j-import csv
neo4j-import is intended to populate a new, empty database. It cannot be used to import into an existing database.
When importing data using neo4j-import, make sure to review the required CSV file structure and considerations before moving on.
http://neo4j.com/docs/stable/import-tool.html
Escaping commas within the CSV:
This applies to escaping any delimiter you use in place of a comma, if specified. Neo4j only supports single character delimiters.
Consider the following string: Use the force, Luke!
If you want import this field to into neo4j from a CSV file, you must escape that comma. The standard way to do this is to simply wrap quotes around the field. neo4j-import will know that everything within un-escaped quotes belongs to the same field.
CSV file:
Csv
Copy to Clipboard
:ID,:LABEL,movie,line
1,Movie,Star Wars,""Use the force, Luke!""
Shell
Import into empty database:
Copy to Clipboard
$ neo4j-import --into data/graph.db.1 --nodes simple_escape_test.csv
Cypher-shell
Verify using Cypher:
Copy to Clipboard
neo4j> match (n:Movie) return n.line;
+------------------------+
| n.line                 |
+------------------------+
| ""Use the force, Luke!"" |
+------------------------+
1 row
Now, what if we want to include multiple lines in an array for a single movie node?
Escaping the array delimiter within the CSV:
Consider the following array: {[Use the force, Luke!], [Help me, Obi-Wan Kenobi; you’re my only hope.]}
If you want import this array into a node property in neo4j from a CSV file, you must choose a single character delimiter that cannot exist within the array. The default is the semi-colon character. However, that won’t work in our example! We can easily substitute something like a pipe (|) character, but if you may have these in the data, you will need to find something more obscure, such as §.
Csv
CSV file:
Copy to Clipboard
:ID,:LABEL,movie,lines:string[]
1,Movie,Star Wars,""Use the force, Luke!§Help me, Obi-Wan Kenobi; you're my only hope.""
Cypher-shell
Verify using Cypher:
Copy to Clipboard
neo4j> match (n:Movie) return n;
+-----------------------------------------------------------------------------------------------------------+
| n                                                                                                         |
+-----------------------------------------------------------------------------------------------------------+
| Node[0]{movie:""Star Wars"",lines:[""Use the force, Luke!"",""Help me, Obi-Wan Kenobi; you're my only hope.""]} |
+-----------------------------------------------------------------------------------------------------------+
1 row
The header for a string array column needs to have :string[], which is case sensitive.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-specify-the-field-and-array-delimiter-to-neo4j-import-as-a-ascii-character;"How do I specify the field and array delimiter to neo4j-import as a ASCII character
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags neo4j-import delimiter
neo4j-import allows one to initially load a graph.db via CSV files. There may be times when using a ',' as a field or array delimiter is not appropriate as your data may contain this character as part of its data. When this is the case you can change the default delimiters via command line parameters of:
--delimiter <delimiter-character>
        Delimiter character, or 'TAB', between values in CSV data. The default option is
        ,.
--array-delimiter <array-delimiter-character>
        Delimiter character, or 'TAB', between array elements within a value in CSV
        data. The default option is ;.
If you wanted to change the default field delimiter to be the * character then you would need to define:
 --delimiter ""*""
but it can also be defined as a ASCII character sequence. For example, '*' is decimal 42 on the ASCII chart, and the equivalent would be:
 --delimiter ""\042""
The same syntax to specify a ASCII character can also be used for the --array-delimiter.
Was this page helpful?"
https://neo4j.com/developer/kb/using-apoc-load-jsonparams-to-load-data-from-zendesk-into-neo4j-to-learn-about-article-subscribers;"Using apoc.load.jsonParams to load data from Zendesk into Neo4j to learn about article subscribers
Author Dana Canzano Applicable versions 3.2 3.3 3.4 Tags apoc json import
The following document describes how to utilize the Zendesk API to load data from Zendesk into Neo4j, specifically data about users who have chosen to subscribe/follow Knowledge Base section(s). This document attempts to solve the issue described by the following questions from Zendesk Question & Answers. Although the Zendesk UI allows users to subscribe/follow a Knowledge Section it does not provide an equivalent UI for a Zendesk Administrator to see what users are subscribed to each section.
The Cypher below, will create supporting indexes and then iterate overr every section, request all the user_ids with said section, create the relationship between the user_id and section and then populate the user_id with more identifying details.
Cypher
Copy to Clipboard
Run in Neo4j Browser
create index on :Section(id);
create index on :User(id);
create index on :Organization(id);

// get all sections
CALL apoc.load.jsonParams(""https://your_domain.zendesk.com/api/v2/help_center/sections.json"",{Authorization:""Basic base64Encoded_username:password""},null)
  yield value as sectionvalue
  with sectionvalue
  unwind sectionvalue.sections as section_item
    Merge (n:Section {id:section_item.id,name:section_item.name, created_at:section_item.created_at, updated_at:section_item.updated_at,url:section_item.html_url})
    with section_item.id as secid
    // foreach section then find the subscribers
    CALL apoc.load.jsonParams(""https://your_domain.zendesk.com/api/v2/help_center/sections/""+secid+""/subscriptions.json?per_page=200"",{Authorization:""Basic base64Encoded_username:password""},null)
       yield value as subscribervalue
       with subscribervalue, secid
        subscribervalue.subscriptions  subscription_item
            
             (s: {id:secid})  s,subscription_item
             (n: {id: subscription_item.user_id})
             (n)-[: {subscribed_on: subscription_item.created_at}]->(s)
             subscription_item.user_id  s_userid
             apoc..jsonParams(+s_userid+"".json"",{Authorization:""Basic base64Encoded_username:password""},null)
                  value  userRecord
                userRecord, s_userid
                userRecord.user  uid
                (n: {id:s_userid})
               
                     n.name=uid.name,
                     n.email=uid.email,
                     n.created_at=uid.created_at,
                     n.last_login=uid.last_login_at,
                     n.url=uid.url;

 (n:) 
       n,n.organization_id  organization_id
       apoc..jsonParams(+organization_id+"".json"",{Authorization:""Basic base64Encoded_username:password""},null)
       value  orgRecord
       orgRecord.organization  orgid
       n,orgid
       (o: {id: orgid.id, name: orgid.name, created_at: orgid.created_at})
       (n)-[:]->(o);
View all (26 more lines)
and to load 140 nodes (81 Users, 7 Sections, 52 Organizations) and associated relationships took 54 seconds.
In the above Cypher code, you will need to replace all occurances of
`your_domain`  with the actual domain your Zendesk is hosted under
`base64Encoded_username:password` with the base64 encoding (https://www.base64encode.org/) of a Zendesk
 Admin user and password who has Admin rights in Zendesk
Additionally, to use basic authentication, you must enable password access in the Zendesk Support admin interface at Admin > Channels > API.
Finally, per the Zendesk API, if you expect to have more than 100 results per API call you will need to consider Pagination.
Pagination By default, most list endpoints return a maximum of 100 records per page. You can change the number of records on a per-request basis by passing a per_page parameter in the request URL parameters. Example: per_page=50. However, you can’t exceed 100 records per page on most endpoints.
When the response exceeds the per-page maximum, you can paginate through the records by incrementing the page parameter. Example: page=3. List results include next_page and previous_page URLs in the response body for easier navigation:
Copying the above Cypher into a shell script file, for example build_zd.cql, will then allow for it to be run through cypher-shell by running
Shell
Copy to Clipboard
$ cat build_zd.cql | bin/cypher-shell
And the resultant graph model is thus defined as:
The entire graph thus appears as
To which we will see there are 4 Sections (i.e. green nodes/circles) which have no subscribers (i.e the 4 green nodes in the upper left corner). Three other sections have subscribers, though the Section on the right has the most subscribers (i.e blue nodes/circles) Additionally some subscribers/users have choosen to follow multiple sections.
Each Node is defined with the following properties
User:
        name
        email
        created-at
        last_login
        url
        suspended
        orgainization_id
        id

Section:
            name
            url
            created_at
            updated_at
            id

Organization:
                 name
                 created_at
                 id
Useful Cypher statements to query the graph
Find # of users subscribed by Section
Cypher
Copy to Clipboard
Run in Neo4j Browser
match     (n:Section)
return     n.name,
           size (  (n)<-[:Follows]-() ) as subscribers
order by   subscribers desc;
Find users and associated organization, per section and when the user subscribed subscribed
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (s:Section)<-[r:Follows]-(u:User)-[:IS_MEMBER_OF_ORG]->(o:Organization)
return      s.name,
            u.name,
            u.email,
            o.name,
            u.suspended,
            r.subscribed_on as DateWhenSubscribed
order by    s.name,
            o.name,
            u.name
Was this page helpful?"
https://neo4j.com/developer/kb/using-apoc-to-parse-json-results-from-trello-api;"Using APOC to parse JSON results from Trello API
Author Dana Canzano Applicable versions 3.0 3.1 Tags apoc json import
Prior to Neo4j 3.0, if you wanted to parse the JSON results from a call to a Web API, it would require you use one of the database drivers to fetch and parse the JSON data. This is described here.
With the inclusion of stored procedures as part of Neo4j 3.0.x and the APOC procedure package, one can read the JSON data and create nodes and relationships in the graph. The following describes how this is accomplished when using the Trello API. Trello is a collaboration tool that organizes your projects into boards. In one glance, Trello shows you what’s being worked on, who’s working on what, and where something is in a process. The Trello taxonomy includes boards, lists, and cards where tasks are recorded.
When using the Trello API you must register an API key and token as they are required to access the URL. The key and token can be created here. In the example below, the generated key and token are:
Properties
Copy to Clipboard
key=00981709d8fa49b9fb3c66f41178c14h
token=06128ee9bb10787d6fdee4942c12b5de5f39be11794fcb0604e072e1940475e2
And the goal of the Cypher in this example is to create a Graph Model similar to:
To produce such a data model we are going to interact with the Trello API /1/member/me/actions?filter=createCard which will return a JSON result representing the detail on when cards were created. Additionally, the inclusion of the 'me' value in the URL indicates to only retrieve createCards actions that I have taken.
Json
Copy to Clipboard
{
  ""id"": ""56f29d59ef82d7312c56710f"",
  ""idMemberCreator"": ""5637836872deaba954947610"",
  ""data"": {
    ""board"": {
      ""name"": ""New Features Board"",
      ""id"": ""563ce96c73ae60bc1a3d40"",
      ""shortLink"": ""bYO0FVJ7Q""
    },
    ""list"": {
      ""name"": ""Inbox"",
      ""id"": ""55f7f0db68294b2a319c0519""
    },
    ""card"": {
      ""shortLink"": ""OwUvlhf7"",
      : ,
      : ,
      : 
    }
  },
  : ,
  : ,
  : {
    : ,
    : ,
    : ,
    : ,
    : 
  }
}
View all (15 more lines)
The following Cypher will process the JSON results of the /1/member/me/actions request:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""https://api.trello.com/1/member/me/actions?filter=createCard&limit=1000&key=00981709d8fa49b9fb3c66f41178c14h&token=06128ee9bb10787d6fdee4942c12b5de5f39be11794fcb0604e072e1940475e2"" AS url
CALL apoc.load.json(url) YIELD value AS action
WITH action, action.memberCreator AS m, action.data AS d
MERGE (u:User {id:m.id}) ON CREATE SET u.initials = m.initials, u.name = m.fullname, u.user = m.username
MERGE (b:Board {id: d.board.id}) ON CREATE SET b = d.board
MERGE (c:Card {id: d.card.id}) ON CREATE SET c = d.card
MERGE (u)-[r:CREATED]->(c) ON CREATE SET r.id = action.id, r.date_created=apoc.date.parse(action.date,'s',""yyyy-MM-dd'T'HH:mm:ss'Z'"")
MERGE (c)-[:IN_BOARD]->(b)
RETURN count(*);
And then one can run
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (u:User)-[r:CREATED]->(c:Card)-[r2:IN_BOARD]->(b:Board)
RETURN u.user AS Author, r.date_created,c.name AS CardName ,b.name AS BoardName
This is helpful in attempting to find metrics about the author/creator of Trello cards.
The above is but one example of the Trello API and all data represented above is not actual data but representations.
Was this page helpful?"
https://neo4j.com/developer/kb/space-in-import-filename-for-load-csv;"How to import a file with LOAD CSV that has a space in file name?
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load-csv
When you try to import data from a file using LOAD CSV where the filename containing spaces for example you get the following error:
Statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv from ""file:///test copy.csv"" as row return row
Error:
java.net.URISyntaxException: Illegal character in path at index 10: file:/test copy.csv
To allow for a space in the filename, simply replace the space in the LOAD CSV command with %20 (url encoding)
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv from ""file:///test%20copy.csv"" as row return row
Similarly, if you have any other characters (such as #) in the filename, simply replace that charater with the appropriate ASCII url encoding (for # it happens to be %23).
An ASCII encoding reference can be found here:
https://www.w3schools.com/tags/ref_urlencode.asp
Was this page helpful?"
https://neo4j.com/developer/kb/categories/gds;"Articles tagged as gds
Graph Analytics In Layman Terms
Graphs in general are very powerful in providing answers where relations do matter a lot. In this context, using graph queries (Cypher) allows us to answer specific questions when we…
Read more
analytics storage graph gds"
https://neo4j.com/developer/kb/a-method-to-calculate-index-size;"A method to calculate the size of an index in Neo4j.
Author Stephen Levett Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher indexes schema capacity planning
If the need arises to calculate the size of an index in Neo4j, for capacity planning purposes, there are two methods available:
1) Execute the db.indexes() procedure:
CALL db.indexes() YIELD id, name, labelsOrTypes, properties;
From that output, you can obtain the id:
None
Copy to Clipboard
neo4j@customers> CALL db.indexes() YIELD id, name, labelsOrTypes, properties;
+--------------------------------------------+
| id | name     | labelsOrTypes | properties |
+--------------------------------------------+
| 1  | ""kb_idx"" | [""Movie""]     | [""idd""]    |
+--------------------------------------------+

1 row available after 49 ms, consumed after another 5 ms
The id here is 1. By executing the procedure with no parameters, a fuller listing is returned, including the state:
None
Copy to Clipboard
call db.indexes();
+-------------------------------------------------------------------------------------------------------------------------------------+
| id | name     | state    | populationPercent | uniqueness  | type    | entityType | labelsOrTypes | properties | provider           |
+-------------------------------------------------------------------------------------------------------------------------------------+
| 1  | ""kb_idx"" | ""ONLINE"" | 100.0             | ""NONUNIQUE"" | ""BTREE"" | ""NODE""     | [""Movie""]     | [""idd""]    | ""native-btree-1.0"" |
+-------------------------------------------------------------------------------------------------------------------------------------+

1 row available after 49 ms, consumed after another 2 ms
Now you have the id ,you can execute du -h in the $NEO4J_HOME/data/databases/customers/schema/index directory for the index directory.
None
Copy to Clipboard
pwd
/Users/stephenlevett/Documents/scripts/cluster-build-scripts-master/instance1/neo4j-enterprise-4.2.5/data/databases/customers/schema/index/native-btree-1.0

ll
total 0
0 drwxr-xr-x  3 stephenlevett  staff    96B  2 Jun 10:45 1
Note 1 matches the id above.
Then:
None
Copy to Clipboard
du -h 1/*
 96K 1/index-1
2) Or using the id, you can look in debug.log for the following section under the database name:
None
Copy to Clipboard
[customers/eb86f508]   schema:
[customers/eb86f508]     index:
[customers/eb86f508]       native-btree-1.0:
[customers/eb86f508]         1:
[customers/eb86f508]           index-1: 2021-06-02T11:09:20+01:00 - 96.00KiB
[customers/eb86f508]         - Total: 2021-06-02T10:45:09+01:00 - 96.00KiB
[customers/eb86f508]       - Total: 2021-06-02T10:45:08+01:00 - 96.00KiB
[customers/eb86f508]     - Total: 2021-06-02T10:45:08+01:00 - 96.00KiB
[customers/eb86f508]   - Total: 2021-06-02T10:45:08+01:00 - 96.00KiB
Was this page helpful?"
https://neo4j.com/developer/kb/categories/desktop;"Articles tagged as desktop
Launching Neo4j Desktop in Linux (Ubuntu & Debian) with an .appimage file
A quicker way to install is using the .appimage file directly from https://neo4j.com/download/ The download for linux distributions is in the form of a .appimage file. AppImage files can then…
Read more
install desktop
Extracting Java Error When Installing Neo4j Desktop
In rare cases, Neo4j Desktop install might fail during the Java extract phase with the following message on Windows: Initialization Error: error: end of central directory record not found (see…
Read more
installation
How to import a GrapheneDB database into Neo4j Desktop
This assumes you already have the zip file of the GrapheneDB database. The goal here is to import this as an entire database, not to pull the data from it…
Read more
import
How activation keys work
Summary Activation keys are mini-contracts that are signed by Neo4j, granting access to a ""feature"". Typically, features are entire applications like ""Neo4j Desktop"" or ""Neo4j Bloom"" but they may be…
Read more
desktop
How to Configure Proxy in Neo4j Desktop
Organizations have proxy settings in order to access the internet or external websites. Neo4j Desktop has a way to setup proxy configuration so one can use their organization’s proxy settings.…
Read more
configuration
Resolve Port Conflicts in Neo4j Desktop
Occasionally upon upgrade or re-install, Neo4j Desktop may throw a repetitive port conflict exception for ports 7474, 7687, 7473, whilst providing a ""Fix Configuration"" option. However, selecting this option does…
Read more
desktop
Troubleshooting Neo4j Desktop Issues on Linux
This page describes common issues users may encounter when running Neo4j Desktop on Linux. Error: The SUID sandbox helper binary was found, but is not configured correctly. Explanation Neo4j Desktop…
Read more
desktop linux"
https://neo4j.com/developer/kb/how-to-import-a-graphenedb-database-into-neo4j-desktop;"How to import a GrapheneDB database into Neo4j Desktop
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags import
This assumes you already have the zip file of the GrapheneDB database.
The goal here is to import this as an entire database, not to pull the data from it into an existing database.
Note that there are already export instructions on GrapheneDB’s site here: https://docs.graphenedb.com/docs/importing-and-exporting-databases#loading-an-exported-datastore-into-a-local-neo4j-instance
Try using those first, and if those don’t work proceed as follows depending on the Neo4j version of the GrapheneDB database.
In Neo4j 3.5.x
We only have a single database per dbms in this version, so the steps are simpler.
In Neo4j Desktop, create an instance of the right version of 3.5.x in desktop, but don’t start it yet.
Manage the instance (from the … in the upper right), and press the Open Terminal button to open a terminal window to the instance’s home directory.
Perform cd data/database from the terminal (if you then do an ls, the directory should be empty).
Extract the GrapheneDB zip file to this directory, make sure that it results in a graph.db folder with neostore* files inside. If needed, rename the top-level directory to graph.db to align with the default graph name (or adjust the graph name in your config file accordingly).
Check ownership permissions for the unzipped directory. They should match with the ownership permissions you see when you do a ls -l at the home directory for the db. If they do not match, you may need to change the ownership of the files recursively so Neo4j Desktop is able to read and write to them: https://linuxize.com/post/linux-chown-command/
Start the database.
In Neo4j 4.x
Neo4j 4.x allows multiple databases per dbms instance. As such we can add the GrapheneDB database without replacing any other databases.
We can even add to an existing dbms instance that already have databases, and that may already be running.
You should have a zipped database, and you may also have a transactions zip too.
In Neo4j Desktop, either create a new dbms instance of the appropriate version, or identify an existing database (whose minor version matches that of the GrapheneDB instance) into which you will import the database.
Manage the instance (from the … in the upper right), and press the Open Terminal button to open a terminal window to the instance’s home directory.
Perform cd data/databases from the terminal. This may have other directories here, corresponding with other databases on the instance.
Extract the GrapheneDB zip file to this directory. The top level directory of the expanded zip should have a unique name that follows Neo4j’s naming rules: https://neo4j.com/docs/cypher-manual/current/syntax/naming/
Check ownership permissions for the unzipped directory. They should match with the ownership permissions you see when you do a ls -l at the home directory for the dbms. If they do not match, you may need to change the ownership of the files recursively so Neo4j Desktop is able to read and write to them: https://linuxize.com/post/linux-chown-command/
(Only if you have a transactions zip included) From the terminal, return to the home directory of the Neo4j instance and perform cd data/transactions. This is where transactions for each database are stored. You should see a directory per database.
Extract the transactions zip file to this directory. The top level directory of the expanded zip should have a name matching the database you extracted earlier in step 4.
Check ownership permissions for the unzipped directory. They should match with the ownership permissions you see when you do a ls -l at the home directory for the dbms. If they do not match, you may need to change the ownership of the files recursively so Neo4j Desktop is able to read and write to them: https://linuxize.com/post/linux-chown-command/
Start the Neo4j dbms if it is not started already.
After it starts and you log in, execute :use system to switch to the system database, where we can execute database administration commands.
Using the name of the database (used as the directory name in steps 4 and 7) issue a CREATE DATABASE <dbname> command, replacing <dbname> with the database name. This will create an entry in the system db for the new database, which will be using the database and transaction files extracted from steps 4 and 7.
You can use SHOW DATABASES to check if the database was created.
Execute :use <dbname> (replacing with the database name) to switch to the db.
Was this page helpful?"
https://neo4j.com/developer/kb/categories/geospatial;"Articles tagged as geospatial
Geocoding with Arcgis
Prerequisites Create/obtain an Arcgis account. Create application within your account. The application will be assigned a 'client_id' and 'secret'. APOC The APOC library provides a apoc.spatial.geocode('address') procedure (as well as…
Read more
cypher configuration"
https://neo4j.com/developer/kb/categories/browser;"Articles tagged as browser
Explanation of error ""Security Error: 18"" when using Internet Explorer and Neo4j Browser
When connecting to the Neo4j Browser http://localhost:7474 and using Internet Explorer 11, submission of cypher statements may result in error message: As the Neo4j Browser is using websockets to connect…
Read more
internet-explorer browser
Explanation of error ""WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver…
In Neo4j 3.0 and its implementation of the Bolt protocol, if a remote browser connects to Neo4j (http://<remote_neo4j_host>:7474) and attempts to authenticate, the following error may be encountered: This error…
Read more
browser bolt websocket
How do I display the REST code from the 3.0 Browser
In Neo4j 3.0 and its implementation of the Bolt protocol, requests submitted via the browser (http://localhost:7474) are submitted using Bolt. From the results frame, on the bottom left, you can…
Read more
browser rest bolt
How do I export Cypher Favorites recorded in the browser
Cypher Favorites are common Cypher statements which one can save to the left panel of the Neo4j browser. A Favorite is created by entering the Cypher at the top prompt…
Read more
cypher browser
How do I override browser configuration settings
Commencing with Neo4j 3.2.2 one can override default configuration settings of the browser whereby a number of these settings are defined under the left frame and through the 'gears' icon.…
Read more
browser configuration
How do I zoom in/out within the graph visualization of the browser?
Within the graph visualization pane of the browser (reached locally at http://localhost:7474), to zoom in/out of the graph display one first needs to select Full Screen mode. The zoom in/out…
Read more
browser zoom
How Does Neo4j Browser interact with Neo4j Server?
Starting with Neo4j 3.2, the Neo4j Browser only supports Bolt connectivity to the Neo4j Server. This requires that the network allows for socket communication between the browser and Bolt Port…
Read more
browser bolt websocket
List of restricted ports in browsers
This document provides a list of ports which generate an error when browsing via Chrome. It is a super-set of ports most of which are also restricted in Mozilla Firefox…
Read more
browser chrome ports url
Troubleshooting Connection Issues in Neo4j Browser and Cypher Shell
This page describes common issues users may encounter in connecting Neo4j Browser or cypher-shell to a Neo4j database, and how to address them. Connection Timeout Symptom: connection attempts lag for…
Read more
https cypher-shell browser
Why do my deleted property keys appear?
When using the Neo4j Browser and selecting the left frame and top icon entitled Database Information or using the built in stored procedure db.propertyKeys() you may see property keys which…
Read more
properties browser"
https://neo4j.com/developer/kb/categories/cypher;"Articles tagged as cypher
A note on OPTIONAL MATCHes
An OPTIONAL MATCH matches patterns against your graph database, just like a MATCH does. The difference is that if no matches are found, OPTIONAL MATCH will use a null for…
Read more
cypher match
A significant change in apoc.periodic.iterate() in apoc 4.0
In 3.5 an entity (node, relationship, path) could be acquired in one transaction and safely reused by another. However, in 4.0 these entities do hold a reference to their originating…
Read more
apoc
Achieving longestPath Using Cypher
While Cypher is optimized for finding the shortest path between two nodes, with such functionality as shortestPath(), it does not have the same sort of function for longest path. In…
Read more
cypher path apoc
All shortest paths between a set of nodes
Consider a number of arbitrary nodes, A,B,C,D,E,F,….. I wish to return all of the shortest paths between these nodes. The nodes may have many edges between them, but anticipate a…
Read more
cypher path unwind shortest-path
Alternatives to UNION queries
While UNIONs can be useful for certain cases, they can often be avoided completely with small changes to the query. In this article we’ll present various example cases where a…
Read more
cypher union path
Comparing relationship properties within a path
You want to compare relationship-properties of a path, either by a global value or parameter, or with each other within a path. Basic model: Make sure to have an constraint…
Read more
cypher path relationships properties
Conditional Cypher Execution
At some point you’re going to write a Cypher query requiring some conditional logic, where you want different Cypher statements executed depending on the case. At this point in time…
Read more
cypher conditional apoc
Creating and working with linked lists in Cypher
At some point when working with a graph, you may want to create a linked list out of some nodes. If each of the nodes to be linked has its…
Read more
cluster
Cross Product Cypher queries will not perform well
Just like SQL, if you do not properly connect the parts of your query, it will result in a cross (cartesian) product, which is seldom what you want. Take the…
Read more
cypher performance
Using Cypher how do I determine the version and edition of Neo4j
If you want to determine version and edition of the running Neo4j instance this can be accomplished via running the following cypher: The expected output will be:
Read more
edition version
Explanation of the ""consumed after"" message in query results
After successfully executing a query through the Neo4j Browser or cypher-shell, you may see a message formatted as follows accompanying the query results: This provides the following information: These are…
Read more
cypher
Explantion of debug.log message of Commits found after last checkpoint
When running backup for example you may observe in the output of said command detail similar to and see that there is a long pause (i.e. 5+ minutes) from Start…
Read more
backup transaction
Explanation of error ""Cannot merge node using null property value for""
When running a MERGE, which is a combination of MATCH and/or CREATE one may encounter an error of Cannot merge node using null property value for if the MERGE is…
Read more
cypher merge
Explanation of error LOAD CSV error of ""Couldn’t load the external resource …""
When running a LOAD CSV Cypher statement, for example whether through bin/neo4j-shell or the browser at http://localhost:7474 this may result in an error as follows And the data/graph.db/messages.log (2.x) or…
Read more
load csv user-agent
Fast counts using the count store
Neo4j maintains a transactional count store for holding count metadata for a number of things. The count store is used to inform the query planner so it can make educated…
Read more
cypher counts
Fulltext search in Neo4j
Fulltext search in Neo4j is supported by means of fulltext schema indexes. Fulltext schema indexes are created, dropped, and updated transactionally, and are automatically replicated throughout a cluster. For example…
Read more
fulltext search indexing
How do I achieve the equivalent of a SQL Having clause with Cypher
With a traditional SQL based database a HAVING clause will restrict aggregated values. For example will return all zipcodes which have more than 100k residents. To achieve the same in…
Read more
sql
How do I compare two graphs for equality
If you are looking to compare 2 graphs (or sub-graphs) to determine if they are equivalent, the following Cypher will produce a md5sum of the nodes and properties to make…
Read more
apoc
How do I convert a property representing a date timestamp to another timezone
Temporal datatype support was introduced with with Neo4j 3.4 and as a result it is possible to record a date timestamp with timezone as a property value. The following Cypher…
Read more
cypher temporal timezone
How do I define a LOAD CSV FIELDTERMINATOR in hexidecimal notation
When using LOAD CSV one can define the field delimiter used, whereby the default is the ',' character. If you want to override the default this can be accomplished via…
Read more
load-csv
How do I define, display, and use parameters with neo4j-shell
bin/neo4j-shell allows for a command line interface to query your graph via Cypher statements and to include parameters to those statements. Usage of parameters, rather than hard coding values, will…
Read more
parameters neo4j-shell quotes
How do I determine the number of nodes and relationships to be effected by a detach delete
Prior to running a match …. detach delete n; which will find said nodes and delete all relationships associated with said nodes as well as delete the nodes themselves one…
Read more
delete
How do I display all nodes with no defined labels
Although assigning a node one or more labels provides many benefits (i.e. performance gains from index usage, ability to group nodes into sets, etc), it is possible to create a…
Read more
cypher
How do I display the nodes with the most properties
To display the nodes with the most properties defined, run the following Cypher: Representative output is similar to: The first row of output indicates that there is a Label named…
Read more
cypher
How do I improve the performance of counting number of relationships on a node
Using Cypher one could count number of relationships in the following manner Which will report the number of incoming/outgoing relationships for the Actor named Sylvester Stallone. Using bin/neo4j-shell and running…
Read more
cypher performance
How do I pass parameters when calling apoc.cypher.runFile
APOC allows one to have a stored procedure, apoc.cypher.runFile, to then run the contents of the file to the Cypher engine. To allow the reading of the file in the…
Read more
apoc parameters cypher procedures
How do I perform the equivalent of a SQL Create Table as Select with Cypher
With a traditional SQL RDBMS one could perform a create table as select (i.e. CTAS) whereby its purpose is to create a new table and copy existing data from the…
Read more
copy sql
How do I produce a profile/explain through cypher-shell and pipeing query file
If you prepare a file with a Cypher statement that includes either a profile or explain clause and then want to pipe that file to bin/cypher-shell, to produce the profile/explain…
Read more
cypher-shell explain profile
How do I produce an inventory of statistics on nodes, relationships, properties
Using the following Cypher will produce an 'inventory' of the nodes within the graph and statistics related to number of Nodes per label, average number of properties, minimum number of…
Read more
cypher
How do I report on nodes with multiple labels
If your data model has chosen to define multiple labels on a node, for example To find all nodes which are defined with both labels of Actor AND Director use…
Read more
labels
How do I set a breakpoint in a Cypher statement for further analysis
If you wish to set a 'breakpoint' in a Cypher statement so as to perform further analysis (i.e. see how many locks are taken, memory utilization) one can add a…
Read more
debug
How do I view the column headers of a CSV file with LOAD CSV
If one has a CSV file with the following content and one simply wants to run a LOAD CSV command to have the column headers returned, the following should suffice…
Read more
load-csv
How does apoc.periodic.iterate work with resources?
How does apoc.periodic.iterate work? For example, when running call apoc.periodic.iterate(""MATCH (n) RETURN n"", ""DETACH DELETE n"", {batchSize:1000}) does it append a LIMIT to the MATCH RETURN so that it only…
Read more
apoc procedures
How to avoid costly traversals with join hints
When matching a pattern using Cypher, the number of possible paths to evaluate often correlates with query execution time. When there is a supernode in the path (a node with…
Read more
cypher
How to check for time range overlap in Cypher
Neo4j 3.4 introduced temporal types into Cypher, so now we have dates, dateTimes, and their local versions, too, as well as durations. While we don’t have a type for time…
Read more
cypher temporal apoc
How to get a high level inventory of objects in your graph (part 2)
Following the knowledge base article on How to get a high level inventory of objects in your graph, this article will cover how to get more detailed high level inventory…
Read more
counts metadata
How to get a high level inventory of objects in your graph
The following Cypher can be used to get a simple high level view of the number of objects within your graph database. This may be used if one is trying…
Read more
metadata procedures
How to implement a primary key property for a label
Commencing with Neo4j 2.3.x it is possible to create the equivalent of a primary key on a property of a label. For example the following Cypher: will create two constraints…
Read more
cypher
How to write a Cypher query to return the top N results per category
The following Cypher describes how you can display the Top 5 test scores within an entire :Score population broken out by a field_of_study property. running: will return output of: and…
Read more
cypher grouping
Limiting MATCH results per row
Since LIMIT applies to the total number of rows of the query, it can’t be used in cases when matching from multiple nodes where the limit must be on match…
Read more
cypher limit
Neo4j: Convert string to date
Neo4j 3.4 saw the introduction of the temporal date type, and while there is now powerful in built functionality, converting strings to dates is still a challenge. If our string…
Read more
cypher
Performing match intersection
Match intersection is a common use case where you’re searching for nodes which have relationships to all of a set of input nodes. For the rest of the article we’ll…
Read more
cypher intersection
Performing pattern negation to multiple nodes
Some use cases require matching to nodes which aren’t connected to any of some other set of nodes. We’ll discuss both incorrect and correct approaches to this kind of query.…
Read more
performance cypher
Post-UNION processing
Cypher does not allow further processing of UNION or UNION ALL results, since RETURN is required in all queries of the union. Here are some workarounds. Post-UNION processing in Neo4j…
Read more
cypher union
Resetting query cardinality
As queries execute, they build up result rows. Cypher executes operations per-row. When a query is made up of completely separate parts, unrelated to each other, and you don’t want…
Read more
cypher cardinality
Understanding aggregations on zero rows
Aggregations in Cypher can be tricky in some cases. Notably, when performing aggregation right after a MATCH where there are no matches, or after a filter operation that filters out…
Read more
cypher
Tuning Cypher queries by understanding cardinality
Cardinality issues are the most frequent culprit in slow or incorrect Cypher queries. Because of this, understanding cardinality, and using this understanding to manage cardinality issues, is a critical component…
Read more
performance cypher cardinality
Understanding how MERGE works
What is MERGE, and how does it work? The MERGE clause ensures that a pattern exists in the graph. Either the entire pattern already exists, or the entire pattern needs…
Read more
merge cypher
Understanding Neo4j Query Plan Caching
This article is based on the behavior of Neo4j 2.3.2. Query plan caching is governed by three parameters, as defined in the conf/neo4j.properties file, which are detailed here. The three…
Read more
cypher configuration performance
Understanding non-existent properties and working with nulls
In Neo4j, since there is no table schema or equivalent to restrict possible properties, non-existence and null are equivalent for node and relationship properties. That is, there really is no…
Read more
cypher
Understanding the Query Plan Cache
When a Cypher statement is first submitted Neo4j will attempt to determine if the query is in the plan cache before planning it. By default Neo4j will keep 1000 query…
Read more
performance plan cache cypher parameters
Updating a node but returning its state from before the update
Some use cases require updating node (or relationship) properties, but returning the node (or relationship) as it was prior to the update. You’ll need to get a 'snapshot' of the…
Read more
cypher
Using Cypher to generate Cypher statements to recreate indexes and constraints
The following can be used to extract index definitions and constraint definitions from an existing database and the resultant output can be played back on another Neo4j database. For example…
Read more
indexing constraint cypher
Using explicit indexes for text search
As of Neo4j 3.4.x, the schema index is optimal for indexing exact property values, but does not support ""fuzzy"" or full-text search. However, legacy indexing does allow for optimization for…
Read more
fulltext indexing
Using max() and min() while keeping items
The aggregation functions of max() and min() are very useful, but you can sometimes find yourself fighting against Cypher’s aggregation behavior for cases that should be simple. This often comes…
Read more
cypher aggregations max min
Using Subqueries to Control the Scope of Aggregations
Aggregations, such as collect() and count(), show up as EagerAggregation operators (with dark blue headers) in query plans. These are similar to the Eager operator in that it presents a…
Read more
cypher performance
Why doesn’t my WHERE clause work?
It can be frustrating when it seems like a WHERE clause isn’t working. You can use these approaches to figure out what’s wrong. Check for WHERE clauses following OPTIONAL MATCH…
Read more
cypher where
Working with streaks in Cypher
When using Cypher for data analysis, you might have a problem where you need to identify or filter based upon some kind of streak. For example, for a sports graph,…
Read more
cypher apoc"
https://neo4j.com/developer/kb/understanding-the-query-plan-cache;"Understanding the Query Plan Cache
Author Dana Canzano Applicable versions 3.0 3.1 Tags performance plan cache cypher parameters
When a Cypher statement is first submitted Neo4j will attempt to determine if the query is in the plan cache before planning it. By default Neo4j will keep 1000 query plans in cache based upon the conf/neo4j.conf parameter of dbms.query_cache_size. In fact this actually represents 2 query plan caches.
The string cache
When Cypher is initially submitted, the Cypher statement will have a hash computed on the string as-is. Using this resultant hash value we will attempt to determine if statement already exists in the plan cache and if it does then re-planning may not be necessary.
Note however that statements that are logically the same but differing in case will produce a different hash. The following 2 statement, though semantically equivalent, will produce a different hash and a replan may be necessary.
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n) return count(n);
MATCH (n) return COUNT(n);
Additionally, statements that are logically the same but differing in whitespace/carriage returns will produce different hash values. The following 3 statements will produce a different hash and a replan may be necessary
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n) return COUNT(n);
MATCH (n) return      COUNT(n);

MATCH (n)
return COUNT(n);
Cypher statements prefaced by PROFILE/EXPLAIN will have their PROFILE/EXPLAIN removed before the statement is hashed. The following 2 statements will hash to the same value
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n) return COUNT(n);
PROFILE MATCH (n) return COUNT(n);
If the Cypher statements hash value is not found in the first cache Neo4j will then attempt to determine if it is in the 2nd cache.
The AST cache
The Neo4j compiler parses the query from a string to an abstract syntax tree (AST), which is an object represenation of the query. The optimizer then normalizes the statement so as to make planning easier. For example
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person {id:101}) return n;
will be normalized to
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person) where n.id={param1} return n;   {param1: 101}
in this case Neo4j has moved the predicate {id:101} from the MATCH pattern to the WHERE clause, and has parameterized 101 value into a parameter, e.g. n.id={param1}. Usage of parameters is further detailed here
The AST doesn’t store information such as white spaces and casing of keywords, and since it has been parameterized, literal values can change but still produce the same AST.
This second query cache is keyed on this normalized AST. i.e. these queries will re-use the same query plan.
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person) where n.id=101 return n;
match (n:Person {id:101}) return n;

MATCH ( n:Person { id : 101 } )
RETURN n;
Finally should the Cypher statement be found in either the 1st or 2nd cache the query may still be subject to being replanned based upon conf/neo4j.conf parameters of cypher.min_replan_interval and cypher.statistics_divergence_threshold
cypher.min_replan_interval is used to define the duration, defaulting at 10 seconds, a cached plan exists before it is eligible for replanning
cypher.statistics_divergence_threshold is used to indicate what percent of the statistcs for the underlying data used by the Cypher has changed. The default value us 0.75 which would indicate if the statistics in the object have changed by more than 75% since the last time thhe cached plan was generated then a new plan would need to be generated. For example running
Cypher
Copy to Clipboard
Run in Neo4j Browser
// remove all :Person nodes
match (n:Person) detach delete n;
// create 10 :Person nodes
foreach (x in range (1,10) | create (n:Person {id:x}));
// list the 10 :Person nodes created
match (n:Person) return n.id order by n.id desc;
// create 8 new :Person nodes
foreach (x in range (11,18) | create (n:Person {id:x}));
// list the 18 :Person nodes
match (n:Person) return n.id order by n.id desc;
The 2 match (n:Person) return n.id order by n.id desc; would each be planned and specifically the 2nd instance although having the same hash value, the statistics on :Person had changed from 10 nodes to 18 nodes and thus exceeding the 75% change.
If an existing plan needs to be replanned as a result of the above 2 parameters the logs/debug.log will log
2017-03-31 19:14:27.820+0000 INFO [o.n.c.i.ExecutionEngine] Discarded stale query from the query cache: match (n:Person)
return n.id order by n.id desc;
2017-03-31 19:14:27.821+0000 INFO [o.n.c.i.EnterpriseCompatibilityFactory] Discarded stale query from the query cache: match
(n:Person) return n.id order by n.id desc;
Additionally, it should be noted that when a query plan is removed from the cache so as to make room for a new plan a least frequently used (LFU) algorithm. So if the first query added to the plan cache is run every 1 second, and the 2nd query added to the query plan cache is added every 2 minutes, then when we need to remove a query plan from the cache to make room for a new query, we will remove the 2nd query before the 1st since the first is more frequently called upon.
Finally it should be noted that any schema changes, for example index/constraint creation/removal will flush the entire query plan cache.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-convert-a-property-representing-a-date-timestamp-to-another-timezone;"How do I convert a property representing a date timestamp to another timezone
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher temporal timezone
Temporal datatype support was introduced with with Neo4j 3.4 and as a result it is possible to record a date timestamp with timezone as a property value.
The following Cypher can be used to convert a date timestamp with timezone from one timezone to another
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person)
       where    exists(n.date_enrolled)
       return   n.date_enrolled,
                datetime({datetime:datetime(n.date_enrolled), timezone:'America/New York'}) as EST limit 1;
For example using the following data
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:Person) set n.date_enrolled='2019-02-26T01:23:40Z'
in this case the property date_enrolled is recorded as a string and represents 2019-02-26 at time 01:23:40 UTC
and the above MATCH statement will return:
n.date_enrolled       | EST
""2019-02-26T01:23:40Z""│""2019-02-25T20:23:40[America/New_York]""
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-convert-neo4j-logs-from-base-utc-to-local-timezone;"How do I convert Neo4j logs from base UTC to local timezone
Author Dana Canzano Applicable versions 2.3 3.0 3.1 Tags logs temporal
With the introduction of Neo4j 3.3.1 it is possible to represent date timestamps in your $NEO4J_HOME/logs/* in either UTC or SYSTEM timezone through the implementation of dbms.logs.timezone
However for prior releases all Neo4j logs will preface each line with a date/time string of the format
<YYYY-MM-DD HH24:MM:SS.MMM+0000>
for example
2016-12-01 15:51:00.222+0000 INFO  [o.n.k.i.DiagnosticsManager] --- INITIALIZED diagnostics START ---
where the +0000 above indicates the date/time is expesssed in UTC format. Logging in UTC is helpful for analysis when a cluster is defined with members in different timezones. However, when cluster members are in the same timezone or you are running a single instance you may want to log in local timezone. There is a pending product improvement to request the date/time string be configurable based upon timezone.
In the absence of this feature, one can run the following Perl script to convert any file from UTC timezone to the machine timezone where the perl script is run.
For most Unix implementations to determine the timezone, if one runs
Shell
Copy to Clipboard
$ date
this will return output similar to
Mon Jan 16 14:38:06 EST 2017
indicating the EST timezone.
To convert a log from UTC to EST run
Shell
Copy to Clipboard
$ ./utc.pl debug.log > debug.EST.log
To install the script, copy the following lines from here to a file named utc.pl on your linux server.
Perl
Copy to Clipboard
#!/usr/bin/perl -w
use strict;
use Time::Local;  #needed for timegm()

my $file = $ARGV[0] or die ""USAGE: $0 <filename>\n"";

open(my $data, '<', $file) or die ""Could not open '$file' $!\n"";

while (my $line = <$data>) {
  # where a line might start as
  # 2017-01-11 23:22:28.372+0000 INFO ... .... ....
  chomp $line;
  # check to make sure the line begins with a YYYY-MM-DD HH
  if ( $line =~ /\d\d\d\d-\d\d-\d\d \d\d/ ) {
          my $newstring = UTC2LocalString($line);
           ;
  }
   {
       ;
  }
}

{
  
   $t = ;
   ($datehour, $rest) = (,$t,);
  
  
  
   ($year, $month, $day, $hour) =
      $datehour =~ ;

  
   $epoch = timegm (,,$hour,$day,$month-,$year);

  
  
   ($lyear,$lmonth,$lday,$lhour,$isdst) =
            (($epoch))[,,,,-];

  $lyear += ;  
  $lmonth++;       
  
   ( (,
           $lyear,$lmonth,$lday,$lhour,$rest) );
}
View all (32 more lines)
Make the script executable by running:
Shell
Copy to Clipboard
$ chmod +x utc.pl
Run the script as:
Shell
Copy to Clipboard
$ ./utc.pl <log file>
replacing <log file> with a filename.
With Neo4j 3.3 and as a result of PR 10127 the timestamp timezone can be configured through parameter dbms.logs.timezone.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-collect-neo4j-logs;"How to collect Neo4j logs
Author Damiano Mondardo / Sandeep Reehal Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags logs
When raising Neo4j Support cases, it is important to upload Neo4j logs.
This allows the Neo4j Support Engineers to efficiently begin working on the support case.
If clustering is used, logs and configurations should be collected from all nodes in the cluster.
The following log files are usually required to troubleshoot support issues:
- debug.log.*
- neo4j.conf
- query.log.*
These log files should cover the time frame that issues or errors were observed.
The files are located by default within the folders ''$NEO4J_HOME/logs'' and ''$NEO4J_HOME/conf'' .
These files should be zipped and added to the support case.
In the case of large files above 25MB, notify the Neo4j Support Engineer and a secure location will be provided.
Other logs may be required during the course of a support case, since some files may be rotated by Neo4j it’s a good idea to store a copy of the following folders for further analysis:
- $NEO4J_HOME/data/cluster-state
- $NEO4J_HOME/data/transactions
- $NEO4J_HOME/metrics
These will be requested as required by Neo4j Support.
Deployment specific collection
There are many logging configurations in Neo4j, below are some options for locating logging configurations by deployment type.
Neo4j Standalone instance (Server / Container)
The default location for logs is $NEO4J_HOME/logs
Logs are stored under the path specified for the property ""dbms.directories.logs"". Your logs folder location may differ based on the value of this configuration property, check our documentation for further details: https://neo4j.com/docs/operations-manual/current/reference/configuration-settings/#config_dbms.directories.logs
It’s also possible to specify individual folders for the different log files. This is done by changing respective configuration property as described in table 2 on the following link: https://neo4j.com/docs/operations-manual/current/monitoring/logging/#general-logging
For container deployment (for example Docker) the same rules applies. We recommend to always map the logs folder to an external volume to avoid losing the files once the container is terminated.
Neo4j Embedded instance
The default location for logs is $NEO4J_HOME/logs, the same as the standalone deployment.
The log options mentioned under the standalone section apply for embedded as well, but the value of $NEO4J_HOME is defined within your application source code, and is usually the home directory provided to the Java class used to handle the Neo4j instance (for example Java class “DatabaseManagementServiceBuilder”).
Below is a list of files you can provide (the actual file location depends on the app configuration):
- Application logs (replacing the standard neo4j.log file)
- debug.log
- query.log
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-logrotate-neo4j-dot-log;"How to logrotate neo4j.log file
Author Christophe Willemsen Applicable versions 3.0 Tags logs
The neo4j.log file is a redirection to STDOUT. When you implement a default logrotate strategy, Neo4j will not be able to write to that file anymore after a rotation.
Solution
You can use ""copytruncate"" in your logrotate configuration file.
Logrotate
Example Logrotate Configuration
Copy to Clipboard
/usr/local/neo4j/logs/neo4j.log {
 su neo4j neo4j
 copytruncate
 rotate 4
 daily
 compress
 missingok
 notifempty
}
There is a very small time slice between copying the file and truncating it, so some logging data might be lost. When this option is used, the create option will have no effect, as the old log file stays in place.
References
Logrotate Manual
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-check-time-range-overlap;"How to check for time range overlap in Cypher
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher temporal apoc
Neo4j 3.4 introduced temporal types into Cypher, so now we have dates, dateTimes, and their local versions, too, as well as durations.
While we don’t have a type for time ranges, we can use two temporal instants as the start and end of a range.
While it’s easy to check if a temporal instant falls within a time range, it’s much more complicated to calculate whether two time ranges overlap.
This article provides a simple logical formula for checking if two time ranges overlap, and gives examples of how to apply the formula in Cypher.
We’ll use a simple graph for our examples:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (:Event {id:1, start:date(), end:date() + duration({days:5})}),
       (:Event {id:2, start:date() + duration({days:3}), end:date() + duration({days:8})})
Event 2’s start and end dates are each 3 days later than Event 1’s. The events overlap.
A simplified formula for checking time range overlap
There are 4 possible ways in which time ranges can overlap, excluding the cases where they are identical ranges or tangentially adjacent, one ending where the other begins (and we can use inclusive inequalities for these).
While we won’t cover the details, the point is that calculating overlap isn’t usually trivial, it’s easy to create a calculation that misses out on some kinds of overlap, leading to incorrect results.
Thankfully there’s a logical reduction, proved here, that is relatively simple at the end:
Max(StartA, StartB) <= Min(EndA, EndB)
The latest of start times must occur before (or at the same time) as the earliest of the end times for the ranges to overlap.
Cypher doesn’t have a scaler min() and max() function we can use (they’re both aggregation functions, not what we need to solve this), so we need an alternate approach.
A pure Cypher approach using CASE
We can use CASE functionality to implement the scaler min() and max() operation.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (e1:Event {id:1}), (e2:Event {id:2})
WITH CASE WHEN e1.start >= e2.start THEN e1.start ELSE e2.start END as maxStart,
     CASE WHEN e1.end <= e2.end THEN e1.end ELSE e2.end END as minEnd
RETURN maxStart <= minEnd as rangesOverlap
The above returns true, so the ranges do overlap.
We could use the CASE evaluations in the RETURN, but it is a bit easier to see and understand when we break up the min() and max() calculations from the application of the overlap formula.
An APOC approach using collection functions
APOC Procedures has some functions for calculating the max and min of a collection, apoc.coll.max() and apoc.coll.min().
While these seem like the right tools for the job, one issue remains: as of April 2020, these functions don’t yet work with temporal types, though a fix is coming.
Here’s what this would look like once the fix is in place:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (e1:Event {id:1}), (e2:Event {id:2})
RETURN apoc.coll.max([e1.start, e2.start]) <= apoc.coll.min([e1.end, e2.end]) as rangesOverlap
Until then, there is another workaround (aside from the pure Cypher case above) by comparing the epochMillis values, but that requires that we’re working with dateTime types. If we just have dates, we can derive a dateTime from them with dateTime({date:date()}) as dateTimeFromADate.
Since the example nodes created earlier were date types, we’ll need to do that conversion:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (e1:Event {id:1}), (e2:Event {id:2})
WITH apoc.coll.max([dateTime({date:e1.start}).epochMillis, dateTime({date:e2.start}).epochMillis]) as maxStart,
     apoc.coll.min([dateTime({date:e1.end}).epochMillis, dateTime({date:e2.end}).epochMillis]) as minEnd
RETURN maxStart <= minEnd as rangesOverlap
You may think that this would be much easier if we just had an overlap() function of some sort we could call, which takes in the start and ends of the ranges, and we agree.
We’re working on an APOC function, which should simplify these checks considerably.
Was this page helpful?"
https://neo4j.com/developer/kb/pass-temporal-objects-parameters;"Pass Temporal Objects as Parameters
Author Jennifer Reif Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags drivers cypher temporal
With the support of datetime types in Neo4j, users might wonder how or if it works to transport those types along with other data types via the drivers.
It is possible and supported to send temporal objects using one of our Neo4j drivers. We will show how to do that here.
Passing objects in Drivers
The Neo4j drivers export nearly all of the supported Cypher data types, including temporal types. This means that you can send an object of parameters containing strings, numbers, dates/times, and mixed value types back and forth between the database and applications.
For a full list of the supported Cypher types in the Neo4j drivers, check out the documentation page on the Cypher type system.
Let us look at an example using the JavaScript driver.
JavaScript
Copy to Clipboard
const neo4j = require('neo4j-driver').v1

const myDate = new neo4j.types.Date(2000, 01, 01);

session.run('CREATE (p:Person {name: $name, born: $birthday})', {name: ""Bob"", birthday: myDate})
In the example above, we created a constant of a date type, instantiating the value in the variable definition. Our next statement runs a Cypher CREATE and passes in a String value for the name parameter and our date constant for the birthday parameter. Our Cypher statement references the parameters by using the $ in front of the parameter name.
This avoids having to convert values from Strings using the date() function within the Cypher statement like the example below.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Person { name: 'Bob', birthday: date(2018,01,01) })
Resources
Have questions? Feel free to raise them on our Community Site and have experts respond with answers!
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-achieve-the-equivalent-of-a-sql-having-clause-with-cypher;"How do I achieve the equivalent of a SQL Having clause with Cypher
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags sql
With a traditional SQL based database a HAVING clause will restrict aggregated values. For example
Sql
Copy to Clipboard
select zipcode, count(*) as population
from Person
group by zipcode
having population>100000;
will return all zipcodes which have more than 100k residents. To achieve the same in Cypher use the following
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Person)
with n.zipcode as zip, count(*) as population
where population > 100000
return zip, population
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-pass-parameters-when-calling-apoc-cypher-runfile;"How do I pass parameters when calling apoc.cypher.runFile
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags apoc parameters cypher procedures
APOC allows one to have a stored procedure, apoc.cypher.runFile, to then run the contents of the file to the Cypher engine. To allow the reading of the file in the conf/neo4j.conf one needs to define
Properties
Copy to Clipboard
apoc.import.file.enabled=true
and then if one defines a file, for example import/myRunFile.cyp and it contains the following content
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (n:Person {id:123, name:'Emil Eifrem'});
the running via Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.cypher.runFile(""myRunFile.cyp"",{}) yield row, result;
will create the :Person node with id=123 and name='Emil Eifrem'.
However if you want to provide more flexibility such that you pass in via parameters the values for id and name this can be accomplished by changing the contents of the import/myRunFile.cyp such that it is defined as
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (n:Person { id: $id_p1, name: $name_p2});
and then calling the apoc.cypher.runfile as follows
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.cypher.runFile(""myRunFile.cyp"",{parameters: {id_p1: 123, name_p2:'Emil Eifrem'}}) yield row, result;
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-get-a-high-level-inventory-of-objects-in-your-graph;"How to get a high level inventory of objects in your graph
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags metadata procedures
The following Cypher can be used to get a simple high level view of the number of objects within your graph database. This may be used if one is trying to compare the contents of two databases:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n) return 'Number of Nodes: ' + count(n) as output UNION
match ()-[]->() return 'Number of Relationships: ' + count(*) as output UNION
CALL db.labels() YIELD label RETURN 'Number of Labels: ' + count(*) AS output UNION
CALL db.relationshipTypes() YIELD relationshipType  RETURN 'Number of Relationships Types: ' + count(*) AS output UNION
CALL db.propertyKeys() YIELD propertyKey  RETURN 'Number of Property Keys: ' + count(*) AS output UNION
CALL db.constraints() YIELD description RETURN 'Number of Constraints:' + count(*) AS output UNION
CALL db.indexes() YIELD description RETURN 'Number of Indexes: ' + count(*) AS output UNION
CALL dbms.procedures() YIELD name RETURN 'Number of Procedures: ' + count(*) AS output
To which sample output is as follows:
Number of Nodes: 50013
Number of Relationships: 4
Number of Labels: 4
Number of Relationships Types: 2
Number of Property Keys: 9
Number of Constraints:2
Number of Indexes: 7
Number of Procedures: 215
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-get-a-high-level-inventory-of-objects-in-your-graph-part-2;"How to get a high level inventory of objects in your graph (part 2)
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags counts metadata
Following the knowledge base article on How to get a high level inventory of objects in your graph, this article will cover how to get more detailed high level inventory of objects in your graph.
The first article showed how by running:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n) return 'Number of Nodes: ' + count(n) as output UNION
match ()-[]->() return 'Number of Relationships: ' + count(*) as output UNION
CALL db.labels() YIELD label RETURN 'Number of Labels: ' + count(*) AS output UNION
CALL db.relationshipTypes() YIELD relationshipType  RETURN 'Number of Relationships Types: ' + count(*) AS output UNION
CALL db.propertyKeys() YIELD propertyKey  RETURN 'Number of Property Keys: ' + count(*) AS output UNION
CALL db.constraints() YIELD description RETURN 'Number of Constraints:' + count(*) AS output UNION
CALL db.indexes() YIELD description RETURN 'Number of Indexes: ' + count(*) AS output UNION
CALL dbms.procedures() YIELD name RETURN 'Number of Procedures: ' + count(*) AS output
You will get all the counts for nodes, relationships, labels, relationship types, property keys, constraints, indexes and procedures.
If you are running any version up to 3.2.x (inclusive) and want to drill down to see more detailed information on these objects, you can run the following command on your $NEO4J_HOME directory:
Shell
Copy to Clipboard
$ java -cp ""lib/*"" org.neo4j.kernel.impl.util.dbstructure.DbStructureTool MyDatabaseStats.java /data/databases/graph.db > ./MyDatabaseStats.java
Unlike the query mentioned in the other article, you cannot execute this on a running database. However, you can point it to a backup and you will get all the information.
This will generate a file called MyDatabaseStats.java and its contents will give you:
1. Labels in the graph
Java
Copy to Clipboard
visitor.visitLabel( 0, ""Label"" );
2.Property keys in the graph
Java
Copy to Clipboard
visitor.visitPropertyKey( 0, ""property"" );
3. Relationship types in the graph
Java
Copy to Clipboard
visitor.visitRelationshipType( 0, ""REL"" );
4. Indexes in the graph
Java
Copy to Clipboard
visitor.visitIndex( IndexDescriptorFactory.forLabel( 0, 0 ), "":Label(property)"", 1.0d, 1053000L );
5. Constraints in the graph
Java
Copy to Clipboard
visitor.visitUniqueConstraint( ConstraintDescriptorFactory.uniqueForLabel( 0, 1 ), ""CONSTRAINT ON ( label:Label ) ASSERT label.property IS UNIQUE"" );
6. Node count
6.1. Count of all nodes in the graph
Java
Copy to Clipboard
visitor.visitAllNodesCount( 49625435L );
6.2. Count of all :Label nodes in the graph
Java
Copy to Clipboard
visitor.visitNodeCount( 0, ""Label"", 1053000L );
7. Relationship count You can find the total number of relationships and the numbers of all incoming/outgoing relationship permutations as follows:
7.1. Count of all relationships in the graph
Java
Copy to Clipboard
visitor.visitRelCount( -1, -1, -1, ""MATCH ()-[]->() RETURN count(*)"", 910243L );
7.2. Count of all outgoing relationships from `:Label`
Java
Copy to Clipboard
visitor.visitRelCount( 0, -1, -1, ""MATCH (:Label)-[]->() RETURN count(*)"", 10600L );
7.3. Count of all incoming relationships to `:Label`
Java
Copy to Clipboard
visitor.visitRelCount( -1, -1, 0, ""MATCH ()-[]->(:Label) RETURN count(*)"", 0L );
7.4. Count of all :REL relationships
Java
Copy to Clipboard
visitor.visitRelCount( -1, 0, -1, ""MATCH ()-[:REL]->() RETURN count(*)"", 10600L );
7.5. Count of outgoing :REL relationships from `:Label`
Java
Copy to Clipboard
visitor.visitRelCount( 0, 0, -1, ""MATCH (:Label)-[:REL]->() RETURN count(*)"", 10600L );
7.6. Count of incoming :REL relationships to `:Label`
Java
Copy to Clipboard
visitor.visitRelCount( -1, 0, 0, ""MATCH ()-[:REL]->(:Label) RETURN count(*)"", 0L );
On a graph composed by:
3 labels: User, Device, Accessory
3 property keys: uuid, name, state
3 relationships: OWNS, BELONGS, HAS
3 indexes: User(name), Device(uuid), Accessory(uuid)
1 constraint: user.uuid is unique
MyDatabaseStats.java would have the following output:
Java
Copy to Clipboard
package MyDatabaseStats;

import org.neo4j.helpers.collection.Visitable;
import org.neo4j.kernel.impl.util.dbstructure.DbStructureVisitor;

import org.neo4j.kernel.api.schema.constaints.ConstraintDescriptorFactory;
import org.neo4j.kernel.api.schema.constaints.UniquenessConstraintDescriptor;
import org.neo4j.kernel.api.schema.constaints.RelExistenceConstraintDescriptor;
import org.neo4j.kernel.api.schema.constaints.NodeExistenceConstraintDescriptor;
import org.neo4j.kernel.api.schema.constaints.NodeKeyConstraintDescriptor;
import org.neo4j.kernel.api.schema.LabelSchemaDescriptor;
import org.neo4j.kernel.api.schema.SchemaDescriptorFactory;
import org.neo4j.kernel.api.schema.index.IndexDescriptor;
import org.neo4j.kernel.api.schema.index.IndexDescriptorFactory;











  java
implements Visitable<DbStructureVisitor>
{
    INSTANCE;

    {
        visitor.visitLabel( ,  );
        visitor.visitLabel( ,  );
        visitor.visitLabel( ,  );
        visitor.visitPropertyKey( ,  );
        visitor.visitPropertyKey( ,  );
        visitor.visitPropertyKey( ,  );
        visitor.visitRelationshipType( ,  );
        visitor.visitRelationshipType( ,  );
        visitor.visitRelationshipType( ,  );
        visitor.visitIndex( IndexDescriptorFactory.forLabel( ,  ), , d,  );
        visitor.visitIndex( IndexDescriptorFactory.forLabel( ,  ), , d, 2029998L );
        visitor.visitIndex( IndexDescriptorFactory.forLabel( ,  ), , d, 6011998L );
        visitor.visitUniqueConstraint( ConstraintDescriptorFactory.uniqueForLabel( ,  ), ""CONSTRAINT ON ( user:User ) ASSERT user.uuid IS UNIQUE"" );
        visitor.visitAllNodesCount(  );
        visitor.visitNodeCount( , ,  );
        visitor.visitNodeCount( , ,  );
        visitor.visitNodeCount( , ,  );
        visitor.visitRelCount( -, -, -, ,  );
        visitor.visitRelCount( , -, -, ,  );
        visitor.visitRelCount( -, -, , ,  );
        visitor.visitRelCount( , -, -, ,  );
        visitor.visitRelCount( -, -, , ,  );
        visitor.visitRelCount( , -, -, ,  );
        visitor.visitRelCount( -, -, , ,  );
        visitor.visitRelCount( -, , -, ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
        visitor.visitRelCount( , , -, , 0L );
        visitor.visitRelCount( -, , , , 0L );
        visitor.visitRelCount( -, , -, ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
        visitor.visitRelCount( , , -, , 31800L );
        visitor.visitRelCount( -, , , , 0L );
        visitor.visitRelCount( , , -, , 0L );
        visitor.visitRelCount( -, , , , 31800L );
        visitor.visitRelCount( -, , -, ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
        visitor.visitRelCount( , , -, ,  );
        visitor.visitRelCount( -, , , ,  );
   }
}
View all (66 more lines)
Was this page helpful?"
https://neo4j.com/developer/kb/fast-counts-using-the-count-store;"Fast counts using the count store
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher counts
Neo4j maintains a transactional count store for holding count metadata for a number of things.
The count store is used to inform the query planner so it can make educated choices on how to plan the query.
Obtaining counts from the count store is constant-time, so if you want counts for something that is obtainable from the count store, it can be queried quickly.
You can tell if the count store is being used in your query by looking at the query plan from an EXPLAIN of the query. You should see either a NodeCountFromCountStore or a RelationshipCountFromCountStore operator.
Limitations of count store queries
By definition, a query to get counts has to have a count() aggregation.
A WHERE clause cannot be present, nor can there be any inlined properties in the match pattern.
Due to limitations of the query planner, the count store will only be leveraged if the count() aggregation is alone on a WITH or RETURN. If any other variable is in scope along with the count() aggregation, the count store will not be used.
As previously mentioned, you can tell if the count store is being used by checking for either a NodeCountFromCountStore or a RelationshipCountFromCountStore in the query plan.
Workarounds for when you want multiple counts in the same query will be discussed near the end of the article.
Node counts
You can use the count store to get a count of all the nodes in the db:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
RETURN count(n) as count
You can also get a count for all nodes of a given label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person)
RETURN count(n) as count
Variables are optional for these kinds of queries, so you can omit them and use count(*) instead with the same results:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()
RETURN count(*) as count
and
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)
RETURN count(*) as count
Limitation - Can’t use the count store for querying for nodes with multiple labels
The count store will not be used when querying for nodes with multiple labels, as these counts are not tracked in the count store.
The following will not use the count store:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person:Director)
RETURN count(n) as count
Relationship counts
The count store also holds relational count metadata, and the pattern used here must depict a single relationship pattern. Note that the query must use a directed relationship in the match pattern for the count store to be used, do not omit the direction.
The count store can be used whether or not a relationship type is present:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r]->()
RETURN count(r) as count
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r:ACTED_IN]->()
RETURN count(r) as count
The count store will also be used when querying for relationships of multiple types, this will just add the counts together for each of the types:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r:ACTED_IN|DIRECTED]->()
RETURN count(r) as count
As with nodes, variables are optional here, and count(*) can be used instead:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[:ACTED_IN]->()
RETURN count(*) as count
Relationship counts to/from a node with a single label
The count store also keeps count of the relationships with respect to the label of a single end-node. The following queries will get their count from the count store.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r:ACTED_IN]->(:Movie)
RETURN count(r) as count
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)-[r:ACTED_IN]->()
RETURN count(r) as count
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH ()-[r]->(:Movie)
RETURN count(r) as count
Limitation - Can’t use the count store with labels present on both start and end nodes
The count store does not keep metadata with respect to labels on both the start and end node.
The following will not use the count store:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)-[r:ACTED_IN]->(:Movie)
RETURN count(r) as count
Getting multiple counts in a single query
In cases where you want to get multiple counts from the count store in a single query, you may run into the limitation mentioned at the top of this article: that the count() aggregation must be alone on the WITH or RETURN row for the count store to be used.
There are two notable workarounds to this limitation.
Use a UNION ALL query for counts
If we get the counts using the count store for separate queries and UNION them together, we can get the desired counts with just a bit of extra work:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person)
WITH count(n) as count
RETURN 'Person' as label, count
UNION ALL
MATCH (n:Movie)
WITH count(n) as count
RETURN 'Movie' as label, count
Note that we need another variable present to provide context, but we must introduce that variable only after we get the count(), as an additional variable at the point of aggregation would otherwise prevent usage of the count store.
Alternately, we can return a map structure where the type of the label and its associated count is included in the map:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Person)
RETURN {label:'Person', count: count(n)} as info
UNION ALL
MATCH (n:Movie)
RETURN {label:'Movie', count: count(n)} as info
Use apoc.cypher.run() to get counts dynamically per label/type
apoc.cypher.run() can be used to execute a single Cypher query per row, which can allow you to get the counts from the counts store per row.
Combined with a call to get node labels or relationship types, this can be an effective way to automatically and quickly get multiple counts at the same time:
For labels:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels() YIELD label
CALL apoc.cypher.run('MATCH (:`'+label+'`) RETURN count(*) as count',{}) YIELD value
RETURN label, value.count
For relationships:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.relationshipTypes() YIELD relationshipType as type
CALL apoc.cypher.run('MATCH ()-[:`'+type+'`]->() RETURN count(*) as count',{}) YIELD value
RETURN type, value.count
Use apoc.meta.stats() from APOC Procedures
APOC Procedures has meta procedures that can be used to access nearly all of the count store data at once.
You will need to pick and choose what data from the apoc.meta.stats() call you want to display.
Contents
The following values are YIELDed by the apoc.meta.stats() call:
labelCount - The number of labels in the graph.
relTypeCount - The number of relationship types in the graph.
propertyKeyCount - The number of property keys in the graph.
nodeCount - The number of total nodes in the graph.
relCount - The number of total relationships in the graph.
labels - A map of each label with the count of nodes of that label.
relTypes - A map of each relationship pattern (of typed relationships only, and including patterns with a label at one end node) and their associated count.
relTypesCount - A map of each relationship type and the counts for that type.
stats - A map that holds all of the counts data mentioned above.
Usage
The labels counts are often the most useful on their own, but similar approaches can be used for the others:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.stats() YIELD labels
RETURN labels
This may return a map like:
Json
Copy to Clipboard
{
  ""Movie"": 38,
  ""Word"": 12,
  ""News"": 2,
  ""Director"": 28,
  ""Reviewer"": 3,
  ""Person"": 133,
  ""Sentence"": 17
}
Getting one of the values is as easy as just using dot notation to get values for a key.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.stats() YIELD labels
RETURN labels.Person as personCount
If multiple values are needed, we can use map projection to get a map of only the counts we want:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.stats() YIELD labels
RETURN labels {.Person, .Movie, .Director} as counts
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-perform-a-soundex-search;"How to perform a Soundex search
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags soundex procedures
Using apoc.text.phonetic one can perform a Soundex search. For example if one defines the following nodes
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:Person {name:'Anders'})
CREATE (m:Person {name:'Andrew'})
CREATE (p:Person {name:'Andres'})
then to find these 3 nodes, since they all have the same Soundex value as Andre, one can run
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.text.phonetic('Andre') YIELD value
WITH value AS search_str
MATCH (n:Person)
CALL apoc.text.phonetic(n.name) YIELD value
WITH value AS match_str, search_str, n
WHERE search_str = match_str
RETURN n
Was this page helpful?"
https://neo4j.com/developer/kb/viewing-schema-data-with-apoc;"Viewing schema data with APOC Procedures
Author Andrew Bowman Applicable versions 3.1 3.2 Tags apoc procedures schema
APOC Procedures offers meta procedures to view information about your database schema and the data it stores.
The procedure apoc.meta.schema() uses a sampling of the graph data to produce a map of metadata on the graph labels, relationships, properties, and more.
As the metadata returned is a map, it can be transformed to better surface desired information, and may be formatted to provide a more tabular structure of the data.
This requires UNWINDing the collection of map keys and obtaining the value for each key.
Here’s one possible way to transform the schema data so it resembles the USER_TAB_COLUMNS system object from Oracle:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.schema() YIELD value as schemaMap
UNWIND keys(schemaMap) as label
WITH label, schemaMap[label] as data
WHERE data.type = ""node""
UNWIND keys(data.properties) as property
WITH label, property, data.properties[property] as propData
RETURN label,
property,
propData.type as type,
propData.indexed as isIndexed,
propData.unique as uniqueConstraint,
propData.existence as existenceConstraint
Here’s an example result table, if run on the movies graph from the built-in tutorial using :play movies, and adding an index on :Person(name) and a unique constraint on :Movie(title). Order of the output is not guaranteed to be the same across Neo4j instances, though the labels should always be grouped together.
label property type isIndexed uniqueConstraint existenceConstraint
""Person""
""name""
""STRING""
true
false
false
""Person""
""born""
""STRING""
false
false
false
""Movie""
""tagline""
""STRING""
false
false
false
""Movie""
""title""
""STRING""
true
true
false
""Movie""
""released""
""INTEGER""
false
false
false
As an alternative, if using APOC 3.1.3.8 or newer (along the 3.1.x line) or 3.2.0.4 or newer (along the 3.2.x line) you can use apoc.map.sortedProperties(), using UNWIND on the result.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.meta.schema() yield value
UNWIND apoc.map.sortedProperties(value) as labelData
WITH labelData[0] as label, labelData[1] as data
WHERE data.type = ""node""
UNWIND apoc.map.sortedProperties(data.properties) as property
WITH label, property[0] as property, property[1] as propData
RETURN label,
property,
propData.type as type,
propData.indexed as isIndexed,
propData.unique as uniqueConstraint,
propData.existence as existenceConstraint
Output will be the same but alphabetically sorted by label, then property.
label property type isIndexed uniqueConstraint existenceConstraint
""Movie""
""released""
""INTEGER""
false
false
false
""Movie""
""tagline""
""STRING""
false
false
false
""Movie""
""title""
""STRING""
true
true
false
""Person""
""born""
""STRING""
false
false
false
""Person""
""name""
""STRING""
true
false
false
Keep in mind that since Neo4j allows dynamic node properties instead of a fixed schema, a sampling of the database is needed to obtain this data. It is possible this may miss some elements in the graph, such as node properties that are only present in a small subset of nodes within a label.
Was this page helpful?"
https://neo4j.com/developer/kb/using-cypher-and-apoc-to-move-a-property-value-to-a-label;"Using Cypher and APOC to move a property value to a label
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags apoc refactoring procedures
Commencing with Neo4j 3.0 and the introduction of stored procedures as well as APOC one can utilize the stored procedure apoc.create.addLabels to move a property to a label with Cypher as follows
Cypher
Copy to Clipboard
Run in Neo4j Browser
// create a node with property studio
create (n:Movies {name: 'A Few Good Men', studio: 'Warner Brothers'})
Cypher
Copy to Clipboard
Run in Neo4j Browser
// move the 'studio' property to a label and remove it as a property
MATCH (n:Movies)
call apoc.create.addLabels([ id(n) ], [ n.studio ]) yield node
with node
remove node.studio
return node
Was this page helpful?"
https://neo4j.com/developer/kb/how-does-apoc-periodic-iterate-work-with-resources;"How does apoc.periodic.iterate work with resources?
Author Daniel Terlizzi Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags apoc procedures
How does apoc.periodic.iterate work?
For example, when running call apoc.periodic.iterate(""MATCH (n) RETURN n"", ""DETACH DELETE n"", {batchSize:1000}) does it append a LIMIT to the MATCH RETURN so that it only returns the batchSize or does it return everything but it just passes batchSize number of rows to the DETACH DELETE?
It does not do a limit. It executes the “MATCH (n) RETURN n” just as it is. The key to remember is that there is a stream of results to be consumed. It does not create a huge result set which could affect the heap. There is a method called iterateAndExecuteBatchedInSeparateThread which uses a separate thread and “consumes” from that stream in chunks, as specified in the parameters.
The first argument is prefixed to enforce usage of slotted runtime since compiled runtime collects the results in a in-memory structure. This is not desired for huge result sets, hence we ensure the first bit is streamed. That stream is populating lists of batchSize elements. These are handed over to the second statement as parameter. In the example the second argument will be on the fly changed to UNWIND $_batch as n DETACH DELETE n. So there’s no explicit limit, but an implicit one due to the UNWIND. You can switch that list collection off with {iterateList:false} and fire the second statement for each result of the first.
The query will only return to the client after the original query completes, so there is only the one round trip. What happens is that the results are being streamed in batches and need to be consumed. This operation occurs via a separate thread and will only absorb a limited amount of memory, so the resources are not exhausted. The external connection will stay open until everything is processed up until the last batch was pulled into memory even if not yet consumed via streaming at which point the connection is closed.
Link to the code is here:
https://github.com/neo4j-contrib/neo4j-apoc-procedures/blob/4.2/core/src/main/java/apoc/periodic/Periodic.java#L232
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-procedure-is-not-available-due-to-having-restricted-access-rights-check-configuration;"Explanation of error: procedure is not available due to having restricted access rights, check configuration
Author Dana Canzano Applicable versions 3.2 Tags procedures apoc security
Commencing with Neo4j 3.2 when running a stored procedure, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.warmup.run();
this may error with
apoc.warmup.run is not available due to having restricted access rights, check configuration.
The cause of this error is as a result of not configuring the security extensions. To allow for all APOC procedures to be available to all users define the conf/neo4j.conf as
Properties
Copy to Clipboard
dbms.security.procedures.unrestricted=apoc.*
If you have installed Neo4j as a Docker container then to achieve the same you would initiate Neo4j by running
Shell
Copy to Clipboard
$ docker run \
    -e NEO4J_dbms_security_procedures_unrestricted=apoc.\\\* \
    -v $PWD/plugins:/plugins \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=$HOME/neo4j/data:/data \
    --volume=$HOME/neo4j/logs:/logs \
    neo4j:3.2.0-enterprise
Was this page helpful?"
https://neo4j.com/developer/kb/conditional-cypher-execution;"Conditional Cypher Execution
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher conditional apoc
At some point you’re going to write a Cypher query requiring some conditional logic, where you want different Cypher statements executed depending on the case.
At this point in time Cypher does not include native conditional functionality to address this case, but there are some workarounds that can be used.
This article covers the ways you can perform conditional Cypher execution.
First a note on CASE
The CASE expression does some conditional logic, but the logic can only be used to output an expression. It cannot be used to conditionally execute Cypher clauses.
Using correlated subqueries in 4.1+
Neo4j 4.1 introduced correlated subqueries, letting us perform a subquery using variables present mid-query. By combining subquery usage with filtering, we can use subqueries to implement conditional Cypher execution.
This requires the use of WITH as the first clause within the subquery CALL block, for the purpose of importing variables to the subquery.
This import usage has some special restrictions that do not normally apply to WITH usage:
You may only include variables from the outer query and no others. You cannot perform calculations, aggregations, or introduction of new variables in the initial WITH.
You cannot alias any variables within this initial WITH.
You cannot follow the initial WITH with a WHERE clause for filtering.
If you try any of these, you will be met with some kind of error, such as:
Importing WITH should consist only of simple references to outside variables. Aliasing or expressions are not supported.
or more cryptically, if you try to use a WHERE clause after the initial WITH
Variable `x` not defined
(where the variable is the first one present in the WITH clause)
You can get around all of these restrictions by simply introducing an additional WITH clause after the importing WITH, like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (bruce:Person {name:'Bruce Wayne'})
CALL {
    WITH bruce
    WITH bruce
    WHERE bruce.isOrphan
    MERGE (batman:Hero {name:'Batman'})
    CREATE (bruce)-[:SuperheroPersona]->(batman)
    WITH count(batman) as count
    RETURN count = 1 as isBatman
}
RETURN isBatman
This demonstrates the ability to filter on imported variables to the subquery by adding a second WITH clause, which is not restricted in the same way as the initial WITH used for the import into the subquery.
The subquery must return a row for the outer query to continue
Subqueries are not independent of the outer query, and if they don’t yield any rows, the outer query won’t have any rows to continue execution.
This can be a problem with conditional Cypher, since by definition you are evaluating a condition as a filter to figure out whether to do something or not.
If that conditional evaluates to false, then the row is wiped out, which is often fine within the subquery itself (you don’t want to create Batman if Bruce isn’t an orphan yet), but you usually want to continue execution no matter what happened in the subquery, and maybe return some boolean value for whether or not the conditional succeeded.
There are some workarounds to avoid having the row wiped out.
Use a standalone aggregation to restore a row before the subquery return
An aggregation (such as count()), when there are no other non-aggregation variables present to act as a grouping key, can restore a row even if the row has been wiped out.
This is because it is valid to get the count() of 0 rows, or to do a collect() over 0 rows to produce an empty collection.
Again, there must be no other non-aggregation variables present when you perform this aggregation.
In the above example, we are using this technique in the subquery so that the outer query can continue no matter how the conditional evaluates:
Cypher
Copy to Clipboard
Run in Neo4j Browser
    WITH count(batman) as count
    RETURN count = 1 as isBatman
With that count() we will get 0 or 1 no matter how the query evaluated, allowing us a row to continue execution when the subquery finishes.
Use a UNION subquery to cover all possible conditionals
We can instead use a UNION within a subquery, where the set of all the unioned queries covers all possible conditional outcomes. This ensures there will be an execution path that succeeds and will return a row, allowing the outer query to continue.
This is also useful for keeping the equivalent of if/else or case logic together, as otherwise you would have to use separate subqueries per conditional block.
With this approach you no longer have to use aggregation to ensure rows remain, you just need to make sure at least one of the UNIONed queries will succeed no matter what.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (bruce:Person {name:'Bruce Wayne'})
CALL {
    WITH bruce
    WITH bruce
    WHERE bruce.isOrphan
    MERGE (batman:Hero {name:'Batman'})
    CREATE (bruce)-[:SuperheroPersona]->(batman)
    RETURN true as isBatman

    UNION

    WITH bruce
    WITH bruce
    WHERE NOT coalesce(bruce.isOrphan, false)
    SET bruce.name = 'Bruce NOT BATMAN Wayne'
    RETURN false as isBatman
}
RETURN isBatman
Note that we have to use the import WITH for each of the UNIONed queries, to ensure each of them imports variables from the outer query, and we still must use a second WITH to allow us to filter.
Since there is no limit to the number of queries that can be unioned together, you can use this approach to handle multiple conditional evaluations.
Using FOREACH for write-only Cypher
The FOREACH clause can be used to perform the equivalent of an IF conditional, with the restriction that only write clauses are used (MERGE, CREATE, DELETE, SET, REMOVE).
This relies on the characteristic that the Cypher in a FOREACH clause is executed per element in the given list. If a list has 1 element, then the Cypher in the FOREACH will execute. If the list is empty, then the contained Cypher will not execute.
We can use CASE to evaluate a boolean condition and output a single-element list, or an empty list, and this drives the conditional Cypher execution (to execute the subsequent write-only clauses, or not).
For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (node:Node {id:12345})
FOREACH (i in CASE WHEN node.needsUpdate THEN [1] ELSE [] END |
  SET node.newProperty = 5678
  REMOVE node.needsUpdate
  SET node:Updated)
...
To get the equivalent of if/else logic, a separate FOREACH must be used for the else part.
Remember that any other non-write clause, such as MATCH, WITH, and CALL, cannot be used with this approach.
APOC conditional procedures
Alternately, the APOC Procedures library includes procedures designed for conditional Cypher execution.
There are two types of procedures:
apoc.when() - When you only have an if (and maybe else) queries to execute based on a single condition. Cannot write to the graph.
apoc.case() - When you want to check a series of separate conditions, each having their own separate Cypher query to execute if the condition is true. Only the first condition that evaluates to true will execute its associated query. If no condition is true, then an else query can be supplied as a default. Cannot write to the graph.
Read and write variations
The procedures shown above have read permission only, they are not allowed to write to the graph, and so if there are any write operations in the conditional Cypher within, the query will error out.
There are variations available that have permission to write to the graph:
apoc.do.when() - Conditional if/else Cypher execution like apoc.when(), but writes are allowed to the graph.
apoc.do.case() - Conditional case Cypher execution like apoc.case(), but writes are allowed to the graph.
This is necessary because the read or write mode of a procedure must be declared in the procedure code.
Having only a read-only procedure would not have the capability to write to the graph.
Having only a write capable procedure means it’s not callable by read-only users, even if the conditional Cypher doesn’t perform any writes.
Both of these are necessary to offer full capabilities no matter the user type or needs of the conditional Cypher query.
The full signatures:
CALL apoc.when(condition, ifQuery, elseQuery:'', params:{}) yield value
based on the conditional, executes read-only ifQuery or elseQuery with the given params
CALL apoc.do.when(condition, ifQuery, elseQuery:'', params:{}) yield value
based on the conditional, executes writing ifQuery or elseQuery with the given params
CALL apoc.case([condition, query, condition, query, …], elseQuery:'', params:{}) yield value
given a list of conditional / read-only query pairs, executes the query associated with the first conditional evaluating to true (or the elseQuery if none are true) with the given params
CALL apoc.do.case([condition, query, condition, query, …], elseQuery:'', params:{}) yield value
given a list of conditional / writing query pairs, executes the query associated with the first conditional evaluating to true (or the elseQuery if none are true) with the given params
In all cases, the condition must be a boolean expression, and all conditional queries (ifQuery, elseQuery, query) are actually Cypher query strings, and must be quoted.
As such, be careful to properly handle quotes within your query string. If the query string itself is inside double-quotes, any strings within that query ought to be single-quotes (or vice versa).
Using these procedures can be tricky. Here are some more tips to help avoid the most common tripping points.
Dealing with quotes/escapes in complex nested queries
For more complicated queries (such as nested queries that must handle quotes at multple levels), consider either defining the query string as a variable first, then pass the variable into the procedure, or alternately pass the conditional queries as parameters to the query itself. This might save you from the headaches of dealing with escape characters within Java strings.
Pass parameters that must be visible within the conditional queries
When executed, the conditional Cypher queries do not have visibility to the variables outside of the CALL.
If a query must see or use a variable, pass it along as part of the params map argument to the call like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (bruceWayne:Person {name:'Bruce Wayne'})
CALL apoc.do.when(bruceWayne.isOrphan, ""MERGE (batman:Hero {name:'Batman'}) CREATE (bruce)-[:SuperheroPersona]->(batman) RETURN bruce"", ""SET bruce.name = 'Bruce NOT BATMAN Wayne' RETURN bruce"", {bruce:bruceWayne}) YIELD value
...
The params map is the last argument of the call: {bruce:bruceWayne}, and allows the bruceWayne variable to be visible to any of the conditional queries as bruce. Additional parameters can be added to the params map if needed.
Conditional queries must RETURN something if you want to keep executing the query after the CALL
Currently, when a (non-empty) conditional query is executed, and the query doesn’t RETURN anything, nothing is YIELDed for the row, wiping out the row. For that original row, anything after the CALL is now a no-op, since there is no longer a row to execute upon (Cypher operations execute per row).
While this may be fine for when the conditional CALL is the last part of the query (and thus there is nothing more to execute after), this behavior will be an unwelcome and confusing surprise to anyone who wants to continue the query, but forgot to add a RETURN to their conditional queries.
The resulting symptom is that the query executes up to the conditional CALL, but (maybe for all rows, maybe for only a subset) no part of the query after the CALL gets executed.
To avoid confusion, it may help to always include a RETURN in all of your conditional queries (except those you leave completely blank, such as no-op else queries…they behave as expected).
This often-confusing behavior will be fixed up in a later APOC update within 2020.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-write-a-cypher-query-to-return-the-top-n-results-per-catgeory;"How to write a Cypher query to return the top N results per category
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher grouping
The following Cypher describes how you can display the Top 5 test scores within an entire :Score population broken out by a field_of_study property.
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (n:Score {student_id: 'DC001', score: 89, field_of_study: 'chemistry'});
create (n:Score {student_id: 'MK812', score: 97, field_of_study: 'chemistry'});
create (n:Score {student_id: 'JT909', score: 77, field_of_study: 'chemistry'});
create (n:Score {student_id: 'SA743', score: 84, field_of_study: 'chemistry'});
create (n:Score {student_id: 'EH331', score: 68, field_of_study: 'chemistry'});

create (n:Score {student_id: 'AE034', score: 89, field_of_study: 'economics'});
create (n:Score {student_id: 'DC001', score: 91, field_of_study: 'economics'});
create (n:Score {student_id: 'JF623', score: 74, field_of_study: 'economics'});
create (n:Score {student_id: 'TP810', score: 77, field_of_study: 'economics'});
create (n:Score {student_id: 'BB317', score: 82, field_of_study: 'economics'});
create (n:Score {student_id: 'AH042', score: 61, field_of_study: 'economics'});
create (n:Score {student_id: 'RV448', score: 59, field_of_study: 'economics'});
running:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Score)
with n order by n.score desc
with n.field_of_study as class,collect(n.student_id + '('+ n.score +')') as student
return class,student[0..5]
order by class
will return output of:
class               student[0..5]
chemistry       [MK812(97), DC001(89), SA743(84), JT909(77), EH331(68)]
economics       [DC001(91), AE034(89), BB317(82), TP810(77), JF623(74)]
and in the above the students score has been appended to their student_id value by way of the reference '('+ n.score +')'.
The Cypher can also be written as
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n:Score)
with n order by n.score desc
with n.field_of_study as class,collect({student_id:n.student_id, score:n.score}) as student
return class,student[0..5]
order by class
will produce the same output but the Top 5 students will be listed in a map of author and score: and thus
╒═══════════╤══════════════════════════════╕
│""class""    │""student[0..5]""               │
╞═══════════╪══════════════════════════════╡
│""chemistry""│[{""student_id"":""MK812"",""score""│
│           │:""97""},{""student_id"":""DC001"",""│
│           │score"":""89""},{""student_id"":""SA│
│           │743"",""score"":""84""},{""student_i│
│           │d"":""JT909"",""score"":""77""},{""stu│
│           │dent_id"":""EH331"",""score"":""68""}│
│           │]                             │
├───────────┼──────────────────────────────┤
│""economics""│[{""student_id"":""DC001"",""score""│
│           │:""91""},{""student_id"":""AE034"",""│
│           │score"":""89""},{""student_id"":""BB│
│           │317"",""score"":""82""},{""student_i│
│           │d"":""TP810"",""score"":""77""},{""stu│
│           │dent_id"":""JF623"",""score"":""74""}│
│           │]                             │
└───────────┴──────────────────────────────┘
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-cypher-cardinality;"Tuning Cypher queries by understanding cardinality
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags performance cypher cardinality
Cardinality issues are the most frequent culprit in slow or incorrect Cypher queries. Because of this, understanding cardinality, and using this understanding to manage cardinality issues, is a critical component in Cypher query tuning, and query correctness in general.
A note about the following examples
We will use the built in Movies graph for examples (use :play movies in the Neo4j browser to create the dataset).
Note that the query planner can optimize some operations. It may change the order of some operations, changing the order of expansion, or which nodes we use as the starting nodes, or more. It’s still best to be mindful of cardinality when tuning your queries, even if the plan isn’t as expected, or circumvents the issue for you in some cases.
Cypher operations execute per row, and generate rows of results
To understand cardinality in Cypher, two important aspects of Cypher execution need to be understood first:
Cypher operations execute per record/row* of the input stream to the operation
Cypher operations generate streams of result records/rows*
* While ""record"" is more technically correct (Neo4j doesn’t use tables, so it doesn’t really have rows), ""row"" is often more familiar, and is the term used in query plan output. We’ll be using ""row"" from here on.
These are two aspects of the same principle: streams of rows are both the input and output for cypher operations.
You can see how streams of rows flow between Cypher operations in a PROFILE query plan, increasing from match expansions and unwinds, and diminishing through filtering, aggregations, and limits.
The more rows in the stream, the more work is performed by the next operation, contributing to db hits and query execution time.
As an example, take this simple query on the movies graph to find all actors in The Matrix:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
If we decided to return the data at this point (RETURN movie.title as title, actor.name as name) we would get the following results (in no particular order):
title name
""The Matrix""
""Keanu Reeves""
""The Matrix""
""Hugo Weaving""
""The Matrix""
""Laurence Fishburne""
""The Matrix""
""Carrie-Anne Moss""
""The Matrix""
""Emil Eifrem""
These are 5 rows in the result stream.
If instead of returning we decide to do something more from those match results, these rows will be the input for the next operation in the query.
That operation will execute for each these rows.
What is cardinality in Cypher and why does it matter?
Cardinality in general refers to the number of rows flowing between operations.
Remember, operations execute per row, and depending upon your query, it’s possible for there to be multiple rows where the same value is present for a variable that you’re operating upon.
For example, if you’re performing an expansion out from a node variable, if the same specific node is present on multiple rows, you could be performing the same operation multiple times redundantly.
Managing cardinality is all about making sure that when you perform operations on values, that you shrink the cardinality first, if possible, so that you avoid those redundant operations.
Why does that matter?
Because we want the query to be quick; we want to do the least amount of work needed, as opposed to redundantly performing the same operation for the same value multiple times.
Because we want the query to be correct; we don’t want to see unwanted duplicate result rows, or end up creating duplicate graph elements.
Cardinality issues can lead to redundant and wasteful operations
Note that in the results of our Matrix query above, the same values occur across multiple rows because they are present in multiple matched paths.
In the query results above, The Matrix movie is the same starting node for all results, so the same node is present on all rows of the stream. Each distinct actor only occurs in a single row of the stream.
If we performed a match from actor (the variable for actors in the match), that match would only be performed once per distinct actor.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
MATCH (actor)-[:ACTED_IN]->(otherMovie)
...
However if we performed a match from movie (the variable for movies in the match), that match would be performed 5 times redundantly for the same Matrix node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
MATCH (movie)<-[:DIRECTED]-(director)
...
Cardinality issues can result in duplicated data
Remember that operations execute per row. This includes CREATE and MERGE operations.
Consider if we wanted to create a new relationship :WORKED_ON between actors and directors to movies they worked on.
Just looking at the Matrix movie, a wrong approach may look like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
If we viewed the result, we would see two :WORKED_ON relationships between each actor and The Matrix, and 5 :WORKED_ON relationships between each director and The Matrix.
Why? Because the first two matches above resulted in a cross product of the 5 actors and the 2 directors, 10 rows total.
Each distinct director would appear on 5 of those rows (once for each actor) and each distinct actor would appear on 2 of those rows (once for each director). The CREATE operations would execute on each of those 10 rows, leading to the redundant relationships.
While we could solve this by using MERGE instead of CREATE, which would only create the expected number of relationships, we’re still performing redundant operations in the process.
How do we manage cardinality?
We manage cardinality mostly through aggregations and reordering operations in the query, and sometimes through the use of LIMIT (when it makes sense to do so).
Aggregation
The important part about aggregations is that the combination of non-aggregation variables become distinct. If an operation executes upon those distinct variables, then there should be no wasted executions.
Let’s take the above query and use an aggregation to reduce the cardinality
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
WITH movie, collect(actor) as actors
MATCH (movie)<-[:DIRECTED]-(director)
WITH movie, actors, collect(director) as directors
...
In the second line, we perform a collect() aggregation. The only non-aggregation variable, movie, becomes the distinct grouping key. The cardinality drops to a single row here, as the row only has The Matrix node and the list of actors.
Because of this, the subsequent expand operation from the next MATCH will only execute once for The Matrix node, instead of 5 times as before.
But what if we want to perform additional matches from actor?
In that case we can UNWIND our collection after our match:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
WITH movie, collect(actor) as actors
MATCH (movie)<-[:DIRECTED]-(director)
WITH movie, collect(director) as directors
UNWIND actors as actor
MATCH (actor)-[:ACTED_IN]->(other)
WHERE other <> movie
...
Pattern comprehension can help
Pattern comprehension is a way to populate a list with the results of an expansion. If your desired result include collections of connected nodes, it’s a good way to keep cardinality low and make the query a little less verbose.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})
WITH movie, [(movie)<-[:DIRECTED]-(director) | director] as directors
MATCH (movie)<-[:ACTED_IN]-(actor:Person)-[:ACTED_IN]->(other)
...
Reorder the query to aggregate earlier
Newcomers to Cypher (especially those from SQL backgrounds) often try to perform many operations (limit, aggregation, etc) in the RETURN statement.
In Cypher, we encourage performing these operations early, where it makes sense to do so, as it can keep cardinality low and prevent wasteful operations.
Here’s an example of performing aggregations late, though we get the correct answer through usage of COLLECT(DISTINCT …)
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
OPTIONAL MATCH (movie)<-[:ACTED_IN]-(actor)
OPTIONAL MATCH (movie)<-[:DIRECTED]-(director)
RETURN movie, collect(distinct actor) as actors, collect(distinct director) as directors
In Neo4j 3.3.5, the PROFILE for this has 621 db hits.
We do get the right answer in the end, but the more back-to-back matches or optional matches we perform, the more cardinality issues have a chance to snowball multiplicatively.
If we reorder the query to COLLECT() after each OPTIONAL MATCH instead, or use pattern comprehension, we cut down on unnecessary work, as our expand operations occur on each movie keeping cardinality as low as possible and eliminating redundant operations.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WITH movie, [(movie)<-[:DIRECTED]-(director) | director] as directors, [(movie)<-[:ACTED_IN]-(actor) | actor] as actors
RETURN movie, actors, directors
In Neo4j 3.3.5, the PROFILE for this has 331 db hits.
Of course, on queries on small graphs like this with small result sets, and few operations, the difference is negligible when we look at timing differences.
However, as graph data grows, as well as the complexity of graph queries and results, keeping cardinality low and avoiding multiplicative db hits becomes the difference between a quick streamlined query and one that may exceed acceptable execution time.
Use DISTINCT or an aggregation to reset cardinality
Sometimes in the course of a query we want to expand from some node, perform operations on the nodes we expand to, then expand on a different set of nodes from the original. If we’re not careful, we can encounter cardinality issues.
Consider the attempt to create :WORKED_ON relationships from earlier:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
This query resulted in duplicated relationships, even if we used MERGE we would still be doing more work than needed.
One solution here is to do all the processing on one set of nodes first, then do the processing on the next set. The first step toward such a solution might look like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
WITH movie
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
Even though we get 1 :WORKED_ON relationship for each actor, we are still seeing 5 :WORKED_ON relationship per director.
Why? Because cardinality does not reset automatically. Even though we have WITH movie in the middle, we still have 5 rows, one per actor (even though the actor variable is no longer in scope), with The Matrix as movie for each of them.
To fix this, we need to either use DISTINCT or an aggregation to reset the cardinality so there is only a single row per distinct movie.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[:ACTED_IN]-(actor)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
WITH DISTINCT movie
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
By using WITH DISTINCT movie we ensure there are no duplicates in the stream, minimizing cardinality.
The following query will also work just fine, since when we aggregate the non-aggregation variables become distinct:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[:ACTED_IN]-(actor)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
WITH movie, count(movie) as size
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
DISTINCT nodes from variable-length paths
Variable-length pattern matches can be costly in some cases, as Cypher attempts to find all possible paths that match the given pattern.
When you are only interested in distinct nodes at the end of the pattern, this behavior is wasteful, as you don’t need multiples of the same node that were reached from different paths, and continuing to work with those results will likely lead to cardinality issues.
You can tell your query that you’re only interested in DISTINCT nodes, and by meeting a few small conditions the planner will optimize the expand operation (this shows as VarLengthExpand(Pruning) in the query plan).
You need an upper bound on the expansion, and to have a WITH DISTINCT or RETURN DISTINCT clause after the match to take advantage of this optimization.
Cypher
Copy to Clipboard
Run in Neo4j Browser
PROFILE
MATCH (:Person{name:'Keanu Reeves'})-[:ACTED_IN*..5]-(movie)
WITH DISTINCT movie
...
A note about limitations of var-length pattern matches
Although pruning var expands can be faster than the regular expand operation, it still must find all possible paths, even if we are only retaining distinct results.
On even moderately connected graphs, such as the movies graph, if there aren’t tight constraints on the relationship type and direction, var-length path matches may still get increasingly expensive at higher (or no) upper bounds if the permutation of all possible paths skyrockets, to the point where such a query may hang.
If you need distinct connected nodes in these cases, you may need to turn to APOC Procedures for path expansions that traverse the graph in a more efficient manner that better fits this use case.
Be careful with LIMIT when it comes after write operations
LIMIT is lazy in that once it receives the number of results to be limited, processing stops for previous operations.
While this can make it very efficient, it may have an unexpected effect when you’re performing write operations before the LIMIT, in that the query will only process as many results as are necessary for the limited amount to be reached (though Eager operations and aggregations between the write operations and the LIMIT should be safe, in that all processing before this point should have executed as expected).
Let’s use a modified version of the above example, but instead of using DISTINCT or an aggregation to reduce cardinality, let’s use LIMIT 1, since that’s guaranteed to get us down to one row:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie {title:'The Matrix'})<-[:ACTED_IN]-(actor)
CREATE (actor)-[:WORKED_ON {role:'actor'}]->(movie)
WITH movie
LIMIT 1
MATCH (movie)<-[:DIRECTED]-(director)
CREATE (director)-[:WORKED_ON {role:'director'}]->(movie)
While this seems to make sense, because LIMIT is lazy, it will only pull through enough results to satisfy the limit, and then no more rows will be pulled through.
As a result, even though there are 5 actors in The Matrix and 2 directors, this query will only create 3 relationships: 1 will be for an actor, the remaining 2 will be for the directors. The first match was found, the first relationship created, then since the limit was reached, further matches (and relationship creations) for actors were not processed.
If we added a collect(actor) as actors or similar aggregation before the usage of LIMIT, we would have introduced an EagerAggregation operation (as seen in the EXPLAINed query plan) which would have processed that part of the query for all input rows to that point before the LIMIT was reached, ensuring that our expected 7 relationships were created.
The takeaway here is to be aware of where in the query you’re using LIMIT, especially when there are write operations occurring before the LIMIT.
If you need to ensure the write operations occur for all rows before the LIMIT is applied, introduce an Eager in the query plan with aggregations, or use an alternative to LIMIT instead.
Note that the lazy behavior of LIMIT as illustrated here is under review — future versions of Cypher may adjust its behavior.
Use LIMIT early if possible
While not directly related to cardinality, if you’re using LIMIT in your query it’s advantageous to LIMIT early, if possible, instead of at the end.
Consider the differences here:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
OPTIONAL MATCH (movie)<-[:ACTED_IN]-(actor)
WITH movie, collect(actor) as actors
OPTIONAL MATCH (movie)<-[:DIRECTED]-(director)
WITH movie, actors, collect(director) as directors
RETURN movie, actors, directors
LIMIT 1
In Neo4j 3.3.5 the PROFILE for this has 331 db hits.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WITH movie
LIMIT 1
OPTIONAL MATCH (movie)<-[:ACTED_IN]-(actor)
WITH movie, collect(actor) as actors
OPTIONAL MATCH (movie)<-[:DIRECTED]-(director)
WITH movie, actors, collect(director) as directors
RETURN movie, actors, directors
In Neo4j 3.3.5 the PROFILE for this has 11 db hits.
We avoid doing work that will only be thrown out when we finally perform the LIMIT.
Was this page helpful?"
https://neo4j.com/developer/kb/resetting-query-cardinality;"Resetting query cardinality
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher cardinality
As queries execute, they build up result rows. Cypher executes operations per-row. When a query is made up of completely separate parts, unrelated to each other, and you don’t want to split the single query into multiple queries, you sometimes need a way to reset cardinality back to 1 to avoid executing an operation multiple times.
For example, using the Movies graph, let’s write a query to label actors, and then create a new :Movie node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE (p)-[:ACTED_IN]->(:Movie)
SET p:Actor

CREATE (:Movie{title:'The Animatrix'})
When run all in a single query, you’ll see that multiple 'The Animatrix' nodes were created, not just one. This is because the CREATE clause executes per row, and we have one row for each :Actor just before the CREATE executes.
While you could get around the extra node creations by using MERGE instead of CREATE, you still pay the cost of executing multiple redundant MERGE operations per row, db hits that are completely unnecessary.
To reset cardinality back to 1 before the next part of the query, you’ll need to use WITH DISTINCT on some arbitrary value.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE (p)-[:ACTED_IN]->(:Movie)
SET p:Actor

WITH DISTINCT 1 AS ignored
CREATE (:Movie{title:'The Animatrix'})
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-define-a-load-csv-fieldterminator-in-hexidecimal-notation;"How do I define a LOAD CSV FIELDTERMINATOR in hexidecimal notation
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load-csv
When using LOAD CSV one can define the field delimiter used, whereby the default is the ',' character.
If you want to override the default this can be accomplished via the paramter FIELDTERMINATOR, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS from 'file:///actors.csv' as row
FIELDTERMINATOR ';'
RETURN row.name;
will read a file named actors.csv and expect each field is delimited by the semi-colon character ';'
One can also define the FIELDTERMINATOR as a hexidecimal representation of its ASCII character. This can be helpful if you have chosen a field delimiter as a non-printable character, for example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
LOAD CSV WITH HEADERS from 'file:///actors.csv' as row
FIELDTERMINATOR '\u0080'
RETURN row.name;
the usage of '\u' as a FIELDTERMINATOR needs to be a 4 character zero padded value. In the above example the field terminator is now defined to be hexidecimal value 80, which is decimal character 128 of the ASCII extended characters and represents the cedilla character.
Was this page helpful?"
https://neo4j.com/developer/kb/using-max-and-min-while-keeping-items;"Using max() and min() while keeping items
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher aggregations max min
The aggregation functions of max() and min() are very useful, but you can sometimes find yourself fighting against Cypher’s aggregation behavior for cases that should be simple.
This often comes up when you want to calculate the max() or min() or something, but keep the item or items associated with that maximum or minimum value.
Let’s use a very simple example, a graph of people who bought food at a store:
Cypher
Copy to Clipboard
Run in Neo4j Browser
(:Person {name})-[:BOUGHT]->(:FoodItem {name})
We want to find, per person, the food item or items that they bought the most.
Complex when it should be simple
We can easily use max() to find the count of the food item that they bought the most:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[:BOUGHT]->(food:FoodItem)
WITH person, food, count(food) as timesBought
RETURN person, max(timesBought) as mostBoughtCount
But we lose the data associated with the food that generated that result! WHICH food item was bought that many times? And was it just a single food item, or were there ties among several?
If we keep food in scope like so: RETURN person, food, max(timesBought) as mostBoughtCount, we get a wrong result, since each food is listed on its own row, and the mostBoughtCount is for each food and not aggregated across all of them.
If we collect() the food like so: RETURN person, collect(food) as foods, max(timesBought) as mostBoughtCount, while mostBoughtCount is correct, we’ve collected all the foods, and have no idea which one is associated with that maximum value.
We’re forced to abandon this approach and instead perform an ordering, a collect(), then keep the top result:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[:BOUGHT]->(food:FoodItem)
WITH person, food, count(food) as timesBought
ORDER BY timesBought DESC
RETURN person, collect(food)[0] as favoriteFood, max(timesBought) as mostBoughtCount
But again, what about ties? A person might have several favorite foods tied in their mostBoughtCount. We might spend a lot of time refactoring that query, doing collects() and UNWINDs and counting and comparison, and the query gets even more complex.
APOC Procedures helps keep things simple
First, we were granted custom procedures, then we were given custom functions, and last we received the ability to write custom aggregation functions. As of APOC 3.5.0.5, new functions were added that help out in these cases.
apoc.agg.maxItems(item, value, groupLimit: -1)
returns a map {items:[], value:n} where value is the maximum value present, and items are all items with the same value. The number of items can be optionally limited.
There is an apoc.agg.minItems() as well that works similarly.
In short, this function lets us use the equivalent of min() or max(), but also to keep the item or items associated with that value.
If we add this to our query we get:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[:BOUGHT]->(food:FoodItem)
WITH person, food, count(food) as timesBought
WITH person, apoc.agg.maxItems(food, timesBought) as maxData
RETURN person, maxData.items as favoriteFoods, maxData.value as mostBoughtCount
This lets us keep all the foods that tied as favorites, and if we did want to limit ties, we could add that as an additional parameter to the function call.
Was this page helpful?"
https://neo4j.com/developer/kb/a-note-on-optional-matches;"A note on OPTIONAL MATCHes
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher match
An OPTIONAL MATCH matches patterns against your graph database, just like a MATCH does. The difference is that if no matches are found, OPTIONAL MATCH will use a null for missing parts of the pattern. OPTIONAL MATCH could be considered the Cypher equivalent of the outer join in SQL.
Knowing this, one could write a cypher query as so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (actor:Actor)-[:ACTED_IN]->(:Movie)<-[:DIRECTED]-(director:Director {uuid:'fd787f45-df1a-4f8b-b4a9-ab7b90fefae4'})
OPTIONAL MATCH (director)-[:HAS_STUDIO*2]->(:Studio)-[:HAS_ACTOR]->(actor)-[:HAS_PROFILE]->(profile:Profile)
WHERE profile.type IN [""Drama"", ""Action""]
MERGE (director)-[:HAS]->(actor)
ON CREATE SET profile.uuid = apoc.create.uuid(), profile.lastTimeReported = '2018-12-15T23:13:22.274', profile.reportingState = 'Active'
ON MATCH SET profile.lastTimeReported = '2018-07-15T23:30:00.000', profile.reportingState = 'Active'
RETURN COUNT(profile) as updatedCount
However, this query may return an error such as:
Neo.DatabaseError.General.UnknownError: org.neo4j.values.storable.NoValue cannot be cast to org.neo4j.values.virtual.VirtualNodeValue
(pre 3.4.5)
or
Neo.DatabaseError.Statement.ExecutionFailed: Expected to find a node at ref slot 0 but found instead: null
(post 3.4.5)
This is because starting a query with an OPTIONAL MATCH doesn’t always play well with Neo4j, namely when your OPTIONAL MATCH returns no value and affects the rest of the query plan. The simplest form of query to trigger this is the following, when run on an empty database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
OPTIONAL MATCH (a)
MERGE (a)-[:X]->()
Messages thrown in these cases are the following:
Expected to find a node at $name but found instead: null
Expected to find a node at $name but found instead: $x
Expected to find a node at $name but found instead: null
When faced with one of these messages, the problem is related to the optional matches and can be solved by starting the query with a normal MATCH such as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (actor:Actor)-[:ACTED_IN]->(:Movie)<-[:DIRECTED]-(director:Director {uuid:'fd787f45-df1a-4f8b-b4a9-ab7b90fefae4'})
OPTIONAL MATCH (director)-[:HAS_STUDIO*2]->(:Studio)-[:HAS_ACTOR]->(actor)-[:HAS_PROFILE]->(profile:Profile)
WHERE profile.type IN [""Drama"", ""Action""]
MERGE (director)-[:HAS]->(actor)
ON CREATE SET profile.uuid = apoc.create.uuid(), profile.lastTimeReported = '2018-12-15T23:13:22.274', profile.reportingState = 'Active'
ON MATCH SET profile.lastTimeReported = '2018-07-15T23:30:00.000', profile.reportingState = 'Active'
RETURN COUNT(profile) as updatedCount
If you have a long OPTIONAL MATCH we suggest you break it down so that you turn it into (at least) one MATCH followed by the OPTIONAL MATCH(es). You should MATCH the portions that must be present, and then the OPTIONAL MATCH(es) on the pieces of the pattern that may not be present.
For the example above, the full pattern in the first line is needed, since we want the director and its actors at a minimum. In other cases, maybe only a single starting node is needed at a minimum. Rule of thumb is starting with a MATCH to attempt to capture the minimum part of the graph needed, then use OPTIONAL MATCH(es) on anything else that is optional.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-avoid-costly-traversals-with-join-hints;"How to avoid costly traversals with join hints
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
When matching a pattern using Cypher, the number of possible paths to evaluate often correlates with query execution time.
When there is a supernode in the path (a node with a high number of relationships whose type are included in your MATCH pattern), or simply enough nodes with many relationships, the number of possible paths can explode, slowing down your query. Traversal like this through supernodes can be expensive.
Sometimes when traversing certain kinds of patterns, you may know from your modeling that if at all possible, a relationship between two specific kinds of nodes ought to be traversed in a certain direction instead of its opposite for best performance, and this is often the case with supernodes.
For example, if we had a social graph of :People who :LIKE musical artists, it’s very likely that some of those artists, perhaps many, are supernodes. If we were looking at (:Person)-[:LIKES]→(:Artist {name:'Britney Spears'}), we could reasonably assume that a :Person likely has relatively few :LIKES relationships, perhaps less than 100, but that a popular :Artist like Britney Spears may have millions of :LIKES relationships pointing her way.
Traversing through Britney Spears is going to be costly as it could multiply the number of possible paths by the number of :LIKES relationships, blowing up the execution of the query. However, traversing only to Britney Spears is likely going to be relatively cheap.
In cases where a query has the potential for multiple starting places, and if the planner isn’t providing an efficient plan in light of bad traversals through supernodes, you can use a join hint in the query to prevent traversal through a node.
Instead, multiple starting points are used, and from each one expansion is performed until reaching the node specified in the join hint. Then a hash join is used to find the common nodes that were matched to from both directions, and the fully matched path is realized.
If I’m trying to find out artists my friends and I like in common (and how many likes are in common) I might have a query like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:Person {name:'Me'})-[:FRIENDS_WITH]-(friend)-[:LIKES]->(a:Artist)<-[:LIKES]-(me)
RETURN a, count(a) as likesInCommon
If the planner decides to use only a single starting point for this query and doesn’t recognize a potential supernode issue, it’s possible that it may choose to plan expansion through the :Artist node, which could be very costly:
As the Cypher query planner has the ability to rearrange the ordering of adjacent MATCH patterns (and across some WITH clauses), simply reordering my pattern isn’t enough. I can use a join hint to ensure we only traverse to the node in question, but not through it or away from it.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:Person {name:'Me'})-[:FRIENDS_WITH]-(friend)-[:LIKES]->(a:Artist)<-[:LIKES]-(me)
USING JOIN on a
RETURN a, count(a) as likesInCommon
From the query plan we can see that from the same starting point we traverse two different paths toward a, but not through it, and perform a node hash join to unify the paths on the common artist nodes.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-report-on-nodes-with-multiple-labels;"How do I report on nodes with multiple labels
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags labels
If your data model has chosen to define multiple labels on a node, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
create (n:Actor:Director {name:'Clint Eastwood'})
To find all nodes which are defined with both labels of Actor AND Director use the following Cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
match (n) where n:Actor and n:Director return n;
Using this syntax will be performant as it will start with a NodeByLabelScan
If you need to find all nodes which have either label of Actor OR Director use the following Cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Actor) RETURN n UNION MATCH (n:Director) RETURN n
Using this syntax will be performant as it will perform a NodeByLabelScan on both the Actor label and the Director label and then merge the results.
Was this page helpful?"
https://neo4j.com/developer/kb/performing-pattern-negation;"Performing pattern negation to multiple nodes
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags performance cypher
Some use cases require matching to nodes which aren’t connected to any of some other set of nodes. We’ll discuss both incorrect and correct approaches to this kind of query.
For our examples we’ll use a recipe graph, where the primary structure is as follows:
Cypher
Copy to Clipboard
Run in Neo4j Browser
(:Recipe)-[:INCLUDES]->(:Ingredient)
The use case is, provided a list of ingredient names to exclude, to match to recipes which do not contain any of those ingredients.
Incorrect approach: leave nodes on their own rows when testing for exclusion
A common incorrect approach does not use collections, but assumes (wrongly) that the pattern negated treats the variable values as a collection.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (excluded:Ingredient)
WHERE excluded.name in $excludedIngredients
MATCH (r:Recipe)
WHERE NOT (r)-[:INCLUDES]->(excluded)
RETURN r
For a single excluded ingredient, the above query will work just fine.
However, when $excludedIngredients contains several entries, this query may fail to produce correct results.
The reason is because each excluded ingredient is on its own record/row, and will be tested individually, which will mean some recipes that have one of the excluded ingredients, but not all, will not be filtered correctly.
For example, let’s say the parameters are as follows: {excludedIngredients:['eggs', 'walnuts']}
Let’s say a Chocolate Cake :Recipe is being evaluated, which contains eggs, but not walnuts.
Because each excluded ingredient is on its own record, if we inspected the built-up records at the time of evaluation, it may look like this:
excluded.name r.name
eggs
Chocolate Cake
walnuts
Chocolate Cake
The build up records are for each single ingredient with each recipe that contains it. These are not arranged into collections automatically (that would require use of collect())
Each record will be independently evaluated: WHERE NOT (r)-[:INCLUDES]→(excluded)
The first record will be evaluated, and as the Chocolate Cake contains eggs, the record will be eliminated.
The second record will be evaluated, and as the Chocolate Cake does not contain walnuts, the record is kept.
The Chocolate Cake :Recipe will be returned as a result, which is clearly incorrect.
Correct approach: collect nodes to exclude, and use WHERE NONE() on the collection to drive exclusion
The correct approach is to use collection membership to drive the exclusion. There are actually many similar correct queries that start from this approach, some with varying efficiency, depending on the actual graph:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (excluded:Ingredient)
WHERE excluded.name in $excludedIngredients
WITH collect(excluded) as excluded
MATCH (r:Recipe)-[:INCLUDES]->(i)
WITH excluded, r, collect(i) as ingredients
WHERE NONE (i in ingredients where i in excluded)
RETURN r
We can do the same thing using pattern comprehension to expand and collect all at once.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (excluded:Ingredient)
WHERE excluded.name in $excludedIngredients
WITH collect(excluded) as excluded
MATCH (r:Recipe)
WITH excluded, r, [(r)-[:INCLUDES]->(i) | i] as ingredients
WHERE NONE (i in ingredients where i in excluded)
RETURN r
Or we can avoid collecting ingredients for each recipe and instead use NONE() to exclude the pattern of the relationship having any of the excluded ingredients.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (excluded:Ingredient)
WHERE excluded.name in $excludedIngredients
WITH collect(excluded) as excluded
MATCH (r:Recipe)
WHERE NONE(i in excluded WHERE (r)-[:INCLUDES]->(i))
RETURN r
Another correct approach: use OPTIONAL MATCH to members of the excluded collection, and exclude non-null values
An alternate approach doesn’t use WHERE NONE(), but instead uses an OPTIONAL MATCH from a :Recipe, but only to the nodes we want to exclude.
If there isn’t a match to any of the excluded nodes, the newly introduced variable i will be null, and we can filter with another WHERE clause to get only those rows.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (excluded:Ingredient)
WHERE excluded.name in $excludedIngredients
WITH collect(excluded) as excluded
MATCH (r:Recipe)
OPTIONAL MATCH (r)-[:INCLUDES]->(i)
WHERE i in excluded
WITH r
WHERE i IS NULL
RETURN r
Was this page helpful?"
https://neo4j.com/developer/kb/using-subqueries-to-control-the-scope-of-aggregations;"Using Subqueries to Control the Scope of Aggregations
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher performance
Aggregations, such as collect() and count(), show up as EagerAggregation operators (with dark blue headers) in query plans.
These are similar to the Eager operator in that it presents a barrier that all rows must execute to and stop at for the aggregation to process, but it otherwise doesn’t change the streaming behavior of a query (provided there are no actual Eager operators in the plan).
This is less memory-intensive than the Eager operator, but the aggregation results (including the variables used for the grouping keys) must be kept in memory until the aggregation finishes processing all inputs, and only then can streaming resume from the resulting rows.
As such, the rows that build up resulting from the aggregation may stress the heap, if numerous enough, which could result in high GC pauses, or at the worst going out of heap memory.
This article shows hot to use subqueries, introduced in Neo4j 4.1, to provide a way to narrow the scope of an aggregation. This may be easier on your heap leading to a more memory efficient query.
That said, correctness matters first; it is possible that an eager aggregation over all input rows is necessary to calculate correct results. However, when you want the eager to apply only to a certain expansion (or segment of input), then you can control that via subqueries.
Even before 4.1, you can accomplish something similar (though on a smaller scale) with pattern comprehensions, which has the effect of scoping a collect() to the pattern expanded in the comprehension.
Some APOC procedures can also be used as a subquery replacement.
An example of aggregation behavior
Let’s use something simple, the Movies graph from the :play movies guide in the Neo4j Browser.
Once we’ve created this graph from the guide, let’s look at a simple query, returning each movie node, and its list of actor nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[:ACTED_IN]-(p:Person)
RETURN movie, collect(p) as actors
How will this execute?
The first path match will be found (a label scan from one of the two two nodes, then an expand of the pattern, and a filter based on the node label), and then the aggregation processing begins.
The next path match will be found, and the aggregation will process that row, and so on, with the aggregation continuing to take in rows of data of build up the aggregation results accordingly.
Eventually all 172 paths have been processed by the aggregation. The aggregation has built up 38 result rows (one per movie, which is the grouping key), each consisting of the movie node and the list of actors for the movie. Now that all input rows have been processed, the aggregation is complete, and streaming begins from the 38 resulting rows.
This interim state in the heap does NOT include node or relationship properties, excepting any that have been projected out as variables.
A slightly larger dataset
This was a small data set. But what if we instead had a graph with a far larger data set? It’s estimated that 500,000 movies have been made up to this point in history. 500,000 rows held in heap at once still won’t be a problem, we have to look at bigger numbers to present a challenge, or at least a notable time difference during execution..
Let’s create a movies graph with 1 million movies, 1 million actors, and 10 actors per movie.
We’ll use apoc.periodic.iterate() from APOC Procedures to create our graph.
First let’s create 1 million nodes for both movies and persons:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(""
UNWIND range(1,1000000) as id
RETURN id
"",
""
CREATE (m:Movie {id:id})
CREATE (p:Person {id:id})
"", {}) YIELD batches, total, errorMessages
RETURN batches, total, errorMessages
We don’t need additional properties right now. The matching and aggregating that we’re doing don’t depend upon the node properties, and we don’t pay a cost for using them until we project them out anyway.
Now let’s make sure we have indexes in place:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE INDEX ON :Person(id);
CREATE INDEX ON :Movie(id);
Now that we have indexes, we can randomly assign 10 persons to each movie as actors:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate(""
MATCH (m:Movie)
RETURN m
"",
""
UNWIND range(0,10) as i
WITH m, toInteger(rand() * 1000000) as id
MATCH (p:Person {id:id})
CREATE (m)<-[:ACTED_IN]-(p)
"", {}) YIELD batches, total, errorMessages
RETURN batches, total, errorMessages
For my particular laptop, I’ve configured 4gb of memory for the heap. Actual server deployments would tend to use at least double that, up to 31gb as the recommended maximum.
Let’s see how we do, using a slightly modified version of the original query. I want to factor out the returning of the results (which includes the property access of all of those nodes), so we’ll just end with a count() aggregation, which tends to be much cheaper (after all it’s just incrementing the count per input row, at the end).
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)<-[:ACTED_IN]-(p:Person)
WITH movie, collect(p) as actors
RETURN count(*)
The grouping key is still the movie, so we know we have to hold up to 1 million rows as the aggregation builds up, along with the lists of actors per movie.
Depending on heap memory (as well as what other queries were executing at the same time), that could stress the heap, leading to high GC pauses as memory is used up and unable to be reclaimed. We could blow through all heap memory completely.
So let’s give this a try. First up, here’s the EXPLAIN plan:
We can see the aggregations for the collect (more expensive) and the count (cheap). Let’s try running it:
None
Copy to Clipboard
Started streaming 1 records after 1 ms and completed after 14907 ms.
It returns a count of 1 million (omitted because that’s not interesting), but more interesting is the execution time, or rather it will be interesting once we have an alternate query to compare it to. For me this took about 15 seconds.
The most interesting part of this query is actually in the debug log:
None
Copy to Clipboard
2020-10-01 04:06:31.703+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=178, gcTime=248, gcCount=1}
2020-10-01 04:06:32.893+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=254, gcTime=269, gcCount=1}
2020-10-01 04:06:34.620+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=277, gcTime=295, gcCount=1}
2020-10-01 04:06:36.506+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=328, gcTime=383, gcCount=1}
2020-10-01 04:06:38.847+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=542, gcTime=628, gcCount=1}
2020-10-01 04:06:40.937+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=346, gcTime=384, gcCount=1}
2020-10-01 04:06:42.994+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=314, gcTime=348, gcCount=1}
2020-10-01 04:06:44.965+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=241, gcTime=271, gcCount=1}
2020-10-01 04:07:04.570+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=242, gcTime=256, gcCount=1}
2020-10-01 04:08:42.469+0000 WARN [o.n.k.i.c.VmPauseMonitorComponent] Detected VM stop-the-world pause: {pauseTime=169, gcTime=198, gcCount=1}
These gcs are not very high individually, but this shows that aggregations like this can and do cause GC pauses. With a more complex query, or a more complex dataset, these pauses might actually become quite significant.
Subqueries narrow the scope of an aggregation
If we use a subquery in the right place, and aggregate within the subquery, we can narrow down the scope of the aggregation, and avoid the need to manifest all of those rows in memory at the same time.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
CALL {
    WITH movie
    MATCH (movie)<-[:ACTED_IN]-(p:Person)
    RETURN collect(p) as actors
}
RETURN count(*)
This one should be more memory-efficient.
Remember that subqueries are executed per row. And due to the MATCH just before the subquery, we have a row per movie.
The MATCH and the aggregation happens within the subquery, so per collect(), it’s only considering the paths for a single movie at a time. That means each collect() is only being applied over 10 input rows (because of 10 actors per movie), so the results for a single row will be available very quickly.
Note that this is a tradeoff: instead of performing a single collect() aggregation applied to 1 million rows, we are using subqueries to break down the work at the movie level. Because we have 1 million movies, we end up making 1 million subquery calls, each doing its own expansion and collect(), so in total collect() gets called 1 million times, but each only needs to run on a tiny set of data.
We can execute the subquery for each input row, perform the aggregation on this limited scope, output the result, and move on to the next row. The memory we used during execution of that row is all eligible for garbage collection, and doesn’t need to be kept in the heap as the subsequent rows are processed.
First let’s check the plan for this query:
Note that we still see the eager aggregation for the collect(), but it’s feeding into an Apply operation, this shows that the scope of the aggregation is only for the item that it is being applied to, which will be each movie node.
Let’s try running it. I’ll omit the actual query result, since we know that will still be 1 million, but let’s check the timing:
None
Copy to Clipboard
Started streaming 1 records after 1 ms and completed after 5542 ms.
Repeated runs vary a bit, but we usually end up between 4 and 6 seconds. That’s a nice improvement over the 15 seconds from the original query.
What about GC pauses in the debug log? Your milage may vary, but even after repeating the query execution several times, I didn’t see any GCs being logged.
This shows that aggregations over large number of rows at once can be memory intensive, and you can often avoid this and the resulting GC pauses via clever application of subqueries to narrow the scope of your aggregations (provided that doing so is correct for your use case).
Pattern comprehension is similar to a collect() called within a subquery
Pattern comprehensions can be used for similar effect, and have been available since Neo4j 3.1.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WITH movie, [(movie)<-[:ACTED_IN]-(p:Person) | p] as actors
RETURN count(*)
Pattern comprehensions are most like OPTIONAL MATCH followed by collect(), but similar to subqueries, they are executed per row. Even the EXPLAIN plan is similar:
Note that the line of execution with the collect() eager aggregation feeds into a ConditionalApply this time, which is a variant of Apply, meaning the right hand side is executing in a nested loop, which is also the scope for those operations.
How does it perform?
None
Copy to Clipboard
Started streaming 1 records after 1 ms and completed after 4539 ms.
Repeated runs fall between 4 and 6 seconds, so about the same as the version with the subquery. Likewise, we see no GCs in the debug log.
So as far as efficiency goes, both in timing and memory, pattern comprehensions are about the same as using subqueries.
While this is more concise than using subqueries, and can often be more versatile (you can use several pattern comprehensions within a single WITH clause), these are only used for collecting results. Though you could get the size() of the resulting list as an equivalent of a count(), you can’t use this for any other kind of aggregation.
Also, pattern comprehensions do not yet allow sorting, skipping, or limiting of the list results, all of which can be freely used if using subqueries instead.
APOC Procedures can substitute for subqueries
If you’re not on Neo4j 4.1.x or higher, there are some procedures in APOC that act as subqueries for the same effect.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
CALL apoc.cypher.run(""
    WITH movie
    MATCH (movie)<-[:ACTED_IN]-(p:Person)
    RETURN collect(p) as actors"", {movie:movie}) YIELD value
WITH movie, value.actors as actors
RETURN count(*)
Procedures, like subqueries, execute per row, so the collect() aggregation is similarly scoped only to the rows matched within that particular call.
Since there are 1 million movies, there will be a total of 1 million apoc.cypher.run() calls, each one doing its own MATCH and small collect().
We’re going to omit the plan for this one, because it won’t show anything interesting. We would see a procedure call operation, but since the meat of the query is in the form of a query string, the planner has no ability to evaluate it, so it won’t show up in the plan.
We could run an EXPLAIN of the copy/pasted query string separately, with a few small modifications so it will compile, but we’ve already seen a plan like this, with the collect() aggregation. The only differences is that this plan will be planned and executed as an entirely separate transaction, whose reults will be yielded to the transaction for this query. Let’s see how it does:
None
Copy to Clipboard
Started streaming 1 records after 1 ms and completed after 136441 ms.
Whoa, what happened here? The time spiked super high, at around 2 minutes. Why did this happen?
This APOC procedure creates and executes the query as a new transaction, as opposed to native subqueries which still execute within the same single transaction. This means that we’re actually executing 1 million separate transactions via APOC with this approach, and that has a cost in terms of setup and execution.
Why would we ever consider this approach, if it can be so costly timewise when run over so many rows? Because we still see no GC pauses in the debug log.
If GCs and out of heap are issues for your query as a result of an aggregation like this, and if you aren’t running a high enough version to use native subqueries, and if the use case doesn’t let you use pattern comprehensions, then this approach with certain APOC procs may let you avoid those GCs and heap pressure, but possibly at a cost of time.
As always, perform your own timing over your data to test.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-display-the-nodes-with-the-most-properties;"How do I display the nodes with the most properties
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
To display the nodes with the most properties defined, run the following Cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n)
RETURN labels(n), keys(n), size(keys(n)), count(*)
ORDER BY size(keys(n)) DESC
Representative output is similar to:
labels(n) keys(n) size(keys(n)) count(*)
[Movie]
[TotalRevenue, year_of_release, name, id]
4
1
[Movie]
[TotalRevenue, name, id]
3
2
[Artist]
[name, year]
2
4
The first row of output indicates that there is a Label named Movie, which has 4 properties (TotalRevenue, year_of_release, name, id) and there is 1 node defined with that Label and those properties.
The second row of output indicates that there is a Label named Movie which has 3 properties (TotalRevenue, name, id) and there are 2 nodes defined as such.
The third row of output indicates that there is a Label named Artists which has 2 properties (name, year) and there are 4 nodes defined as such.
Was this page helpful?"
https://neo4j.com/developer/kb/cross-product-cypher-queries-will-not-perform-well;"Cross Product Cypher queries will not perform well
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher performance
Just like SQL, if you do not properly connect the parts of your query, it will result in a cross (cartesian) product, which is seldom what you want. Take the following example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person), (m:Movie)
RETURN p, m;
In Cypher, what happens is that p contains all of the nodes in the graph with the :Person label, and m contains all of the nodes in the graph with the :Movie label. Returning both of these results in a combination of each node p being returned with each node m, like so:
If there are three nodes with label Person:
Neo,
Trinity, and
Morpheus
and three nodes with label Movie:
The Matrix,
The Matrix Reloaded, and
The Matrix Revolutions
The result of the above Cypher would be:
p m
Neo
The Matrix
Neo
The Matrix Reloaded
Neo
The Matrix Revolutions
Trinity
The Matrix
Trinity
The Matrix Reloaded
Trinity
The Matrix Revolutions
Morpheus
The Matrix
Morpheus
The Matrix Reloaded
Morpheus
The Matrix Revolutions
Keep in mind, this is a simple example, so the result set is small. With a production size graph, this would be a very large, potentially memory intensive query.
In general, inadvertent cross products happen in more complex queries. They are common in queries with many WITH clauses, and a close look at the query is needed to flush out the issue. By following general performance best practices, this can easily be avoided. Be as specific with your query as possible, make sure to use identifiers to properly tie parts of the query together, and only return the data you need. And profile your slow queries so that you can see where the time and effort is spent.
From Neo4j 2.3 on there is a warning issued in Neo4j browser or if you run your query with EXPLAIN that highlights this issue.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-view-the-column-headers-of-a-csv-file-with-load-csv;"How do I view the column headers of a CSV file with LOAD CSV
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags load-csv
If one has a CSV file with the following content
Csv
Copy to Clipboard
id,name,dob,addr1,addr2,city,state,country
1,Joe Smith,04/23/1971,121 Main Street,San Mateo,CA,USA
2,Bill Williams,09/21/2008,43 Overlook St,San Mateo,CA, USA
and one simply wants to run a LOAD CSV command to have the column headers returned, the following should suffice
Cypher
Copy to Clipboard
Run in Neo4j Browser
load csv with headers from 'file:///test.csv' as row with row limit 1 return keys(row);
which will return output similar to
+---------------------------------------------------------------------+
| keys(row)                                                           |
+---------------------------------------------------------------------+
| [""country"", ""addr2"", ""city"", ""addr1"", ""dob"", ""name"", ""state"", ""id""] |
+---------------------------------------------------------------------+
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-neo4j-query-plan-caching;"Understanding Neo4j Query Plan Caching
Author Dana Canzano Applicable versions 2.3 Tags cypher configuration performance
This article is based on the behavior of Neo4j 2.3.2. Query plan caching is governed by three parameters, as defined in the conf/neo4j.properties file, which are detailed here.
The three parameters which govern whether a Cypher statement is planned/replanned are:
query_cache_size
dbms.cypher.min_replan_interval
dbms.cypher.statistics_divergence_threshold
query_cache_size - Defaults to 1000 and represents the number of query plans recorded in the cache. For example, if you restarted Neo4j and ran 1001 unique Cypher statements, each of these statements would be planned and the last 1000 would be recorded in the query plan cache. If you then re-ran the 1st Cypher statement it would be replanned since it is no longer in the query cache, as only Cypher statements 2 through 1001 are currently in the cache.
dbms.cypher.min_replan_interval - Defaults to 1 second and describes the amount of time a Cypher statement will exist in the cache before it is replanned. For example, if a Cypher statement is planned at 09:02:00 and the dbms.cypher.min_replan_interval was defined to be 5 seconds, then resubmitting the same Cypher statement at 09:02:01 would not result in replanning. Not until 09:02:06 would the Cypher statement be eligible for replanning.
dbms.cypher.statistics_divergence_threshold - Defaults to 0.5 (value to be between 0 and 1) and describes the percentage change of statistics for the objects related to the Cypher that would force a replan. For example, if more than 50% of the nodes with label Movie were changed, then running a Cypher statement involving this label would result in a replan. However running a Cypher statement that did not involve the label Movie would not result in a replan.
Also relative to query cache you should be aware of the following:
If there are any schema changes, either by way of addition/removal of indexes or constraints, all query plans are immediately invalidated.
Cypher supports querying with parameters. This means developers don’t have to resort to string building to create a query.
In addition to that, it also makes caching of execution plans much easier for Cypher.
More details are described here.
Additionally, if you should see in the graph.db/messages.log a message similar to:
2016-03-08 09:43:16.854+0000 INFO [o.n.c.i.ServerExecutionEngine] Discarded stale query from the query cache: CYPHER 2.3 match n return n ... ... ...
this indicates a plan which was previously in the query plan cache and has since been replanned. This message would not be encountered if the query plan had never been generated previously.
For this message to occur, the following conditions must be met:
a) At least one transaction has to happen in between seeing the query again
b) At least dbms.cypher.min_replan_interval seconds must have passed
c) More than dbms.cypher.statistics_divergence_threshold percent of the statistics used by the query must have changed (edited)
For example, to generate the above message one could define:
Properties
Copy to Clipboard
dbms.cypher.min_replan_interval=0s
dbms.cypher.statistics_divergence_threshold=0
If you then issue 2 Cypher statements, X and Y, in the following order:
statement 1: X
statement 2: Y
statement 3: X
and Y modifies the statistics used by X, then we will see the message above in the messages.log.
For example, if statement X is MATCH n RETURN n and statement Y is CREATE (), then:
statement 1 results in X being placed in the query cache
statement 2 results in Y being placed in the query cache
statement 3 will replan statement X since more
than dbms.cypher.min_replan_interval has elapsed and statement Y changed the statistics used by statement X
Was this page helpful?"
https://neo4j.com/developer/kb/working-with-streaks-in-cypher;"Working with streaks in Cypher
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher apoc
When using Cypher for data analysis, you might have a problem where you need to identify or filter based upon some kind of streak.
For example, for a sports graph, you might want to know the maximum number of consecutive wins or losses for a team.
In such a query, you’ve probably gotten to the point where your data is ordered and in a list, but you need to figure out how to get streak information from the list.
Using APOC to break up a list into consecutive streaks
APOC Procedures has rich helper functions and procedures that let you query and manipulate collections and maps in all kinds of interesting ways.
For this particular kind of problem, the collection procedure apoc.coll.split() will provide the quickest and easiest way to derive streak data.
This procedure takes a list as input as well as a delimiter value, and splits around the delimiter values to provide the sublists.
As an example, we’ll use a literal list of boolean values symbolizing wins (true) vs losses (false), then split around the losses to get the lists of consecutive wins:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH [true, false, true, false, true, true, true, true, false, false, false, true, true] as games
CALL apoc.coll.split(games, false) YIELD value
RETURN value
The output looks like this:
╒═════════════════════╕
│""value""              │
╞═════════════════════╡
│[true]               │
├─────────────────────┤
│[true]               │
├─────────────────────┤
│[true,true,true,true]│
├─────────────────────┤
│[true,true]          │
└─────────────────────┘
We can instead filter to get the maximum win streak:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH [true, false, true, false, true, true, true, true, false, false, false, true, true] as games
CALL apoc.coll.split(games, false) YIELD value as winStreak
RETURN max(size(winStreak)) as longestWinStreak
This gives us a longest win streak of 4.
A more complex example
While actual graph data and queries aren’t usually so simple, we can often simplify it in the query.
Let’s use a graph like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
(:Team {name:string})-[:PLAYED {won:boolean}]->(:Game {date:date})
Here’s a pared down example dataset you can test out yourself:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (p:Team{name:'Paris St-Germain'}) ,
(d:Team{name:'Dijon'}),
(b:Team{name:'Bordeaux'}),
(a:Team{name:'Amiens SC'}),
(o:Team{name:'Olympique Lyonnais'}),
(n:Team{name:'Nantes'}),
(mp:Team{name:'Montpellier'}),
(l:Team{name:'Lille'}),
(mo:Team{name:'Monaco'}),
(se:Team{name:'Saint-Etienne'})

CREATE (p)-[:PLAYED {won:true }]->(:Game {date:date('2020-02-29')})<-[:PLAYED {won: false}]-(d),
(p)-[:PLAYED {won:true }]->(:Game {date:date('2020-02-23')})<-[:PLAYED {won: false}]-(b),
(p)-[:PLAYED {won:false }]->(:Game {date:date('2020-02-15')})<-[:PLAYED {won: true}]-(a),
(p)-[:PLAYED {won:true }]->(:Game {date:date('2020-09-02')})<-[:PLAYED {won: false}]-(o),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(n),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(mp),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(l),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(mo),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(a),
(p)-[: {won: }]->(: {date:date()})<-[: {won: }]-(se)
View all (6 more lines)
This dataset centers on Paris St-Germain, it doesn’t have data about games played between the other teams.
We can use the same approach as in our simpler example from before to calculate each team’s longest consecutive win streak and order and limit the output accordingly:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (team:Team)-[r:PLAYED]->(game:Game)
WITH team, r, game
ORDER BY game.date ASC
WITH team, collect(r.won) as results
CALL apoc.coll.split(results, false) YIELD value as winStreak
WITH team, max(size(winStreak)) as longestStreak
RETURN team.name as teamName, longestStreak
ORDER BY longestStreak DESC
LIMIT 3
Our results are:
╒══════════════════╤═══════════════╕
│""teamName""        │""longestStreak""│
╞══════════════════╪═══════════════╡
│""Paris St-Germain""│4              │
├──────────────────┼───────────────┤
│""Amiens SC""       │2              │
└──────────────────┴───────────────┘
We only see two results here because in our dataset none of the other teams won any games, so there’s no streak to report.
What if we also want the game data?
While this gets us the top 3 teams by their longest streak of wins, we do lose the game data along the way. What if we want to know which teams they beat for each game in that single longest streak?
We can preserve this data with a clever use of CASE. Instead of just using collect(r.won) as results, we can use CASE to project some custom data in the event that the team won, but only output false when the team lost. This still allows us a common value to split around to find streaks, but each element of the streak is now as rich as we need it to be.
That said, we do need to adjust how we calculate the longestStreak, as the max() function will otherwise cause us to lose the streak data that we still want at the end.
Here’s a modefied query that should do the trick:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (team:Team)-[r:PLAYED]->(game:Game)<-[:PLAYED]-(opponent)
WITH team, r, game, opponent
ORDER BY game.date ASC
WITH team, collect(CASE WHEN r.won THEN opponent ELSE false END) as results
CALL apoc.coll.split(results, false) YIELD value as winStreak
WITH team, winStreak, size(winStreak) as streakLength
ORDER BY streakLength DESC
WITH team, collect(winStreak)[0] as streak, max(streakLength) as longestStreak
WITH team, longestStreak, streak
ORDER BY longestStreak DESC
LIMIT 3
RETURN team.name as teamName, longestStreak, [opponent IN streak | opponent.name] as beat
And the query results:
╒══════════════════╤═══════════════╤══════════════════════════════════════════════════╕
│""teamName""        │""longestStreak""│""beat""                                            │
╞══════════════════╪═══════════════╪══════════════════════════════════════════════════╡
│""Paris St-Germain""│4              │[""Bordeaux"",""Dijon"",""Nantes"",""Olympique Lyonnais""]│
├──────────────────┼───────────────┼──────────────────────────────────────────────────┤
│""Amiens SC""       │2              │[""Paris St-Germain"",""Paris St-Germain""]           │
└──────────────────┴───────────────┴──────────────────────────────────────────────────┘
Note the use of CASE on a win to do a custom projection of the opponent faced in the game:
Cypher
Copy to Clipboard
Run in Neo4j Browser
collect(CASE WHEN r.won THEN opponent ELSE false END) as results
Since we need to preserve the streak data, we have to do a sort, picking the top streak by length by collecting and only keeping the streak at the head of the list.
Lastly, we leave property projection until the end, after we’ve limited to the top 3 teams by their longest streaks so we avoid property access for data will only be filtered out.
One last helper function to simplify
It’s a pain to have to add our own ordering and take the top of the collection in the middle of that query. The simplicity we had when we only needed the max() on the streakLength was nice.
Fortunately there is a relatively new APOC aggregation function that can help us keep that simplicity and avoid doing our own sorting and collecting.
apoc.coll.maxItems() (there’s an apoc.coll.minItems() too) lets us take the max of some value, but keep the items associated with that maximum value.
Let’s add that to the query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (team:Team)-[r:PLAYED]->(game:Game)<-[:PLAYED]-(opponent)
WITH team, r, game, opponent
ORDER BY game.date ASC
WITH team, collect(CASE WHEN r.won THEN opponent ELSE false END) as results
CALL apoc.coll.split(results, false) YIELD value as winStreak
WITH team, apoc.agg.maxItems(winStreak, size(winStreak), 1) as longestStreakData
WITH team, longestStreakData.items[0] as streak, longestStreakData.value as longestStreak
ORDER BY longestStreak DESC
LIMIT 3
RETURN team.name as teamName, longestStreak, [opponent IN streak | opponent.name] as beat
The results remain the same as before.
The maxItems() aggregation function call is here:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH team, apoc.agg.maxItems(winStreak, size(winStreak), 1) as longestStreakData
This takes the item, the value (for which we will want the max), and optionally a limit to the number of items with the same value. It is possible that a single team may have multiple win streaks of the same length, but for our case we’re only interested in the first we find, so we’ll limit it to one streak per team and disregard any others.
Note that we do still need to take the head of the list on the next line
Cypher
Copy to Clipboard
Run in Neo4j Browser
longestStreakData.items[0] as streak
This is because as we just mentioned, the function has the capability of getting all (or some optionally limited) number of items that share the same max value (other streaks of the same length), so items from the result is a list type, and we only want the single value present, which is our streak of opponents we beat.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-set-a-breakpoint-in-a-cypher-statement-for-further-analysis;"How do I set a breakpoint in a Cypher statement for further analysis
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags debug
If you wish to set a 'breakpoint' in a Cypher statement so as to perform further analysis (i.e. see how many locks are taken, memory utilization) one can add a call to apoc.utils.sleep(XXX) which will result in the query sleeping for XXXX msec.
For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (n:Movie {title:'The Matrix'})
set n.production_company='Warner Brothers'
with n call apoc.util.sleep(10000) return n;
will run the MERGE statement with its 'set' operation and then 'pause' for 10000 miliseconds (i.e. 10 seconds) and then return.
Further one could run
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (n:Movie {title:'The Matrix'})
with n call apoc.util.sleep(10000)
set n.production_company='Warner Brothers' return n;
which will run the MERGE statement, then 'pause' for 10000 miliseconds and then run its 'set' operation on the property.
During these 10000 miliseconds one could perform any other further analysis, i.e. call dbms.listQueries() or call dbms.showActiveLocks()
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-use-the-debug-log-parser-script;"How to Use the Debug Log Parser Script
Author Shawn Tozeski Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags debug
For analysis of the Neo4j debug.log, read this guide for using the debugInfo.sh parser script.
What is the this script?
The debug.log is quite verbose and contains a lot of useful information for understanding the health and behavior of a Neo4j server instance or cluster. To assist in enabling support teams to more quickly and efficiently understand if the Neo4j server is health or not, Neo4j Support has produced debugInfo.sh script to parse a debug.log file into a condensed, usable summary of information.
How do I use it?
First, download the script and helper files here.
To run the debugInfo.sh script on Linux systems, follow these steps:
As the neo4j user:
Copy the debugInfo.sh script and the debugLogErrorsFile.neo4j and debugLogExcludeFile.neo4j files to $NEO4J_HOME/logs
Review and modify the script User variables as required.
The default log location is the working directory where the script is run from. The default output file is called debugInfo.txt.
Run chmod 750 debugInfo.sh to set execute permissions on the script.
Script usage:
Shell
Copy to Clipboard
  $ ./debugInfo.sh debug.log
NOTE 1: The debugInfo.sh script will accept one input, which is the name of the Neo4j debug log to process.
NOTE 2: The debugLogErrorsFile.neo4j file is used to parse specific error values in the debug log. This file can be modified as required. The debugLogExcludeFile.neo4j file is used to exclude specific error values from the debug log error parsing. This file can be modified as required.
NOTE 3: The debugInfo.sh script will output results to the screen and also to the default output file called debugInfo.txt in the working directory.
To run the script from an alternative location, just provide the full path to the debug.log to analyze:
Shell
Copy to Clipboard
$ pwd
/home/neo4j

$ ls -la
total 40
drwxrwxr-x   2 neo4j neo4j   112 Dec 19 13:23 .
drwx------. 13 neo4j neo4j  4096 Dec 13 17:01 ..
-rwx------   1 neo4j neo4j 17521 Dec 13 17:04 debugInfo.sh
-rw-rw-r--   1 neo4j neo4j   427 Dec 13 16:47 debugLogErrorsFile.neo4j
-rw-rw-r--   1 neo4j neo4j  1671 Dec 13 16:51 debugLogExcludeFile.neo4j

$ ./debugInfo.sh debug.log $NEO4J_HOME/logs/debug.log
NOTE 1: The script will parse the debug.log from the location provided and output results to the screen and also to the default output file called debugInfo.txt in the working directory.
Was this page helpful?"
https://neo4j.com/developer/kb/why-where-clause-does-not-filter;"Why doesn’t my WHERE clause work?
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher where
It can be frustrating when it seems like a WHERE clause isn’t working. You can use these approaches to figure out what’s wrong.
Check for WHERE clauses following OPTIONAL MATCH
WHERE clauses can’t be used on their own, they are always paired with a MATCH, WITH, or OPTIONAL MATCH, and it is this pairing that defines behavior when a WHERE clause evaluates to false.
WITH … WHERE and MATCH … WHERE apply the WHERE clause to all result rows, and this is usually how most users expect WHERE to behave, removing rows when the WHERE evaluates to false.
However, OPTIONAL MATCH … WHERE behaves differently because OPTIONAL MATCH never removes rows. When using OPTIONAL MATCH, if the given pattern does not match, or its WHERE clause evalutes to false, then newly-introduced variables in the pattern become null for the given row. Rows are never removed, and existing variables remain unchanged, which can give the impression that the WHERE clause isn’t working at all, when the real problem is that it’s being applied to the wrong thing.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
OPTIONAL MATCH (m)<-[:WORKED_ON]-(a:Animator)
WHERE m.releaseYear > 1999 AND a IS NOT NULL
RETURN m, collect(a) as animators
In the above example, it may look like this is a query to get movies released after 1999 and animators on the movie where an animator worked on the movie, but that’s incorrect. The WHERE clause will only affect the OPTIONAL MATCH, so all movies will be returned, none will be filtered out, but the animators collection will only be populated on movies released after 1999.
To fix the query, we need to move the WHERE elsewhere so it’s associated with a MATCH or a WITH so it filters out rows as required:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
OPTIONAL MATCH (m)<-[:WORKED_ON]-(a:Animator)
WITH m, a
WHERE m.releaseYear > 1999 AND a IS NOT NULL
RETURN m, collect(a) as animators
Check for misspellings or case mismatches in your WHERE clause
Typos and misspelled elements can easily throw off WHERE clauses, and this includes mismatches in case.
Node labels, relationship types, variables, and both property keys and values are all case-sensitive, so make sure you’re being consistent and correct in your cases.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)
WHERE NOT (m)<-[:worked_on]-(a:animator) AND m.ReleaseYear > 1999
RETURN m
The above query doesn’t have any spelling errors, but it has different case in the relationship type, node label, and property key than what’s actually in the graph, which will throw off the WHERE clause significantly.
Check if an assumed numeric property is actually a string
In circumstances where numeric comparisons or matches seem to be failing, it helps to make sure the properties you’re comparing against are actually numbers.
In text result views, string values will have quotes around them, while numeric values will not.
Be especially mindful during imports, especially CSV imports, as all values are interpreted as strings. You’ll need to use toInteger() and toFloat() to cast strings to numeric values, to avoid this problem.
Check for leading or trailing whitespace in property keys and values
Leading or trailing whitespace in properties can make it seem like WHERE clauses aren’t working, and this is often an issue with the data in the graph rather than the query itself.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person)
WHERE p.name = 'Keanu Reeves'
RETURN m
The above query looks fine, and may be completely correct. However, if the node’s name property actually happens to be ""Keanu Reeves "" with a trailing space, the query won’t work.
It’s often a good idea to double-check expected string values on your nodes and relationships to see if unexpected whitespace is the problem. If using the Neo4j browser, the text results view is usually the best way to easily detect extra whitespace. Querying using STARTS WITH, ENDS WITH, or CONTAINS can also help test assumptions about your property values.
Extra whitespace in property keys is rarer, but can happen, such as when importing data from badly formatted files.
For example, if we tried to import a csv file with the following header:
nickName, firstName,lastName
There is some leading whitespace before firstName, and trailing whitespace after lastName. When imported, the property keys themselves will include leading and trailing whitespace, so the actual property keys become ""nickName"", "" firstName"" and ""lastName "", and may quickly become a source of confusion, if undetected.
Was this page helpful?"
https://neo4j.com/developer/kb/limiting-match-results-per-row;"Limiting MATCH results per row
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher limit
Since LIMIT applies to the total number of rows of the query, it can’t be used in cases when matching from multiple nodes where the limit must be on match results per row.
Take an example case using the Movies database.
If you needed a query to get all the actors from The Matrix, and for each actor, get 3 movies that actor has acted in, a first (incorrect) attempt might look like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
                   MATCH (p)-[:ACTED_IN]->(m)
                   RETURN p, m LIMIT 3
The above query won’t return the desired results. The LIMIT will instead make the query return only 3 rows total.
Here are some solutions to apply a limit to match results per-row
Use LIMIT within a subquery in 4.1+
Neo4j 4.1 introduced correlated subqueries, letting us perform a subquery using variables present mid-query.
Since subqueries execute per row, we can perform the MATCH and apply the LIMIT within the subquery, giving us the easiest means of limiting match results per row.
This requires the use of WITH as the first clause within the subquery CALL block, for the purpose of importing variables to the subquery.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
CALL {
    WITH p
    MATCH (p)-[:ACTED_IN]->(m)
    RETURN m
    LIMIT 3
}

RETURN p, m
This will correctly return all actors in the matrix and up to 3 of the movies they have acted in.
If we wanted each actor only once, with the collection of up to 3 movies per actor, we could collect those movies within the subquery after the limit:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
CALL {
    WITH p
    MATCH (p)-[:ACTED_IN]->(m)
    WITH m
    LIMIT 3
    RETURN collect(m) as movies
}

RETURN p, movies
Be aware that this WITH import has some special restrictions that do not normally apply to WITH usage:
You may only include variables from the outer query and no others.
You cannot perform calculations, aggregations, or introduction of new variables in the initial WITH.
You cannot alias any variables within this initial WITH.
You cannot follow the initial WITH with a WHERE clause for filtering.
If you try any of these, you will be met with some kind of error, such as:
Importing WITH should consist only of simple references to outside variables. Aliasing or expressions are not supported.
or more cryptically, if you try to use a WHERE clause after the initial WITH
Variable `x` not defined
(where the variable is the first one present in the WITH clause)
You can get around all of these restrictions by simply introducing an additional WITH clause after the importing WITH, like so:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
CALL {
    WITH p
    WITH p as actor
    MATCH (actor)-[:ACTED_IN]->(m)
    RETURN m
    LIMIT 3
}

RETURN p, m
This shows how we can alias (or filter, if we wanted) the imported variables, but not on the initial import WITH itself.
For 4.0.x and earlier
For earlier versions, native correlated subqueries are not available, so other workarounds must be used.
Take the interested slice of a collection
One common solution is to collect() and take the interested slice:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
MATCH (p)-[:ACTED_IN]->(m)
RETURN p, collect(m)[..3] AS movies
In Neo4j 3.1.x and newer you can use pattern comprehension as a shorthand approach:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
RETURN p, [(p)-[:ACTED_IN]->(m) | m][..3] as movies
If only one element in the collection is needed, the head() function can be used to get the first element from the pattern comprehension:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
RETURN p, head([(p)-[:ACTED_IN]->(m) | m]) as movie
While this works when there are few relationships per node, it may become infeasible on supernodes with larger numbers of relationships, as it must expand all :ACTED_IN relationships before collecting.
Use apoc.cypher.run() to execute a limited subquery
Neo4j doesn’t currently offer native subquery support aside from pattern comprehension, but even those don’t support LIMIT.
However, in Neo4j 3.0.x and newer, using APOC Procedures, you can use apoc.cypher.run() to execute a subquery with a LIMIT, which performs the way we want since it executes per-row.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
CALL apoc.cypher.run('
 WITH {p} AS p
 MATCH (p)-[:ACTED_IN]->(m)
 RETURN m LIMIT 3',
 {p:p}) YIELD value
RETURN p, value.m AS movie
This approach is efficient since by using LIMIT we don’t have to pay the cost of expanding all :ACTED_IN relationships, we only need to expand 3 per row.
Use APOC path expander using end node or termination filters and limit param
With Neo4j 3.1.3 and higher, and APOC Procedures 3.1.3.6 and higher, you can use use new path expander features to limit expansion to certain nodes.
The limit param is only usable with path expander procedures that take a config map, and only when using the end node (>) or termination label filters (/):
apoc.path.expandConfig()
apoc.path.subgraphNodes()
apoc.path.subgraphAll()
apoc.path.spanningTree()
Using this approach, the query becomes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Movie{title:'The Matrix'})<-[:ACTED_IN]-(p:Person)
CALL apoc.path.subgraphNodes(p, {relationshipFilter:'ACTED_IN>', labelFilter:'/Movie', limit:3}) YIELD node
RETURN p, node as movie
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-implement-a-primary-key-property-for-a-label;"How to implement a primary key property for a label
Author Dana Canzano Applicable versions 3.4 3.5 Tags cypher
Commencing with Neo4j 2.3.x it is possible to create the equivalent of a primary key on a property of a label. For example the following Cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE CONSTRAINT ON (book:Book) ASSERT book.isbn IS UNIQUE
CREATE CONSTRAINT ON (book:Book) ASSERT exists(book.isbn)
will create two constraints on the property isbn of nodes with label Book and ensure that when a new Book node is created, its isbn must be defined, and that it must be unique across all nodes with the Book label.
Property existence constraints are only available in the Neo4j Enterprise Edition. Databases with property existence constraints cannot be opened using Neo4j Community Edition.
Was this page helpful?"
https://neo4j.com/developer/kb/creating-and-working-with-linked-lists;"Creating and working with linked lists in Cypher
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster
At some point when working with a graph, you may want to create a linked list out of some nodes.
If each of the nodes to be linked has its own variable, this is easy, you just do a CREATE of the pattern using the node variables:
Cypher
Copy to Clipboard
Run in Neo4j Browser
// assume a, b, and c were previously matched and in scope
CREATE (a)-[:REL]->(b)-[:REL]->(c)
You can of course break up a larger pattern into smaller ones, and use MERGE on the smaller patterns if needed, when there’s a possibility that a part of this linked pattern already exists.
However, when we don’t have separate variables for the nodes in question, such as if all of the nodes to link are under the same variable, or within a list, it’s not obvious how to link them.
Using apoc.nodes.link() to link together nodes in a list
The easiest approach is to leverage apoc.nodes.link() from APOC Procedures, passing the collection of nodes and the relationship type to use. Relationships will be created of the given type, outgoing between each of the nodes sequentially.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p
ORDER BY p.name ASC
LIMIT 5
WITH collect(p) as persons
CALL apoc.nodes.link(persons, 'KNOWS')
RETURN persons
This will take the first 5 :Person nodes by name and link them together as a 5-node chain in the given order.
Linking nodes without APOC
If you don’t have APOC available, you can use just Cypher, but this requires a tricky triple-FOREACH syntax:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p
ORDER BY p.name ASC
LIMIT 5
WITH collect(p) as persons
FOREACH (i in range(0, size(persons) - 2) |
 FOREACH (node1 in [persons[i]] |
  FOREACH (node2 in [persons[i+1]] |
   CREATE (node1)-[:KNOWS]->(node2))))
The outer FOREACH is to only apply this up to the second-to-last node, since the last node won’t need an outgoing relationship from it.
The other two FOREACHes look more complex, but these are just workarounds so we can have a variable to use for each of the nodes we want to link together, since we can’t use indexed collection access within our CREATE like so: CREATE (persons[i])-[:KNOWS]→(persons[i+1]), and we can’t use WITH within a FOREACH to manifest a variable for us to use. If you take another look at these two FOREACHes, you’ll see that all they’re doing is getting the node in the persons list at position i and the node at position i+1 and allowing them to be addressed as variables node1 and node2.
Alternately we could use UNWIND in place of FOREACH, allowing us to alias the nodes we want to link together, but in a more complex query with high cardinality this may not be a recommended approach:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WITH p
ORDER BY p.name ASC
LIMIT 5
WITH collect(p) as persons
UNWIND range(0, size(persons) - 2) as index
WITH persons[index] as node1, persons[index+1] as node2
CREATE (node1)-[:KNOWS]->(node2)
Mutual exclusion when altering a linked list
If you have a linked list in your graph, you may at some point want to alter it, appending or removing at any point in the list.
If there is any chance that list alteration queries can execute at the same time, it’s important to make sure you use appropriate locking to ensure mutual exclusion when updating and avoid race conditions which could compromise your linked list structure and correctness.
It’s often useful to have a 0th node at the head of a linked list which is always present, but doesn’t represent an actual entry in the list. This 0th node can be locked upon first for any query that needs to alter the list.
To lock on a node, you can either write a property or label on it, or use an APOC locking procedure.
As an example, let’s say we have a to-do list linked to a person, and we want to append to this list. We have a :TODO_LIST node as our 0th node linked to the person.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person {name:'Keanu Reeves'})-[:TO_DO]->(listHead:TO_DO_LIST)
CALL apoc.lock.nodes([listHead])
MATCH (listHead)-[:NEXT*0..]->(end)
WHERE NOT (end)-[:NEXT]->()
CREATE (end)-[:NEXT]->(new:Event {name:'Punch Agent Smith'})
By acquiring a lock on the 0th node, listHead, BEFORE we match into the list itself we ensure that we avoid any race conditions by concurrently executing queries that can alter the list underneath us during execution (the lock is released when the transaction commits).
For example, without this locking, it’s possible that between the time we have matched to the end node, but before we CREATE the new event at the end, a concurrent query adds a different event at the end, and we could end up with a list that is no longer a list since it branches at what used to be the end node, which now has two children.
Using a 0th node to lock upon provides a consistent node to lock upon no matter if the list is empty or not, and provides a safe means to avoid race conditions from concurrent updates.
Was this page helpful?"
https://neo4j.com/developer/kb/a-significant-change-in-apoc-periodic-iterate-in-apoc-4-0;"A significant change in apoc.periodic.iterate() in apoc 4.0
Author Vivek Saran Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags apoc
In 3.5 an entity (node, relationship, path) could be acquired in one transaction and safely reused by another.
However, in 4.0 these entities do hold a reference to their originating transaction.
The problem might occur in any APOC calls that open new transactions, e.g. apoc.periodic.iterate (and couple more). Anything you hand over from the driving statement must be rebound in the action statement.
This means that we basically need to rebind entities that originate in a different transaction.
Rebinding means, doing a MATCH (n) WHERE id(n) = id(myKnownNode).
As an example, the following statement would work perfectly in 3.5.x:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate('MATCH (:Account)-[r:ASSOCIATED_WITH]->() RETURN r',
    'CALL apoc.do.case(.....) YIELD value RETURN value',
     {batchSize: 10000, parallel: false, iterateList: true});
But, in 4.0.x, the above statement will need to be modified as:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.periodic.iterate('MATCH (:Account)-[r:ASSOCIATED_WITH]->() RETURN id(r) as id',
    'MATCH ()-[r]->() WHERE id(r)=id CALL apoc.do.case(.....) YIELD value RETURN value',
    {batchSize: 10000, parallel: false, iterateList: true});
Note that in the first (outer statement), we changed RETURN r to RETURN id(r) as id.
In the second (inner statement), we inserted MATCH ()-[r]→() WHERE id(r)=id before the CALL apoc.do.case().
For other highly useful procedures from the APOC library, please refer to the APOC User Guide 4.0.
Was this page helpful?"
https://neo4j.com/labs/apoc/4.0/overview/apoc.util/apoc.util.sha512;"apoc.util.sha512
Contents
Signature
Input parameters
Function
apoc.util.sha512([values]) | computes the sha512 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Was this page helpful?"
https://neo4j.com/labs/apoc/4.0/overview/apoc.util/apoc.util.md5;"apoc.util.md5
Contents
Signature
Input parameters
Function
apoc.util.md5([values]) | computes the md5 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
More documentation of apoc.util.md5
Was this page helpful?"
https://neo4j.com/labs/apoc/4.0/overview/apoc.util/apoc.util.sha256;"apoc.util.sha256
Contents
Signature
Input parameters
Function
apoc.util.sha256([values]) | computes the sha256 of the concatenation of all string values of the list
Signature
None
Copy to Clipboard
apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)
Input parameters
Name Type Default
values
LIST? OF ANY?
null
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-aggregations-on-zero-rows;"Understanding aggregations on zero rows
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
Aggregations in Cypher can be tricky in some cases. Notably, when performing aggregation right after a MATCH where there are no matches, or after a filter operation that filters out all results. In some cases a query using aggregations in these situations may produce no results, which may be surprising for some users.
Aggregations can be successfully performed on zero rows, when all previous results have been filtered out, but there are some aspects of this behavior, and limitations in usage, that need to be understood in order to perform these aggregations properly and get correct results.
A refresh on rows, operators, and aggregations
Operators in Cypher produce rows, and they also execute per row. When there are no more rows (due to MATCH not finding matches, or WHERE clause filtering), then there is nothing left to execute upon, and remaining operations become no-op.
One big exception to this are aggregation functions, most often count() and collect().
These functions are allowed because situations exist where we may want to count something where there are 0 occurrences, so a count() of 0 makes sense:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.nonExistentProperty = 123
// after the WHERE, there are 0 rows
RETURN count(person) as count
// but when we apply the count(), we get a single row with 0
Likewise, we may want to collect() some things from matched paths when there are no paths, so an empty list makes sense:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE person.nonExistentProperty = 123
// after the WHERE, there are 0 rows
RETURN collect(person) as people
// but when we apply the collect(), we get a single row with []
Usage of either of these have an input of 0 rows and produce an output of a single row with the count of 0 or the empty list. And now that we have a row to work with, subsequent operations in the query can execute (if we used a WITH instead of a RETURN).
The other aggregation functions can produce similar results when run on 0 rows.
sum() produces an output of 0, stDev() and stDevP() produce an output of 0.0, while avg(), min(), max(), percentileDisc() and percentileCont() produce null.
When non-aggregation terms are present, you cannot aggregate on 0 rows
Aggregations only have meaning with respect to the non-aggregation terms present when the aggregation is performed.
When only aggregations are present, then the context of the aggregation is with respect to all rows.
When any other non-aggregation terms are present, then the aggregation is with respect to those combination of terms, AKA the grouping key.
So for example, in the following query snippet the count() aggregation is with respect to a person, it’s a count of the movies per person that acted in them:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)-[:ACTED_IN]->(movie:Movie)
WITH person, count(movie) as actedMovieCount
...
However this does require at least one row for the aggregation to work (we aggregate with respect to something).
But in situations where we drop to 0 rows, there is no grouping key (no data for one at least), and so Cypher does not allow the aggregation to take place, and rows remain at 0.
Let’s consider a case where we’re working with :Movie and :Person nodes. :Movie nodes have a title, but :Person nodes do not.
Let’s look at this query first:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (person:Person)
WHERE EXISTS(person.title)
WITH count(person) as personCount
MATCH (movie:Movie)
WHERE EXISTS(movie.title)
RETURN personCount, count(movie) as movieCount
This returns a personCount of 0, and a movieCount of 38.
Here’s the sequence of events:
:Person nodes were matched, but none have a title property. Rows go to 0.
Next we count() the person nodes, and since there is only the single aggregation term, this emits a single row with a personCount of 0, which is correct.
As we have a row to operate upon, the next MATCH can take place, and as all movies have the title property, what we get is a count of all movies, with respect to the earlier personCount entry. We get expected results.
But what if we changeup the order of this query? What happens then?
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WHERE EXISTS(movie.title)
WITH count(movie) as movieCount
MATCH (person:Person)
WHERE EXISTS(person.title)
WITH movieCount, count(person) as personCount
RETURN personCount, movieCount
We’ve swapped the order, so we match to and aggregate movies first, then match to and aggregate persons with respect to the earlier movieCount.
Our result is:
(no changes, no records)
So what happened here?
:Movie nodes were matched, and they all have the title property. Rows go to 38, one per movie.
Next we count() the movie nodes, which gives us a single row with a movieCount of 38.
Our next MATCH is to :Person nodes that have a title property. No such nodes exist, so our single row is filtered out. We have no rows! Our movieCount data is gone (it was stored in that single row) so we can’t reference it!
We attempt to aggregate, getting the count() of people, but we have a grouping key, movieCount. Whatever data we might have had in this previously is gone, lost when the row was filtered out. We can’t perform this aggregation since we have nothing to use for the grouping key (note that not having a grouping key is NOT the same as having a grouping key of null values). We can’t run the aggregation. We don’t output any rows.
Avoiding the problem by using OPTIONAL MATCH or pattern comprehensions
The problem happens when we aggregate with a grouping key when there are no rows present, so we can avoid the problem by avoiding going to 0 rows.
One way we can do this is to use an OPTIONAL MATCH when we know there may be no matches, yet want to continue the query. This won’t filter out rows, and our aggregation will emit expected results.
If we’re collecting results from an expansion, then we can use a pattern comprehension as a shortcut, as we’ll get an empty collection if the pattern in the comprehension doesn’t exist, again without filtering out the row.
Why not just default to null for the grouping key when we have 0 rows?
For some, the idea that we can’t aggregate when we have a grouping key but 0 rows doesn’t sit right. A common suggestion is: why not allow the aggregation (the same as if we didn’t have a grouping key) and set the grouping key values to null?
The short answer is that changing the data of what’s in scope to null in these circumstances can lead to unexpected and drastically wrong results, especially when the query is allowed to keep executing on this bad data. The resulting query results may not be sane.
For example, consider if we were using a variation on the earlier query to store some counts in a node for fast access later. We’ll fix up the property used (person.name instead of person.title), but let’s run this before we’ve added :Person nodes to our graph, we only have movie nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (movie:Movie)
WHERE EXISTS(movie.title)
WITH count(movie) as movieCount
MATCH (person:Person)
WHERE EXISTS(person.name)
WITH movieCount, count(person) as personCount
MERGE (count:CountTracker)
SET count.personCount = personCount, count.movieCount = movieCount
RETURN personCount, movieCount
Now we know from what we’ve covered that our rows will go to 0 when we match to :Person nodes, since there aren’t any in the graph yet, and that as a result our aggregation where we count(person) will fail and we’ll get 0 rows and nothing further in the query will be able to execute (no rows to execute upon).
But what if Cypher nulled out the grouping key instead and allowed the query to continue? Then movieCount would go to null, and personCount would go to 0. Whatever personCount had before (assuming it had anything before) would be removed, because setting a property to null is the same as removing it.
If this were a more complex query, consider the implications of having a value which you KNEW couldn’t possibly be null suddenly get changed to null. Usage of that property could have entirely unexpected results. You might end up erasing properties if you set a property to the now null value. You might be relying on comparisons on the value, and now because it’s a null the result of the comparison will be null (in Cypher inequalities with null result in null), and may propogate further depending on what you use that resulting value for.
Thankfully you wouldn’t run into trouble with a MATCH or a WHERE when comparing a property to null, since we require usage of IS NULL or IS NOT NULL for this check, using regular equality of a property value to null will always fail.
However, it should be clear that setting the grouping key to null can have negative and unexpected consequences, especially if the values are used to write into the graph. If we don’t return and inspect the output, it’s possible for bad data to have been written to the graph, and who knows when that would be detected.
For these reasons, we feel justified that it is more correct to stay at 0 rows in these situations than to suddenly and unexpectedly change variable values and let the query continue in a not-so-sane state.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-produce-an-inventory-of-statistics-on-nodes-relationships-properties;"How do I produce an inventory of statistics on nodes, relationships, properties
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
Using the following Cypher
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n) WHERE rand() <= 0.1
WITH labels(n) as labels, size(keys(n)) as props, size((n)--()) as degree
RETURN
DISTINCT labels,
count(*) AS NumofNodes,
avg(props) AS AvgNumOfPropPerNode,
min(props) AS MinNumPropPerNode,
max(props) AS MaxNumPropPerNode,
avg(degree) AS AvgNumOfRelationships,
min(degree) AS MinNumOfRelationships,
max(degree) AS MaxNumOfRelationships
will produce an 'inventory' of the nodes within the graph and statistics related to number of Nodes per label, average number of properties, minimum number of properties, maximum number of properties, average number of relationships, minimum number of relationships and maximum number of relationships. This Cypher can be used to help in the understanding in terms of performance and/or database growth.
This above Cypher does perform an entire graph traversal and then will 'sample' out 90% of the nodes by way of inclusion of 'rand()⇐ 0.1'. As a result the numbers returned are effectively a 10% sample of the graph.
With Neo4j 3.0, the above query is included as a Favorite within the browser and is defined under Data Profiling / What kind of nodes exist.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-debug-log-message-of-commits-found-after-last-check-point;"Explantion of debug.log message of Commits found after last checkpoint
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags backup transaction
When running backup for example
Shell
Copy to Clipboard
$ bin/neo4j-admin backup --backup-dir=/home/neo4j/backups/01172020/ --name=graph.db
you may observe in the output of said command detail similar to
2020-01-17 12:54:06.767+0000 INFO [o.n.b.i.BackupOutputMonitor] Finish receiving store file /home/neo4j/backups/backups/01172020/graph.db/temp-copy/schema/index/lucene_native-2.0/5/native-1.0/profiles/index-5.708254.cacheprof
2020-01-17 12:54:06.767+0000 INFO [o.n.b.i.BackupOutputMonitor] Start receiving store file /home/neo4j/backups/backups/01172020/graph.db/temp-copy/schema/index/lucene_native-2.0/5/string-1.0/profiles/index-5.708254.cacheprof
2020-01-17 12:54:06.767+0000 INFO [o.n.b.i.BackupOutputMonitor] Finish receiving store file /home/neo4j/backups/backups/01172020/graph.db/temp-copy/schema/index/lucene_native-2.0/5/string-1.0/profiles/index-5.708254.cacheprof
2020-01-17 12:54:06.767+0000 INFO [o.n.b.i.BackupOutputMonitor] Start receiving store file /home/neo4j/backups/backups/01172020/graph.db/temp-copy/neostore
2020-01-17 12:54:06.767+0000 INFO [o.n.b.i.BackupOutputMonitor] Finish receiving store file /home/neo4j/backups/backups/01172020/graph.db/temp-copy/neostore
2020-01-17 12:54:06.769+0000 INFO [o.n.b.i.BackupOutputMonitor] Finish receiving store files, took 9s 552ms
2020-01-17 12:54:06.869+0000 INFO [o.n.b.i.BackupOutputMonitor] Start recovering store
2020-01-17 12:59:34.411+0000 INFO [o.n.b.i.BackupOutputMonitor] Finish recovering store, took 5m 27s 542ms
2020-01-17 12:59:37.370+0000 INFO [o.n.b.i.BackupOutputMonitor] Finished, took 5m 40s 157m
and see that there is a long pause (i.e. 5+ minutes) from Start Recovering store and Finished recovering store.
It should be noted that at the same time the screen output was being produced we were also logging to the path of the backup destination a debug.log.<epochtime>, in this case /home/neo4j/backups/01172020/, one will see a message similar to
2020-01-17 12:54:06.869+0000 INFO [o.n.k.NeoStoreDataSource] Commits found after last check point (which is at LogPosition{logVersion=26059, byteOffset=219081898}). First txId after last checkpoint: 643034051
2020-01-17 12:54:06.929+0000 INFO [o.n.k.NeoStoreDataSource] Recovery required from position LogPosition{logVersion=26059, byteOffset=219081898}
2020-01-17 12:54:34.411+0000 INFO [o.n.k.r.Recovery]   10% completed
2020-01-17 12:54:35.232+0000 INFO [o.n.k.r.Recovery]   20% completed
2020-01-17 12:54:35.338+0000 INFO [o.n.k.r.Recovery]   30% completed
2020-01-17 12:56:02.151+0000 INFO [o.n.k.r.Recovery]   40% completed
2020-01-17 12:56:21.642+0000 INFO [o.n.k.r.Recovery]   50% completed
2020-01-17 12:56:49.419+0000 INFO [o.n.k.r.Recovery]   60% completed
2020-01-17 12:58:06.401+0000 INFO [o.n.k.r.Recovery]   70% completed
2020-01-17 12:58:14.209+0000 INFO [o.n.k.r.Recovery]   80% completed
2020-01-17 12:58:48.040+0000 INFO [o.n.k.r.Recovery]   90% completed
2020-01-17 12:59:34.411+0000 INFO [o.n.k.r.Recovery]   100% completed
2020-01-17 12:59:34.411+0000 INFO [o.n.k.NeoStoreDataSource] Recovery completed. 215589 transactions, first:643034051, last:643249639 recovered
the reason for these messages and delay is as a result of the way in which backup is run and performs checkpoints. When backup is run the first thing it does is performs a database checkpoint which flushes all pagecache data to the store files (i.e. graph.db/neostore.*.db) files. Backup will then copy the files from the runnning data/databases/graph.db to the backup destination. Once all files are copied it then will look back to see if any transactions had been added since the initial copy of files to the backup destination and if there are transactions it will perform a 'Recovery' as described above. For example if backup was started at 09:00 and from 09:00 to 09:04 it copied all the data/database/graph.db files to the backup destination and during these 4 minutes 10k new transactions were committed to the database then backup will perform a 'Recovery' so as to capture these additional 10k transactions so that they too are also written to the backup destination.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-display-all-nodes-with-no-defined-labels;"How do I display all nodes with no defined labels
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
Although assigning a node one or more labels provides many benefits (i.e. performance gains from index usage, ability to group nodes into sets, etc), it is possible to create a node without any labels.
The following Cypher can be used to identify all nodes in the graph which have no label defined:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n) WHERE size(labels(n)) = 0 RETURN n
Label usage is detailed here.
Was this page helpful?"
https://neo4j.com/developer/kb/performing-match-intersection;"Performing match intersection
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher intersection
Match intersection is a common use case where you’re searching for nodes which have relationships to all of a set of input nodes.
For the rest of the article we’ll use the built-in movies graph for demonstration. The example use case will be:
Given a list of actor names, find movies featuring all the given actors.
A common first (and wrong) approach is something like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ['Keanu Reeves', 'Hugo Weaving', 'Emil Eifrem'] as names
MATCH (p:Person)-[:ACTED_IN]->(m:Movie)
WHERE p.name in names
RETURN m
The above query returns movies featuring at least one of the given actors, not movies with all the given actors.
We need alternate approaches to get the correct results.
Filter to the nodes in common by the count of input nodes in the match
We can make some changes to the above query to get the relevant set of :Movie nodes.
The idea here is that in our match, the :Movie nodes we want will have the same number of distinct matched actors as the size of our input collection.
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ['Keanu Reeves', 'Hugo Weaving', 'Emil Eifrem'] as names
MATCH (p:Person)-[:ACTED_IN]->(m:Movie)
WHERE p.name in names
WITH m, size(names) as inputCnt, count(DISTINCT p) as cnt
WHERE cnt = inputCnt
RETURN m
By filtering down based upon the distinct nodes matched, we’re able to get the correct answer even if there are multiple relationships of the same type between the nodes in our match.
This is typically the most efficient approach for finding match intersections, but it requires that all inputs in the input list are distinct.
Use WHERE ALL() to ensure all nodes in a list have a relationship to another node
An alternate (but typically less efficient) approach is to collect input nodes, and use the WHERE ALL() predicate to ensure all the collected nodes have a relationship to the common node.
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ['Keanu Reeves', 'Hugo Weaving', 'Emil Eifrem'] as names
MATCH (p:Person)
WHERE p.name in names
WITH collect(p) as persons
MATCH (m:Movie)
WHERE ALL(p in persons WHERE (p)-[:ACTED_IN]->(m))
RETURN m
The problem with this approach is that there is a performance hit proportional to the number of :Movie nodes, since the last MATCH starts from all :Movie nodes.
We can improve this query somewhat by starting from :Movie nodes matched from one of our input nodes, though this increases the complexity of the query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ['Keanu Reeves', 'Hugo Weaving', 'Emil Eifrem'] as names
MATCH (p:Person)
WHERE p.name in names
WITH collect(p) as persons
WITH head(persons) as head, tail(persons) as persons
MATCH (head)-[:ACTED_IN]->(m:Movie)
WHERE ALL(p in persons WHERE (p)-[:ACTED_IN]->(m))
RETURN m
Use APOC to intersect result lists
Some use cases might introduce extra complexity. Perhaps we want result nodes to intersect with results from another matched pattern, or with a different collection of results. In these cases, we might simply use a WHERE clause to enforce the additional pattern, or list membership.
But when there are several lists requiring intersection, this can become tougher to perform with Cypher alone.
When using Neo4j 3.0.x or higher, using the reduce() function along with an intersection function from APOC Procedures, we can perform intersections across multiple lists.
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ['Keanu Reeves', 'Hugo Weaving', 'Emil Eifrem'] as names
MATCH (p:Person)-[:ACTED_IN]->(m:Movie)
WHERE p.name in names
WITH p, collect(m) as moviesPerActor
WITH collect(moviesPerActor) as movies
WITH reduce(commonMovies = head(movies), movie in tail(movies) |
 apoc.coll.intersection(commonMovies, movie)) as commonMovies
RETURN commonMovies
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-compare-two-graphs-for-equality;"How do I compare two graphs for equality
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags apoc
If you are looking to compare 2 graphs (or sub-graphs) to determine if they are equivalent, the following Cypher will produce a md5sum of the nodes and properties to make that comparison. For example, you may wish to compare a test/QA instance with a production instance.
Neo4j 3.1 forward
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
WITH n
ORDER BY n.title
WITH collect(properties(n)) AS propresult
RETURN apoc.util.md5(propresult);
pre 3.1
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
WITH n
ORDER BY n.title
WITH collect(properties(n)) AS propresult
CALL apoc.util.md5(propresult) YIELD value AS md5_property
RETURN md5_property
and when run against the default Movie Graph which includes 38 nodes with a label of Movie, this returns:
md5_property
3f8d4737d078783e12f7cf57a207dd67
The above Cypher requires the installation of the apoc stored procedures set.
In the above example, we are examining all nodes with the label :Movie and producing a md5sum of all properties those nodes, using that sum to produce a md5sum hash.
To get correct results we need to order the nodes by a property value that is both defined for each node and unqiue. For this reason you might want to use a property that is defined as a property existence constraint and unique property constraint.
For example if the :Movie nodes had multiple nodes with the same title property, and since the Cypher above is ordering by n.title, then the results are passed to the md5 stored procedure in the order they are found. This is typically based upon the order the nodes were created. If you had two :Movie nodes with title='The Matrix' created with the following Cypher:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n:Movie {title:'The Matrix', genre:'Sci-Fi'})
CREATE (n1:Movie {title:'The Matrix', genre:'Action'})
then simply running the Cypher to produce the md5 hash will produce a md5_property of:
md5_property
5bc18a680ef59ba09466da4217166d30
However, if you reversed the order of the CREATE statements, like this:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE (n1:Movie {title:'The Matrix', genre:'Action'})
CREATE (n:Movie {title:'The Matrix', genre:'Sci-Fi'})
the result of the same md5 hashing Cypher will yield a different md5_property:
md5_property
c3c565b45457d2182731050e0cbab221
In the above example, so as to get the correct md5 values, regardless of the order of the creates, we need to run Cypher which will return data in a guaranteed order, using an ORDER BY clause:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Movie)
WITH n
ORDER BY n.name, n.genre
WITH collect(properties(n)) AS propresult
CALL apoc.util.md5(propresult) YIELD value AS md5_property
RETURN md5_property
which will always return:
md5_property
c3c565b45457d2182731050e0cbab221
Additionally, we cannot simply collect(n) (i.e. the entire node) for internally it includes the internal node id (a unique internal identifier).
If you run the same Cypher on two separate environments and get the same md5 sums, the nodes can be proven to be the same in terms of definition of labels and properties.
Was this page helpful?"
https://neo4j.com/developer/kb/updating-a-node-but-returning-its-state-from-before-the-update;"Updating a node but returning its state from before the update
Author Andrew Bowman Applicable versions 3.0 3.1 3.2 3.3 3.4 3.5 4.0 4.1 4.2 Tags cypher
Some use cases require updating node (or relationship) properties, but returning the node (or relationship) as it was prior to the update.
You’ll need to get a 'snapshot' of the node before the update, and return that snapshot instead of the node itself.
Neo4j 3.1 and above
You can use map projection to get your node snapshot:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person{name:'Keanu Reeves'})
WITH p, p {.*} as snapshot
SET p.name = 'The One'
RETURN snapshot
The returned map result will still have the name property set to 'Keanu Reeves'.
Note that the result is a map, not a node, so node id and labels are not included in the returned data.
Returning an explicit null value
If you need to explicitly show a missing field (in the snapshot) as a null value in Neo4j 3.1 or above, you can also solve this with map projection by explicitly including the field in the projection.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person{name:'Keanu Reeves'})
WITH p, p {.*, .lastUpdated} as snapshot
SET p.lastUpdated = TIMESTAMP()
RETURN snapshot
If the lastUpdated property didn’t exist on the node, it will still be returned in the map with a null value instead of not appearing at all.
Neo4j 3.0 and below
Map projection isn’t available, so use properties() instead.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person{name:'Keanu Reeves'})
WITH p, properties(p) as snapshot
SET p.name = 'The One'
RETURN snapshot
The returned map result will still have the name property set to 'Keanu Reeves'.
Note that the result is a map, not a node, so node id and labels are not included in the returned data.
Returning an explicit null value
If you need to explicitly show a missing field (in the snapshot) as a null value in Neo4j 3.0, you’ll need to use the map helper functions of APOC Procedures.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person{name:'Keanu Reeves'})
WITH p, properties(p) as props
CALL apoc.map.setKey(props, 'lastUpdated', null) YIELD value as snapshot
SET p.lastUpdated = timestamp()
RETURN snapshot
If the lastUpdated property didn’t exist on the node, it will still be returned in the map with a null value instead of not appearing at all.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-improve-the-performance-of-counting-number-of-relationships-on-a-node;"How do I improve the performance of counting number of relationships on a node
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher performance
Using Cypher one could count number of relationships in the following manner
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Actor {name:'Sylvester Stallone'})-->() RETURN count(*);
Which will report the number of incoming/outgoing relationships for the Actor named Sylvester Stallone.
Using bin/neo4j-shell and running a profile on the query will produce the following output
The Cypher can be rewritten to
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Actor {name:'Sylvester Stallone'})
RETURN size((n)-->())
And to which the profile is:
From the profile above you will see a reference to GetDegree(n,None,BOTH) which occurs as a result of the usage of size( (n)-[]-()); Because of this we do not actually perform a traversal of relationships from (n) but rather consult the degree value stored with the given node.
In the above GetDegree() expression, the 2nd parameter refers to the relationship name, and the 3rd parameter refers to the direction of the relationship.
For example the Cypher of
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:Actor {name:'Sylvester Stallone'})
RETURN size( (n)-[:ACTED_IN]->())
would result in the following profile:
and thus a GetDegree(n,Some(ACTED_IN),OUT)
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-consumed-after-message-in-query-results;"Explanation of the ""consumed after"" message in query results
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher
After successfully executing a query through the Neo4j Browser or cypher-shell, you may see a message formatted as follows accompanying the query results:
None
Copy to Clipboard
X rows available after Y ms, consumed after another Z ms
This provides the following information:
None
Copy to Clipboard
X rows
These are the total number of rows resulting from the query.
None
Copy to Clipboard
available after Y ms
This is the number of milliseconds before the first row of results became available, where we could start sending results back across the wire to the client.
None
Copy to Clipboard
consumed after another Z ms
This is the number of milliseconds it took to consume the remaining results.
This includes the time it took to transport all results over the wire and back to the client, so it doesn’t only include the time it took to finish the query on the server.
To calculate the total time for the query to finish and to obtain all results, add the ""available after"" and ""consumed afer another"" values.
If you are only interested in the time it took to execute the query on the server, then look to the query logs instead: https://neo4j.com/docs/operations-manual/current/monitoring/logging/#query-logging
Was this page helpful?"
https://neo4j.com/developer/kb/categories/security;"Articles tagged as security
Creating and configuring database-local roles
Neo4j 4.0 introduced advanced security features in the form of role-based access controls, much needed, especially with the introduction of multiple database functionality. These controls can be accessed by administrators…
Read more
security rbac multi-database
Explanation of error ""javax.net.ssl.SSLException: Received fatal alert: certificate_unknown""
When connecting to a Neo4j instance with the Neo4j Browser, the following error may be logged in the $NEO4J_HOME\logs\debug.log This is usually as a result of either a bad certificate…
Read more
certificates client
LDAP Error: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
When configuring LDAP with certificates you may encounter the following issue: The problem appears when your server uses a self-signed certificate. To workaround it, you can add this certificate to…
Read more
ldap certificate security
Protecting against Cypher injection
What is Cypher injection? Cypher injection is a way for maliciously formatted input to jump out of its context, and by altering the query itself, hijack the query and perform…
Read more
cypher security
Protecting against Server Side Request Forgery (SSRF)
What is SSRF? Server-side request forgery (SSRF) vulnerabilities let an attacker send crafted requests from the back-end server of a vulnerable web application. Criminals usually use SSRF attacks to target…
Read more
cypher security
Resolve TLS certificate errors
TLS encryption is required everywhere. This is a compilation of few errors you can expect while configuring your server. openssl command is required to diagnose or manipulate the certificates. Check…
Read more
tls ssl configuration
TLS/SSL Configuration for Specific Ciphers
Per documentation: dbms.ssl.policy.<policyname>.ciphers is by default set to the Java platform default allowed cipher suites, which can also be explicitly set to any specific ciphers (separated by "","") to further…
Read more
ssl tls cipher security unix operations"
https://neo4j.com/developer/kb/explanation-of-error-javax-net-ssl-sslexception-received-fatal-alert-certificate-unknown;"Explanation of error ""javax.net.ssl.SSLException: Received fatal alert: certificate_unknown""
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags certificates client
When connecting to a Neo4j instance with the Neo4j Browser, the following error may be logged in the $NEO4J_HOME\logs\debug.log
2020-06-20 13:33:13.039-0400 ERROR [o.n.b.t.TransportSelectionHandler] Fatal error occurred when initialising pipeline: [id: 0x59d02719, L:/12.31.54.51:5502 ! R:/192.168.9.5:55140] javax.net.ssl.SSLException: Received fatal alert: certificate_unknown
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLException: Received fatal alert: certificate_unknown
 at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:468)
 at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:401)
 at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:368)
 at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:351)
 at io.netty.handler.ssl.SslHandler.channelInactive(SslHandler.java:1084)----
This is usually as a result of either a bad certificate recorded at the client or incorrect url for the browser.
For example, as depicted from the screenshot and when using Google Chrome Browser and clicking on the padlock icon next to the url
you should see that this reports Certificate Valid.
Further if you click the text for Certificate Valid it should report similar to
and describe to which domain the certificate is Issued to:
If you encounter the error described above you should validate that your Neo4j Client has a valid certificate and replace at the client if not correct.
Was this page helpful?"
https://neo4j.com/developer/kb/creating-database-local-roles;"Creating and configuring database-local roles
Author Andrew Bowman Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags security rbac multi-database
Neo4j 4.0 introduced advanced security features in the form of role-based access controls, much needed, especially with the introduction of multiple database functionality.
These controls can be accessed by administrators on the system database, present on every Neo4j instance.
The system database comes with several built-in roles, but it is not completely clear on the means to grant these kinds of privileges to users constrained to specific databases.
This article seeks to explain the global nature of these roles and provide some examples of how to make the equivalent of these built-in roles at the local database level.
Built-in roles are global and apply to all databases
A common but wrong assumption is that a role can be assigned to a user on a database, such as assigning the reader role to user_a on database db1. But roles and the databases for which they apply are not independent of each other. Each role includes within itself not just its privileges, but also the databases for which it has access. Privileges themselves can be scoped to specific databases.
So the databases for which the built-in roles apply are already set and immutable: They include global database access, and their privileges apply to every database, past, present, and future. A user granted the reader role is a reader for every database that will ever be created on that dbms.
The same is true for the other built-in roles. They aren’t meant to be used at a local database level.
When it comes to per-database access and roles, it is best to think in terms of privileges, and not the built-in roles. So don’t think in terms of granting the reader role to user_a on database db1, but instead think about creating some new role that has read privileges on db1, and access on db1, and grant that new role to user_a.
We can copy built-in roles and adjust their database access privileges
Instead of creating new roles from scratch, we can use the built-in roles as a template, when all we need is the equivalent of a built-in role scoped down to a specific database or databases.
We do this by creating a new role as a copy of an existing role. Then we can revoke global database access, then grant access to the database or databases that the role should have access to.
So to create the equivalent of the reader role but to database db1, and grant it to user_a, we would do the following from the system database:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE ROLE db1_reader AS COPY OF reader;
REVOKE GRANT ACCESS ON DATABASES * FROM db1_reader;
GRANT ACCESS ON DATABASE db1 TO db1_reader;
GRANT ROLE db1_reader TO user_a;
Of course, user_a and database db1 must exist first for this to be successful.
This grants privileges equivalent to the reader role, but constraints the user’s access to only database db1.
Be aware that privileges from multiple roles can combine
It’s important to note that the db1_reader role doesn’t actually have reader privileges scoped to only db1. They still have full read privileges across any and all databases (as copied from the built-in reader role), it’s just that currently, their role only allows access on db1. We had only revoked the ACCESS from all database, not the READ privilege.
If the user was granted another role that granted access privileges on a different database and didn’t constrain their privileges in some way, then the global read privileges inherent in the db1_reader role would allow them to be a reader of the new database.
Let’s illustrate that by adding a new role db2_accessor, and granting it to user_a:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE ROLE db2_accessor;
GRANT ACCESS ON DATABASE db2 TO db2_accessor;
GRANT ROLE db2_accessor TO user_a;
Even though the db2_accessor role merely gives access to the database, no permissions for reading, writing, or anything else, because of the global read privileges from db1_reader, user_a can read everything on db2.
Let’s check user_a’s privileges to verify:
Cypher
Copy to Clipboard
Run in Neo4j Browser
SHOW USER user_a PRIVILEGES;
╒═════════╤══════════╤════════════════╤═══════╤═════════════════╤══════════════╤════════╕
│""access"" │""action""  │""resource""      │""graph""│""segment""        │""role""        │""user""  │
╞═════════╪══════════╪════════════════╪═══════╪═════════════════╪══════════════╪════════╡
│""GRANTED""│""read""    │""all_properties""│""*""    │""NODE(*)""        │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""traverse""│""graph""         │""*""    │""NODE(*)""        │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""read""    │""all_properties""│""*""    │""RELATIONSHIP(*)""│""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""traverse""│""graph""         │""*""    │""RELATIONSHIP(*)""│""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""access""  │""database""      │""db1""  │""database""       │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""access""  │""database""      │""db2""  │""database""       │""db2_accessor""│""user_a""│
└─────────┴──────────┴────────────────┴───────┴─────────────────┴──────────────┴────────┘
We can mask privileges with DENY
The ability for privileges to combine isn’t necessarily an obstacle. Sometimes it can be very useful.
For example, what if we’re fine with having this combined read access, but we want to make sure no matter what database we’re using, that this user can’t read or match to SSN properties on :Person nodes. We can add a special role just for this restriction.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE ROLE ssn_blind;
DENY MATCH {ssn, SSN} ON GRAPH * NODES Person TO ssn_blind;
GRANT ROLE ssn_blind TO user_a;
Scoping privileges narrowly keeps permissions predictable
If we wanted the tightest level of security, scoping privileges such that granting of a new role (and access of a new database) won’t give unintentionally wide privileges, then we need to abandon the idea of copying the built-in roles when creating new ones. Their privileges are database-wide, which may be too permissive for what we want.
Instead, we need to grant the privileges manually and scope them to the database or databases in question.
Let’s drop the db1_reader role and recreate it with more narrowly scoped privileges:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CREATE OR REPLACE ROLE db1_reader;
GRANT ACCESS ON DATABASE db1 TO db1_reader;
GRANT MATCH {*} ON GRAPH db1 to db1_reader;
GRANT ROLE db1_reader TO user_a;
The https://neo4j.com/docs/cypher-manual/current/access-control/manage-privileges/#access-control-graph-privileges[MATCH privilege] is shorthand for both READ and TRAVERSE privileges, so this saves us a line.
Now let’s check user_a’s privileges again:
Cypher
Copy to Clipboard
Run in Neo4j Browser
SHOW USER user_a PRIVILEGES;
╒═════════╤══════════╤════════════════╤═══════╤═════════════════╤══════════════╤════════╕
│""access"" │""action""  │""resource""      │""graph""│""segment""        │""role""        │""user""  │
╞═════════╪══════════╪════════════════╪═══════╪═════════════════╪══════════════╪════════╡
│""GRANTED""│""read""    │""all_properties""│""db1""  │""NODE(*)""        │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""traverse""│""graph""         │""db1""  │""NODE(*)""        │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""read""    │""all_properties""│""db1""  │""RELATIONSHIP(*)""│""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""traverse""│""graph""         │""db1""  │""RELATIONSHIP(*)""│""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""access""  │""database""      │""db1""  │""database""       │""db1_reader""  │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""GRANTED""│""access""  │""database""      │""db2""  │""database""       │""db2_accessor""│""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""DENIED"" │""read""    │""property(SSN)"" │""*""    │""NODE(Person)""   │""ssn_blind""   │""user_a""│
├─────────┼──────────┼────────────────┼───────┼─────────────────┼──────────────┼────────┤
│""DENIED"" │""read""    │""property(ssn)"" │""*""    │""NODE(Person)""   │""ssn_blind""   │""user_a""│
└─────────┴──────────┴────────────────┴───────┴─────────────────┴──────────────┴────────┘
We can see that although user_a has access to both db1 and db2 databases, the read and traverse privileges we granted to db1_reader are scoped just to db1. User_a can access db2, but can’t actually do anything there until we grant them more privileges on one of their existing roles, or via a new role.
Was this page helpful?"
https://neo4j.com/developer/kb/ldap-error-unable-to-find-valid-certification-path-to-requested-target;"LDAP Error: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags ldap certificate security
When configuring LDAP with certificates you may encounter the following issue:
2018-12-24 08:11:14.788+0000 ERROR [someuser]: failed to log in: invalid principal or credentials (LDAP naming error while attempting to authenticate user.) (neo4j01.test.dom:636) (sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target)
The problem appears when your server uses a self-signed certificate. To workaround it, you can add this certificate to the list of trusted certificates for your JVM. The Root Certificate will need to be added to the Java CAstore using keytool.
Shell
Copy to Clipboard
$ keytool -import -alias _alias_name_ -keystore ..\lib\security\cacerts -file _path_to_cer_file
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-configure-mixed-mode-security-in-neo4j;"How to configure mixed-mode security (native and LDAP) in Neo4j
Author Dave Gordon Applicable versions 3.1 3.2 Tags security ldap
For environments where you need both LDAP authentication as well as some native user accounts, there is a way to allow this in Neo4j 3.1 and newer. Use the configuration setting dbms.security.auth_providers instead of the singular version dbms.security.auth_provider. This will allow you to supply a list of providers to use for authentication.
To allow both LDAP and native users to login, use the following setting in conf/neo4j.conf:
Properties
Copy to Clipboard
dbms.security.auth_providers=ldap,native
To control at a finer level which auth provider does (authentication and/or authorization), use the following settings as well (in the example we are setting all to true, but this can differ based on specific needs):
Properties
Copy to Clipboard
dbms.security.native.authentication_enabled=true
dbms.security.native.authorization_enabled=true
dbms.security.ldap.authentication_enabled=true
dbms.security.ldap.authorization_enabled=true
Was this page helpful?"
https://neo4j.com/developer/kb/categories/bloom;"Articles tagged as bloom
Bloom Compatibility with Neo4j 5.0
Neo4j Bloom makes use of database procedures for identifying indexes and constraints that have been deprecated and will be unavailable in Neo4j 5.0. These changes have been implemented to ensure…
Read more
bloom
Recovering Local Bloom Perspectives
Summary When Bloom is connected to a Neo4j server that does not have the Bloom plugin installed it stores perspectives locally in the Web Browser or Neo4j Desktop’s local storage.…
Read more
bloom perspectives recovery"
https://neo4j.com/developer/kb/categories/performance;"Articles tagged as performance
Linux Out of Memory killer
The Out Of Memory Killer or OOM Killer is a process that the linux kernel employs when the system is critically low on memory. This situation occurs because the linux…
Read more
performance memory java out-of-memory
Shared vs Exclusive Transaction locks
This document describes the meaning of a shared lock as seen by transactions and the difference between a shared and exclusive lock. A ""shared lock"" means multiple transactions can be…
Read more
lock transaction deadlock shared exclusive
Tuning GC algorithms
Introduction There are several Garbage Collection algorithms available in Java. You can find the supported JDKs in our product requirements section. We will review some of the available GCs and…
Read more
configuration
Understanding Neo4j’s data on disk
Neo4j database files are persisted to storage for long term durability. Data related files located in data/databases/graph.db (v3.x+) by default in the Neo4j data directory. Below will give you an…
Read more
disk
Understanding memory consumption
So you have configured Neo4j to use 4GB of heap and 6GB of page cache and sat back relaxed, thinking the Java process would not go above 10GB in your…
Read more
performance memory java"
https://neo4j.com/developer/kb/tuning-gc-algorithms;"Tuning GC algorithms
Author Jeremie Phoulchand Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags configuration
Introduction
There are several Garbage Collection algorithms available in Java. You can find the supported JDKs in our product requirements section.
We will review some of the available GCs and their main features.
G1
This is the default GC algorithm since Java 9. This is the one used for internal testing and used by default in neo4j. It is available in every implementation.
Shenandoah
It is officially available in some releases of OpenJDK since Java 8.
It is currently not available in Oracle JDK.
It allows you to have pauseless GCs (<10 ms) but at the expense of an higher CPU usage (20% additional CPU runtime usage).
Please note that we do NOT test those algorithms therefore we will NOT be able to emit a recommendation. Customers are free to test it on a lower environment and choose the one that suits them the best.
You can enable it by commenting the default dbms.jvm.additional=-XX:+UseG1GC and adding dbms.jvm.additional=-XX:+UseShenandoahGC in neo4j.conf
Properties
Copy to Clipboard
#dbms.jvm.additional=-XX:+UseG1GC
dbms.jvm.additional=-XX:+UseShenandoahGC
You can find more information here
C4 Azul
This version had its own proprietary pauseless algorithm which is supported. This is a paid algorithm so you might need to get a licence first.
You can find more information here
Please note that we do NOT test those algorithms therefore we will NOT be able to emit a recommendation. Customers are free to test it on a lower environment and choose the one that suits them the best.
Was this page helpful?"
https://neo4j.com/developer/kb/shared-vs-exclusive-transaction-locks;"Shared vs Exclusive Transaction locks
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags lock transaction deadlock shared exclusive
This document describes the meaning of a shared lock as seen by transactions and the difference between a shared and exclusive lock.
A ""shared lock"" means multiple transactions can be holding the same lock at the same time, where ""same lock"" is a combination of resource type and resource id. For NODE resource types, the resource id would be the node id for instance. So multiple transactions can share the lock. This is in contrast to an exclusive lock, where only one transaction can be holding the lock at any given time. Hence they’re exclusive. So there can be multiple holders of a shared lock, or a single holder of an exclusive lock. Shared locks mostly taken for index or constraint read purposes. They can be taken both during query planning, and during query execution.
Shared locks are taken when we want to read something and at the same time prevent other transactions from writing to, or otherwise modifying that object.
In the screenshot below, the Cypher statement produces a shared-lock:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.name = 'Tom Hanks'
set p.award= 'Oscar'
Below code can be used to watch another transaction that is running:
In one window:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)
WHERE p.name = 'Tom Hanks'
SET p.award = 'Oscar'
with p
call apoc.util.sleep(200000)
RETURN p.award
And in another window:
Cypher
Copy to Clipboard
Run in Neo4j Browser
call dbms.listTransactions() yield currentQueryId , currentQuery
with currentQueryId, currentQuery
WHERE currentQuery STARTS WITH ""MATCH (p:Person)""
WITH currentQueryId
call dbms.listActiveLocks(`currentQueryId`) YIELD mode, resourceType
RETURN mode, resourceType
The above cypher MATCH statement modifies the node, so an exclusive lock is taken on the node. The SHARED LABEL locks are for the schema of the database. They will prevent other transactions from modifying the schema in a way that involves those labels, such as creating a new uniqueness constraint on the Actor label.
Further notes:
Exclusive lock cannot be acquired if that node or relationship has an existing shared lock.
Transactions trying to modify a node with exclusive lock will wait for any existing exclusive lock to be released before they can be acquired. Hence the lock acquisition time comes into play, governing timeouts upon failure to acquire lock with a given time, configurable in neo4j.conf by dbms.lock.acquisition.timeout.
A limit on the maximum transaction runtime, is configurable in neo4j.conf via the dbms.transaction.timeout which can be used as a means to release any acquired exclusive and shared locks by transactions, within a specified time frame.
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-data-on-disk;"Understanding Neo4j’s data on disk
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags disk
Neo4j database files are persisted to storage for long term durability. Data related files located in data/databases/graph.db (v3.x+) by default in the Neo4j data directory. Below will give you an idea of the type of files you’ll find, prefaced with neostore.* and what data they are storing:
nodestore* Stores node related data from your graph
relationship* Stores data related to the relationships created and defined in your graph
property* Stores the key/value properties from your database
label* Stores index related label data from your graph
Since Neo4j is a schema-less database, we use fixed record lengths to persist data and follow offsets in these files to know how to fetch data to answer queries. The following table illustrates the fixed sizes Neo4j uses for the type of Java objects being stored:
Store File                        | Record size   | Contents
----------------------------------------------------------------------------------------------------------------------------
neostore.nodestore.db             | 15 B          | Nodes
neostore.relationshipstore.db     | 34 B          | Relationships
neostore.propertystore.db         | 41 B          | Properties for nodes and relationships
neostore.propertystore.db.strings | 128 B         | Values of string properties
neostore.propertystore.db.arrays  | 128 B         | Values of array properties
Indexed Property                  | 1/3 * AVG(X)  | Each index entry is approximately 1/3 of the average property value size
Some considerations about properties:
The property record has a payload of 32bytes, which is divided into four 8B blocks. Each field can hold either a key or a value, or both a key and a value.
the key and type occupies 3.5 bytes (key 4bit, type 24bit)
boolean, byte, short, int, char, float are fitted in the remaining bytes of that same block
a small long is also fitted in the same block
a big long or a double are stored in a separate block (meaning two blocks used by that property)
a reference to the string store or array store is fitted in the same block as the key
a short string or short array is stored in the same record if it fits in the remaining blocks (including the remaining bytes of the key-block)
long strings/arrays that do not fit in 8B blocks will have a pointer to a record on the string/array store (128B)
… other types get more involved!
Data stored on disk is all linked lists of fixed size records. Properties are stored as a linked list of property records, each holding a key and value and pointing to the next property. Each node and relationship references its first property record. The Nodes also reference the first relationship in its relationship chain. Each Relationship references its start and end node. It also references the previous and next relationship record for the start and end node respectively.
 
A basic example disk space calculation could be something like:
For the sake of simplicity, we assume a 1:1 property to property record ratio meaning one single property will always be 41B. Obviously, as per the considerations above, this may not be as trivial in real life scenarios.
Scenario #1 - Initial status
Node count: 4M nodes
Each node has 3 properties (12M properties total)
Relationship count: 2M relationships
Each relationship has 1 property (2M properties total)
 
This is translated to the following size on disk:
Nodes: 4.000.000x15B = 60.000.000B (60MB)
Relationships: 2.000.000x34B = 68.000.000B (68MB)
Properties: 14.000.000x41B = 574.000.000B (574MB)
TOTAL: 703MB
 
Scenario #2 - 4x growth + added properties + indexes on all properties
Node count: 16M nodes
Each node has 5 properties (80M properties total)
Relationship count: 8M relationships
Each relationship has 2 properties (16M properties total)
 
This is translated to the following size on disk:
Nodes: 16.000.000x15B = 240.000.000B (240MB)
Relationships: 8.000.000x34B = 272.000.000B (272MB)
Properties: 96.000.000x41B = 3.936.000.000B (3936MB)
Indexes: 4448MB * ~33% = 1468MB
TOTAL: 5916MB
 
You can take these values to have an idea of what to expect regarding disk size and growth.
Was this page helpful?"
https://neo4j.com/developer/kb/categories/neo4j-indexes;"Articles tagged as neo4j-indexes
A method to calculate the size of an index in Neo4j.
If the need arises to calculate the size of an index in Neo4j, for capacity planning purposes, there are two methods available: 1) Execute the db.indexes() procedure: CALL db.indexes() YIELD…
Read more
cypher indexes schema capacity planning"
https://neo4j.com/developer/kb/split-between-apoc-core-and-apoc-extended;"Split between APOC Core and APOC Extended
Author Jens Pryce-Åklundh Applicable versions 5 Tags apoc
With the release of Neo4j 5, the APOC library has been split into two separate packages: APOC Core and APOC Extended.
APOC Core
Neo4j 5 brings substantially more support to the APOC library.
While the APOC library was previously supported on a ""best effort"" basis by members of the community, the vast majority of APOC procedures and functions are now officially supported by Neo4j engineers dedicated to the improvement of the APOC library and its integration in the Neo4j Data Platform.
The procedures and functions that receive official Neo4j support constitute the APOC Core library.
For more details about APOC Core, see the APOC Core documentation.
APOC Extended
The minority of procedures and functions that fall outside the remit of APOC Core are still available to users. These constitute the APOC Extended library.
The APOC Extended library will not be officially supported by Neo4j. It will instead continue to receive ""best effort"" support by members of the community.
For more details about APOC Extended, see the APOC Extended documentation.
Was this page helpful?"
https://neo4j.com/labs/apoc/5;"APOC Extended User Guide 5.0
This is the page for APOC Extended documentation. For the officially supported APOC Core, go to the APOC Core page.
The guide covers the following areas:
Introduction — An Introduction to the APOC Extended library.
Installation — Installation instructions for the APOC Extended library.
Usage — A usage example.
Procedures & Functions — A list of all APOC Extended procedures and functions.
Configuration Options — Configuration options used by the APOC Extended library.
Import — A detailed guide to procedures that can be used to import data from different formats including JSON, CSV, and XLS.
Export — A detailed guide to procedures that can be used to export data to different formats including JSON, CSV, GraphML, and Gephi.
Database Integration — A detailed guide to procedures that can be used to integrate with other databases including relational databases, MongoDB, Couchbase, and ElasticSearch.
Graph Updates — A detailed guide to procedures that can be used to apply graph updates.
Cypher Execution — A detailed guide to procedures that can be used for Cypher scripting.
Virtual Resource — A detailed guide to procedures that can be used to create virtual nodes and relationships.
Natural Language Processing (NLP) — A detailed guide to procedures that can be used to add Natural Language Processing functionality to graph applications.
Database Introspection — A detailed guide to procedures that can be used to introspect the database.
Operational — A detailed guide to operational procedures.
Miscellaneous — A detailed guide to miscellaneous procedures and functions, including map and collection functions, text functions, and spatial functionality.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/import;"Import
The APOC Extended library adds support for importing data from various data formats, including JSON, XML, and XLS.
For more information on these procedures, see:
Loading Data from Web-APIs
Load CSV
Loading Excel (XLS)
Load HTML
Was this page helpful?"
https://neo4j.com/labs/apoc/5/import/web-apis;"Loading Data from Web-APIs
Contents
Load Single File From Compressed File (zip/tar/tar.gz/tgz)
Using S3 protocol
Using hdfs protocol
Using Google Cloud Storage
Fail on Error
Supported protocols are file, http, https, s3, gs, hdfs with redirect allowed.
If no procedure is provided, this procedure will try to check whether the URL is actually a file.
As apoc.import.file.use_neo4j_config is enabled, the procedures check whether file system access is allowed and possibly constrained to a specific directory by reading the two configuration parameters dbms.security.allow_csv_import_from_file_urls and server.directories.import respectively. If you want to remove these constraints please set apoc.import.file.use_neo4j_config=false
CALL apoc.load.xml('http://example.com/test.xml', ['xPath'], [config]) YIELD value as doc CREATE (p:Person) SET p.name = doc.name
load from XML URL (e.g. web-api) to import XML as single nested map with attributes and _type, _text and _children fields.
CALL apoc.load.csv('url',{sep:"";""}) YIELD lineNo, list, strings, map, stringMap
load CSV fom URL as stream of values
config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['aColumn'],arraySep:';',results:['map','list','strings','stringMap'],
nullValues:[''],mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false,nullValues:['n.A.']}}
CALL apoc.load.xls('url','Sheet'/'Sheet!A2:B5',{config}) YIELD lineNo, list, map
load XLS fom URL as stream of values
config contains any of: {skip:1,limit:5,header:false,ignore:['aColumn'],arraySep:';'+ nullValues:[''],mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false,nullValues:['n.A.']}}
Load Single File From Compressed File (zip/tar/tar.gz/tgz)
When loading data from compressed files, we need to put the ! character before the file name or path in the compressed file. For example:
Loading a compressed CSV file
apoc.load.csv(""pathToCompressedFile/file.zip!pathToCsvFileInZip/fileName.csv"")
Using S3 protocol
When using the S3 protocol we need to download and copy the following jars into the plugins directory:
aws-java-sdk-core-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-core/1.12.136)
aws-java-sdk-s3-1.12.136.jar (https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-s3/1.12.136)
httpclient-4.5.13.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient/4.5.13)
httpcore-4.4.15.jar (https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore/4.4.15)
joda-time-2.10.13.jar (https://mvnrepository.com/artifact/joda-time/joda-time/2.10.13)
Once those files have been copied we’ll need to restart the database.
The S3 URL must be in the following format:
s3://accessKey:secretKey[:sessionToken]@endpoint:port/bucket/key (where the sessionToken is optional) or
s3://endpoint:port/bucket/key?accessKey=accessKey&secretKey=secretKey[&sessionToken=sessionToken] (where the sessionToken is optional) or
s3://endpoint:port/bucket/key if the accessKey, secretKey, and the optional sessionToken are provided in the environment variables
Using hdfs protocol
To use the hdfs protocol we need to download and copy the additional jars not included in the APOC Extended library. We can download it from this link or locally downloading the apoc repository:
git clone http://github.com/neo4j-contrib/neo4j-apoc-procedures
cd neo4j-apoc-procedures/extra-dependencies
./gradlew shadow
and a jar named apoc-hadoop-dependencies-5.0.0-rc01.jar will be created into the neo4j-apoc-procedures/extra-dependencies/hadoop/build/lib folder.
Once that file is downloaded/created, it should be placed in the plugins directory and the Neo4j Server restarted.
Using Google Cloud Storage
In order to use Google Cloud Storage, you need to add the following Google Cloud dependencies in the plugins directory:
api-common-1.8.1.jar
failureaccess-1.0.1.jar
gax-1.48.1.jar
gax-httpjson-0.65.1.jar
google-api-client-1.30.2.jar
google-api-services-storage-v1-rev20190624-1.30.1.jar
google-auth-library-credentials-0.17.1.jar
google-auth-library-oauth2-http-0.17.1.jar
google-cloud-core-1.90.0.jar
google-cloud-core-http-1.90.0.jar
google-cloud-storage-1.90.0.jar
google-http-client-1.31.0.jar
google-http-client-appengine-1.31.0.jar
google-http-client-jackson2-1.31.0.jar
google-oauth-client-1.30.1.jar
grpc-context-1.19.0.jar
guava-28.0-android.jar
opencensus-api-0.21.0.jar
opencensus-contrib-http-util-0.21.0.jar
proto-google-common-protos-1.16.0.jar
proto-google-iam-v1-0.12.0.jar
protobuf-java-3.9.1.jar
protobuf-java-util-3.9.1.jar
threetenbp-1.3.3.jar
We’ve prepared an uber-jar that contains the above dependencies in a single file in order simplify the process. You can download it from here and copy it to your plugins directory.
You can use Google Cloud storage via the following url format:
gs://<bucket_name>/<file_path>
Moreover, you can also specify the authorization type via an additional authenticationType query parameter:
NONE: for public buckets (this is the default behavior if the parameter is not specified)
GCP_ENVIRONMENT: for passive authentication as a service account when Neo4j is running in the Google Cloud
PRIVATE_KEY: for using private keys generated for service accounts (requires setting GOOGLE_APPLICATION_CREDENTIALS environment variable pointing to a private key json file as described here: https://cloud.google.com/docs/authentication#strategies)
Example:
gs://andrea-bucket-1/test-privato.csv?authenticationType=GCP_ENVIRONMENT
Fail on Error
Adding the config parameter failOnError:false (by default true), will mean that in the case of an error the procedure will not fail, but just return zero rows.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/import/html;"Load HTML
Contents
Config
Example with real data
Scraping Data from Html Pages.
apoc.load.html('url',{name: jquery, name2: jquery}, config) YIELD value
Load Html page and return the result as a Map
This procedures provides a very convenient API for acting using DOM, CSS and jquery-like methods. It relies on jsoup library.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(url, {name: <css/dom query>, name2: <css/dom query>}, {config}) YIELD value
The result is a stream of DOM elements represented by a map
The result is a map i.e.
JavaScript
Copy to Clipboard
{name: <list of elements>, name2: <list of elements>}
Config
Config param is optional, the default value is an empty map.
charset
Default: UTF-8
baserUri
Default: """", it is use to resolve relative paths
htmlString
Default: false, to use an HTML string instead of an url as 1st parameter
Example with real data
The examples below use the Wikipedia home page.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""https://en.wikipedia.org/"",{metadata:""meta"", h2:""h2""})
You will get this result:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""https://en.wikipedia.org/"",{links:""link""})
You will get this result:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.html(""https://en.wikipedia.org/"",{metadata:""meta"", h2:""h2""}, {charset: ""UTF-8""})
You will get this result:
Was this page helpful?"
https://neo4j.com/labs/apoc/5/import/xls;"Loading Excel (XLS)
Contents
Library Requirements
Usage
Examples for apoc.load.xls
Library Requirements
For loading XLS we’re using the Apache POI library, which works well with old and new Excel formats, but is quite large. That’s why we decided not to include it into the apoc jar, but make it an optional dependency.
These dependencies are included in apoc-xls-dependencies-5.0.0-rc01.jar, which can be downloaded from the releases page. Once that file is downloaded, it should be placed in the plugins directory and the Neo4j Server restarted.
Alternatively, you can download these jars from Maven Repository (putting them into plugins directory as well):
For XLS files:
poi-5.1.0.jar
Additional for XLSX files:
commons-collections4-4.4.jar
poi-ooxml-5.1.0.jar
poi-ooxml-lite-5.1.0.jar
xmlbeans-5.0.2.jar
curvesapi-1.06.jar
Usage
The usage of apoc.load.xls is similar to apoc.load.csv with the main difference the ability to select a worksheet or a range from a sheet to load.
You can either select the sheet by name like 'Kids', or offset like 'Results!B2:F3'
CALL apoc.load.xls({url}, {Name of sheet}, {config})
The {config} parameter is a map
name description
mapping
{mapping:{'<sheet>':{type:'<type>', dateFormat: '<format>', dateParse: [<formats>]}}}
<sheet>
name of the sheet
<type>
Default String, The type of the conversion requested (STRING, INTEGER, FLOAT, BOOLEAN, NULL, LIST, DATE, DATE_TIME, LOCAL_DATE, LOCAL_DATE_TIME, LOCAL_TIME, TIME)
dateFormat: <format>
Convert the Date into String (only String is allowed)
dateParse: [<formats>]
Convert the String into Date (Array of strings are allowed)
In dateParse the first format matched return the date formatted, otherwise it will return an error
In format config you can use the pattern describe as the Temporal functions.
Examples for apoc.load.xls
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('file:///path/to/file.xls','Full',{mapping:{Integer:{type:'int'}, Array:{type:'int',array:true,arraySep:';'}}})
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('http://bit.ly/2nXgHA2','Kids')
Some examples with type/dateFormat and dateParse:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String'}}})
Figure 1. results
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String',dateFormat:'iso_date'}}})
Figure 2. results
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String',dateParse:[""wrongPath"", ""dd-MM-yyyy"", ""dd/MM/yyyy"", ""yyyy/MM/dd"", ""yyyy/dd/MM"", ""yyyy-dd-MM'T'hh:mm:ss""]}}})
Figure 3. results
Was this page helpful?"
https://neo4j.com/labs/apoc/5/export;"Export
Neo4j supports exporting whole databases via the backup and dump commands. It doesn’t have support for exporting sub graphs or exporting data into standard data formats, which is where the APOC Extended library comes in.
APOC Extended adds support for exporting data into various data formats, including JSON, CSV, GraphML, and Cypher script.
In addition to exporting data in these formats, we can choose to export the whole database, specified nodes and relationships, a virtual graph, or the results of a Cypher query.
For more information on how to use these procedures, see:
Export to Excel
Was this page helpful?"
https://neo4j.com/labs/apoc/5/export/xls;"Export to Excel
Contents
Available Procedures
The export Xls procedures export data into a format that’s supported by Microsoft Excel, OpenOffice Calc, Apple Numbers and similar.
Available Procedures
The table below describes the available procedures:
Qualified Name Type Release
apoc.export.xls.all
apoc.export.xls.all(file,config) - exports whole database as xls to the provided file
Procedure
Apoc Extended
apoc.export.xls.data
apoc.export.xls.data(nodes,rels,file,config) - exports given nodes and relationships as xls to the provided file
Procedure
Apoc Extended
apoc.export.xls.graph
apoc.export.xls.graph(graph,file,config) - exports given graph object as xls to the provided file
Procedure
Apoc Extended
apoc.export.xls.query
apoc.export.xls.query(query,file,{config,…,params:{params}}) - exports results from the cypher statement as xls to the provided file
Procedure
Apoc Extended
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration;"Database Integration
The APOC Extended library adds support for integrating with other databases, including relational databases (via JDBC), MongoDB, Elastic, and Couchbase. It also has support for importing data from LDAP directories and executing queries against other Neo4j databases.
For more information on how to use these procedures, see:
Load JDBC (RDBMS)
Database Modeling
ElasticSearch
MongoDB
Couchbase
Bolt
Load LDAP
Redis
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-integration/load-ldap;"Load LDAP
Contents
Parameters
Load LDAP Example
Credentials
With 'apoc.load.ldap' you can execute queries on any LDAP v3 enabled directory, the results are turned into a streams of entries. The entries can then be used to update or create graph structures.
Note this utility requires to have the jldap library to be placed the plugin directory.
Qualified Name Type Release
apoc.load.ldap
apoc.load.ldap(""key"" or {connectionMap},{searchMap}) Load entries from an ldap source (yield entry)
Procedure
Apoc Extended
Parameters
Parameter Property Description
{connectionMap}
ldapHost
the ldapserver:port if port is omitted the default port 389 will be used
loginDN
This is the dn of the ldap server user who has read access on the ldap server
loginPW
This is the password used by the loginDN
{searchMap}
searchBase
From this entry a search is executed
searchScope
SCOPE_ONE (one level) or SCOPE_SUB (all sub levels) or SCOPE_BASE (only the base node)
searchFilter
Place here a standard ldap search filter for example: (objectClass=*) means that the ldap entry must have an objectClass attribute.
attributes
optional. If omitted all the attributes of the entries will be returned. When specified only the specified attributes will be returned. Regardless the attributes setting a returned entry will always have a ""dn"" property.
Load LDAP Example
Cypher
Retrieve group member information from the ldap server
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.ldap({ldapHost : ""ldap.forumsys.com"", loginDN : ""cn=read-only-admin,dc=example,dc=com"", loginPW : ""password""},
{searchBase : ""dc=example,dc=com"",searchScope : ""SCOPE_SUB""
,attributes : [""uniqueMember"",""cn"",""uid"",""objectClass""]
,searchFilter: ""(&(objectClass=*)(uniqueMember=*))""}) yield entry
return entry.dn,  entry.uniqueMember
entry.dn entry.uniqueMember
""ou=mathematicians,dc=example,dc=com""
[""uid=euclid,dc=example,dc=com"", ""uid=riemann,dc=example,dc=com"", ""uid=euler,dc=example,dc=com"", ""uid=gauss,dc=example,dc=com"", ""uid=test,dc=example,dc=com""]
""ou=scientists,dc=example,dc=com""
""ou=italians,ou=scientists,dc=example,dc=com""
""uid=tesla,dc=example,dc=com""
""ou=chemists,dc=example,dc=com""
Cypher
Retrieve group member information from the ldap server and create structure in Neo4j
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.ldap({ldapHost : ""ldap.forumsys.com"", loginDN : ""cn=read-only-admin,dc=example,dc=com"", loginPW : ""password""},
{searchBase : ""dc=example,dc=com"",searchScope : ""SCOPE_SUB""
,attributes : [""uniqueMember"",""cn"",""uid"",""objectClass""]
,searchFilter: ""(&(objectClass=*)(uniqueMember=*))""}) yield entry
merge (g:Group {dn : entry.dn})
on create set g.cn = entry.cn
foreach (member in entry.uniqueMember |
  merge (p:Person { dn : member })
  merge (p)-[:IS_MEMBER]->(g)
)
Credentials
To protect credentials, you can configure aliases in conf/apoc.conf:
apoc.conf Syntax
apoc.loadldap.myldap.config=<host>:<port> <loginDN> <loginPW>
apoc.conf:
apoc.loadldap.myldap.config=ldap.forumsys.com:389 cn=read-only-admin,dc=example,dc=com password
Then
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.ldap({ldapHost : ""ldap.forumsys.com"", loginDN : ""cn=read-only-admin,dc=example,dc=com"", loginPW : ""password""}
, {searchBase : ""dc=example,dc=com""
  ,searchScope : ""SCOPE_SUB""
  ,attributes : [""cn"",""uid"",""objectClass""]
  ,searchFilter: ""(&(objectClass=*))""
  }) yield entry
return entry.dn,  entry
becomes
Cypher
Copy to Clipboard
Run in Neo4j Browser
call apoc.load.ldap(""myldap""
,{searchBase : ""dc=example,dc=com""
 ,searchScope : ""SCOPE_SUB""
 ,attributes : [""cn"",""uid"",""objectClass""]
 ,searchFilter: ""(&(objectClass=*))""
 }) yield entry
return entry.dn,  entry
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-introspection;"Database Introspection
The APOC Extended library adds extra tools for introspecting the database.
For more on these procedures, see:
Config
Monitoring
SystemDB
Was this page helpful?"
https://neo4j.com/labs/apoc/5/database-introspection/systemdb;"SystemDB
In Neo4j 4.0 the concept of multi-database was introduced. There’s now a database called system which contains some internal information, e.g. configured permissions. Those can be exposed by APOC.
Do not rely on the data structures within system database. They are a non-public implementation details of Neo4j and might change within minor release updates.
Table 1. Procedures
Qualified Name Type Release
apoc.systemdb.graph
``
Procedure
Apoc Extended
apoc.systemdb.execute
``
Procedure
Apoc Extended
apoc.systemdb.export.metadata
Procedure
Apoc Extended
Cypher
isType example
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.systemdb.graph() YIELD nodes, relationships RETURN *;
CALL apoc.systemdb.execute('SHOW DATABASES') YIELD row RETURN row.name as dbName;
CALL apoc.systemdb.execute([""CREATE USER foo SET PASSWORD 'test'"", ""GRANT ROLE myRole TO foo""])
Was this page helpful?"
https://neo4j.com/labs/apoc/5/operational;"Operational
For more information on how to use these procedures, see:
Cypher init script
Logging
Was this page helpful?"
https://neo4j.com/labs/apoc/5/operational/init-script;"Cypher init script
Apoc optionally allows you to run cypher commands after database initialization is finished. This can e.g. be used to ensure indexes/constraints are created up front.
The initializers are defined by Configuration Options using the following naming convention:
Config
Copy to Clipboard
apoc.initializer.<database_name>.<identifier> = <some cypher string>
For each database all initializer strings are ordered by <identifier> and each of them is executed in a separate transaction. If you only have one single initializer for a given database you can omit <identifier>.
As an example we want to
create another db user in system db
create a index for :Person in default db neo4j
add two person nodes in default db neo4j
This is achieved by
Config
Copy to Clipboard
apoc.initializer.system=create user dummy set password 'abc'
apoc.initializer.neo4j.0=create index person_index for (p:Person) on (p.name)
apoc.initializer.neo4j.1=create (:Person{name:'foo'})
apoc.initializer.neo4j.2=create (:Person{name:'bar'})
Was this page helpful?"
https://neo4j.com/labs/apoc/5/config;"Configuration Options
Contents
Location of config options
Reference of config options
Location of config options
All config options from Reference of config options can be provided either in:
environment variables
set via either export key=val or --env settings when used for docker.
conf/apoc.conf
located in the same folder as neo4j.conf
The order of this table matches their config option precedence. E.g. any env setting will override options set in apoc.conf.
APOC Extended internally relies on Apache commons-config for resolving config settings. The meta-configuration is located in src/main/resources/apoc-config.xml.
Reference of config options
Set these config options in $NEO4J_HOME/conf/apoc.conf, or by using environment variables.
All boolean options default to false. This means that they are disabled, unless mentioned otherwise.
Property Description
apoc.couchbase.<key>.uri=couchbase-url-with-credentials
store couchbase-urls under a key to be used by couchbase procedures
apoc.es.<key>.uri=es-url-with-credentials
store es-urls under a key to be used by elasticsearch procedures
apoc.import.file.enabled=false/true
Enable reading local files from disk
apoc.import.file.use_neo4j_config=true/false (default true)
the procedures check whether file system access is allowed and possibly constrained to a specific directory by reading the two configuration parameters dbms.security.allow_csv_import_from_file_urls and server.directories.import respectively
apoc.jdbc.<key>.uri=jdbc-url-with-credentials
store jdbc-urls under a key to be used by apoc.load.jdbc
apoc.mongodb.<key>.uri=mongodb-url-with-credentials
store mongodb-urls under a key to be used by mongodb procedures
apoc.ttl.enabled=false/true
Enable time to live background task
apoc.ttl.enabled.<name_db>=false/true (default true)
Enable time to live background task for a specific db. Please note that this key has to be set necessarily in apoc.conf. If is true TTL is enabled for the db even if apoc.ttl.enabled is false, instead if is false is disabled for the db even if apoc.ttl.enabled is true
apoc.ttl.schedule=<secs> (default 60)
Set frequency in seconds to run ttl background task
apoc.ttl.schedule.<name_db>=<secs> (default 60)
Set frequency in seconds to run ttl background task for a specific db. It has priority over apoc.ttl.schedule. Please note that this key has to be set necessarily in apoc.conf.
apoc.ttl.limit=<number> (default 1000)
Maximum number of nodes being deleted in one background transaction, that is the batchSize applied to apoc.periodic.iterate() during removing nodes
apoc.ttl.limit.<name_db>=<number> (default 1000)
Maximum number of nodes being deleted in one background transaction for a specific db, that is the batchSize applied to apoc.periodic.iterate() during removing nodes for a specific db. It has priority over apoc.ttl.limit. Please note that this key has to be set necessarily in apoc.conf.
apoc.uuid.enabled=false/true (default false)
global switch to enable uuid handlers
apoc.uuid.enabled.<name_db>=false/true (default true)
Enable/disable uuid handlers for a specific db. Please note that this key has to be set necessarily in apoc.conf. If is true UUID is enabled for the db even if apoc.uuid.enabled is false, instead if is false is disabled for the db even if apoc.uuid.enabled is true
Was this page helpful?"
https://neo4j.com/labs/apoc/5/operational/log;"Logging
APOC provides a set of store procedures in order to add log functionality:
Qualified Name Type Release
apoc.log.info
apoc.log.info(message, params) - logs info message
Procedure
Apoc Extended
apoc.log.error
apoc.log.error(message, params) - logs error message
Procedure
Apoc Extended
apoc.log.warn
apoc.log.warn(message, params) - logs warn message
Procedure
Apoc Extended
apoc.log.debug
apoc.log.debug(message, params) - logs debug message
Procedure
Apoc Extended
Was this page helpful?"
https://neo4j.com/labs/apoc/5/graph-updates;"Graph Updates
The APOC Extended library adds extra functionality for writing to the database.
For more information on how to use these procedures, see:
UUIDs
Time To Live (TTL) - Expire Nodes
Generating Graphs
Was this page helpful?"
https://neo4j.com/labs/apoc/5/misc;"Miscellaneous
Cypher brings along some basic functions for math, text, collections and maps.
Static Value Storage
Was this page helpful?"
https://neo4j.com/labs/apoc/5/usage;"Usage
User defined Functions can be used in any expression or predicate, just like built-in functions.
Procedures can be called stand-alone with CALL procedure.name();
But you can also integrate them into your Cypher statements which makes them so much more powerful.
Cypher
Load JSON example
Copy to Clipboard
Run in Neo4j Browser
WITH 'https://raw.githubusercontent.com/neo4j-contrib/neo4j-apoc-procedures/4.0/src/test/resources/person.json' AS url

CALL apoc.load.json(url) YIELD value as person

MERGE (p:Person {name:person.name})
   ON CREATE SET p.age = person.age, p.children = size(person.children)
Was this page helpful?"
https://neo4j.com/labs/apoc/5/introduction;"Introduction
Contents
APOC Editions - Core and Extended
Neo4j 3.x introduced the concept of user-defined procedures and functions. Those are custom implementations of certain functionality, that can’t be (easily) expressed in Cypher itself. They are implemented in Java and can be easily deployed into your Neo4j instance, and then be called from Cypher directly.
As of 5.0 APOC has been split into separate repositories, one being the main, officially supported, APOC Library. The other belonging to APOC Extended. This documentation handles the extended part of APOC.
There are over 150 different procedures and functions in the Extended APOC library. Their purpose is to increase functionality in areas such as data integration, graph algorithms and data conversion.
APOC Name History
Apoc was the technician and driver on board of the Nebuchadnezzar in the Matrix movie. He was killed by Cypher.
APOC was also the first bundled A Package Of Component for Neo4j in 2009.
APOC also stands for ""Awesome Procedures On Cypher""
APOC Editions - Core and Extended
Starting from Neo4j 4.1.1, there are two available versions of the APOC library:
APOC Core
battle hardened procedures and functions that don’t have external dependencies or require configuration. This is also the based of the functionality available in Neo4j AuraDB which lists the available APOC surface in their docs.
APOC Extended
contains additional procedures and functions, which is available when you self-host the database and add the apoc-extended jar.
A list of functions and procedures in APOC Extended can be found in Procedures & Functions.
Starting from Neo4j 5.0.0, APOC Core and Extended are split into 2 separate repos, with only Core being officially supported by Neo4j.
Was this page helpful?"
https://neo4j.com/labs/apoc/5/virtual-resource;"Virtual Resource
Contents
Graph and RDB for the following example
Managing a Virtualized Resource via JDBC
Creating a Virtualized Resource (JDBC)
Querying a Virtualized Resource (JDBC)
Listing the Virtualized Resource Catalog
Removing Virtualized Resources from the Catalog
Export metadata
Managing a Virtualized Resource via CSV files
Creating a Virtualized Resource (CSV)
Querying a Virtualized Resource (CSV)
There are situations where we would like to enrich/complement the results of a cypher query in a Neo4j graph with additional data coming from an external source that we can’t (or don’t want to) load and persist in the graph.
Think for example in a Neo4j graph with a network topology: All the devices, the connections between them, the dependencies, etc. You want to query all the devices in a particular site and return the performance metrics for the last two hours. This is ""time-series data"", and you may not want to import it and persist it in the graph. apoc.dv gives you the option of accessing that information on-demand at query time and combining it seamlessly with the network topology data in your graph.
The APOC Extended library supports the definition of a catalog of virtual resources. A virtual resource is an external data source that neo4j can use to query and retrieve data on demand presenting it as virtual nodes enriching the data stored in the graph. The Virtual Resource Catalog feature combines two APOC elements:
The apoc.load.* procedures that query data from external sources.
The virtual procedures that create transient graph structures which can be returned as the result of a query but are never persisted in the graph.
At a high level, the virtual resource catalog feature decouples the definition of the connection to an external data source and the actual querying. It offers procedures to manage the virtualized resource catalog (create/remove/modify virtualized resources) and also to query them. In the current version there is support for relational (RDB) data sources and CSV files.
Graph and RDB for the following example
This example uses a database stored in Postgres. You can recreate it using this script. It contains just three tables:
We have imported in Neo4j the regions and departments (script to import is provided as annex) but not the towns, which we will virtualize and only retrieve from the RDB on-demand. The graph looks like this (fragment):
Managing a Virtualized Resource via JDBC
Creating a Virtualized Resource (JDBC)
Before we can query a Virtualized Resource, we need to define it. We do this using the apoc.dv.catalog.add procedure. The procedure takes two parameters:
a name that uniquely identifies the virtualized resource and can be used to query that resource
a set of parameters indicating the type of the resource (type), the access point (url), the parameterised query that will be run on the access point (query) and the labels that will be applied to the generated virtual nodes (labels).
We are defining a virtualized resource over a relational database (type: JDBC) accessible locally (url: ""jdbc:postgresql://localhost/communes?user=jb&password=jb"") that will return nodes that we will type as Town and PopulatedPlace - the generated nodes will have two labels (labels: [""Town"",""PopulatedPlace""]). We also provide the SQL query including the parameters that it requires and that will be passed at query time. Finally, we can include an informative description that will help users understanding what the Virtualized resource produces and how to use it. Here is the cypher that creates such virtualized resource:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.catalog.add(""fr-towns-by-dept"", {
  type: ""JDBC"",
  url: ""jdbc:postgresql://localhost/communes?user=jb&password=jb"",
  labels: [""Town"",""PopulatedPlace""],
  query: ""SELECT code, name FROM towns where department = $dept_no"",
  desc: ""french towns by department number""
})
For more details on how to pass the credentials to access the RDB check the Load JDBC documentation.
Querying a Virtualized Resource (JDBC)
Once defined, we can query a virtualized resource by name passing only the required parameters. We use the apoc.dv.query procedure for this. It takes two parameters
the name of the virtualized resource
a map with the parameters required.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.query(""fr-towns-by-dept"", { dept_no: ""73"" })
The query returns a set of virtual nodes generated on demand by running the query defined in the virtualized resource and with the parameters passed in the apoc.dv.query call.
Normally we will want to combine this procedure call with data from the graph in Neo4j. Here is an example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
WITH ""Basse-Normandie"" AS reg_name
MATCH (dep:Region { name: reg_name})-[:HAS_DEPT]->(d:Department)
CALL apoc.dv.query(""fr-towns-by-dept"",{dept_no: d.code}) YIELD node
RETURN node
We may even have the virtualized nodes returned by apoc.dv.query to be linked to the real nodes in the graph providing a richer query result. That’s the purpose of the apoc.dv.queryAndLink method. The apoc.dv.queryAndLink method takes two additional parameters: the node to link the virtual nodes to, and the relationship type to be used for the linkage:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (dep:Region { name: $regionName })-[hd:HAS_DEPT]->(d:Department)
CALL apoc.dv.queryAndLink(d,""HAS_TOWN"", ""fr-towns-by-dept"",{ dept_no: d.code }) YIELD path
RETURN *
The apoc.dv.queryAndLink method returns a path formed by the node passed as first parameter, and the virtual node and relationship returned from the virtualized resource.
Below is an example of use of the previous query in Bloom. All the blue nodes representing the Towns in a given department are virtual ones retrieved on demand using a search phrase over the previous query.
Listing the Virtualized Resource Catalog
The apoc.dv.catalog.list procedure returns a list with all the existing Virtualized resources and their descriptions. It takes no parameters.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.catalog.list()
Removing Virtualized Resources from the Catalog
When a Virtualized Resource is no longer needed it can be removed from the catalog by using the apoc.dv.catalog.remove procedure passing as parameter the unique name of the VR.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.catalog.remove(""vr-name"")
Export metadata
To import dv catalogs in another database (for example after a ./neo4j-admin backup and /neo4j-admin restore), please see the apoc.systemdb.export.metadata procedure.
Managing a Virtualized Resource via CSV files
Creating a Virtualized Resource (CSV)
The process to define a Virtualized Resource over a CSV file is identical to the one described for relational ones, with the exception of the query parameter.
Let’s think of an example where we have a product catalog in the graph but there is some additional information about the products like the current stock, the unit price, the reorder level that is for some reason maintained in a separate store outside the graph (a file in this case). We’ll show how to seamlessly combine the two bits of information using apoc.dv.
Let’s look at another example where we define a virtualized resource over a CSV file (type: CSV) accessible via HTTP (url: ""http://data.neo4j.com/northwind/products.csv"") that will return nodes that we will type as ProductDetails (labels: [""ProductDetails""]). When it comes to the query, there is not a standard query language like in the case of Relational DBs so we use a cypher-like notation using the map prefix to refer to the records returned by parsing the CSV file (query: ""map.productID = $prod_id""). Note that the file could be also accessed locally using the file:// protocol instead of http://.
Here is the cypher that creates such virtualized resource:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.catalog.add(""prod-details-by-id"", {
  type: ""CSV"",
  url: ""http://data.neo4j.com/northwind/products.csv"",
  labels: [""ProductDetails""],
  query: ""map.productID = $prod_id"",
  desc: ""Product Details By ID""
})
Querying a Virtualized Resource (CSV)
Identical to the JDBC case, we can query a virtualized CSV resource by name passing only the required parameters:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.dv.query(""prod-details-by-id"", { prod_id: ""3"" })
The query returns one virtual nodes in this case generated on demand by parsing the CSV file defined as a virtualized resource and filtering the records by applying the expression in the query parameter with the parameters passed in the apoc.dv.query call (showing the table view of the virtual node returned).
An example of combining this procedure call with data from the graph in Neo4j:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Product { productName: ""Northwoods Cranberry Sauce""})
CALL apoc.dv.query(""prod-details-by-id"",{ prod_id: p.productId }) YIELD node as details
RETURN p.productName as prodName,
  apoc.any.property(details, ""unitsInStock"") as unitsInStock,
  apoc.any.property(details, ""reorderLevel"") as reorderLevel,
  apoc.any.property(details, ""quantityPerUnit"") as quantityPerUnit,
  apoc.any.property(details, ""unitPrice"") as unitPrice
Producing the following output:
In this case we are producing a tabular result combining data from the graph with data retrieved on demand from the virtualized CSV resource. Notice that in order to access the values of properties in virtual nodes we need to use the apoc.any.property function.
If we wanted to have the virtualized nodes returned by the query linked to the real nodes in the graph, we would use the apoc.dv.queryAndLink method as follows:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Product { productName: ""Northwoods Cranberry Sauce"" })
CALL apoc.dv.queryAndLink(p, ""HAS_DETAILS"", ""prod-details-by-id"", { prod_id: p.productId }) YIELD path
RETURN *
Producing this output in the Neo4j browser:
Was this page helpful?"
https://neo4j.com/developer/kb/categories/server;"Articles tagged as server
Connecting via Bolt when using Tunnelling or NAT
This article aims to provide a method to connect to the Neo4j database over bolt, via Neo4j browser where the bolt host is different from the IP of the instance…
Read more
bolt host url nat tunnel
Database Compaction in 4.0 using Neo4j-admin copy
This article demonstrates using the neo4j-admin copy tool to reclaim un-used space occupied by neo4j store files. 1). Adding 100k nodes: foreach (x in range (1,100000) | create (n:testnode1 {id:x})).…
Read more
store compaction
Limiting Bolt Threads vs Connections
Given high levels of read/write transaction requests, some ingress transactions may be rejected by the Neo4j server and the below error may be reported in the Neo4j debug.log: Whilst the…
Read more
cpu core pid thread bolt connection
Neo4j 3.5 to 4.x Migration Help and Resources
This guide is designed to provide key details and links on various 3.5 to 4.x migration resources. With this document, you should be able to read and/or find everything you…
Read more
upgrade migration
Split between APOC Core and APOC Extended
With the release of Neo4j 5, the APOC library has been split into two separate packages: APOC Core and APOC Extended. APOC Core Neo4j 5 brings substantially more support to…
Read more
apoc"
https://neo4j.com/developer/kb/assign-or-restrict-cpu-cores-to-neo4j-process;"Assign or restrict CPU cores to Neo4j process
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cpu core pid thread
Operating system run performance-critical applications on multi-core processors using something called ""processor affinity"" or ""CPU pinning"". This feature ""binds"" a running process to particular CPU core(s), which can be beneficial for example in reducing CPU cache misses. Also, when multiple processes communicate via shared memory, scheduling both processes on the cores in the same NUMA domain may speed up their performance.
Upon initialisation, Neo4j will create an affinity mask (attachment list) to all available cpu cores, i.e. it will attach to all cores available. It may sometimes be desired to restrict or specify these for the Neo4j process, at initilisation or at runtime. Below steps were followed on a Linux Redhat 6.1 and 7.6 versions. Similar steps may be valid for other Linux flavours.
Execute the lscpu command, which yields an output similar to below
Amongst other info, we see the comma separated list of CPUs currently online, in this case 0,1. Note that this may be a binary, decimal, or hexadecimal number. In this case, it is decimal.
Get the Neo4j process ID. The cpu core affinity of this process can now be viewed by executing:
Shell
$ taskset -p pid*
that this outputs a decimal, which can be translated into binary. Alternatively, the binary output can be directly obtained by executing taskset -cp pid. The above shows an affinity mask of 3, which in binary is 1,1, i.e. CPU cores 0 and 1. This also shows us that by default, the Neo4j process executes on all available CPU cores by default.
We can now assign certain cpu cores to a running Neo4j process by executing:
Shell
$ taskset -cp <desired cpu(s) comma separated list> pid*
The above example restricts the Neo4j process to the CPU core with logical ID 0.
References:
http://manpages.ubuntu.com/manpages/trusty/en/man1/taskset.1.html
http://xmodulo.com/run-program-process-specific-cpu-cores-linux.html
Was this page helpful?"
https://neo4j.com/developer/kb/limiting-bolt-threads-vs-connections;"Limiting Bolt Threads vs Connections
Author Umar Muzammil Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cpu core pid thread bolt connection
Given high levels of read/write transaction requests, some ingress transactions may be rejected by the Neo4j server and the below error may be reported in the Neo4j debug.log:
ERROR [o.n.b.r.MetricsReportingBoltConnection] Unable to schedule bolt session <session_id> for execution since there are no
available threads to serve it at the moment. You can retry at a later time or consider increasing max thread pool size for
bolt connector(s). Task java.util.concurrent.CompletableFuture$AsyncSupply@9bde0657 rejected from
org.neo4j.bolt.runtime.CachedThreadPoolExecutorFactory$ThreadPool@95fe540f[Running, pool size = 400, active threads = 400,
queued tasks = 0, completed tasks = 197942]
Whilst the above suggested bolt thread pool size, is configurable in neo4j.conf, one might expect the total number of bolt connections to be equal to active + idle bolt connections (as reported by metrics neo4j.bolt.connections_running and neo4j.bolt.connections_idle), to always add up to less than the configured value of dbms.connector.bolt.thread_pool_max_size. This however, is a misconception, which this article aims to address.
Difference between a bolt thread and a bolt connection:
A bolt thread is a process executor part of the cpu allocated by the Neo4j server to execute a given task. A bolt connection is a request placed to the Neo4j server, from a client driver session. In a JVM server, acceptor threads on a listen socket accept connections and put them into a connection queue. Request processing threads in a thread pool then pick up connections from the queue and service the requests. In the thread-per-request model, the thread is only associated while a request is being processed, i.e. the service needs fewer threads to handle the same number of client connections. Since threads use significant resources, that means that the service will be more scalable.
The dbms.connector.bolt.thread_pool_max_size metric reports the maximum size of the bolt thread pool, where limiting the thread pool does not limit the total number of connections. A thread can handle numerous connections. The bolt thread pool size only limits how many bolt threads, neo4j server can concurrently handle. If a connection is inactive, then no thread is assigned to that connection. Currently there is no limit for idle connections on server. A connection pool size limit is however configurable at the client during driver creation. Since by default there is no upper limit for connections, the driver connection pool size can rise to the total available connections on the machine’s CPU.
What are idle bolt connections?
The metric name neo4j.bolt.connections_idle may suggest that the idle bolt connections are those opened up by a completed bolt transaction but once that transaction completes, the thread is kept in an open but idle state till its closed off by the thread pool.
Above is a misconception, since setting dbms.connector.bolt.thread_pool_max_size in neo4j.conf, limits the peak concurrent thread’s connections that are being worked on (represented by the neo4j.bolt.connections_running metric). Yet idle connections, which are not being worked on, are not limited by this config. A thread pool configuration (server side) cannot be used to regulate connections (client side).
Why is the idle connections metric named neo4j.bolt.connections_idle?
Because those connections are established by drivers and drivers reuse connections over a driver’s lifetime. The bolt connection pool is a driver configuration. Thread pool is a server configuration to specify what it is the peek capacity to handle jobs from connections. If a connection has no jobs, then it is idle on client side. The server does not control these idle connections. Only driver can close them. Further, the server does not have an upper limit of connection count and idle connections should not contribute to cpu usage.
How might one control the maximum number of connections opened by the client side driver?
Driver connection limitations are configurable via the MaxConnectionPoolSize, MaxConnectionLifetime and ConnectionAcquisitionTimeout parameters. An example configuration for the Neo4j Java driver would be:
Java
Copy to Clipboard
Config config = Config.builder()
            .withMaxConnectionLifetime( 30, TimeUnit.MINUTES )
            .withMaxConnectionPoolSize( 50 )
            .withConnectionAcquisitionTimeout( 2, TimeUnit.MINUTES )
            .build();
Driver driver = GraphDatabase.driver( uri, AuthTokens.basic( user, password ), config );
References:
https://neo4j.com/docs/operations-manual/current/performance/bolt-thread-pool-configuration/#_how_thread_pooling_works
https://docs.oracle.com/cd/E19146-01/821-1834/gdpil/index.html
https://stackoverflow.com/questions/15217524/what-is-the-difference-between-thread-per-connection-vs-thread-per-request
Was this page helpful?"
https://neo4j.com/developer/kb/categories/operations;"Articles tagged as operations
A light weight approach to validating network port connectivity
If it becomes necessary to validate, particularly in a clustered environment whether Causal Cluster or High Availability, whether or not 1 instance can talk to another instance on a given…
Read more
ports causal-cluster
A lightweight approach to testing the Neo4j REST API with Authentication
This article will show examples of how to test the Neo4j REST API for authentication via: Google Chrome Advanced REST Client Linux curl command The Neo4j REST API describes each…
Read more
http authentication rest security
Using Amazon CloudWatch to monitor Neo4j logs
This article describes how to set up Amazon CloudWatch. Amazon CloudWatch Logs allows you to monitor, store, and access your Neo4j log files from Amazon EC2 instances, AWS CloudTrail, or…
Read more
aws logging monitoring
An approach to parsing the query.log
When one has enabled query.log through Neo4j Enterprise parameter dbms.logs.query.enabled the included bash shell script can be used to quickly parse the log and identify the top 10 most expensive…
Read more
query.log logging
An explanation of the E_COUNT_EXCEEDED WARNing message in Neo4j’s debug.log.
The document aims to explain the E_COUNT_EXCEEDED WARNing messages that Neo4j can write to its debug.log. It also provides some monitoring and troubleshooting options. When running a Neo4j Causal Cluster,…
Read more
logging performance raft causal cluster
An explanation of entries in query.log
This document aims to provide descriptions of components of the query.log logfile located at $NEO4J_HOME/logs. Note that the following configs in conf/neo4j.conf need to be uncommented for the query log…
Read more
logging query.log monitoring
An overview of the system database
Neo4j 4.0 and higher versions support the management of multiple databases within the same DBMS. All these databases are controlled through a special database called the system database. This article…
Read more
system
Analyzing a java heap dump
The purpose of this article is to help you go through the acquired heapdump with Eclipse MAT. It covers how to parse a large heap files and what to look…
Read more
heap-dump out-of-memory monitoring
Assign or restrict CPU cores to Neo4j process
Operating system run performance-critical applications on multi-core processors using something called ""processor affinity"" or ""CPU pinning"". This feature ""binds"" a running process to particular CPU core(s), which can be beneficial…
Read more
cpu core pid thread
Backup Failed. Unexpected error: Base directory for SSL policy with name 'default' does not exist.
This article is based on a defect report with a suggested workaround until a fix becomes available. When running backup (full or incremental) you may encounter the following error in…
Read more
backup error encryption
Throttling Bolt Requests
When large amounts of data are sent between a Neo4j database and a client (typically large query results, from server to client), there are a few hidden throttling mechanisms that…
Read more
performance configuration bolt tcp
Can I use NFS as my filesystem or datastore storage?
The short answer is no. Although this may seem harmless, the reason for this is not performance related, but rather for control over locking files. NFS and other filesystems that…
Read more
storage disk filesystem unix operations
Capacity Planning Example
Here is a back of the napkin example of capacity planning for a Neo4j workload for the following list of requirements: Requirements Analysis 1) Estimating an initial database size of…
Read more
storage disk filesystem unix capacity
Change logging levels in Neo4j Embedded
In order to change the default logging levels in a Neo4j embedded instance, you must edit/define the configuration file, which is XML. In particular the file is neo4j-logback.xml. The neo4j-logback.xml…
Read more
logging embedded configuration
Changes to metrics.csv reporting from 2.x to 3.x
Metrics reporting is an Enterprise feature which upon enablement allows for the creation of .csv files at a specified interval to record key metrics. This is described in detail at…
Read more
metrics csv monitoring
Retired: Changing your Garbage Collection Method to G1
When to Use G1: By default, Neo4j versions 2.2 and earlier use Concurrent Mark and Sweep (CMS) for garbage collection. Customers with large heaps or who are seeing unacceptable garbage…
Read more
garbage collection heap memory jvm
Checkpointing and Log Pruning interactions
Overview Checkpointing is the process of flushing all pending page updates from the page cache to the store files. This is necessary for ensuring that the number of transactions that…
Read more
checkpoint pruning logging metrics configuration
Example of using the Command Expansion on Windows
The Command Expansion feature, introduced in Neo4j 4.2, is a security feature to avoid having configuration parameters being written in the neo4j.conf file in plain text. The commands are executed…
Read more
system command expansion
Configure Neo4j to authenticate users from different OUs using the Active Directory attribute samAccountName
Beginning with Neo4j version 3.2.2, it is possible to authenticate using the Active Directory attribute samAccountName as opposed to the LDAP Display Name attribute. This is described in detail in…
Read more
samaccountname account authentication authorization
Configuring Neo4j to operate on privileged ports
In some environments, users are required to run Neo4j on ports lower than 1024 due to corporate policies. The following is a sample configuration showing how to configure Neo4j 3.5…
Read more
server ports
Configuring Remote JMX monitoring
In order to enable JMX Remote monitoring, edit the neo4j.conf file in Neo4j 3.1.x versions and uncomment the following lines: After uncommenting the above lines, restart neo4j. If the neo4j…
Read more
jmx monitoring
Control number of file handles created per Lucene Index
In the more recent Neo4j versions (3.4 onwards), the number of file handles opened by Neo4j may seem to increase compared with that in older versions. Native indexes require a…
Read more
indexing lucence open files cpu memory
Database was successfully initialized, but failed to start
Sometimes when the database does not start it could be something as simple as unnecessary characters in the neo4j.conf file. For example if you add space and/or tab characters to…
Read more
configuration
How to diagnose locking issues
Since Neo4j 3.4 it’s possible to better understand locking issues caused by concurrent query. This KB article will not detail the basics of locking in Neo4j. We assume a situation…
Read more
performance tuning write read lock
Diagnosing network latency in a Causal Cluster using MTR
MTR is a simple ICMP based test combining ping and traceroute. The following demonstrates usage of the MTR trace tool to diagnose network latency and packet loss in a Causal…
Read more
cluster latency monitoring
Displaying Query CPU Utilization and Allocated Bytes in Query log
In Neo4j 3.3 and prior versions, when query logging is enabled with the following configuration parameters: The log is written with output as shown below: Note that it displays CPU…
Read more
cpu query.log configuration
Docker ""Permission Denied"" Error
When a docker instance is started, one could get a permission denied error such as and may fail to start. Docker used to run as root and now has been…
Read more
docker permission denied user
Dump the Contents of a Transaction Log
If there is a need to look through the transaction logs, particularly to see if/when a node or relationship (or property) with a given ID was touched, you will need…
Read more
transaction log
Enabling GC Logging
What is Garbage collection and why enabling it? A garbage collection event is a complete pause of the java application (ie: neo4j-server). It can be identified in the debug.log as…
Read more
logging garbage collection heap memory jvm
Enabling TLSv1.2 with IBM JDK9
Neo4j 3.4.0 only supports TLSv1.2 by default. IBM JDK9 uses the TLSv1 protocol by default. When attempting to run cypher-shell, users will be unable to connect to Neo4j. To enable…
Read more
jdk security tls cypher-shell
Explanation of data/log/console.log error of 'TLS certificate error occurred, unable to start server: Neither RSA, DSA nor EC worked…'
On bin/neo4j start the data/log/console.log may log an error similar to Neo4j allows for the configuration of HTTPS certificates via the parameters in conf/neo4j-server.properties. The following are the default values:…
Read more
server security
Explanation of error ""Database constraints have changed (txId=xxxxx) after this transaction (txId=yyyyy) started, which is not yet supported""
The following error, via bin/neo4j-shell: or as logged in log/debug.log (3.x) or graph.db/messages.log (2.3.x): can be explained by the following scenario: where the exception is thrown at Oct-19-2012 09:05 by…
Read more
constraint
Explanation of Error: db fails to start with Caused by: org.neo4j.token.api.NonUniqueTokenException: The PropertyKey NamedToken
When attempting to start Neo4j and one is running a Neo4j 4.0.x release and where x is ⇐2 the following error may be encountered and logged in logs\debg.log This error…
Read more
upgrade
Explanation of error ""DeadlockDetectedException: ForsetiClient[0] can’t acquire ExclusiveLock… …""
Under specific scenarios a DeadlockDetectedException may be encountered and the behavior is described at https://neo4j.com/docs/java-reference/current/transaction-management/#transactions-deadlocks. When a DeadlockDetected is encountered one option is to simply retry the statement. As a…
Read more
deadlock lock
Explanation of error NoClassDefFoundError: org/neo4j/kernel/impl/util/JobScheduler
Upon upgrading to Neo4j 3.3, if you were previously using APOC, and did not download and install the version of APOC for 3.3 bin\neo4j start will fail. The contents of…
Read more
apoc upgrade
Explanation of error: procedure is not available due to having restricted access rights, check configuration
Commencing with Neo4j 3.2 when running a stored procedure, for example this may error with The cause of this error is as a result of not configuring the security extensions.…
Read more
procedures apoc security
Explanation of error ""Record id 65536 is out of range [0, 65535]""
When running a Cypher statement that creates a new relationship type, for example one may encounter an error which is logged in the $NEO4J_HOME/logs/debug.log as and they key part from…
Read more
relationship record-id
Explanation of error ""Unrecognized transaction id. Transaction may have timed out and been rolled back""
When submitting a request via the Neo4j Transactional Cypher HTTP endpoint, one may encounter the following error This error may occur as a result of the transactions expiration date/time being…
Read more
cypher http
Explanation of lucene-1.0: Too many open files error
If one encounters a 'Too many open files' error in their $NEO4J_HOME/logs/debug.log similar to this can be addressed by setting in your $NEO4J_HOME/conf/neo4j.conf and parameter Without this parameter for each…
Read more
index open-files
Explanation of start failure ""java.lang.NoClassDefFoundError: org/neo4j/kernel/impl/logging/LogService""
Upon starting Neo4j 3.5 if one encounters the following error in the logs/neo4j.log this is usually indicative of a incompatible APOC jar file installed into $NEO4J_HOME/plugins. With Neo4j 3.5.0 the…
Read more
upgrade apoc logservice start
Four ways to check the consistency of a Neo4j graph
When it comes checking the inconsistencies in your graph, there are four methods to do. This article describes them below: 1. The easiest approach is it to utilize the check-consistency=true…
Read more
consistency backup
Getting a JVM heap dump
This document provides the process of creating a heap-dump on a java machine to investigate potential memory leaks. Although a heap dump will be auto generated when OutOfMemoryError is thrown…
Read more
jvm memory heap dump
Helpful Commands When Supporting Neo4j
Top 50 Slowest queries from Query log: Find Longest GC Pauses in debug or messages log: Strip all comments / empty lines of neo4j.conf file: Find a class within a…
Read more
cli support
Retired: How can I skip Consistency Check during Backup?
Backups in Neo4j automatically run a consistency check against the backed-up store. The backup itself does not take overly long, but the consistency check can take much more time to…
Read more
backup consistency performance
How deletes work in Neo4j
Neo4j uses logical deletes to delete from the database to achieve maximum performance and scalability. To understand how this might appear to an operator of the database, lets take a…
Read more
delete disk storage
How do I allow for authentication using Active Directory attribute samAccountName
Commencing with Neo4j 3.2.2, it is now possible to authenticate using Active Directory attribute samAccountName as opposed to the LDAP Display Name attribute. The following conf/neo4j.conf parameters must be enabled…
Read more
samaccountname account authentication authorization
How do I authenticate with cypher-shell without specifying the username and password on the command line
When using $NEO4J_HOME/bin/cypher-shell at the command line and authentication is enabled via the setting $NEO4J_HOME/conf/neo4j.conf: a username and password can be provided on the command line using the parameters -u…
Read more
cypher-shell authentication
How do I automate the copy of auth files in a clustered environment
In a clustered Neo4j implementation, user authentication files are recorded in each instance at $NEO4J_HOME/data/dbms. Since this defined per each instance in the cluster if for example you change the…
Read more
logging server
How do I configure init and max java heap when running bin/neo4j-backup
When running $NEO4J_HOME/bin/neo4j-backup if a Java out of heap/memory error occurs you may want define the init and max Java heap to be used by neo4j-backup. The default behavior is…
Read more
backup heap out-of-memory operations
How do i configure Neo4j so that data/graph.db/messages.log is automatically rotated
As tested and verified with Neo4j 2.3.0, the data/graph.db/messages.log, its size and number of rotated archives is governed by the following parameters in the conf/neo4j.properties file With the above default…
Read more
server configuration
How do I convert Neo4j logs from base UTC to local timezone
With the introduction of Neo4j 3.3.1 it is possible to represent date timestamps in your $NEO4J_HOME/logs/* in either UTC or SYSTEM timezone through the implementation of dbms.logs.timezone However for prior…
Read more
logs temporal
How do I display date and time of when neo4j was started and other metrics
The following Cypher will utilize the JMX metrics as part of 3.1 Enterprise and display the date/time when Neo4j was started. which will produce output similar to: In the above…
Read more
functions apoc jmx
How do I enable Java Flight Recorder and view the Results
Java Flight Recorder can be used to capture low level Java properties and run-time data about Java processes, for example Neo4j. Per https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr002.html JFR can be activated by configuring JVM…
Read more
configuration jvm
How do I enable remote HTTPS access with Neo4j 3.0.x
With 3.0.x to enabled remote clients to connect to a HTTPS enabled browser the following parameters in the $NEO4J_HOME/conf/neo4j.conf need to be changed from the default of to The change…
Read more
https connection
How do I log parameter values into the query.log file
Neo4j 3.0 introduced the ability to log the value of query parameters in the log/query.log file. The settings to control this feature are located in the conf/neo4j.conf file. To enable…
Read more
logging parameters query-log
How do I quickly identify long gc pauses via the messages or debug logs
Java Garbage Collection (gc) pauses are monitored by the MonitorGc process in Neo4j, and recorded in the $NEO4J_HOME/logs/debug.log ( or $NEO4J_HOME/data/graph.db/messages.log for Neo4j v2.3.x and prior). To quickly find the…
Read more
garbage-collection
How do I quickly switch between multiple graphs without modifying neo4j.conf?
If you have multiple graphs set up and want to quickly switch between each without modifying dbms.active_database in conf/neo4j.conf, you can accomplish this with a neo4j restart and with the…
Read more
configuration
How do I run Consistency Check Manually?
If you skip the Consistency Check part of neo4j-backup, or you want to check that all is well with a data store, you can run the tool against an offline…
Read more
backup consistency performance operations consistency-check
How do I recover from No space left on device
If one does not routinely monitor the disk space usage on a Neo4j server one may encounter a 'No space left on device' (for linux implementation) or a 'Low Disk…
Read more
disk disk-space
How to avoid using excessive memory on deletes involving dense nodes
In situations where you know you need to delete a bunch of nodes (and by rule their relationships as well), it can be tempting to simply use DETACH DELETE and…
Read more
cypher oom
How to collect Neo4j logs
When raising Neo4j Support cases, it is important to upload Neo4j logs. This allows the Neo4j Support Engineers to efficiently begin working on the support case. The following log files…
Read more
logs
How to configure mixed-mode security (native and LDAP) in Neo4j
For environments where you need both LDAP authentication as well as some native user accounts, there is a way to allow this in Neo4j 3.1 and newer. Use the configuration…
Read more
security ldap
How to configure off-heap transaction state
Commencing with Neo4j 3.5, it is possible to store some of transactions' data in off-heap memory. This can help to reduce GC pressure and/or prevent OOM crashes in a limited…
Read more
memory performance
How to estimate initial memory configuration
The initial and eventual memory configuration parameters can be a moving target, based on how your store changes in size and how your workload increases or changes over time. This…
Read more
heap memory jvm page-cache cache
How to fix ""Cannot close the PageCache while files are still mapped""
Incorrect file permissions on store files It is common to start the database as different users, this can leave store files owned by other user ids. ( e.g. root )…
Read more
shutdown page-cache
How to generate sysinfo output from Cypher
If you need to generate the equivalent output from command :sysinfo as run from the Neo4j Browser at http://localhost:7474 this can be achieved by running the following Cypher To which…
Read more
cypher sysinfo
How to logrotate neo4j.log file
The neo4j.log file is a redirection to STDOUT. When you implement a default logrotate strategy, Neo4j will not be able to write to that file anymore after a rotation. Solution…
Read more
logs
Retired: How to manually clear the Node and Relationship Cache
When troubleshooting transient issues or testing out queries on warm vs. cold cache, you may want to try clearing out the cache without necessarily restarting the Neo4j database. To achieve…
Read more
performance cache warmup
How to monitor Neo4j with Prometheus
Commencing with the release of Neo4j Enterprise 3.4, one can now use the open source monitoring tool Prometheus to monitor Neo4j. The following article details a basic Prometheus implementation to…
Read more
monitoring metrics
How to properly shutdown a Neo4j database after receiving the message took more than 120 seconds to stop
The neo4j script under the bin/ directory of any standard Neo4j install is the primary means of shutting down a running Neo4j instance. That script accepts a stop argument that…
Read more
installation server
How to Setup Neo4j Backup Wrapper Script
Read more
backup
How to Setup Neo4j to Startup on Linux Server Reboot
If you want to emulate the Neo4j RPM service with a tar installation on Linux systems, do the following steps: As root: Copy the $NEO4J_HOME/bin/neo4j script file to /etc/init.d Edit…
Read more
startup linux
Solving the ""Store copy failed due to store ID mismatch"" error
It is possible that after seeding a cluster or restoring from a backup, you may encounter the following error while starting your cluster: In most of the cases, this issue…
Read more
cluster
How to Use the Debug Log Parser Script
For analysis of the Neo4j debug.log, read this guide for using the debugInfo.sh parser script. What is the this script? The debug.log is quite verbose and contains a lot of…
Read more
debug
Increasing Systemd Thread Limits
Problem In some high workload, and large scale multi-database environments, you may find that your Systemd unit configuration limits the maximum number of processes (""tasks"") too low for your use…
Read more
configuration linux systemd
Index limitations and workarounds
In this article we discuss index providers and what limitations and workarounds there are. There are two index types in Neo4j, btree and full-text. This article target btree indexes, up…
Read more
indexing
Installing Neo4j Database on Debian or Ubuntu fails with ""The following packages have unmet dependencies""
Installing Neo4j Database on Debian or Ubuntu fails with the error: Why is this happening? The apt package manager is not handling multiple versions of a package, in this case…
Read more
installation
Large Delete Transaction Best Practices in Neo4j
In order to achieve the best performance, and avoid negative effects on the rest of the system, consider these best practices when processing large deletes. Start by identifying which situation…
Read more
cypher transaction memory garbage collection heap delete
Linkurious bolt configuration
Default Linkurious configuration contains the following snippet in the production.json configuration file: With the documentation stating the following: Where the URL can be set to http/https/bolt/bolt+routing. However, using the above…
Read more
bolt drivers linkurious
Lock Manager Differences Explained
Work in Progress Community: uses Java intrinsic locks, i.e. ’synchronized’. this might not perform that well on multiprocessor machines uses Thread.sleep() and Thread.interrupt() to wait for locks. this involves context…
Read more
lock performance
Long GC Pauses caused by application code calling System.gc()
When investigating the cause of long garbage collection cycles, it is often useful to enable GC logging. You can do so by following the product documentation. Once this is enabled,…
Read more
logging garbage collector heap memory jvm operations
Manually Merging neo4j-wrapper.conf into neo4j.conf in Neo4j 3.1
Neo4j 3.1 takes the configuration changes made in Neo4j 3.0 a step further, and ships with a single configuration file: conf/neo4j.conf. This is the result of merging the contents of…
Read more
configuration upgrade
Manually Migrating Configuration Settings from Neo4j 2.x to Neo4j 3.x
One of the major changes in Neo4j 3.0 was the reworking of configuration files and the individual configuration setting naming convention to make it more consitent and managable going forward.…
Read more
configuration upgrade migration
Migrating Explicit Lucene Indexes to Native Schema Indexes
Given that there are still some customers on the older Neo4j releases that utilize legacy/explicit indexes, we will discuss a few pointers here on how to convert these indexes to…
Read more
lucene index legacy explicit capacity schema full-text
How do I establish a simple HTTP Server local to my Neo4j Instance to serve CSV files
When using LOAD CSV one can define the source file to be either at a local file system (i.e load csv from 'file:///…' ) or a webserver ( i.e. load…
Read more
load csv http webserver
Retired: Modifying the http.log Format on Neo4j 2.x
Prior to Neo4j 3.0, the http.log format was controlled by neo4j-http-logging.xml. The default format works fine, except when you need to diagnose problematic long-running queries. The HTTP requests to the…
Read more
http logging
Run multiple Causal Clusters locally using Docker
It’s rather easy to run multiple causal clusters on the same server or machine. You need to ensure: Each cluster needs to run on its own Docker network Overlapping port…
Read more
docker causal cluster
neo4j-admin load causes ""Not a valid Neo4j archive""
When using neo4j-admin load for loading a .dump file, following error is observerd: Sometimes this has nothing to do with the formatting of the .dump file as indicate by Not…
Read more
dump load neo4j-admin linux
Neo4j behaviour when running out of disk space (3.4+)
Following the improvements on the recovery process after an instance runs out of disk space introduced in v3.4.0, this article aims to offer a view on the behaviour of Neo4j…
Read more
transaction consistency disk-space disk
Neo4j’s commit process explained
This article will try to guide you through Neo4j’s commit and replication processes both for single instances and causal clusters. Single Instance When you call tx.commit(), the transaction will go…
Read more
transaction commit cluster
Neo4j current transaction commit process order
Transactions in Neo4j use a read-committed isolation level, which means they will see data as soon as it has been committed and will not see data in other transactions that…
Read more
transaction commit
Neo4j Desktop password change failure
This document provides info and resolution for the error message on a clean install of Desktop 1.0.2x, Neo4j DB version 3.3.x mentioning ""Database failed to create: Error: Could not change…
Read more
logging query monitoring desktop
Bulk Import / Backups into running 4.0 instances
Neo4j 4.0 allows for multiple running databases. You can use neo4j-admin import or neo4j-admin restore to import or restore a database into a new database on a running 4.0 instance.…
Read more
import-export operations
Neo4j Security Benchmark
Read more
operations security configuration
Neo4j specific http request user agent strings
For those APOC commands that retrieve data using HTTP/HTTPS, and or running Cypher LOAD CSV the request will be sent with Neo4j specific user-agent/browser identifiers. Below is an example log…
Read more
load-csv apoc user-agent webserver logging
Neo4j Streams - Kafka Integration - List of Must Gather for Troubleshooting
When troubleshooting issues on Neo4j Streams, use the below list of must gather information points to help investigating. Which Plugin/Module are you using? Neo4j Streams Source Neo4j Streams Sink Neo4j…
Read more
troubleshooting
Parsing json query logs
There are times when we have to examine a query log in order to find longest running queries and/or other problem queries such as those with missing indexes or when…
Read more
cypher query tunning
Getting ""Permission Denied"" errors after using neo4j-admin commands
If you have leveraged Debian or RPM Packages to install Neo4j on Linux (or used one of the Public Cloud Marketplace offerings), you need to be careful of file and…
Read more
permissions rpm neo4j-admin linux debian
Preserving the Neo4j pagecache across database restarts
Commencing with Neo4j 3.4 and as a result of PR 10957, and when using Neo4j Enterprise the Neo4j pagecache will be preserved across database restarts and as such a need…
Read more
page-cache
Query to kill transactions that take longer than X seconds and doesn’t contain certain keywords
In Neo4j we currently have the configuration property referred to as execution guard: that can be set automatically to kill transactions that take more than “x” seconds (x is equal…
Read more
timeout cancel query cypher
Recreating Indexes and Constraints on 3.5
This article describes the process to drop and recreate all indexes and constraints on 3.5.x. This is a recommended step after upgrading from versions earlier then 3.5 so that all…
Read more
indexing constraint upgrade
Redirect Neo4j logs to sysout (using rsyslog)
Sometimes - due to organizational requirements, security, indexing or plain convenience - we want to output all of our application logs to Linux’s sysout. While Neo4j doesn’t offer this feature,…
Read more
logging
Requirement makes database unavailable: Database available --- INITIALIZED diagnostics START ---
When running neo4j-admin backup, the debug.log shows a message that appears to indicate that the database restarted; however, this is not the case. Let’s explain why this message is showing…
Read more
backup
Sending Neo4j messages to a Slack channel
Although not specific to Neo4j and this knowledge base document is provided as a convenience, if your environment has a Slack implementation, then Slack provides an API to allow you…
Read more
logging operations backup
How to specify a separate debug.log for the backup process?
When running neo4j-admin backup on a running Neo4j instance the backup logs are also written into the existing Neo4j instance debug.log and can get confusing as to which line items…
Read more
backup configuration neo4j.conf debug.log
Startup failure due to misconfigured unmanaged extensions or plugins
Occasionally, following upgrades, one might encounter Neo4j server initialisation failure due to an exception similar to: This exception is usually thrown in following situations: When the plugins directory (by default…
Read more
unmanaged extension plugin startup
Stopping the Neo4j docker image in order to restore from a backup
In a neo4j docker installation, the neo4j-admin restore requires the neo4j service to be stopped as one can’t do a restore on a running database. Subsequently, running as a docker…
Read more
docker restore backup
Store Format Versions Reference Guide
In some situations, you may see a log message or exception that refers to a store format version, and it is not clear which Neo4j store format it is referring…
Read more
store version
Explantion of ""storeId is different from this machine"" error
If you encounter a ""Failed to serve TxPullRequest for … storeId xxxxxx because that storeId is different from this machine with Store…"" in your $NEO4J_HOME/logs/debug.log similar to: This means that…
Read more
causal-cluster
Understanding Database Growth
The easiest way to determine the size of your graph is through the filesystem and summing up the size of the files named *store.db*. For example on linux implementations one…
Read more
database growth copy-store operations
Understanding logical logs and effects of parameters keep_logical_logs and logical_log_rotation_threshold
Neo4j maintains logical logs for incremental backup and cluster consistency. The logical logs are named as follows: When one runs a database backup, via bin/neo4j-backup, if the -to <target directory>…
Read more
server configuration
Understanding memory configurations for neo4j-admin backup
When using bin\neo4j-admin backup to backup a Neo4j database, Neo4j Support recommends explicitly defining the JVM heap size and pagecache memory to be used by the backup JVM process. If…
Read more
neo4j-admin backup
Understanding transaction and lock timeouts
One way to handle runaway queries is to impose a time limit that will terminate a query when exceeded. There are some subtleties here that need to be understood to…
Read more
cypher performance apoc
Upgrading to Neo4j 3.0 Enterprise Step-by-Step - Linux
Neo4j 3.0 is a major release that includes both a directory structure reorganization and a configuration file/parameter name overhaul. This means that upgrading to it requires some additional consideration and…
Read more
upgrade linux
Use Java Runtime 11 with Neo4J 3.5.x
Neo4j 3.5.x supports Java 11 as runtime, however custom code should still be compiled against Java 8. As a best practice, it is recommended to maintain your infrastructure environment on…
Read more
jdk jre java11
Useful Cypher statements for suspending and reactivating users
Commencing with Neo4j 3.1 and implementaion of native database users it is possible to suspend a user, thus preventing the user from further authenticating in. To view all suspended users…
Read more
suspend activate security user
Using AWS CLI to upload/download files to Amazon S3 bucket
If one has installed the AWS CLI To download a file from a S3 bucket anonymously run: and/or to upload to a Neo4j S3 buck anonymously run: replacing <AWS Instance…
Read more
aws s3 upload download
Using Cypher and APOC to move a property value to a label
Commencing with Neo4j 3.0 and the introduction of stored procedures as well as APOC one can utilize the stored procedure apoc.create.addLabels to move a property to a label with Cypher…
Read more
apoc refactoring procedures
Using Cypher to generate Cypher statements to recreate Users and Roles
The following can be used to extract user and role definitions from an existing database and the resultant output can be played back on another Neo4j database. The resultant output…
Read more
user role schema
Access to the neo4j-shell in NEO4J CE 3.x
From Neo4j 3.0 access to neo4j-shell is no longer possible from the desktop-installers for Windows and OSX. To use neo4j-shell, you have to download the TAR/ZIP distribution from: http://neo4j.com/download/other-releases/ For…
Read more
import shell cypher
Warm the cache to improve performance from cold start
Note: For 3.5.x forward the details below are no longer applicable as Neo4j will keep record of what is in the pagecache at all times and upon restart of Neo4j…
Read more
performance cache warmup
Where is my neo4j.log in Ubuntu Linux?
In most Neo4j server environments, all logs will be found in NEO4J_HOME/logs. However, when Neo4j is running as a service on a Ubuntu (debian) Linux environment, usually installed via apt-get…
Read more
logging linux ubuntu
Why does my CREATE CONSTRAINT take so long to complete
When creating a constraint, for example this will require a lock on all nodes with the label the constraint is being created for, in this case ZipCode If you have…
Read more
logging server
Will execution_guard_enabled work in my release of Neo4j?
Background From the beginning, the execution guard was never meant to be used by the general public. However, the feature was there in the product, though undocumented, and it did…
Read more
server configuration"
https://neo4j.com/developer/kb/parsing-json-query-logs;"Parsing json query logs
Author Ali Maddahian Applicable versions 4.0 4.1 4.2 4.3 4.4 5.0 Tags cypher query tunning
There are times when we have to examine a query log in order to find longest running queries and/or other problem queries such as those with missing indexes or when not using parameters appropriately.
This can be done by parsing and sorting the query log attributes, which is typically straight forward when using csv formmated query logs, but with json formatted logs as in Aura, we can use the following jq command to get the longest running queres as needed:
Aura
None
Copy to Clipboard
cat query.log.json |
 jq '. | sort_by(.jsonPayload.elapsedTimeMs) | reverse ' |
 jq '.[] | select(.jsonPayload.event == ""success"") |
 { timestamp: .timestamp,
  severity:  .severity,
  event: .jsonPayload.event,
  id: .jsonPayload.id,
  elapsedTimeMs: .jsonPayload.elapsedTimeMs,
  allocatedBytes: .jsonPayload.allocatedBytes,
  pageFaults: .jsonPayload.pageFaults,
  pageHits: .jsonPayload.pageHits,
  waiting: .jsonPayload.waiting,
  planning: .jsonPayload.planning,
  runtime: .jsonPayload.runtime,
  username: .jsonPayload.username,
  query: .jsonPayload.query } |   join("" | "")  '
Which produces the following row formatted output:
None
Copy to Clipboard
""2022-10-20T04:51:22.485Z | INFO | success | 13452855 | 1792 | 248 | 0 | 905357 | 0 | 0 | slotted | neo4j | MATCH (n) return n""
On-Prem
On the other hand in a non-Aura environment, we will have to use the following version of our jq script in order to confirm to a slightly different format as shown below:
None
Copy to Clipboard
{
  ""time"": ""2022-10-23 00:09:37.772+0000"",
  ""level"": ""INFO"",
  ""event"": ""success"",
  ""type"": ""query"",
  ""elapsedTimeMs"": 2,
  ""planning"": 0,
  ""cpu"": 2,
  ""waiting"": 0,
  ""allocatedBytes"": 176,
  ""pageHits"": 4,
  ""pageFaults"": 0,
  ""source"": ""bolt-session\tbolt\tneo4j-browser/v5.0.0\t\tclient/127.0.0.1:49863\tserver/127.0.0.1:11004>"",
  ""database"": ""neo4j"",
  ""username"": ""neo4j"",
  ""executingUser"": ""neo4j"",
  ""authenticatedUser"": ""neo4j"",
  ""query"": ""MATCH (tom {name: \""Tom Hanks\""}) RETURN tom"",
  ""queryParameters"": ""{}"",
  ""runtime"": ""pipelined"",
  ""annotationData"": ""{type: 'user-direct', app: 'neo4j-browser_v5.0.0'}""
}
View all (8 more lines)
So our jq command will look like the following:
None
Copy to Clipboard
cat query.log.json |
jq  -s -c 'sort_by(.elapsedTimeMs) | reverse | .[]' |
jq '. | select( .event == ""success"") |
 { time: .time,
  level:  .level,
  event: .event,
  type: .type,
  id: .id,
  elapsedTimeMs: .elapsedTimeMs,
  planning: .planning,
  cpu: .cpu,
  waiting: .waiting,
  allocatedBytes: .allocatedBytes,
  pageHits: .pageHits,
  pageFaults: .pageFaults,
  source: .source,
  username: .username,
  executingUser: .executingUser,
  authenticatedUser: .authenticatedUser,
  authenticatedUser: .authenticatedUser,
  runtime: .runtime,
  query: .query,
  queryParameters: .queryParameters }  | join("" | "")  '
View all (9 more lines)
With the output as shown below:
None
Copy to Clipboard
""2022-10-23 00:09:16.352+0000 | INFO | success | query |  | 95 | 62 | 91 | 0 | 0 | 9 | 0 | bolt-session\tbolt\tneo4j-browser/v5.0.0\t\tclient/127.0.0.1:49863\tserver/127.0.0.1:11004> | neo4j | neo4j | neo4j | pipelined | EXPLAIN MATCH (nineties:Movie) WHERE nineties.released >= 1990 AND nineties.released < 2000 RETURN nineties.title | {}""
""2022-10-23 00:09:31.071+0000 | INFO | success | query |  | 27 | 26 | 26 | 0 | 0 | 1 | 0 | bolt-session\tbolt\tneo4j-browser/v5.0.0\t\tclient/127.0.0.1:49863\tserver/127.0.0.1:11004> | neo4j | neo4j | neo4j | pipelined | EXPLAIN MATCH (tom {name: \""Tom Hanks\""}) RETURN tom | {}""
As a last word, please note that the above commands are expected to use a lot of memory when it is run. As an example, for a 7GB file (uncompressed) with some 4 million entries, it used about 60GB of memory and finished in about 10 minutes.
Was this page helpful?"
https://neo4j.com/developer/kb/requirement-makes-database-unavailable-database-available-initialized-diagnostics-start;"Requirement makes database unavailable: Database available --- INITIALIZED diagnostics START ---
Author Daniel Terlizzi Applicable versions 3.4 3.5 Tags backup
When running neo4j-admin backup, the debug.log shows a message that appears to indicate that the database restarted; however, this is not the case.
2019-05-01 03:14:15.230+0000 INFO [o.n.k.AvailabilityGuard] Requirement makes database unavailable: Database available
2019-05-01 03:14:15.250+0000 INFO [o.n.k.i.DiagnosticsManager] --- INITIALIZED diagnostics START ---
Let’s explain why this message is showing up and what it means.
When an online backup starts, a separate new instance of the database engine is used to access the data and allow the tool to perform an online backup. The database must be placed into an unavailable state when running a backup to avoid changes (writes) to the data. This separate instance writes its logging to the same debug.log of the main database engine. Hence the incorrect impression that the database restarted, when instead the log is really showing a separate engine which was started by the backup process, placed into an unavailable state, and then shut down once the backup process completed.
In Release 3.5.3 the messaging noted above has been changed for full backups as follows:
2019-01-04 16:11:59.715+0000 INFO [o.n.b.i.BackupImpl] BackupServer:6362-1: Full backup started...
2019-01-04 16:11:59.717+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by full backup @ txId: 28 checkpoint started...
2019-01-04 16:11:59.768+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by full backup @ txId: 28 checkpoint completed in 47ms
2019-01-04 16:11:59.769+0000 INFO [o.n.k.i.t.l.p.LogPruningImpl] No log version pruned, last checkpoint was made in version 0
2019-01-04 16:11:59.847+0000 INFO [o.n.b.i.BackupImpl] BackupServer:6362-1: Full backup finished.
Was this page helpful?"
https://neo4j.com/developer/kb/explanation-of-error-record-id-65536-is-out-of-range;"Explanation of error ""Record id 65536 is out of range [0, 65535]""
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags relationship record-id
When running a Cypher statement that creates a new relationship type, for example
Cypher
Copy to Clipboard
Run in Neo4j Browser
MERGE (n1:Person {id:1})-[r:knows]->(n2:Person {id:2})
one may encounter an error which is logged in the $NEO4J_HOME/logs/debug.log as
2017-10-30 17:08:29.741+0000 ERROR [o.n.b.v.r.ErrorReporter] Client triggered an unexpected error [UnknownError]: Could not create token, reference 63c2e7ef-6f5b-4834-b2a8-fe74cac3a50a. Could not create token
org.neo4j.graphdb.TransactionFailureException: Could not create token
        at org.neo4j.kernel.impl.core.DelegatingTokenHolder.getOrCreateId(DelegatingTokenHolder.java:85)
        at org.neo4j.kernel.impl.api.store.StorageLayer.relationshipTypeGetOrCreateForName(StorageLayer.java:376)
        at org.neo4j.kernel.impl.api.StateHandlingStatementOperations.relationshipTypeGetOrCreateForName(StateHandlingStatementOperations.java:1384)
        at org.neo4j.kernel.impl.api.DataIntegrityValidatingStatementOperations.relationshipTypeGetOrCreateForName(DataIntegrityValidatingStatementOperations.java:86)
        at org.neo4j.kernel.impl.api.OperationsFacade.relationshipTypeGetOrCreateForName(OperationsFacade.java:774)
        at org.neo4j.cypher.internal.spi.v3_3.TransactionBoundQueryContext.getOrCreateRelTypeId(TransactionBoundQueryContext.scala:114)
        at org.neo4j.cypher.internal.compatibility.v3_3.ExceptionTranslatingQueryContext$$anonfun$getOrCreateRelTypeId$1.apply$mcI$sp(ExceptionTranslatingQueryContext.scala:203)
        ...
        at org.neo4j.bolt.v1.runtime.concurrent.RunnableBoltWorker.run(RunnableBoltWorker.java:96)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
        at org.neo4j.helpers.NamedThreadFactory$2.run(NamedThreadFactory.java:109)
Caused by: org.neo4j.kernel.impl.store.id.validation.IdCapacityExceededException: Record id 65536 is out of range [0, 65535]
        at org.neo4j.kernel.impl.store.id.validation.IdValidator.assertIdWithinCapacity(IdValidator.java:88)
        at org.neo4j.kernel.impl.store.id.validation.IdValidator.assertValidId(IdValidator.java:67)
        at org.neo4j.kernel.impl.store.id.IdGeneratorImpl.nextId(IdGeneratorImpl.java:143)
        at org.neo4j.kernel.impl.core.DefaultRelationshipTypeCreator.createKey(DefaultRelationshipTypeCreator.java:40)
        at org.neo4j.kernel.impl.core.IsolatedTransactionTokenCreator.getOrCreate(IsolatedTransactionTokenCreator.java:59)
        at org.neo4j.kernel.impl.core.DelegatingTokenHolder.createToken(DelegatingTokenHolder.java:103)
        at org.neo4j.kernel.impl.core.DelegatingTokenHolder.getOrCreateId(DelegatingTokenHolder.java:76)
        ... 49 more
and they key part from above is the reference to Record id 65536 is out of range [0, 65535]
This error is caused as a result of hitting the maximum number of relationship types for a graph.db. The current limit is 65536. Note this is specifically for the 'relationship type', i.e. the identifier used to name the relationship. This limit does not apply to number of relationships between nodes or the total number of relationships in the graph.
When this error is encountered running
Cypher
Copy to Clipboard
Run in Neo4j Browser
call db.relationshipTypes() yield relationshipType return count(relationshipType) as numRelTypes;
will return
+-------------+
| numRelTypes |
+-------------+
| 65536       |
+-------------+
To resolve this error would require removal of relationship types which are no longer associated with any nodes. As there is currently no Cypher command to do this, one would need to run copy-store.sh. This command will read a offline graph.db and prepare a new graph.db but exlcuding any relationship types/properties which are no longer in use.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-run-consistency-check-manually;"How do I run Consistency Check Manually?
Author Dave Gordon Applicable versions 2.1 2.2 2.3 3.0 Tags backup consistency performance operations consistency-check
If you skip the Consistency Check part of neo4j-backup, or you want to check that all is well with a data store, you can run the tool against an offline store.
Shell
Copy to Clipboard
$ java -cp 'lib/*:system/lib/*' org.neo4j.consistency.ConsistencyCheckTool /tmp/graph.db
On a Windows implementation the syntax would be similar to
Shell
Copy to Clipboard
$ java -cp ""lib/*;system/lib/*"" org.neo4j.consistency.ConsistencyCheckTool c:\tmp\graph.db
In each of the instance above, replace /tmp/graph.db or c:\tmp\graph.db with the actual path of the Neo database.
To tune the check to skip Indexes (the most impactful modification), simply add the following line to conf/neo4j.properties (2.x) or conf/neo4j.conf(3.x), and pass it into the tool on the command line:
Properties
Copy to Clipboard
consistency_check_indexes=false
Now run the command with the configuration file passed along:
Shell
Copy to Clipboard
$ java -cp 'lib/*:system/lib/*' org.neo4j.consistency.ConsistencyCheckTool -config conf/neo4j.properties /tmp/foo
There are additional configuration options. They are listed in their 2.x name / 3.x name
consistency_check_property_owners / tools.consistency_checker.check_property_owners
Perform optional additional checking on property ownership. This can detect a theoretical inconsistency where a property could be owned by multiple entities. However, the check is very expensive in time and memory, so it is skipped by default.
consistency_check_label_scan_store / tools.consistency_checker.check_label_scan_store
Perform checks on the label scan store. Checking this store is more expensive than checking the native stores, so it may be useful to turn off this check for very large databases.
consistency_check_indexes / tools.consistency_checker.check_indexes
Perform checks on indexes. Checking indexes is more expensive than checking the native stores, so it may be useful to turn off this check for very large databases.
consistency_check_execution_order
Execution order of store cross-checks to be used when running consistency check
consistency_check_report_file: File name for inconsistencies log file. If not specified, logs to a file in the store directory.
See also the Manual Entry on Backup and Consistency Checking
Was this page helpful?"
https://neo4j.com/developer/kb/linkurious-bolt-configuration;"Linkurious bolt configuration
Author Ali Maddahian Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags bolt drivers linkurious
Default Linkurious configuration contains the following snippet in the production.json configuration file:
Json
Copy to Clipboard
{
  ""dataSources"": [{
    ""readOnly"": false,
    ""graphdb"": {
      ""vendor"": ""neo4j"",
      ""url"": ""http://127.0.0.1:7474"",
      ""user"": null,
      ""password"": null
    },
    ""index"": {
      ""vendor"": ""elasticSearch"",
      ""host"": ""127.0.0.1"",
      ""port"": 9201,
      ""forceReindex"": false,
      ""dynamicMapping"": false,
      : 
    }
  }]
}
View all (4 more lines)
With the documentation stating the following:
Linkurious can connect to Neo4j via the Bolt protocol. To do so, you need to enable the protocol in your Neo4j configuration file. If Linkurious is connected over HTTP/S, it will try to automatically upgrade the connection to Bolt. The HTTP/S protocol is still required to perform a small subset of operations.
Where the URL can be set to http/https/bolt/bolt+routing. However, using the above configuration can run into issues with respect to writes in a cluster environment.
In general, writes are generated when:
You create/edit/delete information through the UI
You write your own queries / queries template and let the user run them
When Linkurious uses the bolt+routing protocol, Linkurious can return a node in the cluster that could potentially also be a read-only replica, and of course, when sending a write query to that node, the write will fail.
That said, you can have different scenarios:
You don’t want any user changing the data through LKE UI (and you properly configured all the securities to achieve this, you also have a read-only flag in the datasource). In this case you’ll never face any issue since the system will never perform write operations. You configuration will work.
Your cluster only contains Core Server and no Replica (read-only). In this case every node returned by bolt+routing protocol will accept write requests and then will never fail.
You want to change data through LKE UI and the Neo4j cluster contains also Replica Servers. In this case, to remove the possibility of failure, you’ll need to configure the extra writeUrl parameter as shown below using HTTP/S protocol and point to the core servers, ensuring all write queries are sent to the cores (This is because all http calls are sent via bolt under the cover in Linkurious)
The configuration will then look like:
Json
Copy to Clipboard
{
  ""dataSources"": [
    {
      ""graphdb"": {
        ""vendor"": ""neo4j"",
        ""url"": ""bolt+routing://full-cluster:7687/"",
        ""writeUrl"": ""http://core-server:7474/"",
        ""user"": ""myNeo4jUser"",
        ""password"": ""nyNeo4jPassword""
      },
      ""index"": {
        ""vendor"": ""neo4jSearch""
      }
    }
  ]
}
Where:
full-cluster
is whatever point to any active node in the cluster. If you put a single server, in case of failure of that server the system won’t be able to connect to the cluster. In this case it is recommended to put here an always active component that never return an offline server (e.g. load balancer, reverse proxy with backup server configuration, dns alias with a pull of active servers, etc…)
core-server
should follow the same recommendations above with the only difference that this components should never return a Replica Server, should link only the subset of Core servers
Was this page helpful?"
https://neo4j.com/developer/kb/categories/drivers;"Articles tagged as drivers
Consideration about routing tables on multi-data center deployments
Using the official Neo4j drivers means that you can take advantage of the full cluster routing capabilities of the drivers. This means your requests will be routed automatically to the…
Read more
drivers routing
Enabling Transaction Timeout Within Application
There is a dbms.transaction.timeout global setting on Neo4j that can be set in neo4j.conf file so if any query from any user exceeds the timeout threshold specified, that query is…
Read more
transaction timeout java drivers
Explanation of error on session connection using uniform drivers
As described by http://neo4j.com/docs/developer-manual/current/drivers/#_trust, when establishing an encrypted connection, it needs to be verified that the remote peer is who we expected to connect to. The default connection is to…
Read more
connection security tls
Explanation of ""Failed to update routing table with server"" error
If you encounter a Failed to update routing table with server error in their $NEO4J_HOME/logs/debug.log similar to: This can be addressed by checking your DNS entries. A routing driver is…
Read more
cluster bolt
Why did I get the “Kernel API returned non-existent relationship type: -1” exception?
In rare situations, the Neo4j Bolt driver throws an IllegalStateException. The top part of the stack appears as: Under the covers, this is what happens. The getRelationshipTypeById(int type) method is…
Read more
kernel exception relationships transaction bolt
Pass Temporal Objects as Parameters
With the support of datetime types in Neo4j, users might wonder how or if it works to transport those types along with other data types via the drivers. It is…
Read more
drivers cypher temporal
How to resolve Python Bolt Driver when executed gives an error ""(""Failed to establish connection to {!r}"".format(address))""
Take the example of Python with the latest Bolt driver 1.2. Here is the sample code and when run it gives the following error: There are two options to resolve…
Read more
python bolt
java.lang.OutOfMemoryError: unable to create new native thread
When a client application establishes a session with a Neo4j server via the bolt or bolt+routing protocols, the server allocates a thread to serve as the server-side bolt worker to…
Read more
out-of-memory bolt exception
Using Python 1.7.x Driver with Neo4j 4.0
At the time of writing this article the Bolt Driver for Python has not been released for Neo4j 4.0. The v4 Python driver will not be available until the end…
Read more
python"
https://neo4j.com/developer/kb/resolve-python-bolt-driver-error-connection;"How to resolve Python Bolt Driver when executed gives an error ""(""Failed to establish connection to {!r}"".format(address))""
Author Rohan Kharwar Applicable versions neo4j-python-driver 1.2 Tags python bolt
Take the example of Python with the latest Bolt driver 1.2.
Here is the sample code
Python
Copy to Clipboard
from neo4j.v1 import GraphDatabase
uri = ""bolt://localhost:7687""
driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""Password""))
and when run it gives the following error:
Traceback (most recent call last):
  File ""/Users/rk/Documents/Work/Python-Bolt/boltTest.py"", line 3, in <module>
    driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""Password""))
  File ""/Library/Python/2.7/site-packages/neo4j/v1/api.py"", line 112, in driver
    return driver_class(uri, **config)
  File ""/Library/Python/2.7/site-packages/neo4j/v1/direct.py"", line 56, in __init__
    pool.acquire()
  File ""/Library/Python/2.7/site-packages/neo4j/v1/direct.py"", line 37, in acquire
    return self.acquire_direct(resolved_addresses[0])
  File ""/Library/Python/2.7/site-packages/neo4j/bolt/connection.py"", line 386, in acquire_direct
    connection = self.connector(address)
  File ""/Library/Python/2.7/site-packages/neo4j/v1/direct.py"", line 55, in <lambda>
    pool = DirectConnectionPool(lambda a: connect(a, security_plan.ssl_context, **config), self.address)
  File ""/Library/Python/2.7/site-packages/neo4j/bolt/connection.py"", line 457, in connect
    raise ServiceUnavailable(""Failed to establish connection to {!r}"".format(address))
neo4j.exceptions.ServiceUnavailable: Failed to establish connection to ('::1', 7687, 0, 0)
There are two options to resolve this:
Either change the localhost to 127.0.0.1 and then run it with the current settings. As shown below:
Python
Copy to Clipboard
from neo4j.v1 import GraphDatabase
uri = ""bolt://127.0.0.1:7687""
driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""Password""))
Second option is to set the following parameter in conf/neo4j.conf file as shown below:
dbms.connector.bolt.listen_address=0.0.0.0:7687
We are defining it to connect from any address (i.e. 0.0.0.0). Restart the database and run the code as:
Python
Copy to Clipboard
from neo4j.v1 import GraphDatabase
uri = ""bolt://localhost:7687""
driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""Password""))
Was this page helpful?"
https://neo4j.com/developer/kb/using-python-with-neo4j-ver4-0;"Using Python 1.7.x Driver with Neo4j 4.0
Author Vivek Saran Applicable versions 4.0 Tags python
At the time of writing this article the Bolt Driver for Python has not been released for Neo4j 4.0. The v4 Python driver will not be available until the end of the first quarter of 2020.
So, how do you connect to Neo4j 4.0 with 1.7.x generation of Python drivers?
The most important thing to remember is that you have to disable encrypted traffic, when using 1.7.x generation drivers against 4.0.x database.
Here is how you do it:
Python
Copy to Clipboard
from neo4j import GraphDatabase

uri = ""bolt://localhost:7687""

driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""letmein""), encrypted=False)

def print_movies_acted_in(tx, name):
    for record in tx.run(""MATCH (a:Person)-[:ACTED_IN]->(m) ""
                         ""WHERE a.name = $name ""
                         ""RETURN m.title"", name=name):
        print(record[""m.title""])

with driver.session() as session:
    session.read_transaction(print_movies_acted_in, ""Keanu Reeves"")
Notice the encrypted configuration set through the Driver constructor. It defaults to True if TLS is available.
Python
Copy to Clipboard
driver = GraphDatabase.driver(uri, auth=(""neo4j"", ""letmein""), encrypted=False)
For more details on the Driver object, please refer to the following link -
https://neo4j.com/docs/api/python-driver/current/driver.html#encrypted
As expected the result of the above code would be:
The Matrix Revolutions
The Matrix Reloaded
Something's Gotta Give
The Devil's Advocate
The Replacements
Johnny Mnemonic
The Matrix
Was this page helpful?"
https://neo4j.com/developer/kb/failed-to-update-routing-table-with-server;"Explanation of ""Failed to update routing table with server"" error
Author Vivek Saran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster bolt
If you encounter a Failed to update routing table with server error in their $NEO4J_HOME/logs/debug.log similar to:
ERROR 1 --- [o4jDriverIO-5-2] LoadBalancer : Failed to update routing table. Current routing table: Ttl 1582554193442, currentTime 1582554193471, routers AddressSet=[], writers AddressSet=[], readers AddressSet=[]

Suppressed: org.neo4j.driver.exceptions.DiscoveryException: Failed to update routing table with server 'server-foo:7687'.

Caused by: org.neo4j.driver.exceptions.ClientException: There is no procedure with the name `dbms.cluster.routing.getRoutingTable` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.
This can be addressed by checking your DNS entries. A routing driver is created via a bolt+routing URI, for example, bolt+routing://graph.example.com:7687. The address in the URI must be that of a CORE Server. So, if you get the error mentioned above, very likely, you have a single DNS name to resolve to CORE and READ REPLICA nodes. The READ REPLICA’s should not have an entry in the DNS records. When the hostname resolves to the CORE node IP address, everything will work fine. However, when the hostname resolves to a READ REPLICA IP address, the driver will fail to connect to the database as it cannot get the routing table from that server.
The fix:
Change your DNS entries to ensure that the name resolution includes only CORE nodes, not READ REPLICA’s.
What if you want to connect to READ REPLICA’s only?
Some of our customers have a specific need where they send read requests only to the READ REPLICA’s. If you have a similar requirement, you can do the following -
Add all CORE nodes under a single DNS name, for example - core.graph.example.com
Add all READ REPLICA’s under another (single) DNS name, for instance - rr.graph.example.com
You can then connect to the READ REPLICA’s using the following URI - bolt://rr.graph.example.com:7687
The advantage of this option is that even if the CORE nodes are down, the applications can still connect to READ REPLICA’S.
The disadvantage is that each application can talk to only one READ REPLICA as it is using the bolt protocol. This means that it is possible that multiple applications may get connected to a single READ REPLICA and may not make use of all the READ REPLICA’s available.
References from Neo4j Driver manuals:
1.7 Driver: https://neo4j.com/docs/driver-manual/1.7/client-applications/#driver-connection-uris
4.0 Driver: https://neo4j.com/docs/driver-manual/current/client-applications/#driver-connection-uris
Was this page helpful?"
https://neo4j.com/developer/kb/categories/installation;"Articles tagged as installation
Debian: apt-get failing to update Neo4j
The common cause is an out of date gpg key. To update then run the following command: See also the information on: https://debian.neo4j.com You can get more information about running…
Read more
debian ubuntu
Debian / Ubuntu: How to enforce a certain version of neo4j when using debian packages
If you want to run a specific version of Neo4j and install the software via a debian repository you need to use a technique called apt pinning. Otherwise, any system…
Read more
unix installation
Diagnose storage performance issues
Slow storage can affect Neo4j performance, therefore we recommend using Solid State Drives in the product documentation. Benchmark your underlying system On Ubuntu or RedHat, you can use fio tool…
Read more
storage performance installation configuration
Neo4j Docker image cannot run on kubernetes as non root user
In Kubernetes (K8S) various levels of security can be set which apply cluster-wide to Pods running containers. One of which is a policy which prevents containers within a Pod to…
Read more
kubernetes docker security
Hosting Multiple Neo4j Instances On One Machine
This document lists some considerations whilst planning to host multiple neo4j instances on the same physical host machine. Multiple instances are allowed though this is not typically seen in the…
Read more
hardware planning monitoring cpu ram
How do I define my graph.db at a path other than under NEO4J_HOME for Windows
Commencing with Neo4j 3.0, the default location for your graph.db directory is under $NEO4J_HOME\databases\. To change the path for the location of the database directory, edit the following parameters in…
Read more
installation
How to install Neo4j in a disconnected environment
Premise: You are working with a private/disconnected environment and would like to install the Neo4j Database using RPM packages as a source. You can download the RPM packages on a…
Read more
offline server
How to List and Install Neo4j Versions Using yum
Neo4j 3.0 does NOT provide an rpm, and it is unlikely 3.1 will either. This is on the roadmap to be done soon, but presently it is not an official…
Read more
unix installation
Number of open files
GNU/Linux and Mac OS operating systems impose an upper limit on the number of concurrent files a user may have open. This article covers how to configure the number of…
Read more
linux
Proper File Permissions on Neo4j Server
When installing Neo4j Server, keep in mind that the bin/neo4j executable will need to be run by some OS system user, and that user will need write permissions to some…
Read more
file-system permissions operations server startup unix installation
Recommendations for recovery upon Out Of Memory error
It is possible to configure the JVM (Java Virtual Machine) such that upon encountering an OOM (Out-Of-Memory) error it will force an exception and crash or simply shut down the…
Read more
jvm memory exception error
Running Docker as Non-Root User
When running Neo4j Docker, it will run as neo4j user inside the container. But to run docker as a different user one can specify the --user argument. Documentation has a…
Read more
startup permissions docker
Setting Max Open File Limits on Mac OSX
This document provides a process for setting soft and hard max open file limits on MAC OSX. Each thread created by a user process will require availability in max open…
Read more
open-files
How to set up SSL communcation when running Neo4j within a Docker Container
Neo4j 3.2 added a Unified SSL Framework to setup secure connections for Bolt, HTTPS and Intra-Cluster Encryption. Details on this framework can be found at: https://neo4j.com/docs/operations-manual/current/security/ssl-framework/ Setting up secure Bolt…
Read more
docker security ssl tls
Setup Neo4j Service to run with different service ID
By default when neo4j is installed as an RPM via yum or apt-get, it creates a user neo4j and group neo4j and runs as neo4j user. However it might be…
Read more
installation service id service
Using apt to download a specific Neo4j debian package
By default, using apt-get to install Neo4j allows you to grab the current and previous stable releases. However, if you would like to install an older version, you can specify…
Read more
linux installation enterprise debian
Using supervisord to manage Neo4j process
In general, running the neo4j process directly is the most common way to start and stop the neo4j server. However, if you use supervisord to manage processes, this has worked…
Read more
operations startup shutdown monitoring"
https://neo4j.com/developer/kb/categories/development;"Articles tagged as development
Embed neo4j-enterprise within your java application
The Neo4j Java Reference Documentation generally describes how to embed Neo4j Community Edition within your Java application. If you are licensed for Neo4j Enterprise, this article will guide you through…
Read more
intellij enterprise embedded installation
Fix error: No dependency satisfies type interface org.neo4j.graphdb.GraphDatabaseService
From Neo4j 3.5 onwards, there are 2 kinds of Extension Factories : global and per database. Only the database one has access to the GraphDatabaseService. If you encounter this error,…
Read more
upgrade
How to log to neo4j.log in a Server Plugin
As part of the major changes in 3.0, the way to log to the user log, now neo4j.log (in server mode), has changed. To log within a Server Plugin follow…
Read more
java api logging plugin
How to log to neo4j.log in an Unmanaged Extension
As part of the major changes in 3.0, the way to log to the user log, now neo4j.log (in server mode), has changed. To log within an Unmanaged Extension is…
Read more
java api logging extension
How to perform a Soundex search
Using apoc.text.phonetic one can perform a Soundex search. For example if one defines the following nodes then to find these 3 nodes, since they all have the same Soundex value…
Read more
soundex procedures
Solve dependency issues
There are multiple ways to include neo4j artifacts. In this article, we will focus on maven based on different scenarios or errors. The most common issue is setting up the…
Read more
maven java embedded user-defined-procedures dependencies upgrade
Viewing schema data with APOC Procedures
APOC Procedures offers meta procedures to view information about your database schema and the data it stores. The procedure apoc.meta.schema() uses a sampling of the graph data to produce a…
Read more
apoc procedures schema"
https://neo4j.com/developer/kb/categories/support;"Articles tagged as support
Neo4j 4.2.x Security Vulnerability Fixed in Release 4.2.8
Affected products Neo4j 4.2.x Enterprise and Aura Cloud before 2021-06-18 Unaffected versions: Neo4j Community Edition, all Enterprise versions prior to 4.2 and Aura Cloud from 2021-06-18. Additionally Neo4j 4.3.x includes…
Read more
support
Neo4j Supported Versions
Neo4j Database Enterprise Edition 5 For reference and planning purposes, the following represents a list of Neo4j 5.x releases, release date, and when that release will no longer be supported…
Read more
support"
https://neo4j.com/developer/kb/specify-separate-debug-log-for-backup;"How to specify a separate debug.log for the backup process?
Author Rohan Kharwar Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags backup configuration neo4j.conf debug.log
When running neo4j-admin backup on a running Neo4j instance the backup logs are also written into the existing Neo4j instance debug.log and can get confusing as to which line items in the debug.log is part of backup process and those that are from running Neo4j instance. Hence we recommend having a separate directory where backup debug.log are written.
Here is how to achieve this.
Set the environment variable NEO4J_CONF to point to the new neo4j.conf that you setup for the backup process. Ideally you can copy the neo4j.conf file with the default settings and place it in the folder mentioned in NEO4J_CONF.
Shell
Copy to Clipboard
$ export NEO4J_CONF=/Users/Documents/backup/
$ echo $NEO4J_CONF
# /Users/Documents/backup/
In the neo4j.conf file set the dbms.directories.logs to point to the backup logs folder.
Properties
Copy to Clipboard
dbms.directories.logs=/Users/Documents/backup/logs
Then run the backup as:
Shell
Copy to Clipboard
$ ./neo4j-admin backup --backup-dir=/Users/Documents/backup --name=graph.db.backup
Debug.log for the backup process should be present in the following folder specified /Users/Documents/backup/logs.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-behaviour-when-running-out-of-disk-space-3-4;"Neo4j behaviour when running out of disk space (3.4+)
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags transaction consistency disk-space disk
Following the improvements on the recovery process after an instance runs out of disk space introduced in v3.4.0, this article aims to offer a view on the behaviour of Neo4j when this happens.
Prior to 3.4, running out of disk space caused transaction log corruption. They got corrupted when we tried to append something but there was no more space left on device. This is fine by itself since transactions are in fact never committed from user perspective, the problem was that we were unable to recover from that situation.
This is the expected behaviour (and recovery) on 3.4+:
Standalone instance:
Instance runs out of diskspace
JVM doesn’t crash but neo4j is in a non-usable state (needs manual intervention)
Manually free space on the server
Restart instance
Causal Cluster:
Instance runs out of diskspace
JVM doesn’t crash but neo4j is in a non-usable state (needs manual intervention)
A new leader gets elected automatically and write operations can resume straight away
Manually free space on old leader
Unbind the instance using neo4j-admin unbind (this triggers recovery of local database at startup if it can, instead of a store copy)
Restart instance
If not restarted, the old leader will still part of the cluster (as a follower) as drivers are concerned so client requests may be routed to it and timeout
Although we try to make this process as seamless as possible, this is still regarded as a disaster scenario. You should always monitor your disk space utilization on the OS level to prevent these situations from happening.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-recover-from-no-space-left-on-device;"How do I recover from No space left on device
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags disk disk-space
If one does not routinely monitor the disk space usage on a Neo4j server one may encounter a 'No space left on device' (for linux implementation) or a 'Low Disk Space' (Windows Implementations). For linux implementations one should proactively monitor disk space and this can be accomplished similar to what is described here.
Once you have encountered either, the following steps should be considered so as to free up enough space to start the database and allow recovery to complete. It should be noted that as you have consumed all the disk space, you cannot simply compress files to find more space, since that would require writing to the full file system.
graph.db path
DO NOT manually delete files in your database path, where the default location is $NEO4J_HOME/data/databases/graph.db and also noted by conf/neo4j.conf parameter of dbms.directories.data. Although this path may contain the most data, do not manually remove files from this path, as manually removing files will more than likely corrupt the database and/or prevent future starts.
However if you have another file system on the Neo4j installation which has more free space it is possible to either move the directory in whole to the other file system or commencing with Neo4j 3.4 one can configure dbms.directories.tx_log and this parameter describes where the data/databases/graph.db/neostore.transaction* files are recorded. For example if your current Neo4j installation is at /home/software/, which is where the disk full occurred, and there is another filesystem, for example /home/disk2 which has a signficiant amount of space one can reconfigure the conf/neo4j.conf parameter of dbms.directories.tx_log to a value of /home/disk2/tx_logs and copy the current and existing data/databases/graph.db/neostore.transaction* files to /home/disk2/tx_logs so as to free up space on /home/software. One could also do the same with regards to copying all of data/databases/graph.db from /home/software to /home/disk2 and in turn update conf/neo4j.conf parameter of dbms.directories.data.
Under no circumstances should you delete/modify files in the path of graph.db and/or the location of transaction logs specified by configuration dbms.directories.tx_log
Local backup copies
Consider if you have written the results of neo4j-admin backup to the local file system. If so, and if that copy is not going to be necessary to restore service, can the files be moved/removed from the file system?
Prior versions of Neo4j software
If you have completed multiple upgrades of Neo4j in the past, it may be the case that you have left the prior version software on the file system. For example if you typically install software into /usr/software/ and have upgraded from Neo4j 3.2.1 to Neo4j 3.5.0, you may have a /usr/software/neo4j-enterprise-3.2.1 and /usr/software/neo4j-enterprise-3.5.0. If such an older environment exists and provided you are successfully running on the newer version, you may consider moving/removing the prior version, in this example /usr/software/neo4j-enterprise-3.2.1
Log files
During the normal course of Neo4j operation, diagnostic logs are written to $NEO4J_HOME/logs/ and specifically debug.log, 'neo4j.log', query.log (provided dbms.logs.query.enabled=true) and security.log (provided dbms.security.auth_enabled=true), and where the debug.log can be the largest of these files. Given these files are diagnostic logs you may consider moving/removing/truncating these log files.
Plugins Your $NEO4J_HOME/plugins may contain custom plugins (JARs) for Neo4j. Check to see that your plugins are not writing to this path, or if they are, ensure they are properly managing their log files. Additionally, you might consider removing/moving the apoc* jar as it can be easily restored.
Prune transaction log files through the Neo4j product
If you have freed up a reasonable amount of space, prior to start you may want to configure the conf/neo4j.conf' parameter of dbms.tx_log.rotation.retention_policy to a very small value (example `dbms.tx_log.rotation.retention_policy=100M). In doing so after a sucessful start and then subsequent checkpoint (which defaults to every 900s), a transaction log pruning/rotation will occur and it should remove all but the last transaction log. If you do not want to wait those 900s (15 minutes) and if you are running Neo4j 3.5.6 or later one can manually force a checkpoint by calling stored procedure dbms.checkpoint();
One issue with this approach is that more than likely upon your next backup, if it is an incremental backup, it will revert to a full backup since the transaction logs between the last backup and the next backup are not without a gap. If this approach is taken, after sufficient disk space has been freed up the dbms.tx_log.rotation.retention_policy parameter should be reverted back to the value it was previously set to.
Metrics Commencing with Neo4j 3.5.0 logging of metrics as CSV files is enabled by default and the .CSV files are recorded in the location as described by conf/neo4j.conf parameter of dbms.directories.metrics which defaults to $NEO4J_HOM]E/metrics. Additionally, conf/neo4j.conf parameters of metrics.csv.rotation.keep_number and metrics.csv.rotation.size describe the number of CSV to keep for a given metric as well as the rotation size for said metric.
Prepare for growth
Even after freeing up sufficient space you will still need to prepare for the future in terms of making sure you have sufficient disk space for continued database growth. This is more an OS-related responsibility but should not be overlooked.
Ask for guidance from Neo4j If you are still unable to free up space, ask for guidance from Neo4j.
After Neo4j has safely restarted it is strongly encouraged that you run a database consistency check. This can be performed by either running a backup bin/neo4j-admin backup …. ….. --check-consistency=true on a running instance or on a stopped Neo4j database by running bin/neo4j-admin check-consistency --database=graph.db
Was this page helpful?"
https://neo4j.com/developer/kb/four-ways-to-check-consistency;"Four ways to check the consistency of a Neo4j graph
Author Vivek Saran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags consistency backup
When it comes checking the inconsistencies in your graph, there are four methods to do. This article describes them below:
1. The easiest approach is it to utilize the check-consistency=true option with the backup command. With this approach your graph stays online and the consistency check is done along with the scheduled or adhoc backup.
Shell
Copy to Clipboard
neo4j-home> bin/neo4j-admin backup --backup-dir=/home/backups --name=graph.db --check-consistency=true
2. If you are not checking the consistency through the backup command, then you will need to stop Neo4j to check its consistency.
Shell
Copy to Clipboard
neo4j-home> bin/neo4j stop
neo4j-home> bin/neo4j-admin check-consistency --database=graph.db
3. There will be situations when you would want to test the consistency of a backup. Here is how that is done:
Shell
Copy to Clipboard
neo4j-home> bin/neo4j-admin check-consistency --backup=/<path-to-backup-dir>/<graph_backup.db>
4. Using the dump and load commands is the recommended, and safe, way of transferring databases between environments. It is possible to check the consistency of an offline dump.
Assume you have the dump file sitting in: /mnt/dump_of_dbs
The dump file is a gzip file. To confirm the format, perform these commands:
Shell
Copy to Clipboard
$ cd /mnt/dump_of_db
$ file graph.db.dump
graph.db.dump: gzip compressed data
You will see that the .dump file is a gzip file.
Create a directory under mnt/dump_of_dbs
Shell
Copy to Clipboard
$ mkdir graph.db
Uncompress the gzip file under the graph.db directory:
Shell
Copy to Clipboard
$ cd graph.db
~/dump_of_dbs/graph.db$ tar xvzf ../graph.db.dump
Finally, run the consistency check as:
Shell
Copy to Clipboard
neo4j-home> bin/neo4j-admin check-consistency --backup=/mnt/dump_of_dbs/graph.db
End Notes:
The inconsistencies report is generated only when there are inconsistencies in the graph. So, you can have a process to trigger an alert if the report is created. The filename appears in this format: inconsistencies-yyyy-mm-dd.hh.mm.ss.report.
If the inconsistencies are discovered, follow the link below and use the specific methods to resolve them: https://support.neo4j.com/hc/en-us/articles/218047648-How-do-I-resolve-Consistency-Check-errors
Was this page helpful?"
https://neo4j.com/developer/kb/dump-the-contents-of-a-transaction-log;"Dump the Contents of a Transaction Log
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags transaction log
If there is a need to look through the transaction logs, particularly to see if/when a node or relationship (or property) with a given ID was touched, you will need to dump the log using the DumpLogicalLog tool.
The tools are available separately at the Maven Central Repository prior to version 3.5.x. Download (or build) the correct tools jar for your Neo4j Version from there.
Starting with version 3.5.x, you can find the jar in the Private Repository The username and password can be found here.
Place the jar in $NEO4J_HOME\lib and given a log file of neostore.transaction.db.1, run:
Shell
Copy to Clipboard
For 3.5 and lower
----
$ java -cp 'lib/*:system/lib/*:/usr/share/neo4j/lib/*' org.neo4j.tools.dump.DumpLogicalLog ./data/graph.db/neostore.transaction.db.1 > /tmp/dumptxlog_1.log
----
For 4.0 and higher
----
$ java -cp 'lib/*:system/lib/*:/usr/share/neo4j/lib/*' com.neo4j.tools.dump.DumpLogicalLog ./data/transactions/<Your Database Here>/neostore.transaction.db.0 /tmp/dumptxlog_1.log
----
Once dumped, you can search for a node ID, etc.
=== ./data/databases/graph.db/neostore.transaction.db.0[LogHeader{logFormatVersion=6, logVersion=0, lastCommittedTxId=1}] ===
Start[master=-1,me=-1,time=2019-01-29 00:14:49.524+0000/1548720889524,lastCommittedTxWhenTransactionStarted=1,additionalHeaderLength=8,[-75, 113, -36, 24, -49, -11, -31, -102],position=LogPosition{logVersion=0, byteOffset=16},checksum=-162089288840]
Command[ -PropertyKey[0,no use,nameId=-1,propCount=0]
         +PropertyKey[0,in use,nameId=1,propCount=0,DynamicRecord[1,used=true,(4),type=-1,data=byte[99,111,100,101],start=true,next=-1]]]
Commit[txId=2, 2019-01-29 00:14:49.543+0000/1548720889543]
Start[master=-1,me=-1,time=2019-01-29 00:14:49.500+0000/1548720889500,lastCommittedTxWhenTransactionStarted=1,additionalHeaderLength=8,[-57, 79, -16, 29, 38, 48, 89, -74],position=LogPosition{logVersion=0, byteOffset=134},checksum=-160313975075]
Command[ -Property[0,used=false,prev=-1,next=-1,node=0, (blocks not loaded)]
         +Property[0,used=true,prev=-1,next=-1,node=0,PropertyBlock[blocks=1,SHORT_STRING,key=0,value=A]]]
Command[ -Node[0,used=false,rel=-1,prop=-1,labels=Inline(0x0:[]),light,secondaryUnitId=-1]
         +Node[0,used=true,rel=-1,prop=0,labels=Inline(0x0:[]),light,secondaryUnitId=-1]]
...
Command[UpdateCounts[() + 1]]
Commit[txId=10, 2019-01-29 00:31:04.302+0000/1548721864302]
Start[master=-1,me=-1,time=2019-01-29 00:31:06.405+0000/1548721866405,lastCommittedTxWhenTransactionStarted=10,additionalHeaderLength=8,[77, -57, 58, -59, -5, 87, -51, -31],position=LogPosition{logVersion=0, byteOffset=1824},checksum=-161405968298]
Command[ -Property[5,used=false,prev=-1,next=-1,node=5, (blocks not loaded)]
         +Property[5,used=true,prev=-1,next=-1,node=5,PropertyBlock[blocks=3,SHORT_STRING,key=0,value=CountMyTestString]]]
Command[ -Node[5,used=false,rel=-1,prop=-1,labels=Inline(0x0:[]),light,secondaryUnitId=-1]
         +Node[5,used=true,rel=-1,prop=5,labels=Inline(0x0:[]),light,secondaryUnitId=-1]]
Command[UpdateCounts[() + 1]]
Commit[txId=11, 2019-01-29 00:31:06.406+0000/1548721866406]
CheckPoint[position=LogPosition{logVersion=0, byteOffset=2041}]
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-commit-process-explained;"Neo4j’s commit process explained
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags transaction commit cluster
This article will try to guide you through Neo4j’s commit and replication processes both for single instances and causal clusters.
  Single Instance
When you call tx.commit(), the transaction will go through the Storage Engine which will transform that transaction into a Transaction Representation. This is similar to what you get when you dump a transaction log and contains all of the commands generated by that transaction:
Command[
-Node[0,used=false,rel=-1,prop=-1,labels=Inline(0x0:[]),light,secondaryUnitId=-1]
  +Node[0,used=true,rel=-1,prop=-1,labels=Inline(0x0:[]),light,secondaryUnitId=-1]
]
Image 1 - Storage Engine
On a single instance, this Transaction Representation is then passed on to the Transaction Commit Process which will effectively write that transaction to the transaction log. This internally calls appendToLog(). After that, the Transaction Representation will go to the Record Store Engine which then persists that transaction to disk (applyToStore())
applyToStore() doesn’t necessarily happen together with appendToLog() but rather happens during a checkpoint operation or when a dirty page is flushed from the pagecache.
Image 2 - Transaction Commit Process
Image 3 - Record Storage Engine
This is the process for a single instance which is fairly simple. Naturally, it doesn’t involve any RAFT components.
Causal Cluster
For a Causal Cluster, the work will be done on the Leader. Everything in the process is the same, but the Transaction Commit Process is intercepted before flushing the transaction to the log:
Image 4 - Transaction Commit Process
The Transaction Representation is intercepted by the Replicated Transaction Commit Process which turns the Transaction Representation into a Raft Message (commit()). It is then replicated by a component called Raft Replicator (replicate()). The way this replication occurs is the following:
The Leader will send an append to to followers saying it’s got a new message
Followers append that message to their own RAFT logs and send a response back saying it’s been appended
The Leader then gets that message and sends a commit message saying all is ok in both sides and it’s safe to commit
Image 5 - Replication
SOME CONSIDERATIONS
In this process, you may see the Leader sending append request to itself. This is intended behaviour as the Leader sees itself as a Core instance of the cluster and also needs to append to its own RAFT log.
The flow is: APPEND > APPEND RESPONSE > COMMIT > APPEND (…)
The cluster only needs a majority of instances to ack the message. For this reason, some messages sent to Followers that may have already be committed.
We use message pipelining, where a Commit message can also include an Append to allow for faster processing.
All messages across the network are considered heartbeats.
After this happens, the Transaction Representation goes through to a queue of Transaction Representations we call the Replicated Transaction State Machine (applyCommand()) and this keeps track of the transactions and what order they need to be applied to the store.
Image 6 - Replicated Transaction State Machine
From there, these Transaction Representations will go through the Commit Process which will then connect back to the Transaction Commit Process (image 2) in order to flush to the transaction log and finally apply to store (image 3)
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-quickly-switch-between-multiple-graphs-without-modifying-neo4j-conf;"How do I quickly switch between multiple graphs without modifying neo4j.conf?
Author Dana Canzano Applicable versions 3.0 3.1 Tags configuration
If you have multiple graphs set up and want to quickly switch between each without modifying dbms.active_database in conf/neo4j.conf, you can accomplish this with a neo4j restart and with the environment variable NEO4J_CONF defined pointing to the appropriate/corresponding neo4j.conf file.
For example, one could define:
Bash
Copy to Clipboard
$NEO4J_HOME/conf
$NEO4J_HOME/conf_test
and where each directory has the same files, namely:
jmx.access  jmx.password  neo4j.conf  neo4j-wrapper.conf
and in the $NEO4J_HOME/conf_tests/neo4j.conf one might configure the databse name to a different graph:
Properties
Copy to Clipboard
# The name of the database to mount
dbms.active_database=graph.db.test
Then, prior to a restart of neo4j if one modifies the environment variable NEO4J_CONF to point to the $NEO4J_HOME/conf_test, for example:
Bash
Copy to Clipboard
export NEO4J_CONF=""/home/neo/neo4j-enterprise-3.0.7/conf_test""
then upon restart of neo4j, it will then use the graph in the graph.db.test location.
Note: Be aware that the dbms.active_database setting in neo4j.conf is one of many settings that you may want/need to change. If for example you do not change #dbms.directories.logs=logs then both conf files will result in each Neo instance writing to $NEO4J_HOME/logs.
Was this page helpful?"
https://neo4j.com/developer/kb/database-was-successfully-initialized-but-failed-to-start;"Database was successfully initialized, but failed to start
Author Daniel Terlizzi Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags configuration
Sometimes when the database does not start it could be something as simple as unnecessary characters in the neo4j.conf file. For example if you add space and/or tab characters to below setting:
Properties
Copy to Clipboard
dbms.ssl.policy.client_policy.private_key=/var/lib/neo4j/certificates/client_policy/neo4j.key
The database will fail to start and show you this message:
Caused by: org.neo4j.kernel.lifecycle.LifecycleException: Component 'org.neo4j.server.database.LifecycleManagingDatabase@691eb782' was successfully initialized, but failed to start. Please see the attached cause exception ""/var/lib/neo4j/certificates/client_policy/neo4j.key (No such file or directory)"".
Make sure to edit the neo4j.conf file with a text file editor and not a word processor to reduce the risk of such issues.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-bulk-delete-dense-nodes;"How to avoid using excessive memory on deletes involving dense nodes
Author Dave Gordon Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher oom
In situations where you know you need to delete a bunch of nodes (and by rule their relationships as well), it can be tempting to simply use DETACH DELETE and be done with it. However, this can become problematic if you have dense nodes, or if you have a number of nodes with thousands of relationships per batch. Your ""batch size"" can quickly become much larger than you intend.
APOC allows us to work with this. Essentially, we want to find the set of nodes that we want to delete, pass that into a call to apoc.periodic.commit, and then batch the deletes by the first 10K relationships, then the next 10K, and so on until it is done. The following cypher works quite well on a large set of nodes. In this case, it is looking for :TTL labelled nodes who’s ttl property is older than the current time. It passes those into the periodic commit statement, and deletes in batches of 10K.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (n:TTL)
WHERE n.ttl < timestamp()
WITH collect(n) AS nn
CALL apoc.periodic.commit(""
  UNWIND $nodes AS n
  WITH sum(size((n)--())) AS count_remaining,
       collect(n) AS nn
  UNWIND nn AS n
  OPTIONAL MATCH (n)-[r]-()
  WITH n, r, count_remaining
  LIMIT $limit
  DELETE r
  RETURN count_remaining
"",{limit:10000, nodes:nn}) yield updates, executions, runtime, batches, failedBatches, batchErrors, failedCommits, commitErrors
UNWIND nn AS n
DELETE n
RETURN updates, executions, runtime, batches
Additionally, please consider reviewing KB document Large Delete Transaction Best Practices in Neo4j for other considerations
Was this page helpful?"
https://neo4j.com/developer/kb/preserving-the-neo4j-pagecache-across-database-restarts;"Preserving the Neo4j pagecache across database restarts
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags page-cache
Commencing with Neo4j 3.4 and as a result of PR 10957, and when using Neo4j Enterprise the Neo4j pagecache will be preserved across database restarts and as such a need to pre-warm the pagecache may no longer be needed.
As a result of the PR, at every 60 seconds we will record the pages of the Neo4j pagecache and store this data at graph.db/profile. Contents of this directory are similar to
$ ls -al
total 80
drwxrwxr-x 2 neo4j neo4j 4096 Apr 18 12:12 .
drwxrwxr-x 6 neo4j neo4j 4096 Apr 18 12:06 ..
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.counts.db.a.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 18 12:11 neostore.counts.db.b.cacheprof
-rw-rw-r-- 1 neo4j neo4j   24 Apr 19 08:31 neostore.labelscanstore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.labeltokenstore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.labeltokenstore.db.names.cacheprof
-rw-rw-r-- 1 neo4j neo4j   28 Apr 19 08:31 neostore.nodestore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.nodestore.db.labels.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.propertystore.db.arrays.cacheprof
-rw-rw-r-- 1 neo4j neo4j   29 Apr 19 08:31 neostore.propertystore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.propertystore.db.index.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.propertystore.db.index.keys.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.propertystore.db.strings.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.relationshipgroupstore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.relationshipstore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.relationshiptypestore.db.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.relationshiptypestore.db.names.cacheprof
-rw-rw-r-- 1 neo4j neo4j   21 Apr 19 08:31 neostore.schemastore.db.cacheprof
View all (8 more lines)
Since each file represents a gzipped bitmap of which pages are in-memory for a given file (i.e. each 8 KiB page is represented by one bit) we expect the above files to remain relatively small in size.
Also, the graph.db/profiles will be included in backups and thus upon restore and Neo4j start, the pagecahce will be reloaded based upon the state of the pagecache at time of backup.
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-solve-store-copy-failed-due-to-store-id-mismatch;"Solving the ""Store copy failed due to store ID mismatch"" error
Author Vivek Saran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cluster
It is possible that after seeding a cluster or restoring from a backup, you may encounter the following error while starting your cluster:
ERROR [o.n.c.c.s.s.CoreStateDownloader] Store copy failed due to store ID mismatch
In most of the cases, this issue can be resolved by taking the following steps:
Shell
Copy to Clipboard
neo4j-home> bin/neo4j stop
neo4j-home> bin/neo4j-admin unbind
neo4j-home> bin/neo4j start
In the situation where the member of the cluster is unresponsive, then you will have to add two more steps:
Shell
Copy to Clipboard
neo4j-home> bin/neo4j stop
neo4j-home> bin/neo4j-admin unbind
# remove the graph.db
# restore graph.db from another core server
neo4j-home> bin/neo4j start
If after taking the above steps, your cluster does not come up, then please open a ticket with Neo4j Customer Support.
Was this page helpful?"
https://neo4j.com/developer/kb/command-expansion-example-on-windows;"Example of using the Command Expansion on Windows
Author Vivek Saran Applicable versions 4.2 4.3 4.4 Tags system command expansion
The Command Expansion feature, introduced in Neo4j 4.2, is a security feature to avoid having configuration parameters being written in the neo4j.conf file in plain text.
The commands are executed within the child process by the user who owns and executes the Neo4j server. So, by definition, only the user running the Neo4j process/service would be able to use this feature.
The Command Expansion is very sensitive about the permissions assigned on the neo4j.conf file. If the permissions are not set appropriately, then Neo4j fails to start showing messages similar to:
Properties
Copy to Clipboard
Exception in thread ""main"" java.lang.IllegalArgumentException:
<NEO4J_HOME>/conf/neo4j.conf does not have the correct file permissions to evaluate commands.
Has [OWNER_READ, OWNER_WRITE, OTHERS_READ, GROUP_READ], requires at most [OWNER_READ, OWNER_WRITE].
        at org.neo4j.configuration.Config$Builder.validateFilePermissionForCommandExpansion(Config.java:314)
        at org.neo4j.configuration.Config$Builder.build(Config.java:287)
        at org.neo4j.server.NeoBootstrapper.start(NeoBootstrapper.java:110)
        at org.neo4j.server.NeoBootstrapper.start(NeoBootstrapper.java:90)
        at com.neo4j.server.enterprise.EnterpriseEntryPoint.main(EnterpriseEntryPoint.java:25)
2021-03-03 16:56:23.880+0000 INFO  [c.n.s.e.EnterpriseBootstrapper] Neo4j Server shutdown initiated by request
2021-03-03 16:56:23.891+0000 INFO  [c.n.s.e.EnterpriseBootstrapper] Stopped.
That’s why the need for this article!
Moreover, the Neo4j documentation has provided examples for the Linux based installs, so here is a fun example (step-by-step) of using the Command Expansion on Windows:
Change the neo4j.conf file to have the following setting:
Properties
Copy to Clipboard
dbms.max_databases=$(my_setting.bat)
Create an environment variable:
Properties
Copy to Clipboard
MAX_DATABASES=16
Create a simple batch file my_setting.bat:
Properties
Copy to Clipboard
@ECHO OFF
ECHO %MAX_DATABASES%
Change the permission on the neo4j.conf file to Read. Remove all user groups and user names except the user who owns and executes the Neo4j server. Refer to the picture below:
In the Linux world, this would be equivalent to r-- --- ---, which is done by:
Properties
Copy to Clipboard
$chmod 400 neo4j.conf
Start Neo4j using the following command -
Properties
Copy to Clipboard
C:\neo4j-enterprise-4.2.3-windows\neo4j-enterprise-4.2.3\bin>neo4j console --expand-commands
During the start, the console would show the following INFO messages:
Properties
Copy to Clipboard
2021-03-04 03:17:40.575+0000 INFO  Command expansion is explicitly enabled for configuration
2021-03-04 03:17:40.577+0000 INFO  Executing external script to retrieve value of setting dbms.max_databases
2021-03-04 03:17:40.579+0000 INFO  Starting...
2021-03-04 03:17:43.311+0000 INFO  ======== Neo4j 4.2.3 ========
2021-03-04 03:17:45.825+0000 INFO  Sending metrics to CSV file at C:\neo4j-enterprise-4.2.3-windows\neo4j-enterprise-4.2.3\metrics
2021-03-04 03:17:45.860+0000 INFO  Bolt enabled on 0.0.0.0:7617.
2021-03-04 03:17:46.818+0000 INFO  Remote interface available at http://localhost:7414/
2021-03-04 03:17:46.819+0000 INFO  Started.
To confirm that the dbms.max_databases property has been set to 16, execute the following command in the Neo4j Browser:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL dbms.listConfig() YIELD name, value WHERE name = 'dbms.max_databases' RETURN value
The result would be 16.
Note that by default, the file permissions on the neo4j.conf would look as shown below.
All users such as Authenticated Users, SYSTEM, Administrators, Users, etc. will need to be removed.
Was this page helpful?"
https://neo4j.com/developer/kb/an-overview-of-the-system-database;"An overview of the system database
Author Vivek Saran Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags system
Neo4j 4.0 and higher versions support the management of multiple databases within the same DBMS. All these databases are controlled through a special database called the system database.
This article provides a brief architectural overview of the system database.
The role of the system database is to define the configuration for the other databases. There could be various types of configuration for the databases. For example:
operational configuration
existence (exists or not)
status (online/offline)
security configuration (RBAC)
neo4j.conf (this is not yet maintained by the system database, but there are plans in the future versions)
A lot of interesting operational work happens (behind the scenes) both in standalone and clustered environments, which is handled by a component called the reconciler. Refer to Fig 2 below.
The system database is replicated across the cluster, and there is a leader for it just like any other database. Every database in 4.0 and going forward is in an independent raft group. That means core-1 could be the leader for the system database, whereas core-2 could be the leader for mydb database. Everything inside the system database is also stored in a graph data model. However, only DDL commands (CREATE, DROP, SHOW, etc.) could be executed in this database, not the regular Cypher commands (MATCH, for example). There are nodes representing other databases (neo4j and mydb in this example from Fig 2).
The reconciler talks to another component called the database manager, which manages the actual databases. Every instance reconciles the local copies of all the databases. If the reconciler on core-2 (in the above example) knows that mydb became online in the leader (core-1), it ensures that mydb becomes online in this instance as well. The system database in every instance has a reconciler and a database manager.
The reconciler’s job is to reconcile between the desired state (STOPPED, STARTED, DROPPED) and the current state.
One important aspect of the reconciler is that it operates completely asynchronously and always from the replicated ""source of truth"" desired state as written into the system database. If a server for example is partitioned for a while from the rest of the cluster, or is falling behind for some reason, then it will not get the updates to the ""desired state"" and hence the reconciler on that server will not yet perform the operational changes that the other servers already have done. As soon as the cluster is back to normal though, with connectivity and all, then the reconciler will continue of course.
When a database with the name mydb is created, a node with the label Database gets created in the system database. The node has a few other properties such as name, status, uuid, as shown in the picture above. The interesting thing to note is that when mydb database is dropped, the label of the node will change to DeletedDatabase.
Here is an example of a single Database node:
None
Copy to Clipboard
( n:Database { name : mydb, uuid: 7242f697-7f4f-4bbf-b989-aad3e8980bfb, status: online } )
and if it gets deleted just change the Database label to DeletedDatabase:
None
Copy to Clipboard
( n:DeletedDatabase { name : mydb, uuid: 7242f697-7f4f-4bbf-b989-aad3e8980bfb, status: offline } )
The property that uniquely identifies a database internally, is the uuid, which is of type UUID. So, you may DROP a database neo4j and then CREATE it again. Internally, the first one will exist with the DeletedDatabase label, and the new one will have the Database label with a different uuid.
When you backup the system database, remember that it has the operational configuration in it. Let’s say, when the online backup of the system database was taken, mydb database was stopped at that time. So, when you restore the system database backup, mydb will have the stopped state. So, the operational state is always defined by what is in the system database.
Following is a state diagram (Fig 3) of the all the states reconciler will publish when the SHOW DATABASES command is executed.
The existence of a folder (for example, $neo4j_home/data/database/mydb) in the file system does not define the database’s presence. It is determined by what is in the system database. If the database is not in the system database, then it is not registered even if the folder is there. To have the system pick up the database, you will need to execute CREATE DATABASE mydb.
Furthermore, if the system database has a database Xdb and before it is restored, there is no such database in the $neo4j_home/data/database/ location, then the reconciler will create the folder, and now you will have a blank Xdb. However, if there are other instances in the cluster that actively have an Xdb database up and running, the cluster binding process will do a store copy of that database and not create an empty database.
Finally, here are a few more points to note from a multi database operations standpoint:
The system database needs to be backed up with the same frequency that other databases are backed up.
If you look at the debug.log, the MemberId of the raft membership will not be different for each database. All databases within one instance will have the same MemberId.
All multi-database administrative commands must be run against the system database. These administrative commands are automatically routed to the system database when connected to the DBMS over Bolt.
The native users are stored in the system database, that is where the security model lives.
The neo4j-admin unbind runs on all the databases on the particular server.
The dbms.memory.pagecache.size ,dbms.memory.heap.initial_size, and dbms.memory.heap.max_size settings are all at the instance level. All the databases operate under one JVM, they share the same page cache and heap.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-import-into-running-4-0-instance;"Bulk Import / Backups into running 4.0 instances
Author David Fauth Applicable versions 4.0 4.1 4.2 4.3 4.4 Tags import-export operations
Neo4j 4.0 allows for multiple running databases. You can use neo4j-admin import or neo4j-admin restore to import or restore a database into a new database on a running 4.0 instance.
Neo4j-Admin Import Standalone Server
Run the Neo4j-Admin import to create the database. In this example, we are running a bulk import into a new database called dataload1. Node labels are STORE.
Shell
Copy to Clipboard
$ ./bin/neo4j-admin import --database=dataload1 --nodes=:STORE=""/home/ubuntu/tmp/header.csv,/home/ubuntu/tmp/nodes.csv"" --skip-duplicate-nodes=true --high-io=true
Log into Neo4j 4.0
neo4j> :use system
neo4j> create database dataload1
neo4j> show databases
neo4j> :use dataload1
neo4j> MATCH (n:STORE) return n limit 3;
Run a second Neo4j-Admin import to create another database. In this example, we are running a bulk import into a new database called dataload2. Node labels are STORE.
Shell
Copy to Clipboard
$./bin/neo4j-admin import --database=dataload2 --nodes=:STORE=""/home/ubuntu/tmp/header.csv,/home/ubuntu/tmp/nodes.csv"" --skip-duplicate-nodes=true --high-io=true
Log into Neo4j 4.0
neo4j> :use system
neo4j> create database dataload2
neo4j> show databases
neo4j> :use dataload2
neo4j> MATCH (n:STORE) return n limit 3;
Neo4j-Admin Import Cluster
Run the Neo4j-Admin import to create the database. In this example, we are running a bulk import into a new database called dataload1. Node labels are STORE. Please note that you don’t need to stop your cluster to run the import tool, but the import tool will consume memory and cpu resources which may not be available on a server already running a Neo4j instance.
Shell
Copy to Clipboard
$ ./bin/neo4j-admin import --database=dataload1 --nodes=:STORE=""/home/ubuntu/tmp/header.csv,/home/ubuntu/tmp/nodes.csv"" --skip-duplicate-nodes=true --high-io=true
Copy the store created by the import tool to all core instances. You’ll need to copy the content of both <neo4j-home>/data/databases/dataload1 & <neo4j-home>/data/transactions/dataload1.
Run CREATE DATABASE dataload1 (on Neo4j 4.0 that command would need to run against the system database, on the instance that is currently leader for that database). Once the database is created on the cluster leader, it will be propagated to the other cluster members.
neo4j> :use system
neo4j> create database dataload1
neo4j> show databases
neo4j> :use dataload1
neo4j> MATCH (n:STORE) return n limit 3;
Neo4j-Admin Restore
In this example, we will backup the dataload1 database and use it to create a new dataload3 database.
Shell
Copy to Clipboard
$ ./bin/neo4j-admin backup --backup-dir=/home/ubuntu/tmp/backups --database=dataload1
$ ./bin/neo4j-admin restore --from=/home/ubuntu/tmp/backups/dataload1 --database=dataload3
neo4j> :use system
neo4j> create database dataload3
neo4j> show databases
neo4j> :use dataload3
neo4j> MATCH (n:STORE) return n limit 3;
If you want to replace an existing 4.0 database using neo4j-admin restore, you would run the following:
neo4j> :use system
neo4j> stop database dataload2
Shell
Copy to Clipboard
$ ./bin/neo4j-admin restore --from=/home/ubuntu/tmp/backups/dataload1 --database=dataload2 --force
neo4j> start database dataload2
neo4j> MATCH (n:STORE) return n limit 3;
Was this page helpful?"
https://neo4j.com/developer/kb/storeid-is-different-from-this-machine;"Explantion of ""storeId is different from this machine"" error
Author Vivek Saran Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags causal-cluster
If you encounter a ""Failed to serve TxPullRequest for … storeId xxxxxx because that storeId is different from this machine with Store…"" in your $NEO4J_HOME/logs/debug.log similar to:
INFO [o.n.c.c.t.TxPullRequestHandler] Failed to serve TxPullRequest for tx 29193 and
storeId Store{creationTime:1591347647541, randomId:6812995525063259919, upgradeTime:1591347647541, upgradeId:1}
because that storeId is different from this machine with Store
{creationTime:1595941375808, randomId:-4448032294085490672, upgradeTime:1595941375808, upgradeId:1}
This means that the storId is different. When a Neo4j instance starts, you will notice a line similar to the following entry in the debug.log:
INFO [o.n.c.c.s.LocalDatabase] Starting with storeId: Store
{creationTime:1582039045717, randomId:4716225943436743213, upgradeTime:1582039045717, upgradeId:1}
All instances in a Neo4j Causal Cluster will show a storeId (listed as randomId) entry similar to above in the `debug.log. If the storeId is different for any member of the cluster, the ""storeId is different from this machine"" error will show up.
How do you recover from this mismatch?
Identify the Neo4j node that has the highest randomId, this is the storeId as show in the example above
Take an online backup of the above node
Stop the instance(s) that has a lower randomId
Execute $bin/neo4j-admin unbind
Restore the backup on that instance(s)
Start Neo4j
Please feel free to open a ticket with Neo4j Support, if you have questions about this subject or if you enolunter this error.
Was this page helpful?"
https://neo4j.com/developer/kb/bolt-throttling;"Throttling Bolt Requests
Author David Pecollet Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags performance configuration bolt tcp
When large amounts of data are sent between a Neo4j database and a client (typically large query results, from server to client), there are a few hidden throttling mechanisms that may come into play.
TCP Throttling
Bolt connections between a client & the Neo4j server are riding over TCP.
Client Receive Window
TCP tries to adapt the amount of data sent so as not to overwhelm the client. The client indeed needs to process the received data, which may take time and may cause the read buffer to fill up faster than it’s emptied.
How does that work ? Each time a client acknowledges reception of data, it sends a TCP ACK, with the current available capacity of its read buffer. That’s called the Receive Window.
When capturing traffic (with tcpdump for ex), and opening a capture file in a tool like Wireshark, the Receive Window shows up as property 'WIN' in the ACKs. That value can go up to 65536. To convert it into a number of bytes, multiply that value by the Window Scaling factor, that you can find in the initial TCP connection 3-way handshake (SYN/SYN-ACK/ACK) as property 'WS'.
The server will use that Receive Window to modulate the amount of data it sends. It keeps track of the amount of data 'in flight' (sent but not yet acknowledged), and makes sure that never gets over the Receive Window, by reducing the rate at which it sends data. If the client’s Receive Window gets to zero (Wireshark marks those ACKs as TCP ZeroWindow), the server will stop sending and wait for it to increase again (the client then sends a TCP Window Update to signal the increase).
Congestion Window
TCP also adapts the transmission rate based on congestion. The server maintains a Congestion Window. That window starts at small values (small multiples of the network MTU) and increases steadily until packet loss occurs. When that happens, the Congestion Window is halved (usually, but the decrease varies with different congestion avoidance algorithms), and the steady increase resumes. TCP’s actual sending rate is predicated on the minimum of the client’s Receive Window and the Congestion Window.
Bolt server Throttling
On top of TCP’s own throttling, the Neo4j Bolt server throttles the rate at which it writes data to its write buffers.
That is controlled by the following configuration parameters :
Properties
Copy to Clipboard
unsupported.dbms.bolt.outbound_buffer_throttle=true
unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark=512k
unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark=128k
unsupported.dbms.bolt.outbound_buffer_throttle.max_duration=15min
When the write buffer fills up to the high watermark, writing will pause. While the Bolt server waits, it receives ACKs from the client, which allow him to remove the corresponding data from the write buffer. The server polls the buffer every second to check whether the low watermark has been reached. When that happens, it resumes writing.
Note on Timeouts
The config parameter unsupported.dbms.bolt.outbound_buffer_throttle.max_duration controls the maximum amount of time a connection can be throttled. An exception is returned to the client when that time is reached : ""Bolt connection [%s] will be closed because the client did not consume outgoing buffers for %s which is not expected.""
That timeout may interfere with transaction timeouts (dbms.transaction.timeout). When the transaction timeout is lower than the throttling timeout, a throttling pause may delay the moment when the timed out transaction is terminated, which may make it appear as if the transaction timeout was exceeded.
How can you know Bolt throttling is happening?
Thread dumps are your best chance as there are no entry in the logs when throttling triggers. Generally assumes it does happen for queries with large resultsets relative to the high watermark (1MB+), as it’s very likely that consumption of results is slower than production, and that the outbound buffer fills up rapidly.
Was this page helpful?"
https://neo4j.com/developer/kb/analyzing-a-java-heap-dump;"Analyzing a java heap dump
Author Jérémie Phoulchand Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags heap-dump out-of-memory monitoring
The purpose of this article is to help you go through the acquired heapdump with Eclipse MAT. It covers how to parse a large heap files and what to look for.
When you experience an OutOfMemory exception, it will produce a .hprof file if you have the below settings in the neo4j.conf file:
Properties
Copy to Clipboard
dbms.jvm.additional=-XX:+HeapDumpOnOutOfMemoryError
You can also add tweak the below settings to specify the directory path but ensure that you have enough disk space when such error occurs.
Properties
Copy to Clipboard
dbms.jvm.additional=-XX:HeapDumpPath=/var/tmp/dumps
dbms.jvm.additional=-XX:OnOutOfMemoryError=""tar cvzf /var/tmp/dump.tar.gz /var/tmp/dump;split -b 1G /var/tmp/dump.tar.gz;""
This file is the image of the heap part of the java process running on your system. The structure of the file depends on the JVM vendor you are running neo4j with.
Oracle JDK, Open JDK will produce hprof files and can be analyzed with most available tools. For IBM heap dumps, you need to parse it with IBM heap analyzer or other proprietary tool.
Change the settings in MemoryAnalyzer.ini
On your local environment
You need to allocate as much memory to the process as heap dump filesize you have.
IE: allocate 17GB if the heap is about 15GB.
For large heap dumps (> 25G), see next section.
Edit MemoryAnalyzer.ini (on macOS, it is located in /Applications/mat.app/Contents/Eclipse/MemoryAnalyzer.ini)
Add or change the settings:
-Xms10G
-Xmx25G
On a remote machine
It’s better to upload it to an instance with a lot of disk and RAM on AWS/GCP/etc. If you choose AWS, use a spot instance.
Then you need to attach the EBS storage, create a 250GB volume, attach it to the EC2 instance. Format the volume and mount it on your Amazon Linux instance.
Note down both instanceid and storageid to make sure the ressource have properly been discarded after usage.
If the heap is about 61GB, you need twice as much disk space for parsing. As illustrated below:
Shell
$ du -ch java_pid19820*
116M java_pid19820.a2s.index
5.6G java_pid19820.domIn.index
 17G java_pid19820.domOut.index
 61G java_pid19820.hprof #original heap dump
256K java_pid19820.i2sv2.index
 11G java_pid19820.idx.index
 29G java_pid19820.inbound.index
197M java_pid19820.index
4.5G java_pid19820.o2c.index
 12G java_pid19820.o2hprof.index
 11G java_pid19820.o2ret.index
 29G java_pid19820.outbound.index
988K java_pid19820.threads
 68K java_pid19820_Component_Report_sel.zip
180G total
Pre-requisite Install java and make sure to have 250GB space available
Download MemoryAnalyzer tool for linux: download
Unzip it in a directory
Edit MemoryAnalyzer.ini to adjust both -Xms and -Xmx memory settings :
-startup
plugins/org.eclipse.equinox.launcher_1.5.0.v20180512-1130.jar
--launcher.library
plugins/org.eclipse.equinox.launcher.gtk.linux.x86_64_1.1.700.v20180518-1200
-vmargs
-Xms30G
-Xmx100G
Parse the file on a remote machine
This step is optional if you run Eclipse MAT on your local machine and have enough resources. The index files will be created when opening the heapdump file if they are missing.
Run ./ParseHeapDump.sh heapdump.hprof
It is located in the folder mat of Eclipse Mat tar.gz installation file
Synchronize your local directory with the remote one
To speed up things, you can use rsync over ssh. The advantage is that you can recover if you have a crash and -z flag enables compression.
Example:
Shell
Copy to Clipboard
# on the remote machine
$ mkdir ${REMOTE_DIR}/parsed_files
$ mv *.index ${REMOTE_DIR}/parsed_files/

# on your local machine
$ rsync -P  -e ""ssh -i ${PATH_TO_KEY}""  ec2-user@${REMOTE_IP}:${REMOTE_DIR}/heapdump.zip .
$ rsync -Prz  -e ""ssh -i ${PATH_TO_KEY}  ec2-user@${REMOTE_IP}:${REMOTE_DIR}/parsed_files/ .
Open Eclipse MAT
To open the heapdump, go to File > Open Heap Dump (Not Acquire Heap Dump) and browse to your heapdump location.
No need to open an existing report, press cancel if you have a modal dialog.
In the Overview tab, left-click on the largest object(s)
Choose ""list objects"" > ""with outgoing references"".
It will open a new tab with the list of all the elements.
Expand the first level then expand everything at the second level.
Cypher query string
There are a lot of objects in a heap dump, no need to go through the Object[],byte[],Strings, etc.
You might want to filter for the class that contain PreParsed. Once found, list their outgoing references to cross check of the one that has the most instances. A new tab will open and you will be able to see the rawStatement of the Cypher queries.
Check the thread dumps
With thread dumps that has been taken before the heap dump
The garbage collector will not be able to collect the thread objects until the threading system also dereferences the object, which won’t happen if the thread is alive.
So if you have a large amount of memory in the heap, there should be a potentially long running thread associated to your large object.
To find it, look for the thread name in the thread dumps.
Shell
$ grep neo4j.BoltWorker-394 *

5913-tdump-201903291746.log:""neo4j.BoltWorker-394 [bolt]"" #620 daemon prio=5 os_prio=0 tid=0x00007fb737619800 nid=0x8cec waiting on condition [0x00007fb38d00f000]
5913-tdump-201903291751.log:""neo4j.BoltWorker-394 [bolt] [/www.xxx.yyy.zzz:57570] "" #620 daemon prio=5 os_prio=0 tid=0x00007fb737619800 nid=0x8cec runnable [0x00007fb38d00b000]
5913-tdump-201903291756.log:""neo4j.BoltWorker-394 [bolt] [/www.xxx.yyy.zzz:57570] "" #620 daemon prio=5 os_prio=0 tid=0x00007fb737619800 nid=0x8cec runnable [0x00007fb38d00b000]
Note that the thread dumps are included in the heap dump. They are available in plain text in the file but you don’t have the STATE information in Eclipse Mat. You can have them with other tools such as VisualVM:
Shell
$ head -10 java_pid19820.threads
Thread 0x7fd64b0e1610
  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.addConditionWaiter()Ljava/util/concurrent/locks/AbstractQueuedSynchronizer$Node; (AbstractQueuedSynchronizer.java:1855)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(J)J (AbstractQueuedSynchronizer.java:2068)
  at java.util.concurrent.LinkedBlockingQueue.poll(JLjava/util/concurrent/TimeUnit;)Ljava/lang/Object; (LinkedBlockingQueue.java:467)
  at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run()V (CachedExecutorServiceDelegate.java:210)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(Ljava/util/concurrent/ThreadPoolExecutor$Worker;)V (ThreadPoolExecutor.java:1149)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run()V (ThreadPoolExecutor.java:624)
  at java.lang.Thread.run()V (Thread.java:748)
  at com.hazelcast.util.executor.HazelcastManagedThread.executeRun()V (HazelcastManagedThread.java:76)
  at com.hazelcast.util.executor.HazelcastManagedThread.run()V (HazelcastManagedThread.java:92)
Was this page helpful?"
https://neo4j.com/developer/kb/how-to-configure-off-heap-transaction-state;"How to configure off-heap transaction state
Author Andrei Koval Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags memory performance
This feature is experimental in 3.5, on by default in 4.0.
Commencing with Neo4j 3.5, it is possible to store some of transactions' data in off-heap memory. This can help to reduce GC pressure and/or prevent OOM crashes in a limited set of use cases, such as:
Creating/removing huge number of entities in a single transaction
Creating/updating huge number of properties in a single transaction, especially if those are large strings
There are two relevant configuration parameters, both of which static and cannot be changed at run time.
dbms.tx_state.memory_allocation
This parameter controls whether transaction state should be stored on- or off-heap. Possible values are ON_HEAP and OFF_HEAP. Default value is ON_HEAP.
dbms.tx_state.max_off_heap_memory
This parameter allows to set a global limit on amount of off-heap memory that can be used for storing transaction state data. Zero means ""unlimited"". Default value is 2G.
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-database-growth;"Understanding Database Growth
Author Dana Canzano Applicable versions 3.2 3.3 Tags database growth copy-store operations
The easiest way to determine the size of your graph is through the filesystem and summing up the size of the files named *store.db*. For example on linux implementations one can run
Shell
Copy to Clipboard
$ du -hc $NEO4J_HOME/data/databases/graph.db/*store.db*
and this should be run on a stopped database or one which has recently checkpointed (i.e. immediately after backup)
and this will produce output similar to
5.5M    neostore.labelscanstore.db
8.0K    neostore.labeltokenstore.db
4.0K    neostore.labeltokenstore.db.id
8.0K    neostore.labeltokenstore.db.names
4.0K    neostore.labeltokenstore.db.names.id
72M     neostore.nodestore.db
4.0K    neostore.nodestore.db.id
8.0K    neostore.nodestore.db.labels
4.0K    neostore.nodestore.db.labels.id
196M    neostore.propertystore.db
8.0K    neostore.propertystore.db.arrays
4.0K    neostore.propertystore.db.arrays.id
4.0K    neostore.propertystore.db.id
8.0K    neostore.propertystore.db.index
4.0K    neostore.propertystore.db.index.id
8.0K    neostore.propertystore.db.index.keys
4.0K    neostore.propertystore.db.index.keys.id
8.0K    neostore.propertystore.db.strings
4.0K    neostore.propertystore.db.strings.id
8.0K    neostore.relationshipgroupstore.db
4.0K    neostore.relationshipgroupstore.db.id
0       neostore.relationshipstore.db
4.0K    neostore.relationshipstore.db.id
0       neostore.relationshiptypestore.db
4.0K    neostore.relationshiptypestore.db.id
8.0K    neostore.relationshiptypestore.db.names
4.0K    neostore.relationshiptypestore.db.names.id
8.0K    neostore.schemastore.db
4.0K    neostore.schemastore.db.id
273M    total
To which the final line reports that the total size of the graph is 273M. This does not include the size of the Neo4j transaction logs (neostore.transaction.*) but that is because the size of these files and retention is user configurable.
In the above listing the output was taken from a graph which contained 5 million nodes all with the label :Person and each node had a property named id and it was a value from 1 to 5 million. This data was prepared by running the equivalent of
Cypher
Copy to Clipboard
Run in Neo4j Browser
USING PERIODIC COMMIT 50000
LOAD CSV WITH HEADERS FROM 'file:///person.csv' AS row
CREATE (:Person { id: row.id}  );
Because of this you will see that the neostore.labelscanstore*, neostore.nodestore* and neostore.propertystore* files consume more than their default space. Since the graph has no relationship the files named neostore.relationship* are effectively empty.
It should be obvious that as you add data the files will grow in size. However there is one caveat to this which could explain why adding more data actually results in your database size decreasing.
In the above file listing the files ending in .id, for example neostore.nodestore.db.id, serve as a recycle bin of IDs which are eligible for re-use. As the graph was simply populated with 5 million :Person nodes, and nothing was deleted the neostore.nodestore.db.id is empty and the nodes are recorded in neostore.nodestore.db. However, if we were to then delete all 5 million nodes, we will see that the size of neostore.nodestore.db does not decrease but neostore.nodestore.db.id increases to a size of 39M. And as a result of this delete, we see that the total graph size has increased by at least 39M. Now if we were to re-insert the 5 million nodes, then the size of neostore.nodestore.db.id will decrease because as new nodes are added we first check to see if we can re-use an ID that was previously in use and if so we remove it from the neostore.nodestore.db.id. Since the neostore.nodestore.db.id had 5 million ids which could be re-used and since we added 5 million nodes, then this file would be near empty (i.e. 4.0 K) upon completion. By adding these nodes, which reduced the size of neostore.nodestore.db.id from 39M to 4.0k the total database size also decreased in the same fashion. Note the size of neostore.nodestore.db has not changed in this experience.
In summary the experience is as follows relative to these 2 files (and with file size capture after a neo4j stop)
step 1: empty graph
0       neostore.nodestore.db
4.0K    neostore.nodestore.db.id
step 2: add 5 million :Person nodes
72M     neostore.nodestore.db
4.0K    neostore.nodestore.db.id
step 3: remove 5 million :Person nodes (i.e. CALL apoc.periodic.commit(""match (n:Person) with n limit {limit} delete n return count(*)"",{limit:50000});)  — at which point the graph is now empty
72M     neostore.nodestore.db
39M     neostore.nodestore.db.id
step 4: re-add the 5 million :Person nodes
72M     neostore.nodestore.db
4.0K    neostore.nodestore.db.id
Now if you had reached step #3 above and did not plan to add more nodes but wanted to shrink the size of the files you will want to consider using copy-store.sh. This utility will read a offline database and copy out the data and not include any of the overhead of either data written but no longer in use or the list of eligible IDs to re-use.
After running copy-store.sh against the graph (as it existed at the completion of step #3 above) so as to prepare a new graph the resultant newly created graph.db now defined the 2 files as
0       neostore.nodestore.db
4.0K    neostore.nodestore.db.id
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-streams-kafka-integration-list-of-mustgather-for-troubleshooting;"Neo4j Streams - Kafka Integration - List of Must Gather for Troubleshooting
Author Daniel Terlizzi Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags troubleshooting
When troubleshooting issues on Neo4j Streams, use the below list of must gather information points to help investigating.
Which Plugin/Module are you using?
Neo4j Streams Source
Neo4j Streams Sink
Neo4j Streams Procedure
Kafka Connect Sink. In case of using Sink, also provide the chosen data format (JSON or AVRO).
List of plugin configuration:
If using Neo4j Streams then provide the list of properties used to configure sink into neo4j.conf file
If using Kafka Connect then provide the *.json or the *.properties file used to create the plugin instance into the Kafka Connect framework
Apache Kafka Version
Go to Apache Kafka or Confluent Platform (depending on which distribution you are using) installation folder and then into /bin folder. Run the following command and provide the output: ./kafka-configs.sh --version
Provide the Neo4j/Kafka Connect debug Log: If you are using the Neo4j plugin we need the neo4j.log file otherwise the Kafka Connect log file. The Kafka Connect log file is under the folder <kafka_connect_home>/logs/connectDistributed.out
Kafka configuration
The configuration used to instantiate the Kafka Cluster configuration
(OPTIONAL) Kafka metrics
Broker metrics
Producer metrics
Consumer metrics
Zookeeper metrics
By default metrics logs are under the server.log file
(OPTIONAL) Neo4j metrics
The CSV file
Reference:
Neo4j Streaming Data Integrations User Guide https://neo4j.com/docs/labs/neo4j-streams/current/
Neo4j metrics output facilities https://neo4j.com/docs/operations-manual/current/monitoring/metrics/
Was this page helpful?"
https://neo4j.com/developer/kb/understanding-transaction-and-lock-timeouts;"Understanding transaction and lock timeouts
Author Andrew Bowman Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags cypher performance apoc
One way to handle runaway queries is to impose a time limit that will terminate a query when exceeded. There are some subtleties here that need to be understood to ensure proper behavior and avoid confusion.
Defining a transaction timeout
You can set dbms.transaction.timeout in your neo4j.conf file. The value must be a duration followed by a time unit (ms, s, m, h; default is s).
dbms.transaction.timeout=2m
While this will adequately handle and terminate an executing query that exceeds the timeout, there may be some cases where a query or transaction seems to hang indefinitely, the timeout seemingly not enforced.
Debug logs may report termination of the query, but often after a long time has elapsed:
WARN  [o.n.k.g.TimeoutGuard] Transaction timeout. (Overtime: 523299 ms)
A separate timeout must be set on lock acquisition
The main reason for such behavior is that a transaction might be stuck waiting on a lock. A transaction in such a state is waiting for a lock to be released by another transaction, and not executing code. This includes code that checks to see if the transaction has been marked for termination (as a result of exceeding the transaction timeout).
In Neo4j 3.2, a new configuration option was introduced:
dbms.lock.acquisition.timeout.
This terminates a transaction exceeding the timeout while acquiring a lock.
It’s highly recommended that when you set the transaction timeout that you set the lock acquisition timeout as well.
APOC can be used to execute a timeboxed query
Using apoc.cypher.runTimeboxed() from APOC Procedures, you can execute a dynamic read-only cypher query that will auto-terminate when the given millisecond limit is reached.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runTimeboxed(""MATCH (n:Person{name:'Keanu Reeves'})-[*]-(other)
 RETURN count(*) as allPathsCount"",
 {}, 20000)
Was this page helpful?"
https://neo4j.com/developer/kb/lock-manager-differences-explained;"Lock Manager Differences Explained
Author Dana Canzano Applicable versions 2.3 3.0 Tags lock performance
Work in Progress
Community:
uses Java intrinsic locks, i.e. ’synchronized’. this might not perform that well on multiprocessor machines
uses Thread.sleep() and Thread.interrupt() to wait for locks. this involves context switches which can be expensive
keeps global graph or all locks to detect deadlocks. this is a shared data structure that needs to be updated on every lock operation, so again synchronization overhead
creates lock clients for every new started transaction
Enterprise:
uses compare-and-set instructions (AtomicInteger, AtomicLong) and concurrent non-blocking data structures (ConcurrentHashMap) instead of synchronization. they should give better scaling
uses a combination of busy-waits and Thread.sleep() to wait for locks. this should theoretically give less context switches
has no global resource to detect deadlocks. each lock client has a local unsynchronized bit-set for deadlock detection. so there is no global shared resource to update
pools lock clients so newly created transactions can just take them from a thread-local storage
bit-set used for deadlock detection is not synchronized but is updated and read from different threads. this racy access is on purpose for performance but it leads to false-positive deadlocks
Generally speaking you should not need to change the default lock_manager but to do so would require you to editing the $NEO4J_HOME/conf/neo4j.conf (3.x) or $NEO4J_HOME/conf/neo4j.properties (2.x) and include
Properties
Copy to Clipboard
lock_manager=community
and then restart Neo4j.
Was this page helpful?"
https://neo4j.com/developer/kb/neo4j-current-transaction-commit-process-order;"Neo4j current transaction commit process order
Author José Rocha Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 Tags transaction commit
Transactions in Neo4j use a read-committed isolation level, which means they will see data as soon as it has been committed and will not see data in other transactions that have not yet been committed. This type of isolation is weaker than serialization but offers significant performance advantages whilst being sufficient for the overwhelming majority of cases.
In addition, the Neo4j Java API enables explicit locking of nodes and relationships. Using locks gives the opportunity to simulate the effects of higher levels of isolation by obtaining and releasing locks explicitly. For example, if a write lock is taken on a common node or relationship, then all transactions will serialize on that lock — giving the effect of a serialization isolation level.
During transaction commit, all the transactional operations applied to a store in certain order. At the moment order of operations is:
Label tokens operations
Relationship type tokens operations
Property key token operations
Create Operations for:
Properties
Relationships
Relationship groups
Nodes
Update Operations for:
Properties
Relationships
Relationship groups
Nodes
Delete Operations for:
Properties
Relationships
Relationship groups
Nodes
Neo Store commands
Schema commands
Count store operations
Index operations
Legacy index operations
Please note we cannot guarantee that this order will remain the same in future versions of Neo4j. If it does change for some reason, we will update this article accordingly.
Was this page helpful?"
https://neo4j.com/developer/kb/how-do-i-enable-java-flight-recorder-and-view-the-results;"How do I enable Java Flight Recorder and view the Results
Author Dana Canzano Applicable versions 3.5 4.0 4.1 4.2 4.3 4.4 5.0 Tags configuration jvm
Java Flight Recorder can be used to capture low level Java properties and run-time data about Java processes, for example Neo4j.
Per https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr002.html
The Java Flight Recorder (JFR) is a commercial feature. You can use it for free on developer desktops/laptops, and for
evaluation purposes in test, development, and production environments. However, to enable JFR on a production server,
you require a commercial license. Using JMC UI for other purposes on the JDK does not require a commercial license.
JFR can be activated by configuring JVM options within a Java application at startup or by using the jcmd tool for a running Java application. The commands and options available will depend on the supported JVM in use based on the Neo4j version. The JMC documentation here links to the documentation of various JDK versions for example and may be helpful when the need for additional options arises.
To enable the Java Flight Recorder at the start of Neo4j service, the following JVM options should be added to the neo4j.conf and then Neo4j needs to be restarted for these changes to take effect. The JFR.dump commands discussed later can be used to dump the contents once enabled.
For 3.x
Properties
Copy to Clipboard
dbms.jvm.additional=-XX:+UnlockCommercialFeatures
dbms.jvm.additional=-XX:+FlightRecorder
dbms.jvm.additional=-XX:FlightRecorderOptions=defaultrecording=true,settings=profile
For 4.x
Properties
Copy to Clipboard
dbms.jvm.additional=-XX:StartFlightRecording=settings=profile
For 5.x
Properties
Copy to Clipboard
server.jvm.additional=-XX:StartFlightRecording=settings=profile
To begin a time based recording, at the command line run:
Shell
Copy to Clipboard
$ $JAVA_HOME/jcmd <pid> JFR.start duration=3600s filename=myrecording.jfr settings=/usr/lib/jvm/java-8-oracle/jre/lib/jfr/profile.jfc
replacing <pid> with the linux pid for the Neo4j process (i.e. ps -eaf | grep java).
The inclusion of duration=3600s, should have resulted in a recording that spanned 1 hour and this file will be written to at the completion of the 1 hour run.
The reference to filename=myrecording.jfr above, describes the output file to be produced. When no path is defined the resultant file will be recorded at $NEO4J_HOME. Alternatively one could define filename with a full path reference, for example filename=/tmp/myrecording.jfr.
Also the location of the profile.jfc may be at a different directory/path for your given install. The expected path is in $JRE_HOME/lib/jfr.
If you do not know how long to run the recording since the issue may be intermittent, run:
Shell
Copy to Clipboard
$ $JAVA_HOME/jcmd <pid> JFR.start settings=/usr/lib/jvm/java-8-oracle/jre/lib/jfr/profile.jfc
and to which this will report
3962:
Started recording 1. No limit (duration/maxsize/maxage) in use.

Use JFR.dump recording=1 filename=FILEPATH to copy recording data to file.
and to then dump the recording to a file run:
Shell
Copy to Clipboard
$ jcmd <pid> JFR.dump recording=<recording #> filename=<filename>
and then to completely stop the recording, though this does not dump the contents of the recording to a file run:
Shell
Copy to Clipboard
$ jcmd <pid> JFR.stop recording=<recording #>
(Note: The recording= option in the above commands is not used in the JDK versions for Neo4j 4.x and 5x and instead one can use name= . )
To view the results start Java Mission Control ($JAVA/HOME/jmc). This will launch a Java app as detailed below. Note, if you are connected via Putty or a Telnet client this may not launch. As an alternative, MobaXterm can be used.
The resultant Java Flight Recorder file can be analyzed using Java Mission Control. To start Java Mission Control run $JAVA_HOME/jmc. Once started, using menu File / Open File, one can then browse to the flight recorder file.
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/machine-learning/node-embeddings;"Node embeddings
Contents
1. Generalization across graphs
Node embedding algorithms compute low-dimensional vector representations of nodes in a graph. These vectors, also called embeddings, can be used for machine learning. The Neo4j Graph Data Science library contains the following node embedding algorithms:
Production-quality
FastRP
Beta
GraphSAGE
Node2Vec
1. Generalization across graphs
Node embeddings are typically used as input to downstream machine learning tasks such as node classification, link prediction and kNN similarity graph construction.
Often the graph used for constructing the embeddings and training the downstream model differs from the graph on which predictions are made. Compared to normal machine learning where we just have a stream of independent examples from some distribution, we now have graphs that are used to generate a set of labeled examples. Therefore, we must ensure that the set of training examples is representative of the set of labeled examples derived from the prediction graph. For this to work, certain things are required of the embedding algorithm, and we denote such algorithms as inductive [1].
In the GDS library the algorithms GraphSAGE and FastRP with propertyRatio=1.0 and randomSeed is set are inductive.
Embedding algorithms that are not inductive we call transductive. Their usage should be limited to the case where the test graph and predict graph are the same. An example of such an algorithm is Node2Vec.
1. This practical definition of induction may not agree completely with definitions elsewhere
Depth First Search
Fast Random Projection
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/machine-learning/node-embeddings/node2vec;"Node2Vec
Contents
1. Random Walks
2. Usage in machine learning pipelines
3. Syntax
4. Examples
This feature is in the beta tier. For more information on feature tiers, see API Tiers.
Node2Vec is a node embedding algorithm that computes a vector representation of a node based on random walks in the graph. The neighborhood is sampled through random walks. Using a number of random neighborhood samples, the algorithm trains a single hidden layer neural network. The neural network is trained to predict the likelihood that a node will occur in a walk based on the occurrence of another node.
For more information on this algorithm, see:
Grover, Aditya, and Jure Leskovec. ""node2vec: Scalable feature learning for networks."" Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 2016.
https://snap.stanford.edu/node2vec/
1. Random Walks
A main concept of the Node2Vec algorithm are the second order random walks. A random walk simulates a traversal of the graph in which the traversed relationships are chosen at random. In a classic random walk, each relationship has the same, possibly weighted, probability of being picked. This probability is not influenced by the previously visited nodes. The concept of second order random walks, however, tries to model the transition probability based on the currently visited node v, the node t visited before the current one, and the node x which is the target of a candidate relationship. Node2Vec random walks are thus influenced by two parameters: the returnFactor and the inOutFactor:
The returnFactor is used if t equals x, i.e., the random walk returns to the previously visited node.
The inOutFactor is used if the distance from t to x is equal to 2, i.e., the walk traverses further away from the node t
The probabilities for traversing a relationship during a random walk can be further influenced by specifying a relationshipWeightProperty. A relationship property value greater than 1 will increase the likelihood of a relationship being traversed, a property value between 0 and 1 will decrease that probability.
For every node in the graph Node2Vec generates a series of random walks with the particular node as start node. The number of random walks per node can be influenced by the walkPerNode configuration parameters, the walk length is controlled by the walkLength parameter.
2. Usage in machine learning pipelines
At this time, using Node2Vec as a node property step in a machine learning pipeline (like Link prediction pipelines and Node property prediction) is not well supported, at least if the end goal is to apply a prediction model using its embeddings.
In order for a machine learning model to be able to make useful predictions, it is important that features produced during prediction are of a similar distribution to the features produced during training of the model. Moreover, node property steps (whether Node2Vec or not) added to a pipeline are executed both during training, and during the prediction by the trained model. It is therefore problematic when a pipeline contains an embedding step which yields all too dissimilar embeddings during training and prediction.
The final embeddings produced by Node2Vec depends on the randomness in generating the initial node embedding vectors as well as the random walks taken in the computation. At this time, Node2Vec will produce non-deterministic results even if the randomSeed configuration parameter is set. So since embeddings will not be deterministic between runs, Node2Vec should not be used as a node property step in a pipeline at this time, unless the purpose is experimental and only the train mode is used.
It may still be useful to use Node2Vec node embeddings as features in a pipeline if they are produced outside the pipeline, as long as one is aware of the data leakage risks of not using the dataset split in the pipeline.
3. Syntax
Node2Vec syntax per mode
Stream mode
Mutate mode
Write mode
Cypher
Run Node2Vec in stream mode on a named graph.
Copy to Clipboard
CALL gds.beta.node2vec.stream(
  graphName: String,
  configuration: Map
) YIELD
  nodeId: Integer,
  embedding: List of Float
Table 1. Parameters
Name Type Default Optional Description
graphName
String
n/a
no
The name of a graph stored in the catalog.
configuration
Map
{}
yes
Configuration for algorithm-specifics and/or graph filtering.
Table 2. Configuration
Name Type Default Optional Description
nodeLabels
List of String
['*']
yes
Filter the named graph using the given node labels.
relationshipTypes
List of String
['*']
yes
Filter the named graph using the given relationship types.
concurrency
Integer
4
yes
The number of concurrent threads used for running the algorithm.
jobId
String
Generated internally
yes
An ID that can be provided to more easily track the algorithm’s progress.
walkLength
Integer
80
yes
The number of steps in a single random walk.
walksPerNode
Integer
10
yes
The number of random walks generated for each node.
inOutFactor
Float
1.0
yes
Tendency of the random walk to stay close to the start node or fan out in the graph. Higher value means stay local.
returnFactor
Float
1.0
yes
Tendency of the random walk to return to the last visited node. A value below 1.0 means a higher tendency.
relationshipWeightProperty
String
null
yes
Name of the relationship property to use as weights to influence the probabilities of the random walks. The weights need to be >= 0. If unspecified, the algorithm runs unweighted.
windowSize
Integer
10
yes
Size of the context window when training the neural network.
negativeSamplingRate
Integer
5
yes
Number of negative samples to produce for each positive sample.
positiveSamplingFactor
Float
0.001
yes
Factor for influencing the distribution for positive samples. A higher value increases the probability that frequent nodes are down-sampled.
negativeSamplingExponent
Float
0.75
yes
Exponent applied to the node frequency to obtain the negative sampling distribution. A value of 1.0 samples proportionally to the frequency. A value of 0.0 samples each node equally.
embeddingDimension
Integer
128
yes
Size of the computed node embeddings.
embeddingInitializer
String
NORMALIZED
yes
Method to initialize embeddings. Values are sampled uniformly from a range [-a, a]. With NORMALIZED, a=0.5/embeddingDimension and with UNIFORM instead a=1.
iterations
Integer
1
yes
Number of training iterations.
initialLearningRate
Float
0.01
yes
Learning rate used initially for training the neural network. The learning rate decreases after each training iteration.
minLearningRate
Float
0.0001
yes
Lower bound for learning rate as it is decreased during training.
randomSeed
Integer
random
yes
Seed value used to generate the random walks, which are used as the training set of the neural network. Note, that the generated embeddings are still nondeterministic.
walkBufferSize
Integer
1000
yes
The number of random walks to complete before starting training.
Table 3. Results
Name Type Description
nodeId
Integer
The Neo4j node ID.
embedding
List of Float
The computed node embedding.
4. Examples
Consider the graph created by the following Cypher statement:
Cypher
Copy to Clipboard
CREATE (alice:Person {name: 'Alice'})
CREATE (bob:Person {name: 'Bob'})
CREATE (carol:Person {name: 'Carol'})
CREATE (dave:Person {name: 'Dave'})
CREATE (eve:Person {name: 'Eve'})
CREATE (guitar:Instrument {name: 'Guitar'})
CREATE (synth:Instrument {name: 'Synthesizer'})
CREATE (bongos:Instrument {name: 'Bongos'})
CREATE (trumpet:Instrument {name: 'Trumpet'})

CREATE (alice)-[:LIKES]->(guitar)
CREATE (alice)-[:LIKES]->(synth)
CREATE (alice)-[:LIKES]->(bongos)
CREATE (bob)-[:LIKES]->(guitar)
CREATE (bob)-[:LIKES]->(synth)
 (carol)-[:]->(bongos)
 (dave)-[:]->(guitar)
 (dave)-[:]->(synth)
 (dave)-[:]->(bongos);
View all (4 more lines)
Cypher
Copy to Clipboard
CALL gds.graph.project('myGraph', ['Person', 'Instrument'], 'LIKES');
Cypher
Run the Node2Vec algorithm on myGraph
Copy to Clipboard
CALL gds.beta.node2vec.stream('myGraph', {embeddingDimension: 2})
YIELD nodeId, embedding
RETURN nodeId, embedding
Table 10. Results
nodeId embedding
0
[-0.14295829832553864, 0.08884537220001221]
1
[0.016700705513358116, 0.2253911793231964]
2
[-0.06589698046445847, 0.042405471205711365]
3
[0.05862073227763176, 0.1193704605102539]
4
[0.10888434946537018, -0.18204474449157715]
5
[0.16728264093399048, 0.14098615944385529]
6
[-0.007779224775731564, 0.02114257402718067]
7
[-0.213893860578537, 0.06195802614092827]
8
[0.2479933649301529, -0.137322798371315]
GraphSAGE
Topological link prediction
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/machine-learning/node-embeddings/fastrp;"Fast Random Projection
Contents
1. Introduction
1.1. Node properties
1.2. Usage in machine learning pipelines
2. Tuning algorithm parameters
2.1. Embedding dimension
2.2. Normalization strength
2.3. Iteration weights
2.4. Node Self Influence
2.5. Orientation
3. Syntax
4. Examples
4.1. Memory Estimation
4.2. Stream
4.3. Stats
4.4. Mutate
4.5. Write
4.6. Weighted
4.7. Using node properties as features
Supported algorithm traits:
Directed
Undirected
Homogeneous
Heterogeneous
Weighted
1. Introduction
Fast Random Projection, or FastRP for short, is a node embedding algorithm in the family of random projection algorithms. These algorithms are theoretically backed by the Johnsson-Lindenstrauss lemma according to which one can project n vectors of arbitrary dimension into O(log(n)) dimensions and still approximately preserve pairwise distances among the points. In fact, a linear projection chosen in a random way satisfies this property.
Such techniques therefore allow for aggressive dimensionality reduction while preserving most of the distance information. The FastRP algorithm operates on graphs, in which case we care about preserving similarity between nodes and their neighbors. This means that two nodes that have similar neighborhoods should be assigned similar embedding vectors. Conversely, two nodes that are not similar should be not be assigned similar embedding vectors.
The FastRP algorithm initially assigns random vectors to all nodes using a technique called very sparse random projection, see (Achlioptas, 2003) below. Moreover, in GDS it is possible to use node properties for the creation of these initial random vectors in a way described below. We will also use projection of a node synonymously with the initial random vector of a node.
Starting with these random vectors and iteratively averaging over node neighborhoods, the algorithm constructs a sequence of intermediate embeddings for each node n. More precisely,
where m ranges over neighbors of n and is the node’s initial random vector.
The embedding of node n, which is the output of the algorithm, is a combination of the vectors and embeddings defined above:
where normalize is the function which divides a vector with its L2 norm, the value of nodeSelfInfluence is , and the values of iterationWeights are . We will return to Node Self Influence later on.
Therefore, each node’s embedding depends on a neighborhood of radius equal to the number of iterations. This way FastRP exploits higher-order relationships in the graph while still being highly scalable.
The present implementation extends the original algorithm to support weighted graphs, which computes weighted averages of neighboring embeddings using the relationship weights. In order to make use of this, the relationshipWeightProperty parameter should be set to an existing relationship property.
The original algorithm is intended only for undirected graphs. We support running on both on directed graphs and undirected graph. For directed graphs we consider only the outgoing neighbors when computing the intermediate embeddings for a node. Therefore, using the orientations NATURAL, REVERSE or UNDIRECTED will all give different embeddings. In general, it is recommended to first use UNDIRECTED as this is what the original algorithm was evaluated on.
For more information on this algorithm see:
H. Chen, S.F. Sultan, Y. Tian, M. Chen, S. Skiena: Fast and Accurate Network Embeddings via Very Sparse Random Projection, 2019.
Dimitris Achlioptas. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences, 66(4):671–687, 2003.
1.1. Node properties
Most real-world graphs contain node properties which store information about the nodes and what they represent. The FastRP algorithm in the GDS library extends the original FastRP algorithm with a capability to take node properties into account. The resulting embeddings can therefore represent the graph more accurately.
The node property aware aspect of the algorithm is configured via the parameters featureProperties and propertyRatio. Each node property in featureProperties is associated with a randomly generated vector of dimension propertyDimension, where propertyDimension = embeddingDimension * propertyRatio. Each node is then initialized with a vector of size embeddingDimension formed by concatenation of two parts:
The first part is formed like in the standard FastRP algorithm,
The second one is a linear combination of the property vectors, using the property values of the node as weights.
The algorithm then proceeds with the same logic as the FastRP algorithm. Therefore, the algorithm will output arrays of size embeddingDimension. The last propertyDimension coordinates in the embedding captures information about property values of nearby nodes (the ""property part"" below), and the remaining coordinates (embeddingDimension - propertyDimension of them; ""topology part"") captures information about nearby presence of nodes.
[0, 1, ...        | ...,   N - 1, N]
 ^^^^^^^^^^^^^^^^ | ^^^^^^^^^^^^^^^
  topology part   |  property part
                  ^
           property ratio
1.2. Usage in machine learning pipelines
It may be useful to generate node embeddings with FastRP as a node property step in a machine learning pipeline (like Link prediction pipelines and Node property prediction). Since FastRP is a random algorithm and inductive only for propertyRatio=1.0, there are some things to have in mind.
In order for a machine learning model to be able to make useful predictions, it is important that features produced during prediction are of a similar distribution to the features produced during training of the model. Moreover, node property steps (whether FastRP or not) added to a pipeline are executed both during training, and during the prediction by the trained model. It is therefore problematic when a pipeline contains an embedding step which yields all too dissimilar embeddings during training and prediction.
This has some implications on how to use FastRP as a node property step. In general, if a pipeline is trained using FastRP as a node property step on some graph ""g"", then the resulting trained model should only be applied to graphs that are not too dissimilar to ""g"".
If propertyRatio<1.0, most of the nodes in the graph that a prediction is being run on, must be the same nodes (in the database sense) as in the original graph ""g"" that was used during training. The reason for this is that FastRP is a random algorithm, and in this case is seeded based on the nodes' ids in the Neo4j database from whence the nodes came.
If propertyRatio=1.0 however, the random initial node embeddings are derived from node property vectors only, so there is no random seeding based on node ids.
Additionally, in order for the initial random vectors (independent of propertyRatio used) to be consistent between runs (training and prediction calls), a value for the randomSeed configuration parameter must be provided when adding the FastRP node property step to the training pipeline.
2. Tuning algorithm parameters
In order to improve the embedding quality using FastRP on one of your graphs, it is possible to tune the algorithm parameters. This process of finding the best parameters for your specific use case and graph is typically referred to as hyperparameter tuning. We will go through each of the configuration parameters and explain how they behave.
For statistically sound results, it is a good idea to reserve a test set excluded from parameter tuning. After selecting a set of parameter values, the embedding quality can be evaluated using a downstream machine learning task on the test set. By varying the parameter values and studying the precision of the machine learning task, it is possible to deduce the parameter values that best fit the concrete dataset and use case. To construct such a set you may want to use a dedicated node label in the graph to denote a subgraph without the test data.
2.1. Embedding dimension
The embedding dimension is the length of the produced vectors. A greater dimension offers a greater precision, but is more costly to operate over.
The optimal embedding dimension depends on the number of nodes in the graph. Since the amount of information the embedding can encode is limited by its dimension, a larger graph will tend to require a greater embedding dimension. A typical value is a power of two in the range 128 - 1024. A value of at least 256 gives good results on graphs in the order of 105 nodes, but in general increasing the dimension improves results. Increasing embedding dimension will however increase memory requirements and runtime linearly.
2.2. Normalization strength
The normalization strength is used to control how node degrees influence the embedding. Using a negative value will downplay the importance of high degree neighbors, while a positive value will instead increase their importance. The optimal normalization strength depends on the graph and on the task that the embeddings will be used for. In the original paper, hyperparameter tuning was done in the range of [-1,0] (no positive values), but we have found cases where a positive normalization strengths gives better results.
2.3. Iteration weights
The iteration weights parameter control two aspects: the number of iterations, and their relative impact on the final node embedding. The parameter is a list of numbers, indicating one iteration per number where the number is the weight applied to that iteration.
In each iteration, the algorithm will expand across all relationships in the graph. This has some implications:
With a single iteration, only direct neighbors will be considered for each node embedding.
With two iterations, direct neighbors and second-degree neighbors will be considered for each node embedding.
With three iterations, direct neighbors, second-degree neighbors, and third-degree neighbors will be considered for each node embedding. Direct neighbors may be reached twice, in different iterations.
In general, the embedding corresponding to the i:th iteration contains features depending on nodes reachable with paths of length i. If the graph is undirected, then a node reachable with a path of length L can also be reached with length L+2k, for any integer k.
In particular, a node may reach back to itself on each even iteration (depending on the direction in the graph).
It is good to have at least one non-zero weight in an even and in an odd position. Typically, using at least a few iterations, for example three, is recommended. However, a too high value will consider nodes far away and may not be informative or even be detrimental. The intuition here is that as the projections reach further away from the node, the less specific the neighborhood becomes. Of course, a greater number of iterations will also take more time to complete.
2.4. Node Self Influence
Node Self Influence is a variation of the original FastRP algorithm.
How much a node’s embedding is affected by the intermediate embedding at iteration i is controlled by the i'th element of iterationWeights. This can also be seen as how much the initial random vectors, or projections, of nodes that can be reached in i hops from a node affect the embedding of the node. Similarly, nodeSelfInfluence behaves like an iteration weight for a 0 th iteration, or the amount of influence the projection of a node has on the embedding of the same node.
A reason for setting this parameter to a non-zero value is if your graph has low connectivity or a significant amount of isolated nodes. Isolated nodes combined with using propertyRatio = 0.0 leads to embeddings that contain all zeros. However using node properties along with node self influence can thus produce more meaningful embeddings for such nodes. This can be seen as producing fallback features when graph structure is (locally) missing. Moreover, sometimes a node’s own properties are simply informative features and are good to include even if connectivity is high. Finally, node self influence can be used for pure dimensionality reduction to compress node properties used for node classification.
If node properties are not used, using nodeSelfInfluence may also have a positive effect, depending on other settings and on the problem.
2.5. Orientation
Choosing the right orientation when creating the graph may have the single greatest impact. The FastRP algorithm is designed to work with undirected graphs, and we expect this to be the best in most cases. If you expect only outgoing or incoming relationships to be informative for a prediction task, then you may want to try using the orientations NATURAL or REVERSE respectively.
3. Syntax
This section covers the syntax used to execute the FastRP algorithm in each of its execution modes. We are describing the named graph variant of the syntax. To learn more about general syntax variants, see Syntax overview.
FastRP syntax per mode
Stream mode
Stats mode
Mutate mode
Write mode
Cypher
Run FastRP in stream mode on a named graph.
Copy to Clipboard
CALL gds.fastRP.stream(
  graphName: String,
  configuration: Map
) YIELD
  nodeId: Integer,
  embedding: List of Float
Table 1. Parameters
Name Type Default Optional Description
graphName
String
n/a
no
The name of a graph stored in the catalog.
configuration
Map
{}
yes
Configuration for algorithm-specifics and/or graph filtering.
Table 2. Configuration
Name Type Default Optional Description
nodeLabels
List of String
['*']
yes
Filter the named graph using the given node labels.
relationshipTypes
List of String
['*']
yes
Filter the named graph using the given relationship types.
concurrency
Integer
4
yes
The number of concurrent threads used for running the algorithm.
jobId
String
Generated internally
yes
An ID that can be provided to more easily track the algorithm’s progress.
propertyRatio
Float
0.0
yes
The desired ratio of the property embedding dimension to the total embeddingDimension. A positive value requires featureProperties to be non-empty.
featureProperties
List of String
[]
yes
The names of the node properties that should be used as input features. All property names must exist in the projected graph and be of type Float or List of Float.
embeddingDimension
Integer
n/a
no
The dimension of the computed node embeddings. Minimum value is 1.
iterationWeights
List of Float
[0.0, 1.0, 1.0]
yes
Contains a weight for each iteration. The weight controls how much the intermediate embedding from the iteration contributes to the final embedding.
nodeSelfInfluence
Float
0.0
yes
Controls for each node how much its initial random vector contributes to its final embedding.
normalizationStrength
Float
0.0
yes
The initial random vector for each node is scaled by its degree to the power of normalizationStrength.
randomSeed
Integer
n/a
yes
A random seed which is used for all randomness in computing the embeddings.
relationshipWeightProperty
String
null
yes
Name of the relationship property to use for weighted random projection. If unspecified, the algorithm runs unweighted.
The number of iterations is equal to the length of iterationWeights.
It is required that iterationWeights is non-empty or nodeSelfInfluence is non-zero.
Table 3. Results
Name Type Description
nodeId
Integer
Node ID.
embedding
List of Float
FastRP node embedding.
4. Examples
In this section we will show examples of running the FastRP node embedding algorithm on a concrete graph. The intention is to illustrate what the results look like and to provide a guide in how to make use of the algorithm in a real setting. We will do this on a small social network graph of a handful nodes connected in a particular pattern. The example graph looks like this:
Cypher
The following Cypher statement will create the example graph in the Neo4j database:
Copy to Clipboard
CREATE
  (dan:Person {name: 'Dan', age: 18}),
  (annie:Person {name: 'Annie', age: 12}),
  (matt:Person {name: 'Matt', age: 22}),
  (jeff:Person {name: 'Jeff', age: 51}),
  (brie:Person {name: 'Brie', age: 45}),
  (elsa:Person {name: 'Elsa', age: 65}),
  (john:Person {name: 'John', age: 64}),

  (dan)-[:KNOWS {weight: 1.0}]->(annie),
  (dan)-[:KNOWS {weight: 1.0}]->(matt),
  (annie)-[:KNOWS {weight: 1.0}]->(matt),
  (annie)-[:KNOWS {weight: 1.0}]->(jeff),
  (annie)-[:KNOWS {weight: 1.0}]->(brie),
  (matt)-[:KNOWS {weight: 3.5}]->(brie),
  (brie)-[:KNOWS {weight: 1.0}]->(elsa),
  (brie)-[:KNOWS {weight: 2.0}]->(jeff),
  (john)-[:KNOWS {weight: 1.0}]->(jeff);
This graph represents seven people who know one another. A relationship property weight denotes the strength of the knowledge between two persons.
With the graph in Neo4j we can now project it into the graph catalog to prepare it for algorithm execution. We do this using a native projection targeting the Person nodes and the KNOWS relationships. For the relationships we will use the UNDIRECTED orientation. This is because the FastRP algorithm has been measured to compute more predictive node embeddings in undirected graphs. We will also add the weight relationship property which we will make use of when running the weighted version of FastRP.
In the examples below we will use named graphs and native projections as the norm. However, Cypher projections can also be used.
Cypher
The following statement will project a graph using a native projection and store it in the graph catalog under the name 'persons'.
Copy to Clipboard
CALL gds.graph.project(
  'persons',
  'Person',
  {
    KNOWS: {
      orientation: 'UNDIRECTED',
      properties: 'weight'
    }
  },
  { nodeProperties: ['age'] }
)
4.1. Memory Estimation
First off, we will estimate the cost of running the algorithm using the estimate procedure. This can be done with any execution mode. We will use the stream mode in this example. Estimating the algorithm is useful to understand the memory impact that running the algorithm on your graph will have. When you later actually run the algorithm in one of the execution modes the system will perform an estimation. If the estimation shows that there is a very high probability of the execution going over its memory limitations, the execution is prohibited. To read more about this, see Automatic estimation and execution blocking.
For more details on estimate in general, see Memory Estimation.
Cypher
The following will estimate the memory requirements for running the algorithm:
Copy to Clipboard
CALL gds.fastRP.stream.estimate('persons', {embeddingDimension: 128})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
Table 13. Results
nodeCount relationshipCount bytesMin bytesMax requiredMemory
7
18
11320
11320
""11320 Bytes""
4.2. Stream
In the stream execution mode, the algorithm returns the embedding for each node. This allows us to inspect the results directly or post-process them in Cypher without any side effects. For example, we can collect the results and pass them into a similarity algorithm.
For more details on the stream mode in general, see Stream.
Cypher
The following will run the algorithm, and stream results:
Copy to Clipboard
CALL gds.fastRP.stream('persons',
  {
    embeddingDimension: 4,
    randomSeed: 42
  }
)
YIELD nodeId, embedding
Table 14. Results
nodeId embedding
0
[0.4774002134799957, -0.6602408289909363, -0.36686956882476807, -1.7089111804962158]
1
[0.7989360094070435, -0.4918718934059143, -0.41281944513320923, -1.6314401626586914]
2
[0.47275322675704956, -0.49587157368659973, -0.3340468406677246, -1.7141895294189453]
3
[0.8290714025497437, -0.3260476291179657, -0.3317275643348694, -1.4370529651641846]
4
[0.7749264240264893, -0.4773247539997101, 0.0675133764743805, -1.5248265266418457]
5
[0.8408374190330505, -0.37151476740837097, 0.12121132016181946, -1.530960202217102]
6
[1.0, -0.11054422706365585, -0.3697933852672577, -0.9225144982337952]
The results of the algorithm are not very intuitively interpretable, as the node embedding format is a mathematical abstraction of the node within its neighborhood, designed for machine learning programs. What we can see is that the embeddings have four elements (as configured using embeddingDimension) and that the numbers are relatively small (they all fit in the range of [-2, 2]). The magnitude of the numbers is controlled by the embeddingDimension, the number of nodes in the graph, and by the fact that FastRP performs euclidean normalization on the intermediate embedding vectors.
Due to the random nature of the algorithm the results will vary between the runs. However, this does not necessarily mean that the pairwise distances of two node embeddings vary as much.
4.3. Stats
In the stats execution mode, the algorithm returns a single row containing a summary of the algorithm result. This execution mode does not have any side effects. It can be useful for evaluating algorithm performance by inspecting the computeMillis return item. In the examples below we will omit returning the timings. The full signature of the procedure can be found in the syntax section.
For more details on the stats mode in general, see Stats.
Cypher
The following will run the algorithm and returns the result in form of statistical and measurement values
Copy to Clipboard
CALL gds.fastRP.stats('persons', { embeddingDimension: 8 })
YIELD nodeCount
Table 15. Results
nodeCount
7
The stats mode does not currently offer any statistical results for the embeddings themselves. We can however see that the algorithm has successfully processed all seven nodes in our example graph.
4.4. Mutate
The mutate execution mode extends the stats mode with an important side effect: updating the named graph with a new node property containing the embedding for that node. The name of the new property is specified using the mandatory configuration parameter mutateProperty. The result is a single summary row, similar to stats, but with some additional metrics. The mutate mode is especially useful when multiple algorithms are used in conjunction.
For more details on the mutate mode in general, see Mutate.
Cypher
The following will run the algorithm in mutate mode:
Copy to Clipboard
CALL gds.fastRP.mutate(
  'persons',
  {
    embeddingDimension: 8,
    mutateProperty: 'fastrp-embedding'
  }
)
YIELD nodePropertiesWritten
Table 16. Results
nodePropertiesWritten
7
The returned result is similar to the stats example. Additionally, the graph 'persons' now has a node property fastrp-embedding which stores the node embedding for each node. To find out how to inspect the new schema of the in-memory graph, see Listing graphs.
4.5. Write
The write execution mode extends the stats mode with an important side effect: writing the embedding for each node as a property to the Neo4j database. The name of the new property is specified using the mandatory configuration parameter writeProperty. The result is a single summary row, similar to stats, but with some additional metrics. The write mode enables directly persisting the results to the database.
For more details on the write mode in general, see Write.
Cypher
The following will run the algorithm in write mode:
Copy to Clipboard
CALL gds.fastRP.write(
  'persons',
  {
    embeddingDimension: 8,
    writeProperty: 'fastrp-embedding'
  }
)
YIELD nodePropertiesWritten
Table 17. Results
nodePropertiesWritten
7
The returned result is similar to the stats example. Additionally, each of the seven nodes now has a new property fastrp-embedding in the Neo4j database, containing the node embedding for that node.
4.6. Weighted
By default, the algorithm is considering the relationships of the graph to be unweighted. To change this behaviour we can use configuration parameter called relationshipWeightProperty. Below is an example of running the weighted variant of algorithm.
Cypher
The following will run the algorithm, and stream results:
Copy to Clipboard
CALL gds.fastRP.stream(
  'persons',
  {
    embeddingDimension: 4,
    randomSeed: 42,
    relationshipWeightProperty: 'weight'
  }
)
YIELD nodeId, embedding
Table 18. Results
nodeId embedding
0
[0.10945529490709305, -0.5032674074172974, 0.464673787355423, -1.7539862394332886]
1
[0.3639600872993469, -0.39210301637649536, 0.46271592378616333, -1.829423427581787]
2
[0.12314096093177795, -0.3213110864162445, 0.40100979804992676, -1.471055269241333]
3
[0.30704641342163086, -0.24944794178009033, 0.3947891891002655, -1.3463698625564575]
4
[0.23112300038337708, -0.30148714780807495, 0.584831714630127, -1.2822188138961792]
5
[0.14497177302837372, -0.2312137484550476, 0.5552002191543579, -1.2605633735656738]
6
[0.5139184594154358, -0.07954332232475281, 0.3690345287322998, -0.9176374077796936]
Since the initial state of the algorithm is randomised, it isn’t possible to intuitively analyse the effect of the relationship weights.
4.7. Using node properties as features
To explain the novel initialization using node properties, let us consider an example where embeddingDimension is 10, propertyRatio is 0.2. The dimension of the embedded properties, propertyDimension is thus 2. Assume we have a property f1 of scalar type, and a property f2 storing arrays of length 2. This means that there are 3 features which we order like f1 followed by the two values of f2. For each of these three features we sample a two dimensional random vector. Let’s say these are p1=[0.0, 2.4], p2=[-2.4, 0.0] and p3=[2.4, 0.0]. Consider now a node (n {f1: 0.5, f2: [1.0, -1.0]}). The linear combination mentioned above, is in concrete terms 0.5 * p1 + 1.0 * p2 - 1.0 * p3 = [-4.8, 1.2]. The initial random vector for the node n contains first 8 values sampled as in the original FastRP paper, and then our computed values -4.8 and 1.2, totalling 10 entries.
In the example below, we again set the embedding dimension to 2, but we set propertyRatio to 1, which means the embedding is computed from node properties only.
Cypher
The following will run FastRP with feature properties:
Copy to Clipboard
CALL gds.fastRP.stream('persons', {
    randomSeed: 42,
    embeddingDimension: 2,
    propertyRatio: 1.0,
    featureProperties: ['age'],
    iterationWeights: [1.0]
}) YIELD nodeId, embedding
Table 19. Results
nodeId embedding
0
[0.0, -1.0]
1
[0.0, -1.0]
2
[0.0, -0.9999999403953552]
3
[0.0, -1.0]
4
[0.0, -0.9999999403953552]
5
[0.0, -1.0]
6
[0.0, -1.0]
In this example, the embeddings are based on the age property. Because of L2 normalization which is applied to each iteration (here only one iteration), all nodes have the same embedding despite having different age values (apart from rounding errors).
Node embeddings
GraphSAGE
Was this page helpful?"
https://neo4j.com/docs/graph-data-science/current/algorithms/astar;"A* Shortest Path
Contents
1. Introduction
2. Requirements
3. Syntax
4. Examples
4.1. Memory Estimation
4.2. Stream
4.3. Mutate
4.4. Write
Supported algorithm traits:
Directed
Undirected
Homogeneous
Heterogeneous
Weighted
1. Introduction
The A* (pronounced ""A-Star"") Shortest Path algorithm computes the shortest path between two nodes. A* is an informed search algorithm as it uses a heuristic function to guide the graph traversal. The algorithm supports weighted graphs with positive relationship weights.
Unlike Dijkstra’s shortest path algorithm, the next node to search from is not solely picked on the already computed distance. Instead, the algorithm combines the already computed distance with the result of a heuristic function. That function takes a node as input and returns a value that corresponds to the cost to reach the target node from that node. In each iteration, the graph traversal is continued from the node with the lowest combined cost.
In GDS, the A* algorithm is based on the Dijkstra’s shortest path algorithm. The heuristic function is the haversine distance, which defines the distance between two points on a sphere. Here, the sphere is the earth and the points are geo-coordinates stored on the nodes in the graph.
The algorithm implementation is executed using a single thread. Altering the concurrency configuration has no effect.
2. Requirements
In GDS, the heuristic function used to guide the search is the haversine formula. The formula computes the distance between two points on a sphere given their longitudes and latitudes. The distance is computed in nautical miles.
In order to guarantee finding the optimal solution, i.e., the shortest path between two points, the heuristic must be admissible. To be admissible, the function must not overestimate the distance to the target, i.e., the lowest possible cost of a path must always be greater or equal to the heuristic.
This leads to a requirement on the relationship weights of the input graph. Relationship weights must represent the distance between two nodes and ideally scaled to nautical miles. Kilometers or miles also work, but the heuristic works best for nautical miles.
3. Syntax
This section covers the syntax used to execute the A* algorithm in each of its execution modes. We are describing the named graph variant of the syntax. To learn more about general syntax variants, see Syntax overview.
A* syntax per mode
Stream mode
Mutate mode
Write mode
Cypher
Run A* in stream mode on a named graph.
Copy to Clipboard
CALL gds.shortestPath.astar.stream(
  graphName: String,
  configuration: Map
)
YIELD
  index: Integer,
  sourceNode: Integer,
  targetNode: Integer,
  totalCost: Float,
  nodeIds: List of Integer,
  costs: List of Float,
  path: Path
Table 1. Parameters
Name Type Default Optional Description
graphName
String
n/a
no
The name of a graph stored in the catalog.
configuration
Map
{}
yes
Configuration for algorithm-specifics and/or graph filtering.
Table 2. Configuration
Name Type Default Optional Description
nodeLabels
List of String
['*']
yes
Filter the named graph using the given node labels.
relationshipTypes
List of String
['*']
yes
Filter the named graph using the given relationship types.
concurrency
Integer
4
yes
The number of concurrent threads used for running the algorithm.
jobId
String
Generated internally
yes
An ID that can be provided to more easily track the algorithm’s progress.
sourceNode
Integer
n/a
no
The Neo4j source node or node id.
targetNode
Integer
n/a
no
The Neo4j target node or node id.
latitudeProperty
Float
n/a
no
The node property that stores the latitude value.
longitudeProperty
Float
n/a
no
The node property that stores the longitude value.
relationshipWeightProperty
String
null
yes
Name of the relationship property to use as weights. If unspecified, the algorithm runs unweighted.
Table 3. Results
Name Type Description
index
Integer
0-based index of the found path.
sourceNode
Integer
Source node of the path.
targetNode
Integer
Target node of the path.
totalCost
Float
Total cost from source to target.
nodeIds
List of Integer
Node ids on the path in traversal order.
costs
List of Float
Accumulated costs for each node on the path.
path
Path
The path represented as Cypher entity.
4. Examples
In this section we will show examples of running the A* algorithm on a concrete graph. The intention is to illustrate what the results look like and to provide a guide in how to make use of the algorithm in a real setting. We will do this on a small transport network graph of a handful nodes connected in a particular pattern. The example graph looks like this:
Cypher
The following Cypher statement will create the example graph in the Neo4j database:
Copy to Clipboard
CREATE (a:Station {name: 'Kings Cross',         latitude: 51.5308, longitude: -0.1238}),
       (b:Station {name: 'Euston',              latitude: 51.5282, longitude: -0.1337}),
       (c:Station {name: 'Camden Town',         latitude: 51.5392, longitude: -0.1426}),
       (d:Station {name: 'Mornington Crescent', latitude: 51.5342, longitude: -0.1387}),
       (e:Station {name: 'Kentish Town',        latitude: 51.5507, longitude: -0.1402}),
       (a)-[:CONNECTION {distance: 0.7}]->(b),
       (b)-[:CONNECTION {distance: 1.3}]->(c),
       (b)-[:CONNECTION {distance: 0.7}]->(d),
       (d)-[:CONNECTION {distance: 0.6}]->(c),
       (c)-[:CONNECTION {distance: 1.3}]->(e)
The graph represents a transport network of stations. Each station has a geo-coordinate, expressed by latitude and longitude properties. Stations are connected via connections. We use the distance property as relationship weight which represents the distance between stations in kilometers. The algorithm will pick the next node in the search based on the already traveled distance and the distance to the target station.
In the examples below we will use named graphs and native projections as the norm. However, Cypher projections can also be used.
Cypher
The following statement will project a graph using a native projection and store it in the graph catalog under the name 'myGraph'.
Copy to Clipboard
CALL gds.graph.project(
    'myGraph',
    'Station',
    'CONNECTION',
    {
        nodeProperties: ['latitude', 'longitude'],
        relationshipProperties: 'distance'
    }
)
In the following example we will demonstrate the use of the A* Shortest Path algorithm using this graph.
4.1. Memory Estimation
First off, we will estimate the cost of running the algorithm using the estimate procedure. This can be done with any execution mode. We will use the write mode in this example. Estimating the algorithm is useful to understand the memory impact that running the algorithm on your graph will have. When you later actually run the algorithm in one of the execution modes the system will perform an estimation. If the estimation shows that there is a very high probability of the execution going over its memory limitations, the execution is prohibited. To read more about this, see Automatic estimation and execution blocking.
For more details on estimate in general, see Memory Estimation.
Cypher
The following will estimate the memory requirements for running the algorithm in write mode:
Copy to Clipboard
MATCH (source:Station {name: 'Kings Cross'}), (target:Station {name: 'Kentish Town'})
CALL gds.shortestPath.astar.write.estimate('myGraph', {
    sourceNode: source,
    targetNode: target,
    latitudeProperty: 'latitude',
    longitudeProperty: 'longitude',
    writeRelationshipType: 'PATH'
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
RETURN nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
Table 10. Results
nodeCount relationshipCount bytesMin bytesMax requiredMemory
5
5
984
984
""984 Bytes""
4.2. Stream
In the stream execution mode, the algorithm returns the shortest path for each source-target-pair. This allows us to inspect the results directly or post-process them in Cypher without any side effects.
For more details on the stream mode in general, see Stream.
Cypher
The following will run the algorithm and stream results:
Copy to Clipboard
MATCH (source:Station {name: 'Kings Cross'}), (target:Station {name: 'Kentish Town'})
CALL gds.shortestPath.astar.stream('myGraph', {
    sourceNode: source,
    targetNode: target,
    latitudeProperty: 'latitude',
    longitudeProperty: 'longitude',
    relationshipWeightProperty: 'distance'
})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
RETURN
    index,
    gds.util.asNode(sourceNode).name AS sourceNodeName,
    gds.util.asNode(targetNode).name AS targetNodeName,
    totalCost,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).name] AS nodeNames,
    costs,  path
  
View all (3 more lines)
Table 11. Results
index sourceNodeName targetNodeName totalCost nodeNames costs path
0
""Kings Cross""
""Kentish Town""
3.3
[Kings Cross, Euston, Camden Town, Kentish Town]
[0.0, 0.7, 2.0, 3.3]
[Node[0], Node[1], Node[2], Node[4]]
The result shows the total cost of the shortest path between node King’s Cross and Kentish Town in the graph. It also shows ordered lists of node ids that were traversed to find the shortest paths as well as the accumulated costs of the visited nodes. This can be verified in the example graph. Cypher Path objects can be returned by the path return field. The Path objects contain the node objects and virtual relationships which have a cost property.
4.3. Mutate
The mutate execution mode updates the named graph with new relationships. Each new relationship represents a path from source node to target node. The relationship type is configured using the mutateRelationshipType option. The total path cost is stored using the totalCost property.
The mutate mode is especially useful when multiple algorithms are used in conjunction.
For more details on the mutate mode in general, see Mutate.
Cypher
The following will run the algorithm in mutate mode:
Copy to Clipboard
MATCH (source:Station {name: 'Kings Cross'}), (target:Station {name: 'Kentish Town'})
CALL gds.shortestPath.astar.mutate('myGraph', {
    sourceNode: source,
    targetNode: target,
    latitudeProperty: 'latitude',
    longitudeProperty: 'longitude',
    relationshipWeightProperty: 'distance',
    mutateRelationshipType: 'PATH'
})
YIELD relationshipsWritten
RETURN relationshipsWritten
Table 12. Results
relationshipsWritten
1
After executing the above query, the in-memory graph will be updated with new relationships of type PATH. The new relationships will store a single property totalCost.
The relationship produced is always directed, even if the input graph is undirected.
4.4. Write
The write execution mode updates the Neo4j database with new relationships. Each new relationship represents a path from source node to target node. The relationship type is configured using the writeRelationshipType option. The total path cost is stored using the totalCost property. The intermediate node ids are stored using the nodeIds property. The accumulated costs to reach an intermediate node are stored using the costs property.
For more details on the write mode in general, see Write.
Cypher
The following will run the algorithm in write mode:
Copy to Clipboard
MATCH (source:Station {name: 'Kings Cross'}), (target:Station {name: 'Kentish Town'})
CALL gds.shortestPath.astar.write('myGraph', {
    sourceNode: source,
    targetNode: target,
    latitudeProperty: 'latitude',
    longitudeProperty: 'longitude',
    relationshipWeightProperty: 'distance',
    writeRelationshipType: 'PATH',
    writeNodeIds: true,
    writeCosts: true
})
YIELD relationshipsWritten
RETURN relationshipsWritten
Table 13. Results
relationshipsWritten
1
The above query will write one relationship of type PATH back to Neo4j. The relationship stores three properties describing the path: totalCost, nodeIds and costs.
The relationship written is always directed, even if the input graph is undirected.
Dijkstra Single-Source Shortest Path
Yen’s algorithm Shortest Path
Was this page helpful?"
https://neo4j.com/docs/apoc/5/virtual/nodes-collapse;"Collapse Nodes
Contents
Config:
Nodes collapse example
Qualified Name Type
apoc.nodes.collapse
apoc.nodes.collapse([nodes…],[{properties:'overwrite' or 'discard' or 'combine'}]) yield from, rel, to merge nodes onto first in list
Procedure
Config:
On apoc.nodes.collapse with config properties you can choose from 3 different behavior:
""properties"": ""overwrite"" : if there is the same property in more node, in the new one will have the last relationship’s/node’s property value
""properties"": ""discard"" : if there is the same property in more node, the new one will have the first relationship’s/node’s property value
""properties"": ""combine"" : if there is the same property in more node, the new one a value’s array with all relationship’s/node’s values
If properties parameter isn’t set relationships properties are discard.
""mergeRelsVirtual: true/false"" : give the possibility to merge relationships with same type and direction. (DEFAULT true)
""selfRel: true/false"" : give the possibility to create the self relationship. (DEFAULT false)
""countMerge: true/false"" : give the possibility count all the Nodes/Relationships merged. (DEFAULT true)
""collapsedLabel: true/false"" : give the possibility to add the label :Collapsed to the virtualNode. (DEFAULT false)
Nodes collapse example
With this dataset we have:
If we want to collapse the people living in the city to a single node, we pass them to the procedure.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:LIVES_IN]->(c:City)
WITH c, collect(p) as subgraph
CALL apoc.nodes.collapse(subgraph,{properties:'combine'}) yield from, rel, to
return from, rel, to
And get this result:
With this dataset we have:
If we also want to collapse them onto the city itself, we add the city node first to the collection.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (p:Person)-[:LIVES_IN]->(c:City)
WITH c, c + collect(p) as subgraph
CALL apoc.nodes.collapse(subgraph) yield from, rel, to
return from, rel, to
And get this result:
Virtual Nodes/Rels
Virtual Graph
Was this page helpful?"
https://neo4j.com/docs/apoc/5/cypher-execution/conditionals;"Conditional Cypher Execution
Contents
Procedure and Function Overview
WHEN Procedures
CASE Procedures
Queries occasionally require conditional execution logic which cannot be adequately expressed in Cypher. The conditional execution procedures simulate an if / else structure, where a supplied boolean condition determines which cypher query is executed.
Procedure and Function Overview
The available procedures and functions are described below:
Qualified Name Type
apoc.when
apoc.when(condition, ifQuery, elseQuery:'', params:{}) yield value - based on the conditional, executes read-only ifQuery or elseQuery with the given parameters
Procedure
apoc.do.when
apoc.do.when(condition, ifQuery, elseQuery:'', params:{}) yield value - based on the conditional, executes writing ifQuery or elseQuery with the given parameters
Procedure
apoc.case
apoc.case([condition, query, condition, query, …], elseQuery:'', params:{}) yield value - given a list of conditional / read-only query pairs, executes the query associated with the first conditional evaluating to true (or the else query if none are true) with the given parameters
Procedure
apoc.do.case
apoc.do.case([condition, query, condition, query, …], elseQuery:'', params:{}) yield value - given a list of conditional / writing query pairs, executes the query associated with the first conditional evaluating to true (or the else query if none are true) with the given parameters
Procedure
WHEN Procedures
For if / else conditional logic, when procedures allow an ifQuery and elseQuery to be specified. If the conditional is true, the ifQuery will be run, and if not the elseQuery will be run.
signature
apoc.when(condition :: BOOLEAN?, ifQuery :: STRING?, elseQuery = :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
apoc.do.when(condition :: BOOLEAN?, ifQuery :: STRING?, elseQuery = :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Cypher
Read only
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.when(
  condition: Boolean,
  ifQuery: String,
  elseQuery: String,
  params: Map)
YIELD value
Cypher
Write
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.when(
  condition: Boolean,
  ifQuery: String,
  elseQuery: String,
  params: Map)
YIELD value
For example, to match neighbor nodes one and two traversals away from a start node, and return a smaller set (either those one traversal away, or those that are two traversals away), run the following query:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (start:Node)-[:REL]->(a)-[:REL]->(b)
WITH collect(distinct a) as aNodes, collect(distinct b) as bNodes

CALL apoc.when(
  size(aNodes) <= size(bNodes),
  'RETURN aNodes as resultNodes',
  'RETURN bNodes as resultNodes',
  {aNodes:aNodes, bNodes:bNodes})
YIELD value

RETURN value.resultNodes as resultNodes
To conditionally set or create graph elements in cases where an account could be considered suspicious (while continuing with other query operations), use the procedure apoc.do.when.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (acc:Account)
OPTIONAL MATCH (acc)-[r:ACCESSED_BY]->(suspect:User)
WHERE suspect.id in {suspiciousUsersIdList}

CALL apoc.do.when(
  r IS NOT NULL,
  'SET acc:Suspicious',
  '',
  {acc:acc})
YIELD value

// ignore value and continue
WITH acc
...
CASE Procedures
For more complex conditional logic, case procedures allow for a variable-length list of condition / query pairs, where the query following the first conditional evaluating to true is executed. An elseQuery block is executed if none of the conditionals are true.
signature
apoc.case(conditionals :: LIST? OF ANY?, elseQuery = :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
apoc.do.case(conditionals :: LIST? OF ANY?, elseQuery = :: STRING?, params = {} :: MAP?) :: (value :: MAP?)
Cypher
Read only
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.case(
  conditionals: List of alternating Boolean/String,
  elseQuery: String,
  params: Map)
YIELD value
Cypher
Write
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.do.case(
  conditionals: List of alternating Boolean/String,
  elseQuery: String,
  params: Map)
YIELD value
To MATCH selection nodes in a column, it is possible to use different MATCH clauses depending on the query parameters, or the data already in the graph.
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:User {id:$myId})
CALL apoc.case([
  $selection = 'friends', ""RETURN [(me)-[:FRIENDS]-(friend) | friend] as selection"",
  $selection = 'coworkers', ""RETURN [(me)-[:WORKS_AT*2]-(coworker) | coworker] as selection"",
  $selection = 'all', ""RETURN apoc.coll.union([(me)-[:FRIENDS]-(friend) | friend], [(me)-[:WORKS_AT*2]-(coworker) | coworker]) as selection""],
  'RETURN [] as selection',
  {me:me}
)
YIELD value
RETURN value.selection as selection;
To create different relationship types between two nodes based on a value, run the following statement:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (me:User {id:$myId})
MATCH (friend:User {id:$friendId})
CALL apoc.do.case([
  $selection = 'friends', ""MERGE (me)-[rel:FRIENDS]->(friend) RETURN rel"",
  $selection = 'coworkers', ""MERGE (me)-[rel:CO_WORKER]->(friend) RETURN rel""],
  'MERGE (me)-[rel:CONNECTED]->(friend) RETURN rel',
  {me:me, friend:friend}
)
YIELD value
RETURN value.rel as rel;
Running Cypher fragments
Timeboxed Cypher statements
Was this page helpful?"
https://neo4j.com/docs/apoc/5/cypher-execution/running-cypher;"Running Cypher fragments
Contents
Procedure Overview
Example: Fast Node-Counts by Label
Cypher can be used as a safe, graph-aware, partially compiled scripting language within APOC.
Procedure Overview
The supported procedures are described in the table below:
Qualified Name Type
apoc.cypher.doIt
apoc.cypher.doIt(fragment, params) yield value - executes writing fragment with the given parameters
Procedure
apoc.cypher.run
apoc.cypher.run(fragment, params) yield value - executes reading fragment with the given parameters
Procedure
apoc.cypher.runMany
apoc.cypher.runMany('cypher;\nstatements;',{params},[{statistics:true,timeout:10}]) - runs each semicolon separated statement and returns summary
Procedure
apoc.cypher.runFirstColumnMany
apoc.cypher.runFirstColumnMany(statement, params) - executes statement with given parameters, returns first column only collected into a list, params are available as identifiers
Function
apoc.cypher.runFirstColumnSingle
apoc.cypher.runFirstColumnSingle(statement, params) - executes statement with given parameters, returns first element of the first column only, params are available as identifiers
Function
Example: Fast Node-Counts by Label
It is possible to quickly compute the number of nodes for a specific label using the count function, but only if the query is limited to containing the count function. For example:
Cypher
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person) RETURN count(*);
It is also possible to combine several computations of nodes related to a specific label using the UNION ALL clause:
Cypher
Works
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person) RETURN count(*)
UNION ALL
MATCH (:Movie) RETURN count(*);
The same is not possible using the WITH clause:
Cypher
Doesn’t work
Copy to Clipboard
Run in Neo4j Browser
MATCH (:Person)
WITH count(*) as people
MATCH (:Movie) RETURN people, count(*) as movies;
This query will work out the count by iterating over all nodes, which is a very slow operation.
For a much faster process (completed in a few milliseconds), apoc.cypher.run can be used to construct the COUNT() statements and run each of them individually.
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels() yield label
CALL apoc.cypher.run(""match (:`""+label+""`) return count(*) as count"", null) yield value
return label, value.count as count
A similar approach can be used to get the property-keys for each label:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL db.labels() yield label
CALL apoc.cypher.run(""MATCH (n:`""+label+""`) RETURN keys(n) as keys LIMIT 1"",null) yield value
RETURN label, value.keys as keys
Cypher Execution
Conditional Cypher Execution
Was this page helpful?"
https://neo4j.com/docs/apoc/5/cypher-execution/cypher-timeboxed;"Timeboxed Cypher statements
To terminate a cypher statement if it exceeds a given time threshold, use the apoc.cypher.runTimeboxed procedure. The below example calculates the cross product of shortestpaths for each pair of nodes:
Cypher
Copy to Clipboard
Run in Neo4j Browser
CALL apoc.cypher.runTimeboxed(
  ""match (n),(m) match p=shortestPath((n)-[*]-(m)) return p"",
  null,
  10000
)
YIELD value
RETURN value.p
This will return all results computed within 10000 milliseconds. The statement will be terminated after that period.
Conditional Cypher Execution
Run multiple Statements
Was this page helpful?"
